{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luficerg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "  \n",
    "  #print(w)\n",
    "  context = [0] * block_size\n",
    "\n",
    "  for ch in w + '.':\n",
    "    ix = stoi[ch]\n",
    "    X.append(context)\n",
    "    Y.append(ix)\n",
    "    # print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "    context = context[1:] + [ix] # crop and append\n",
    "  \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5069,  0.1214],\n",
       "        [-0.5469,  0.3503],\n",
       "        [-0.3057, -1.0968],\n",
       "        [-0.5457, -1.5804],\n",
       "        [ 0.6202,  1.2121],\n",
       "        [ 0.5576,  1.5346],\n",
       "        [ 1.1950, -2.5067],\n",
       "        [ 1.5203,  2.3033],\n",
       "        [-0.4379, -1.6889],\n",
       "        [-0.3772, -0.1584],\n",
       "        [ 0.7890,  0.5660],\n",
       "        [ 0.3302, -1.8315],\n",
       "        [-0.7021, -0.0695],\n",
       "        [ 0.1654, -0.0200],\n",
       "        [-0.3235,  0.9381],\n",
       "        [-0.5067,  0.0744],\n",
       "        [ 0.3372, -0.9517],\n",
       "        [ 1.0044, -0.4492],\n",
       "        [ 1.6216,  1.0449],\n",
       "        [-0.1106, -0.1492],\n",
       "        [-1.1735, -2.2405],\n",
       "        [ 0.5109,  0.9723],\n",
       "        [ 2.0844, -1.5946],\n",
       "        [ 0.3786,  0.4059],\n",
       "        [-0.3963, -0.0697],\n",
       "        [ 0.6422,  1.4050],\n",
       "        [-0.9918,  0.7051]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((27, 2))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.5389)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(prob.shape[0]), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ now made respectable :) ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182580, 3]) torch.Size([182580])\n",
      "torch.Size([22767, 3]) torch.Size([22767])\n",
      "torch.Size([22799, 3]) torch.Size([22799])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  for w in words:\n",
    "\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([182580, 3]), torch.Size([182580]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape, Ytr.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((27, 10), generator=g)\n",
    "W1 = torch.randn((30, 200), generator=g)\n",
    "b1 = torch.randn(200, generator=g)\n",
    "W2 = torch.randn((200, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11897"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26.0047, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr]\n",
    "logits = (torch.tanh_(emb.view(-1, 30) @ W1 + b1)) @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 55712, 100535, 111758,  87783,  92264,  31167, 158367, 164223,  87661,\n",
       "         94584, 156825,   4134,  54052,  59635,  41654, 147704,  15525, 130145,\n",
       "          5552,  18572, 150540,  58973, 142533,  12006, 152782, 127836,  62508,\n",
       "        140642,  43721, 152806,   7628, 113359])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, Xtr.shape[0], (32,)) # Taking 32 random example from training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at Iteration @ 0 is 10.629242897033691\n",
      "Loss at Iteration @ 1 is 6.365262508392334\n",
      "Loss at Iteration @ 2 is 9.430753707885742\n",
      "Loss at Iteration @ 3 is 8.629942893981934\n",
      "Loss at Iteration @ 4 is 8.548637390136719\n",
      "Loss at Iteration @ 5 is 8.12479305267334\n",
      "Loss at Iteration @ 6 is 7.364710807800293\n",
      "Loss at Iteration @ 7 is 9.802048683166504\n",
      "Loss at Iteration @ 8 is 8.362715721130371\n",
      "Loss at Iteration @ 9 is 7.81827974319458\n",
      "Loss at Iteration @ 10 is 8.364578247070312\n",
      "Loss at Iteration @ 11 is 8.34182071685791\n",
      "Loss at Iteration @ 12 is 6.344183921813965\n",
      "Loss at Iteration @ 13 is 7.007071018218994\n",
      "Loss at Iteration @ 14 is 7.5287699699401855\n",
      "Loss at Iteration @ 15 is 8.050920486450195\n",
      "Loss at Iteration @ 16 is 7.217986106872559\n",
      "Loss at Iteration @ 17 is 6.136111736297607\n",
      "Loss at Iteration @ 18 is 5.680299282073975\n",
      "Loss at Iteration @ 19 is 8.09614372253418\n",
      "Loss at Iteration @ 20 is 7.805634498596191\n",
      "Loss at Iteration @ 21 is 8.265605926513672\n",
      "Loss at Iteration @ 22 is 7.56301736831665\n",
      "Loss at Iteration @ 23 is 10.276898384094238\n",
      "Loss at Iteration @ 24 is 7.2278265953063965\n",
      "Loss at Iteration @ 25 is 6.761032581329346\n",
      "Loss at Iteration @ 26 is 5.309166431427002\n",
      "Loss at Iteration @ 27 is 5.609730243682861\n",
      "Loss at Iteration @ 28 is 8.069622039794922\n",
      "Loss at Iteration @ 29 is 11.301630973815918\n",
      "Loss at Iteration @ 30 is 7.759653091430664\n",
      "Loss at Iteration @ 31 is 8.695096969604492\n",
      "Loss at Iteration @ 32 is 5.820266246795654\n",
      "Loss at Iteration @ 33 is 8.507351875305176\n",
      "Loss at Iteration @ 34 is 5.954478740692139\n",
      "Loss at Iteration @ 35 is 4.129787921905518\n",
      "Loss at Iteration @ 36 is 5.849157810211182\n",
      "Loss at Iteration @ 37 is 9.208613395690918\n",
      "Loss at Iteration @ 38 is 7.9472150802612305\n",
      "Loss at Iteration @ 39 is 7.681734085083008\n",
      "Loss at Iteration @ 40 is 7.467021465301514\n",
      "Loss at Iteration @ 41 is 7.479593276977539\n",
      "Loss at Iteration @ 42 is 7.316748142242432\n",
      "Loss at Iteration @ 43 is 6.409648418426514\n",
      "Loss at Iteration @ 44 is 5.850304126739502\n",
      "Loss at Iteration @ 45 is 7.693133354187012\n",
      "Loss at Iteration @ 46 is 8.043794631958008\n",
      "Loss at Iteration @ 47 is 4.730765342712402\n",
      "Loss at Iteration @ 48 is 5.475891590118408\n",
      "Loss at Iteration @ 49 is 7.52886962890625\n",
      "Loss at Iteration @ 50 is 6.724172115325928\n",
      "Loss at Iteration @ 51 is 7.513267517089844\n",
      "Loss at Iteration @ 52 is 6.509867191314697\n",
      "Loss at Iteration @ 53 is 6.826796054840088\n",
      "Loss at Iteration @ 54 is 8.073266983032227\n",
      "Loss at Iteration @ 55 is 5.977930068969727\n",
      "Loss at Iteration @ 56 is 7.5785088539123535\n",
      "Loss at Iteration @ 57 is 8.556106567382812\n",
      "Loss at Iteration @ 58 is 7.8448486328125\n",
      "Loss at Iteration @ 59 is 7.8540263175964355\n",
      "Loss at Iteration @ 60 is 8.085158348083496\n",
      "Loss at Iteration @ 61 is 6.375959873199463\n",
      "Loss at Iteration @ 62 is 6.428421497344971\n",
      "Loss at Iteration @ 63 is 6.811866760253906\n",
      "Loss at Iteration @ 64 is 8.702373504638672\n",
      "Loss at Iteration @ 65 is 6.266950607299805\n",
      "Loss at Iteration @ 66 is 6.547930717468262\n",
      "Loss at Iteration @ 67 is 5.733285427093506\n",
      "Loss at Iteration @ 68 is 9.610292434692383\n",
      "Loss at Iteration @ 69 is 6.0264506340026855\n",
      "Loss at Iteration @ 70 is 9.71786117553711\n",
      "Loss at Iteration @ 71 is 8.547919273376465\n",
      "Loss at Iteration @ 72 is 7.214864730834961\n",
      "Loss at Iteration @ 73 is 7.7460784912109375\n",
      "Loss at Iteration @ 74 is 6.014930248260498\n",
      "Loss at Iteration @ 75 is 6.508298873901367\n",
      "Loss at Iteration @ 76 is 5.263253688812256\n",
      "Loss at Iteration @ 77 is 6.527493476867676\n",
      "Loss at Iteration @ 78 is 7.03355073928833\n",
      "Loss at Iteration @ 79 is 8.60085391998291\n",
      "Loss at Iteration @ 80 is 6.683097839355469\n",
      "Loss at Iteration @ 81 is 6.9010515213012695\n",
      "Loss at Iteration @ 82 is 7.233349800109863\n",
      "Loss at Iteration @ 83 is 5.83853006362915\n",
      "Loss at Iteration @ 84 is 7.149866580963135\n",
      "Loss at Iteration @ 85 is 5.874405860900879\n",
      "Loss at Iteration @ 86 is 6.25273323059082\n",
      "Loss at Iteration @ 87 is 7.238577842712402\n",
      "Loss at Iteration @ 88 is 6.699451446533203\n",
      "Loss at Iteration @ 89 is 6.808920383453369\n",
      "Loss at Iteration @ 90 is 6.384576320648193\n",
      "Loss at Iteration @ 91 is 5.727522373199463\n",
      "Loss at Iteration @ 92 is 7.502185344696045\n",
      "Loss at Iteration @ 93 is 6.362740993499756\n",
      "Loss at Iteration @ 94 is 7.737318515777588\n",
      "Loss at Iteration @ 95 is 5.659048557281494\n",
      "Loss at Iteration @ 96 is 6.500425815582275\n",
      "Loss at Iteration @ 97 is 5.508414268493652\n",
      "Loss at Iteration @ 98 is 7.573596000671387\n",
      "Loss at Iteration @ 99 is 8.538467407226562\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.2\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32,))\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[Xtr[ix]]\n",
    "    logits = (torch.tanh_(emb.view(-1, 30) @ W1 + b1)) @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "    \n",
    "    print(f'Loss at Iteration @ {i} is {loss.item()}')\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    #update\n",
    "    for p in parameters:\n",
    "        p.data -= learning_rate * p.grad \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Dev set is 6.429243564605713\n",
      "Loss for Test set is 6.429574012756348\n"
     ]
    }
   ],
   "source": [
    "emb = C[Xdev]\n",
    "logits = (torch.tanh_(emb.view(-1, 30) @ W1 + b1)) @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "\n",
    "print(f'Loss for Dev set is {loss.item()}')\n",
    "\n",
    "emb = C[Xte]\n",
    "logits = (torch.tanh_(emb.view(-1, 30) @ W1 + b1)) @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Yte)\n",
    "\n",
    "print(f'Loss for Test set is {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data's loss is 6.285614490509033\n"
     ]
    }
   ],
   "source": [
    "emb = C[X]\n",
    "logits = (torch.tanh_(emb.view(-1, 30) @ W1 + b1)) @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "\n",
    "print(f\"Full data's loss is {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SO, it did work question is how you can determine the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "lri = []\n",
    "lossi = []\n",
    "stepi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20000):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (32,))\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xtr[ix]] # (32, 3, 10)\n",
    "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 200)\n",
    "  logits = h @ W2 + b2 # (32, 27)\n",
    "  loss = F.cross_entropy(logits, Ytr[ix])\n",
    "  #print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  #lr = lrs[i]\n",
    "  lr = 0.1 if i < 100000 else 0.01\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  # lri.append(lr)\n",
    "  stepi.append(i)\n",
    "  lossi.append(loss.log10().item())\n",
    "\n",
    "#print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x203f2e1d4b0>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4848, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4941, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize dimension 0 and 1 of the embedding matrix C for all characters\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
    "plt.grid('minor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training split, dev/validation split, test split\n",
    "# 80%, 10%, 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 10])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = [0] * block_size\n",
    "C[torch.tensor([context])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ger.\n",
      "reelyn.\n",
      "nessa.\n",
      "reyah.\n",
      "distonisleysynissayapmisai.\n",
      "hacey.\n",
      "lariyci.\n",
      "bayse.\n",
      "elina.\n",
      "gilesameah.\n",
      "romiyah.\n",
      "aldixa.\n",
      "milaumassahaisil.\n",
      "mis.\n",
      "diby.\n",
      "relynick.\n",
      "kasizaty.\n",
      "releccire.\n",
      "reehemorcessip.\n",
      "wevis.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "      logits = h @ W2 + b2\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, you name your son/daughteer by using this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 beat loss of 2.2!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luficerg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182580, 4]) torch.Size([182580])\n",
      "torch.Size([22767, 4]) torch.Size([22767])\n",
      "torch.Size([22799, 4]) torch.Size([22799])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 4 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  for w in words:\n",
    "\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182580, 4, 20])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xtr , Xdev , Xte have dimensions 3 and the words length , it means it takes 3 characters as input and 1 character as output or predicted .\n",
    "#The C is the context with 50 dimensions to represent the characters into context embeddings, so every 27 character has now 50 dimensions embedding for itself . .\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((27, 20), generator=g)\n",
    "C[Xtr].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has converted those 3 character out of total 27 into 15 dimensions embeddings for each character, so basically.\n",
    "# C shape is 27 , and 15 dimensions , it has Xtr which training set for indexing and 3 character of training set used as indexing for retrieving , the 15 dimension representation of that character from those 27 things\n",
    "# This is what exactly we are doing here\n",
    "C[Xtr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_shape = C[Xtr].shape[1] * C[Xtr].shape[2]\n",
    "context_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole Network\n",
    "W1 = torch.randn((context_shape, 54), generator=g)\n",
    "b1 = torch.randn(54, generator=g)\n",
    "W2 = torch.randn((54, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at Iteration @ 0 is 2.2771999835968018\n",
      "Loss at Iteration @ 1 is 2.3110196590423584\n",
      "Loss at Iteration @ 2 is 2.273418426513672\n",
      "Loss at Iteration @ 3 is 2.3255348205566406\n",
      "Loss at Iteration @ 4 is 2.156982660293579\n",
      "Loss at Iteration @ 5 is 2.0027945041656494\n",
      "Loss at Iteration @ 6 is 2.301069736480713\n",
      "Loss at Iteration @ 7 is 2.2043583393096924\n",
      "Loss at Iteration @ 8 is 2.024851083755493\n",
      "Loss at Iteration @ 9 is 2.1413843631744385\n",
      "Loss at Iteration @ 10 is 2.1743576526641846\n",
      "Loss at Iteration @ 11 is 2.354738473892212\n",
      "Loss at Iteration @ 12 is 2.368561029434204\n",
      "Loss at Iteration @ 13 is 2.0290675163269043\n",
      "Loss at Iteration @ 14 is 2.4071717262268066\n",
      "Loss at Iteration @ 15 is 2.3285841941833496\n",
      "Loss at Iteration @ 16 is 2.180391550064087\n",
      "Loss at Iteration @ 17 is 1.9668318033218384\n",
      "Loss at Iteration @ 18 is 2.5405120849609375\n",
      "Loss at Iteration @ 19 is 2.305375099182129\n",
      "Loss at Iteration @ 20 is 2.4158575534820557\n",
      "Loss at Iteration @ 21 is 2.175551652908325\n",
      "Loss at Iteration @ 22 is 2.1847290992736816\n",
      "Loss at Iteration @ 23 is 2.404203414916992\n",
      "Loss at Iteration @ 24 is 2.336498975753784\n",
      "Loss at Iteration @ 25 is 2.4786341190338135\n",
      "Loss at Iteration @ 26 is 2.0804898738861084\n",
      "Loss at Iteration @ 27 is 2.151179313659668\n",
      "Loss at Iteration @ 28 is 2.4497714042663574\n",
      "Loss at Iteration @ 29 is 2.2873480319976807\n",
      "Loss at Iteration @ 30 is 2.33042049407959\n",
      "Loss at Iteration @ 31 is 2.4551033973693848\n",
      "Loss at Iteration @ 32 is 2.1800832748413086\n",
      "Loss at Iteration @ 33 is 2.388519048690796\n",
      "Loss at Iteration @ 34 is 2.5474884510040283\n",
      "Loss at Iteration @ 35 is 2.214942216873169\n",
      "Loss at Iteration @ 36 is 2.1692867279052734\n",
      "Loss at Iteration @ 37 is 2.4397027492523193\n",
      "Loss at Iteration @ 38 is 2.4201173782348633\n",
      "Loss at Iteration @ 39 is 2.2122802734375\n",
      "Loss at Iteration @ 40 is 2.361558675765991\n",
      "Loss at Iteration @ 41 is 2.338820457458496\n",
      "Loss at Iteration @ 42 is 2.2136404514312744\n",
      "Loss at Iteration @ 43 is 2.023803949356079\n",
      "Loss at Iteration @ 44 is 2.240490436553955\n",
      "Loss at Iteration @ 45 is 2.4530868530273438\n",
      "Loss at Iteration @ 46 is 2.420452356338501\n",
      "Loss at Iteration @ 47 is 2.2234110832214355\n",
      "Loss at Iteration @ 48 is 2.340738534927368\n",
      "Loss at Iteration @ 49 is 2.0557429790496826\n",
      "Loss at Iteration @ 50 is 2.1626036167144775\n",
      "Loss at Iteration @ 51 is 2.2936501502990723\n",
      "Loss at Iteration @ 52 is 2.0709009170532227\n",
      "Loss at Iteration @ 53 is 2.3119237422943115\n",
      "Loss at Iteration @ 54 is 2.266927719116211\n",
      "Loss at Iteration @ 55 is 1.8958325386047363\n",
      "Loss at Iteration @ 56 is 2.2119665145874023\n",
      "Loss at Iteration @ 57 is 2.1457865238189697\n",
      "Loss at Iteration @ 58 is 1.9997541904449463\n",
      "Loss at Iteration @ 59 is 2.0159592628479004\n",
      "Loss at Iteration @ 60 is 2.279741048812866\n",
      "Loss at Iteration @ 61 is 2.2284317016601562\n",
      "Loss at Iteration @ 62 is 2.1463520526885986\n",
      "Loss at Iteration @ 63 is 2.2019307613372803\n",
      "Loss at Iteration @ 64 is 2.389920711517334\n",
      "Loss at Iteration @ 65 is 2.2148847579956055\n",
      "Loss at Iteration @ 66 is 2.1724915504455566\n",
      "Loss at Iteration @ 67 is 2.3402202129364014\n",
      "Loss at Iteration @ 68 is 1.9907221794128418\n",
      "Loss at Iteration @ 69 is 2.580178737640381\n",
      "Loss at Iteration @ 70 is 2.4143319129943848\n",
      "Loss at Iteration @ 71 is 2.6497931480407715\n",
      "Loss at Iteration @ 72 is 1.9827327728271484\n",
      "Loss at Iteration @ 73 is 2.1002962589263916\n",
      "Loss at Iteration @ 74 is 2.105849027633667\n",
      "Loss at Iteration @ 75 is 2.421919584274292\n",
      "Loss at Iteration @ 76 is 2.215846538543701\n",
      "Loss at Iteration @ 77 is 2.440239191055298\n",
      "Loss at Iteration @ 78 is 2.4468295574188232\n",
      "Loss at Iteration @ 79 is 2.3372275829315186\n",
      "Loss at Iteration @ 80 is 2.0890448093414307\n",
      "Loss at Iteration @ 81 is 2.1203267574310303\n",
      "Loss at Iteration @ 82 is 1.9459887742996216\n",
      "Loss at Iteration @ 83 is 2.1666653156280518\n",
      "Loss at Iteration @ 84 is 2.1662144660949707\n",
      "Loss at Iteration @ 85 is 2.1864194869995117\n",
      "Loss at Iteration @ 86 is 2.0735671520233154\n",
      "Loss at Iteration @ 87 is 2.4962120056152344\n",
      "Loss at Iteration @ 88 is 2.3035101890563965\n",
      "Loss at Iteration @ 89 is 2.138746976852417\n",
      "Loss at Iteration @ 90 is 2.3614039421081543\n",
      "Loss at Iteration @ 91 is 2.2921254634857178\n",
      "Loss at Iteration @ 92 is 2.051760673522949\n",
      "Loss at Iteration @ 93 is 2.061039686203003\n",
      "Loss at Iteration @ 94 is 2.057926654815674\n",
      "Loss at Iteration @ 95 is 2.4294657707214355\n",
      "Loss at Iteration @ 96 is 2.331206798553467\n",
      "Loss at Iteration @ 97 is 2.1869869232177734\n",
      "Loss at Iteration @ 98 is 2.320152759552002\n",
      "Loss at Iteration @ 99 is 2.3507838249206543\n",
      "Loss at Iteration @ 100 is 1.962444543838501\n",
      "Loss at Iteration @ 101 is 2.3890647888183594\n",
      "Loss at Iteration @ 102 is 2.283660411834717\n",
      "Loss at Iteration @ 103 is 2.0822525024414062\n",
      "Loss at Iteration @ 104 is 2.201054334640503\n",
      "Loss at Iteration @ 105 is 2.1047744750976562\n",
      "Loss at Iteration @ 106 is 2.3317785263061523\n",
      "Loss at Iteration @ 107 is 2.3838961124420166\n",
      "Loss at Iteration @ 108 is 2.1666431427001953\n",
      "Loss at Iteration @ 109 is 2.4162962436676025\n",
      "Loss at Iteration @ 110 is 2.1363110542297363\n",
      "Loss at Iteration @ 111 is 2.109198808670044\n",
      "Loss at Iteration @ 112 is 2.242128372192383\n",
      "Loss at Iteration @ 113 is 2.0952062606811523\n",
      "Loss at Iteration @ 114 is 2.0534982681274414\n",
      "Loss at Iteration @ 115 is 2.116126537322998\n",
      "Loss at Iteration @ 116 is 2.290299892425537\n",
      "Loss at Iteration @ 117 is 2.171788454055786\n",
      "Loss at Iteration @ 118 is 2.2329373359680176\n",
      "Loss at Iteration @ 119 is 2.2162837982177734\n",
      "Loss at Iteration @ 120 is 2.0676565170288086\n",
      "Loss at Iteration @ 121 is 2.3376739025115967\n",
      "Loss at Iteration @ 122 is 1.9710707664489746\n",
      "Loss at Iteration @ 123 is 2.3632395267486572\n",
      "Loss at Iteration @ 124 is 2.291076183319092\n",
      "Loss at Iteration @ 125 is 2.1672332286834717\n",
      "Loss at Iteration @ 126 is 2.3812992572784424\n",
      "Loss at Iteration @ 127 is 2.0780739784240723\n",
      "Loss at Iteration @ 128 is 2.0551090240478516\n",
      "Loss at Iteration @ 129 is 2.2712759971618652\n",
      "Loss at Iteration @ 130 is 2.2045812606811523\n",
      "Loss at Iteration @ 131 is 2.3072032928466797\n",
      "Loss at Iteration @ 132 is 2.145796060562134\n",
      "Loss at Iteration @ 133 is 2.0401296615600586\n",
      "Loss at Iteration @ 134 is 2.4004874229431152\n",
      "Loss at Iteration @ 135 is 2.2737557888031006\n",
      "Loss at Iteration @ 136 is 1.9310318231582642\n",
      "Loss at Iteration @ 137 is 2.0591440200805664\n",
      "Loss at Iteration @ 138 is 2.225696563720703\n",
      "Loss at Iteration @ 139 is 2.231689453125\n",
      "Loss at Iteration @ 140 is 2.317554235458374\n",
      "Loss at Iteration @ 141 is 2.178840160369873\n",
      "Loss at Iteration @ 142 is 2.151315450668335\n",
      "Loss at Iteration @ 143 is 1.8922193050384521\n",
      "Loss at Iteration @ 144 is 2.3391876220703125\n",
      "Loss at Iteration @ 145 is 2.4556233882904053\n",
      "Loss at Iteration @ 146 is 2.157949924468994\n",
      "Loss at Iteration @ 147 is 2.0730271339416504\n",
      "Loss at Iteration @ 148 is 2.3874666690826416\n",
      "Loss at Iteration @ 149 is 2.316840410232544\n",
      "Loss at Iteration @ 150 is 2.138252019882202\n",
      "Loss at Iteration @ 151 is 2.2236688137054443\n",
      "Loss at Iteration @ 152 is 2.222663164138794\n",
      "Loss at Iteration @ 153 is 2.451345682144165\n",
      "Loss at Iteration @ 154 is 2.3055334091186523\n",
      "Loss at Iteration @ 155 is 2.05696439743042\n",
      "Loss at Iteration @ 156 is 2.59499454498291\n",
      "Loss at Iteration @ 157 is 2.2121686935424805\n",
      "Loss at Iteration @ 158 is 2.074714422225952\n",
      "Loss at Iteration @ 159 is 2.440126419067383\n",
      "Loss at Iteration @ 160 is 2.143446445465088\n",
      "Loss at Iteration @ 161 is 2.2924506664276123\n",
      "Loss at Iteration @ 162 is 2.445082187652588\n",
      "Loss at Iteration @ 163 is 2.2323660850524902\n",
      "Loss at Iteration @ 164 is 2.3915882110595703\n",
      "Loss at Iteration @ 165 is 2.388016700744629\n",
      "Loss at Iteration @ 166 is 2.3825130462646484\n",
      "Loss at Iteration @ 167 is 2.5937795639038086\n",
      "Loss at Iteration @ 168 is 2.110507011413574\n",
      "Loss at Iteration @ 169 is 2.4960556030273438\n",
      "Loss at Iteration @ 170 is 2.233525276184082\n",
      "Loss at Iteration @ 171 is 1.985418438911438\n",
      "Loss at Iteration @ 172 is 2.1428751945495605\n",
      "Loss at Iteration @ 173 is 1.8611834049224854\n",
      "Loss at Iteration @ 174 is 2.1597182750701904\n",
      "Loss at Iteration @ 175 is 2.444052219390869\n",
      "Loss at Iteration @ 176 is 2.2033045291900635\n",
      "Loss at Iteration @ 177 is 2.1472725868225098\n",
      "Loss at Iteration @ 178 is 2.179062604904175\n",
      "Loss at Iteration @ 179 is 1.957870602607727\n",
      "Loss at Iteration @ 180 is 2.256826639175415\n",
      "Loss at Iteration @ 181 is 2.0454065799713135\n",
      "Loss at Iteration @ 182 is 2.194554567337036\n",
      "Loss at Iteration @ 183 is 2.182154417037964\n",
      "Loss at Iteration @ 184 is 2.5944201946258545\n",
      "Loss at Iteration @ 185 is 2.2213096618652344\n",
      "Loss at Iteration @ 186 is 2.2306301593780518\n",
      "Loss at Iteration @ 187 is 2.3571557998657227\n",
      "Loss at Iteration @ 188 is 2.2564258575439453\n",
      "Loss at Iteration @ 189 is 2.451594591140747\n",
      "Loss at Iteration @ 190 is 2.08198618888855\n",
      "Loss at Iteration @ 191 is 2.0829598903656006\n",
      "Loss at Iteration @ 192 is 2.440929412841797\n",
      "Loss at Iteration @ 193 is 2.406163215637207\n",
      "Loss at Iteration @ 194 is 2.2573862075805664\n",
      "Loss at Iteration @ 195 is 2.343644618988037\n",
      "Loss at Iteration @ 196 is 2.010791301727295\n",
      "Loss at Iteration @ 197 is 2.1696395874023438\n",
      "Loss at Iteration @ 198 is 2.4462950229644775\n",
      "Loss at Iteration @ 199 is 2.2539825439453125\n",
      "Loss at Iteration @ 200 is 2.1483042240142822\n",
      "Loss at Iteration @ 201 is 1.8925997018814087\n",
      "Loss at Iteration @ 202 is 2.0892562866210938\n",
      "Loss at Iteration @ 203 is 2.1754720211029053\n",
      "Loss at Iteration @ 204 is 2.7178027629852295\n",
      "Loss at Iteration @ 205 is 2.2511532306671143\n",
      "Loss at Iteration @ 206 is 2.1884796619415283\n",
      "Loss at Iteration @ 207 is 2.39324688911438\n",
      "Loss at Iteration @ 208 is 2.0825822353363037\n",
      "Loss at Iteration @ 209 is 2.4812169075012207\n",
      "Loss at Iteration @ 210 is 2.0159261226654053\n",
      "Loss at Iteration @ 211 is 2.092679023742676\n",
      "Loss at Iteration @ 212 is 2.2097878456115723\n",
      "Loss at Iteration @ 213 is 2.047253131866455\n",
      "Loss at Iteration @ 214 is 2.266340970993042\n",
      "Loss at Iteration @ 215 is 2.110461473464966\n",
      "Loss at Iteration @ 216 is 2.2086079120635986\n",
      "Loss at Iteration @ 217 is 2.074492931365967\n",
      "Loss at Iteration @ 218 is 2.3603017330169678\n",
      "Loss at Iteration @ 219 is 2.248952865600586\n",
      "Loss at Iteration @ 220 is 2.3254899978637695\n",
      "Loss at Iteration @ 221 is 2.4813461303710938\n",
      "Loss at Iteration @ 222 is 2.346137285232544\n",
      "Loss at Iteration @ 223 is 2.217926025390625\n",
      "Loss at Iteration @ 224 is 2.280564546585083\n",
      "Loss at Iteration @ 225 is 2.2111456394195557\n",
      "Loss at Iteration @ 226 is 2.215643882751465\n",
      "Loss at Iteration @ 227 is 2.0658810138702393\n",
      "Loss at Iteration @ 228 is 2.3662288188934326\n",
      "Loss at Iteration @ 229 is 2.3488800525665283\n",
      "Loss at Iteration @ 230 is 2.2764532566070557\n",
      "Loss at Iteration @ 231 is 2.519270658493042\n",
      "Loss at Iteration @ 232 is 2.370511531829834\n",
      "Loss at Iteration @ 233 is 2.3433072566986084\n",
      "Loss at Iteration @ 234 is 2.5273683071136475\n",
      "Loss at Iteration @ 235 is 2.5178134441375732\n",
      "Loss at Iteration @ 236 is 2.295297145843506\n",
      "Loss at Iteration @ 237 is 2.5012917518615723\n",
      "Loss at Iteration @ 238 is 2.338245153427124\n",
      "Loss at Iteration @ 239 is 2.2982757091522217\n",
      "Loss at Iteration @ 240 is 2.247528076171875\n",
      "Loss at Iteration @ 241 is 2.2040302753448486\n",
      "Loss at Iteration @ 242 is 2.3612239360809326\n",
      "Loss at Iteration @ 243 is 2.1169047355651855\n",
      "Loss at Iteration @ 244 is 2.166836738586426\n",
      "Loss at Iteration @ 245 is 2.2037317752838135\n",
      "Loss at Iteration @ 246 is 2.192885637283325\n",
      "Loss at Iteration @ 247 is 2.442349672317505\n",
      "Loss at Iteration @ 248 is 2.627784013748169\n",
      "Loss at Iteration @ 249 is 2.30361270904541\n",
      "Loss at Iteration @ 250 is 2.236081600189209\n",
      "Loss at Iteration @ 251 is 2.256375551223755\n",
      "Loss at Iteration @ 252 is 2.18601655960083\n",
      "Loss at Iteration @ 253 is 2.123745918273926\n",
      "Loss at Iteration @ 254 is 2.148721218109131\n",
      "Loss at Iteration @ 255 is 2.310910224914551\n",
      "Loss at Iteration @ 256 is 2.296649694442749\n",
      "Loss at Iteration @ 257 is 2.464778184890747\n",
      "Loss at Iteration @ 258 is 2.0974862575531006\n",
      "Loss at Iteration @ 259 is 2.1201956272125244\n",
      "Loss at Iteration @ 260 is 2.160966157913208\n",
      "Loss at Iteration @ 261 is 2.114941120147705\n",
      "Loss at Iteration @ 262 is 1.9881213903427124\n",
      "Loss at Iteration @ 263 is 2.2788515090942383\n",
      "Loss at Iteration @ 264 is 2.1373207569122314\n",
      "Loss at Iteration @ 265 is 2.2323269844055176\n",
      "Loss at Iteration @ 266 is 2.209723472595215\n",
      "Loss at Iteration @ 267 is 2.447554349899292\n",
      "Loss at Iteration @ 268 is 2.2272891998291016\n",
      "Loss at Iteration @ 269 is 1.975792407989502\n",
      "Loss at Iteration @ 270 is 2.3019208908081055\n",
      "Loss at Iteration @ 271 is 2.19228458404541\n",
      "Loss at Iteration @ 272 is 2.523149013519287\n",
      "Loss at Iteration @ 273 is 2.307039260864258\n",
      "Loss at Iteration @ 274 is 2.2507638931274414\n",
      "Loss at Iteration @ 275 is 1.9817256927490234\n",
      "Loss at Iteration @ 276 is 2.3029839992523193\n",
      "Loss at Iteration @ 277 is 2.1842823028564453\n",
      "Loss at Iteration @ 278 is 1.8619353771209717\n",
      "Loss at Iteration @ 279 is 2.415734052658081\n",
      "Loss at Iteration @ 280 is 2.2996809482574463\n",
      "Loss at Iteration @ 281 is 2.3326072692871094\n",
      "Loss at Iteration @ 282 is 2.071936845779419\n",
      "Loss at Iteration @ 283 is 2.2954208850860596\n",
      "Loss at Iteration @ 284 is 2.268317937850952\n",
      "Loss at Iteration @ 285 is 2.3399782180786133\n",
      "Loss at Iteration @ 286 is 2.2412707805633545\n",
      "Loss at Iteration @ 287 is 2.1017587184906006\n",
      "Loss at Iteration @ 288 is 2.364847183227539\n",
      "Loss at Iteration @ 289 is 2.252513885498047\n",
      "Loss at Iteration @ 290 is 2.1010971069335938\n",
      "Loss at Iteration @ 291 is 2.044149398803711\n",
      "Loss at Iteration @ 292 is 2.2850072383880615\n",
      "Loss at Iteration @ 293 is 2.34539794921875\n",
      "Loss at Iteration @ 294 is 2.250983238220215\n",
      "Loss at Iteration @ 295 is 1.9551465511322021\n",
      "Loss at Iteration @ 296 is 2.2710530757904053\n",
      "Loss at Iteration @ 297 is 2.138787031173706\n",
      "Loss at Iteration @ 298 is 2.1409757137298584\n",
      "Loss at Iteration @ 299 is 2.1019957065582275\n",
      "Loss at Iteration @ 300 is 2.0717294216156006\n",
      "Loss at Iteration @ 301 is 2.1455090045928955\n",
      "Loss at Iteration @ 302 is 2.152574062347412\n",
      "Loss at Iteration @ 303 is 2.437772750854492\n",
      "Loss at Iteration @ 304 is 2.2582576274871826\n",
      "Loss at Iteration @ 305 is 2.4678778648376465\n",
      "Loss at Iteration @ 306 is 2.102200746536255\n",
      "Loss at Iteration @ 307 is 2.2586557865142822\n",
      "Loss at Iteration @ 308 is 2.2999892234802246\n",
      "Loss at Iteration @ 309 is 2.3635716438293457\n",
      "Loss at Iteration @ 310 is 2.114908218383789\n",
      "Loss at Iteration @ 311 is 2.2537007331848145\n",
      "Loss at Iteration @ 312 is 2.1057143211364746\n",
      "Loss at Iteration @ 313 is 2.218546152114868\n",
      "Loss at Iteration @ 314 is 2.4627585411071777\n",
      "Loss at Iteration @ 315 is 2.0460238456726074\n",
      "Loss at Iteration @ 316 is 2.2450428009033203\n",
      "Loss at Iteration @ 317 is 2.2127654552459717\n",
      "Loss at Iteration @ 318 is 2.2767744064331055\n",
      "Loss at Iteration @ 319 is 2.5902302265167236\n",
      "Loss at Iteration @ 320 is 2.104341506958008\n",
      "Loss at Iteration @ 321 is 2.4293696880340576\n",
      "Loss at Iteration @ 322 is 2.042292356491089\n",
      "Loss at Iteration @ 323 is 2.093808889389038\n",
      "Loss at Iteration @ 324 is 2.0508391857147217\n",
      "Loss at Iteration @ 325 is 2.230593681335449\n",
      "Loss at Iteration @ 326 is 2.2890307903289795\n",
      "Loss at Iteration @ 327 is 2.4642348289489746\n",
      "Loss at Iteration @ 328 is 2.387406349182129\n",
      "Loss at Iteration @ 329 is 2.1682465076446533\n",
      "Loss at Iteration @ 330 is 2.2873427867889404\n",
      "Loss at Iteration @ 331 is 2.3538687229156494\n",
      "Loss at Iteration @ 332 is 2.178163766860962\n",
      "Loss at Iteration @ 333 is 2.4057881832122803\n",
      "Loss at Iteration @ 334 is 2.320547580718994\n",
      "Loss at Iteration @ 335 is 2.315495729446411\n",
      "Loss at Iteration @ 336 is 2.0418121814727783\n",
      "Loss at Iteration @ 337 is 2.0380923748016357\n",
      "Loss at Iteration @ 338 is 2.045658826828003\n",
      "Loss at Iteration @ 339 is 2.355271577835083\n",
      "Loss at Iteration @ 340 is 2.2881224155426025\n",
      "Loss at Iteration @ 341 is 2.224987745285034\n",
      "Loss at Iteration @ 342 is 2.323838710784912\n",
      "Loss at Iteration @ 343 is 2.1713905334472656\n",
      "Loss at Iteration @ 344 is 2.2337541580200195\n",
      "Loss at Iteration @ 345 is 2.001974582672119\n",
      "Loss at Iteration @ 346 is 2.042401075363159\n",
      "Loss at Iteration @ 347 is 2.1987650394439697\n",
      "Loss at Iteration @ 348 is 2.309885025024414\n",
      "Loss at Iteration @ 349 is 2.1685101985931396\n",
      "Loss at Iteration @ 350 is 2.225198268890381\n",
      "Loss at Iteration @ 351 is 2.048961877822876\n",
      "Loss at Iteration @ 352 is 2.1808643341064453\n",
      "Loss at Iteration @ 353 is 2.3410990238189697\n",
      "Loss at Iteration @ 354 is 2.012009382247925\n",
      "Loss at Iteration @ 355 is 2.217402696609497\n",
      "Loss at Iteration @ 356 is 2.376643657684326\n",
      "Loss at Iteration @ 357 is 2.1474626064300537\n",
      "Loss at Iteration @ 358 is 2.249620199203491\n",
      "Loss at Iteration @ 359 is 2.1283514499664307\n",
      "Loss at Iteration @ 360 is 2.643324851989746\n",
      "Loss at Iteration @ 361 is 2.211778402328491\n",
      "Loss at Iteration @ 362 is 2.155914545059204\n",
      "Loss at Iteration @ 363 is 2.0584733486175537\n",
      "Loss at Iteration @ 364 is 2.2489986419677734\n",
      "Loss at Iteration @ 365 is 2.1424224376678467\n",
      "Loss at Iteration @ 366 is 1.799081802368164\n",
      "Loss at Iteration @ 367 is 2.2600135803222656\n",
      "Loss at Iteration @ 368 is 2.149996519088745\n",
      "Loss at Iteration @ 369 is 2.3254806995391846\n",
      "Loss at Iteration @ 370 is 2.224918842315674\n",
      "Loss at Iteration @ 371 is 2.2915685176849365\n",
      "Loss at Iteration @ 372 is 2.3981683254241943\n",
      "Loss at Iteration @ 373 is 2.2436399459838867\n",
      "Loss at Iteration @ 374 is 2.041520595550537\n",
      "Loss at Iteration @ 375 is 2.0923218727111816\n",
      "Loss at Iteration @ 376 is 2.317979335784912\n",
      "Loss at Iteration @ 377 is 2.192064046859741\n",
      "Loss at Iteration @ 378 is 2.552380084991455\n",
      "Loss at Iteration @ 379 is 2.425429105758667\n",
      "Loss at Iteration @ 380 is 1.9941200017929077\n",
      "Loss at Iteration @ 381 is 2.1708998680114746\n",
      "Loss at Iteration @ 382 is 2.3293795585632324\n",
      "Loss at Iteration @ 383 is 2.2162022590637207\n",
      "Loss at Iteration @ 384 is 2.1496851444244385\n",
      "Loss at Iteration @ 385 is 2.251248836517334\n",
      "Loss at Iteration @ 386 is 2.213043212890625\n",
      "Loss at Iteration @ 387 is 2.1933982372283936\n",
      "Loss at Iteration @ 388 is 2.2171411514282227\n",
      "Loss at Iteration @ 389 is 2.070255756378174\n",
      "Loss at Iteration @ 390 is 2.2493815422058105\n",
      "Loss at Iteration @ 391 is 2.0985217094421387\n",
      "Loss at Iteration @ 392 is 2.137861490249634\n",
      "Loss at Iteration @ 393 is 2.106006383895874\n",
      "Loss at Iteration @ 394 is 2.256209135055542\n",
      "Loss at Iteration @ 395 is 1.9566677808761597\n",
      "Loss at Iteration @ 396 is 2.139019012451172\n",
      "Loss at Iteration @ 397 is 2.2837984561920166\n",
      "Loss at Iteration @ 398 is 2.3821663856506348\n",
      "Loss at Iteration @ 399 is 2.4543325901031494\n",
      "Loss at Iteration @ 400 is 2.109886407852173\n",
      "Loss at Iteration @ 401 is 2.270134210586548\n",
      "Loss at Iteration @ 402 is 2.4082016944885254\n",
      "Loss at Iteration @ 403 is 2.380932331085205\n",
      "Loss at Iteration @ 404 is 2.2825427055358887\n",
      "Loss at Iteration @ 405 is 2.472869873046875\n",
      "Loss at Iteration @ 406 is 2.161820888519287\n",
      "Loss at Iteration @ 407 is 2.5407426357269287\n",
      "Loss at Iteration @ 408 is 2.176614761352539\n",
      "Loss at Iteration @ 409 is 2.094857931137085\n",
      "Loss at Iteration @ 410 is 2.1104462146759033\n",
      "Loss at Iteration @ 411 is 2.2027552127838135\n",
      "Loss at Iteration @ 412 is 2.2871596813201904\n",
      "Loss at Iteration @ 413 is 2.15315842628479\n",
      "Loss at Iteration @ 414 is 2.33543062210083\n",
      "Loss at Iteration @ 415 is 2.4037156105041504\n",
      "Loss at Iteration @ 416 is 2.392025947570801\n",
      "Loss at Iteration @ 417 is 2.487668991088867\n",
      "Loss at Iteration @ 418 is 2.252284049987793\n",
      "Loss at Iteration @ 419 is 1.9185822010040283\n",
      "Loss at Iteration @ 420 is 2.437248468399048\n",
      "Loss at Iteration @ 421 is 2.4268767833709717\n",
      "Loss at Iteration @ 422 is 2.1931228637695312\n",
      "Loss at Iteration @ 423 is 2.3720014095306396\n",
      "Loss at Iteration @ 424 is 2.456523895263672\n",
      "Loss at Iteration @ 425 is 2.405961513519287\n",
      "Loss at Iteration @ 426 is 2.1479122638702393\n",
      "Loss at Iteration @ 427 is 2.158435106277466\n",
      "Loss at Iteration @ 428 is 2.379366636276245\n",
      "Loss at Iteration @ 429 is 2.6418073177337646\n",
      "Loss at Iteration @ 430 is 2.2315096855163574\n",
      "Loss at Iteration @ 431 is 2.069988965988159\n",
      "Loss at Iteration @ 432 is 2.096113681793213\n",
      "Loss at Iteration @ 433 is 2.1814732551574707\n",
      "Loss at Iteration @ 434 is 2.3162903785705566\n",
      "Loss at Iteration @ 435 is 2.525778293609619\n",
      "Loss at Iteration @ 436 is 2.1837892532348633\n",
      "Loss at Iteration @ 437 is 2.061340808868408\n",
      "Loss at Iteration @ 438 is 2.4177815914154053\n",
      "Loss at Iteration @ 439 is 2.4070565700531006\n",
      "Loss at Iteration @ 440 is 2.2795591354370117\n",
      "Loss at Iteration @ 441 is 2.239901304244995\n",
      "Loss at Iteration @ 442 is 2.24212908744812\n",
      "Loss at Iteration @ 443 is 2.085935592651367\n",
      "Loss at Iteration @ 444 is 2.319960594177246\n",
      "Loss at Iteration @ 445 is 2.131720781326294\n",
      "Loss at Iteration @ 446 is 2.184041976928711\n",
      "Loss at Iteration @ 447 is 2.1958868503570557\n",
      "Loss at Iteration @ 448 is 2.509418487548828\n",
      "Loss at Iteration @ 449 is 2.2770707607269287\n",
      "Loss at Iteration @ 450 is 2.200131893157959\n",
      "Loss at Iteration @ 451 is 2.1319947242736816\n",
      "Loss at Iteration @ 452 is 2.634537696838379\n",
      "Loss at Iteration @ 453 is 2.3608808517456055\n",
      "Loss at Iteration @ 454 is 2.2022860050201416\n",
      "Loss at Iteration @ 455 is 2.0295801162719727\n",
      "Loss at Iteration @ 456 is 2.287367820739746\n",
      "Loss at Iteration @ 457 is 2.192699909210205\n",
      "Loss at Iteration @ 458 is 2.0737578868865967\n",
      "Loss at Iteration @ 459 is 2.141268014907837\n",
      "Loss at Iteration @ 460 is 2.175424098968506\n",
      "Loss at Iteration @ 461 is 2.0976598262786865\n",
      "Loss at Iteration @ 462 is 2.1167900562286377\n",
      "Loss at Iteration @ 463 is 2.4260458946228027\n",
      "Loss at Iteration @ 464 is 2.3966925144195557\n",
      "Loss at Iteration @ 465 is 2.3845040798187256\n",
      "Loss at Iteration @ 466 is 2.36438250541687\n",
      "Loss at Iteration @ 467 is 2.44661808013916\n",
      "Loss at Iteration @ 468 is 2.2222495079040527\n",
      "Loss at Iteration @ 469 is 2.1426522731781006\n",
      "Loss at Iteration @ 470 is 2.2940022945404053\n",
      "Loss at Iteration @ 471 is 2.5475122928619385\n",
      "Loss at Iteration @ 472 is 2.0354108810424805\n",
      "Loss at Iteration @ 473 is 2.1438353061676025\n",
      "Loss at Iteration @ 474 is 2.2009971141815186\n",
      "Loss at Iteration @ 475 is 2.369628667831421\n",
      "Loss at Iteration @ 476 is 2.0914158821105957\n",
      "Loss at Iteration @ 477 is 2.2329039573669434\n",
      "Loss at Iteration @ 478 is 2.2836272716522217\n",
      "Loss at Iteration @ 479 is 1.9938453435897827\n",
      "Loss at Iteration @ 480 is 2.215851306915283\n",
      "Loss at Iteration @ 481 is 2.2188963890075684\n",
      "Loss at Iteration @ 482 is 2.3856704235076904\n",
      "Loss at Iteration @ 483 is 2.415222644805908\n",
      "Loss at Iteration @ 484 is 2.21665096282959\n",
      "Loss at Iteration @ 485 is 2.3797426223754883\n",
      "Loss at Iteration @ 486 is 2.3817381858825684\n",
      "Loss at Iteration @ 487 is 2.3392679691314697\n",
      "Loss at Iteration @ 488 is 2.1198742389678955\n",
      "Loss at Iteration @ 489 is 1.9471629858016968\n",
      "Loss at Iteration @ 490 is 2.304912567138672\n",
      "Loss at Iteration @ 491 is 2.213045120239258\n",
      "Loss at Iteration @ 492 is 2.165339469909668\n",
      "Loss at Iteration @ 493 is 2.4005541801452637\n",
      "Loss at Iteration @ 494 is 2.2015860080718994\n",
      "Loss at Iteration @ 495 is 2.100252151489258\n",
      "Loss at Iteration @ 496 is 2.1919658184051514\n",
      "Loss at Iteration @ 497 is 2.204572916030884\n",
      "Loss at Iteration @ 498 is 2.2585766315460205\n",
      "Loss at Iteration @ 499 is 2.070247173309326\n",
      "Loss at Iteration @ 500 is 2.23256516456604\n",
      "Loss at Iteration @ 501 is 2.124540328979492\n",
      "Loss at Iteration @ 502 is 2.4867773056030273\n",
      "Loss at Iteration @ 503 is 2.2873549461364746\n",
      "Loss at Iteration @ 504 is 2.300243854522705\n",
      "Loss at Iteration @ 505 is 2.1205241680145264\n",
      "Loss at Iteration @ 506 is 2.496394395828247\n",
      "Loss at Iteration @ 507 is 2.5710930824279785\n",
      "Loss at Iteration @ 508 is 2.251014471054077\n",
      "Loss at Iteration @ 509 is 2.419957399368286\n",
      "Loss at Iteration @ 510 is 2.2600154876708984\n",
      "Loss at Iteration @ 511 is 1.9728261232376099\n",
      "Loss at Iteration @ 512 is 2.2794675827026367\n",
      "Loss at Iteration @ 513 is 2.1746535301208496\n",
      "Loss at Iteration @ 514 is 2.0237128734588623\n",
      "Loss at Iteration @ 515 is 2.0586793422698975\n",
      "Loss at Iteration @ 516 is 2.218808174133301\n",
      "Loss at Iteration @ 517 is 2.119375228881836\n",
      "Loss at Iteration @ 518 is 2.1460330486297607\n",
      "Loss at Iteration @ 519 is 1.9759576320648193\n",
      "Loss at Iteration @ 520 is 2.0143702030181885\n",
      "Loss at Iteration @ 521 is 2.3513123989105225\n",
      "Loss at Iteration @ 522 is 2.38319993019104\n",
      "Loss at Iteration @ 523 is 2.358358383178711\n",
      "Loss at Iteration @ 524 is 2.266787528991699\n",
      "Loss at Iteration @ 525 is 2.5019121170043945\n",
      "Loss at Iteration @ 526 is 2.2494328022003174\n",
      "Loss at Iteration @ 527 is 2.2736096382141113\n",
      "Loss at Iteration @ 528 is 2.179882526397705\n",
      "Loss at Iteration @ 529 is 2.02163028717041\n",
      "Loss at Iteration @ 530 is 2.312425374984741\n",
      "Loss at Iteration @ 531 is 1.9611934423446655\n",
      "Loss at Iteration @ 532 is 2.3047244548797607\n",
      "Loss at Iteration @ 533 is 2.4343690872192383\n",
      "Loss at Iteration @ 534 is 2.4186527729034424\n",
      "Loss at Iteration @ 535 is 2.214073896408081\n",
      "Loss at Iteration @ 536 is 1.9563878774642944\n",
      "Loss at Iteration @ 537 is 2.340839147567749\n",
      "Loss at Iteration @ 538 is 2.1740543842315674\n",
      "Loss at Iteration @ 539 is 2.154188394546509\n",
      "Loss at Iteration @ 540 is 2.129607915878296\n",
      "Loss at Iteration @ 541 is 2.161480188369751\n",
      "Loss at Iteration @ 542 is 2.2443277835845947\n",
      "Loss at Iteration @ 543 is 2.128427267074585\n",
      "Loss at Iteration @ 544 is 2.006340980529785\n",
      "Loss at Iteration @ 545 is 2.2305705547332764\n",
      "Loss at Iteration @ 546 is 2.1699435710906982\n",
      "Loss at Iteration @ 547 is 2.247084856033325\n",
      "Loss at Iteration @ 548 is 2.0705952644348145\n",
      "Loss at Iteration @ 549 is 2.3400440216064453\n",
      "Loss at Iteration @ 550 is 2.2705910205841064\n",
      "Loss at Iteration @ 551 is 2.0452921390533447\n",
      "Loss at Iteration @ 552 is 2.045811891555786\n",
      "Loss at Iteration @ 553 is 2.227640151977539\n",
      "Loss at Iteration @ 554 is 2.390132427215576\n",
      "Loss at Iteration @ 555 is 2.45782470703125\n",
      "Loss at Iteration @ 556 is 2.292069911956787\n",
      "Loss at Iteration @ 557 is 2.4610111713409424\n",
      "Loss at Iteration @ 558 is 2.354248285293579\n",
      "Loss at Iteration @ 559 is 2.1829893589019775\n",
      "Loss at Iteration @ 560 is 2.205230712890625\n",
      "Loss at Iteration @ 561 is 2.047522783279419\n",
      "Loss at Iteration @ 562 is 2.2944507598876953\n",
      "Loss at Iteration @ 563 is 2.1545896530151367\n",
      "Loss at Iteration @ 564 is 1.9576566219329834\n",
      "Loss at Iteration @ 565 is 2.1227798461914062\n",
      "Loss at Iteration @ 566 is 2.2164201736450195\n",
      "Loss at Iteration @ 567 is 2.2475032806396484\n",
      "Loss at Iteration @ 568 is 2.406423568725586\n",
      "Loss at Iteration @ 569 is 1.9483497142791748\n",
      "Loss at Iteration @ 570 is 2.371333360671997\n",
      "Loss at Iteration @ 571 is 2.0854837894439697\n",
      "Loss at Iteration @ 572 is 2.446284532546997\n",
      "Loss at Iteration @ 573 is 2.216647148132324\n",
      "Loss at Iteration @ 574 is 2.3718624114990234\n",
      "Loss at Iteration @ 575 is 2.3659732341766357\n",
      "Loss at Iteration @ 576 is 2.2015185356140137\n",
      "Loss at Iteration @ 577 is 2.187778949737549\n",
      "Loss at Iteration @ 578 is 2.485016345977783\n",
      "Loss at Iteration @ 579 is 2.2852351665496826\n",
      "Loss at Iteration @ 580 is 2.3774287700653076\n",
      "Loss at Iteration @ 581 is 2.1866586208343506\n",
      "Loss at Iteration @ 582 is 2.3259823322296143\n",
      "Loss at Iteration @ 583 is 2.067941665649414\n",
      "Loss at Iteration @ 584 is 2.266859531402588\n",
      "Loss at Iteration @ 585 is 2.251673936843872\n",
      "Loss at Iteration @ 586 is 2.245018243789673\n",
      "Loss at Iteration @ 587 is 2.3195793628692627\n",
      "Loss at Iteration @ 588 is 2.153820276260376\n",
      "Loss at Iteration @ 589 is 2.361358165740967\n",
      "Loss at Iteration @ 590 is 2.194401741027832\n",
      "Loss at Iteration @ 591 is 2.2000539302825928\n",
      "Loss at Iteration @ 592 is 2.3920376300811768\n",
      "Loss at Iteration @ 593 is 2.028041362762451\n",
      "Loss at Iteration @ 594 is 2.102268934249878\n",
      "Loss at Iteration @ 595 is 2.417086362838745\n",
      "Loss at Iteration @ 596 is 1.9176656007766724\n",
      "Loss at Iteration @ 597 is 2.216273784637451\n",
      "Loss at Iteration @ 598 is 2.240772247314453\n",
      "Loss at Iteration @ 599 is 2.2165873050689697\n",
      "Loss at Iteration @ 600 is 2.415539264678955\n",
      "Loss at Iteration @ 601 is 2.3123526573181152\n",
      "Loss at Iteration @ 602 is 2.3514294624328613\n",
      "Loss at Iteration @ 603 is 2.2275140285491943\n",
      "Loss at Iteration @ 604 is 2.3594956398010254\n",
      "Loss at Iteration @ 605 is 2.123029947280884\n",
      "Loss at Iteration @ 606 is 1.970876932144165\n",
      "Loss at Iteration @ 607 is 2.245051622390747\n",
      "Loss at Iteration @ 608 is 2.5159199237823486\n",
      "Loss at Iteration @ 609 is 2.0882201194763184\n",
      "Loss at Iteration @ 610 is 2.2942452430725098\n",
      "Loss at Iteration @ 611 is 2.1913745403289795\n",
      "Loss at Iteration @ 612 is 2.278820037841797\n",
      "Loss at Iteration @ 613 is 2.4967122077941895\n",
      "Loss at Iteration @ 614 is 2.2782037258148193\n",
      "Loss at Iteration @ 615 is 2.1424834728240967\n",
      "Loss at Iteration @ 616 is 2.365715265274048\n",
      "Loss at Iteration @ 617 is 2.2813899517059326\n",
      "Loss at Iteration @ 618 is 2.2820303440093994\n",
      "Loss at Iteration @ 619 is 2.168182373046875\n",
      "Loss at Iteration @ 620 is 1.811481237411499\n",
      "Loss at Iteration @ 621 is 2.1079065799713135\n",
      "Loss at Iteration @ 622 is 2.205127000808716\n",
      "Loss at Iteration @ 623 is 2.0030581951141357\n",
      "Loss at Iteration @ 624 is 2.3488569259643555\n",
      "Loss at Iteration @ 625 is 2.6481852531433105\n",
      "Loss at Iteration @ 626 is 2.118232250213623\n",
      "Loss at Iteration @ 627 is 2.02504825592041\n",
      "Loss at Iteration @ 628 is 2.2266342639923096\n",
      "Loss at Iteration @ 629 is 1.8328815698623657\n",
      "Loss at Iteration @ 630 is 2.386655807495117\n",
      "Loss at Iteration @ 631 is 2.0864102840423584\n",
      "Loss at Iteration @ 632 is 2.2974472045898438\n",
      "Loss at Iteration @ 633 is 2.489919424057007\n",
      "Loss at Iteration @ 634 is 2.1777524948120117\n",
      "Loss at Iteration @ 635 is 2.1234984397888184\n",
      "Loss at Iteration @ 636 is 2.0505611896514893\n",
      "Loss at Iteration @ 637 is 2.2031381130218506\n",
      "Loss at Iteration @ 638 is 2.1198184490203857\n",
      "Loss at Iteration @ 639 is 2.1385507583618164\n",
      "Loss at Iteration @ 640 is 2.1263620853424072\n",
      "Loss at Iteration @ 641 is 2.2439374923706055\n",
      "Loss at Iteration @ 642 is 2.317230463027954\n",
      "Loss at Iteration @ 643 is 2.635922908782959\n",
      "Loss at Iteration @ 644 is 2.2660694122314453\n",
      "Loss at Iteration @ 645 is 2.3199563026428223\n",
      "Loss at Iteration @ 646 is 2.390528440475464\n",
      "Loss at Iteration @ 647 is 2.1225507259368896\n",
      "Loss at Iteration @ 648 is 2.179225206375122\n",
      "Loss at Iteration @ 649 is 1.9237399101257324\n",
      "Loss at Iteration @ 650 is 2.23404598236084\n",
      "Loss at Iteration @ 651 is 2.1883037090301514\n",
      "Loss at Iteration @ 652 is 2.1048474311828613\n",
      "Loss at Iteration @ 653 is 1.8717159032821655\n",
      "Loss at Iteration @ 654 is 2.0467047691345215\n",
      "Loss at Iteration @ 655 is 2.1887614727020264\n",
      "Loss at Iteration @ 656 is 2.209094524383545\n",
      "Loss at Iteration @ 657 is 2.1696183681488037\n",
      "Loss at Iteration @ 658 is 2.2162609100341797\n",
      "Loss at Iteration @ 659 is 2.0894711017608643\n",
      "Loss at Iteration @ 660 is 2.10433030128479\n",
      "Loss at Iteration @ 661 is 2.2170772552490234\n",
      "Loss at Iteration @ 662 is 2.2030811309814453\n",
      "Loss at Iteration @ 663 is 2.0679943561553955\n",
      "Loss at Iteration @ 664 is 2.315040111541748\n",
      "Loss at Iteration @ 665 is 2.384047746658325\n",
      "Loss at Iteration @ 666 is 2.3096718788146973\n",
      "Loss at Iteration @ 667 is 2.0863943099975586\n",
      "Loss at Iteration @ 668 is 2.1804757118225098\n",
      "Loss at Iteration @ 669 is 2.2706565856933594\n",
      "Loss at Iteration @ 670 is 2.1397299766540527\n",
      "Loss at Iteration @ 671 is 2.16243577003479\n",
      "Loss at Iteration @ 672 is 2.3036134243011475\n",
      "Loss at Iteration @ 673 is 2.3257229328155518\n",
      "Loss at Iteration @ 674 is 2.254782199859619\n",
      "Loss at Iteration @ 675 is 2.0442848205566406\n",
      "Loss at Iteration @ 676 is 2.17155385017395\n",
      "Loss at Iteration @ 677 is 2.4787039756774902\n",
      "Loss at Iteration @ 678 is 2.412790536880493\n",
      "Loss at Iteration @ 679 is 2.151876926422119\n",
      "Loss at Iteration @ 680 is 2.3152081966400146\n",
      "Loss at Iteration @ 681 is 2.2528626918792725\n",
      "Loss at Iteration @ 682 is 2.437925100326538\n",
      "Loss at Iteration @ 683 is 2.39634108543396\n",
      "Loss at Iteration @ 684 is 2.4339513778686523\n",
      "Loss at Iteration @ 685 is 2.241398811340332\n",
      "Loss at Iteration @ 686 is 2.259931802749634\n",
      "Loss at Iteration @ 687 is 2.237611770629883\n",
      "Loss at Iteration @ 688 is 2.5507731437683105\n",
      "Loss at Iteration @ 689 is 2.2318756580352783\n",
      "Loss at Iteration @ 690 is 2.0819859504699707\n",
      "Loss at Iteration @ 691 is 2.289844274520874\n",
      "Loss at Iteration @ 692 is 2.1333467960357666\n",
      "Loss at Iteration @ 693 is 2.3979053497314453\n",
      "Loss at Iteration @ 694 is 2.2317545413970947\n",
      "Loss at Iteration @ 695 is 2.6268351078033447\n",
      "Loss at Iteration @ 696 is 2.3188560009002686\n",
      "Loss at Iteration @ 697 is 2.2195985317230225\n",
      "Loss at Iteration @ 698 is 2.2009615898132324\n",
      "Loss at Iteration @ 699 is 2.082984685897827\n",
      "Loss at Iteration @ 700 is 2.296058177947998\n",
      "Loss at Iteration @ 701 is 2.0041885375976562\n",
      "Loss at Iteration @ 702 is 2.227708578109741\n",
      "Loss at Iteration @ 703 is 2.267179250717163\n",
      "Loss at Iteration @ 704 is 2.090637445449829\n",
      "Loss at Iteration @ 705 is 2.1512041091918945\n",
      "Loss at Iteration @ 706 is 2.5839762687683105\n",
      "Loss at Iteration @ 707 is 2.2965853214263916\n",
      "Loss at Iteration @ 708 is 2.2213828563690186\n",
      "Loss at Iteration @ 709 is 2.481405735015869\n",
      "Loss at Iteration @ 710 is 2.216996192932129\n",
      "Loss at Iteration @ 711 is 2.1186294555664062\n",
      "Loss at Iteration @ 712 is 2.187708854675293\n",
      "Loss at Iteration @ 713 is 2.2486767768859863\n",
      "Loss at Iteration @ 714 is 2.0498855113983154\n",
      "Loss at Iteration @ 715 is 2.052629232406616\n",
      "Loss at Iteration @ 716 is 2.157588481903076\n",
      "Loss at Iteration @ 717 is 2.188873291015625\n",
      "Loss at Iteration @ 718 is 2.1782543659210205\n",
      "Loss at Iteration @ 719 is 2.298353433609009\n",
      "Loss at Iteration @ 720 is 2.2827863693237305\n",
      "Loss at Iteration @ 721 is 2.260334014892578\n",
      "Loss at Iteration @ 722 is 2.155803680419922\n",
      "Loss at Iteration @ 723 is 2.0983963012695312\n",
      "Loss at Iteration @ 724 is 2.497892141342163\n",
      "Loss at Iteration @ 725 is 2.0921640396118164\n",
      "Loss at Iteration @ 726 is 2.441176652908325\n",
      "Loss at Iteration @ 727 is 2.1703126430511475\n",
      "Loss at Iteration @ 728 is 2.344421863555908\n",
      "Loss at Iteration @ 729 is 2.3375067710876465\n",
      "Loss at Iteration @ 730 is 2.0638625621795654\n",
      "Loss at Iteration @ 731 is 2.383099317550659\n",
      "Loss at Iteration @ 732 is 2.27932071685791\n",
      "Loss at Iteration @ 733 is 2.3601937294006348\n",
      "Loss at Iteration @ 734 is 2.526660680770874\n",
      "Loss at Iteration @ 735 is 2.4724228382110596\n",
      "Loss at Iteration @ 736 is 2.2323222160339355\n",
      "Loss at Iteration @ 737 is 2.3942620754241943\n",
      "Loss at Iteration @ 738 is 2.0512735843658447\n",
      "Loss at Iteration @ 739 is 2.077695846557617\n",
      "Loss at Iteration @ 740 is 2.0069918632507324\n",
      "Loss at Iteration @ 741 is 2.220648765563965\n",
      "Loss at Iteration @ 742 is 2.286740779876709\n",
      "Loss at Iteration @ 743 is 2.3023178577423096\n",
      "Loss at Iteration @ 744 is 1.9653854370117188\n",
      "Loss at Iteration @ 745 is 2.179227590560913\n",
      "Loss at Iteration @ 746 is 2.276595115661621\n",
      "Loss at Iteration @ 747 is 2.3075711727142334\n",
      "Loss at Iteration @ 748 is 2.135545492172241\n",
      "Loss at Iteration @ 749 is 1.97352933883667\n",
      "Loss at Iteration @ 750 is 2.2165634632110596\n",
      "Loss at Iteration @ 751 is 2.204195737838745\n",
      "Loss at Iteration @ 752 is 2.4191997051239014\n",
      "Loss at Iteration @ 753 is 2.3722336292266846\n",
      "Loss at Iteration @ 754 is 2.2473297119140625\n",
      "Loss at Iteration @ 755 is 2.286252021789551\n",
      "Loss at Iteration @ 756 is 2.2085371017456055\n",
      "Loss at Iteration @ 757 is 2.4361677169799805\n",
      "Loss at Iteration @ 758 is 2.787051200866699\n",
      "Loss at Iteration @ 759 is 2.072293281555176\n",
      "Loss at Iteration @ 760 is 2.221149206161499\n",
      "Loss at Iteration @ 761 is 2.4058306217193604\n",
      "Loss at Iteration @ 762 is 2.230341672897339\n",
      "Loss at Iteration @ 763 is 2.104020833969116\n",
      "Loss at Iteration @ 764 is 1.9469478130340576\n",
      "Loss at Iteration @ 765 is 2.206727981567383\n",
      "Loss at Iteration @ 766 is 2.4706950187683105\n",
      "Loss at Iteration @ 767 is 2.3636422157287598\n",
      "Loss at Iteration @ 768 is 2.570413112640381\n",
      "Loss at Iteration @ 769 is 2.314824104309082\n",
      "Loss at Iteration @ 770 is 2.273799180984497\n",
      "Loss at Iteration @ 771 is 2.300808906555176\n",
      "Loss at Iteration @ 772 is 2.4306862354278564\n",
      "Loss at Iteration @ 773 is 2.263491153717041\n",
      "Loss at Iteration @ 774 is 1.9535943269729614\n",
      "Loss at Iteration @ 775 is 2.18707275390625\n",
      "Loss at Iteration @ 776 is 2.292020797729492\n",
      "Loss at Iteration @ 777 is 2.2923481464385986\n",
      "Loss at Iteration @ 778 is 2.0791685581207275\n",
      "Loss at Iteration @ 779 is 2.354259729385376\n",
      "Loss at Iteration @ 780 is 2.2869725227355957\n",
      "Loss at Iteration @ 781 is 2.0639560222625732\n",
      "Loss at Iteration @ 782 is 2.078352928161621\n",
      "Loss at Iteration @ 783 is 2.31264591217041\n",
      "Loss at Iteration @ 784 is 2.1544456481933594\n",
      "Loss at Iteration @ 785 is 2.3647854328155518\n",
      "Loss at Iteration @ 786 is 2.170801877975464\n",
      "Loss at Iteration @ 787 is 2.1772210597991943\n",
      "Loss at Iteration @ 788 is 1.8394813537597656\n",
      "Loss at Iteration @ 789 is 2.390152931213379\n",
      "Loss at Iteration @ 790 is 2.1955490112304688\n",
      "Loss at Iteration @ 791 is 2.343618631362915\n",
      "Loss at Iteration @ 792 is 2.3390212059020996\n",
      "Loss at Iteration @ 793 is 1.925115704536438\n",
      "Loss at Iteration @ 794 is 2.068314790725708\n",
      "Loss at Iteration @ 795 is 2.0012686252593994\n",
      "Loss at Iteration @ 796 is 2.2215535640716553\n",
      "Loss at Iteration @ 797 is 1.8960468769073486\n",
      "Loss at Iteration @ 798 is 2.1825904846191406\n",
      "Loss at Iteration @ 799 is 2.0523996353149414\n",
      "Loss at Iteration @ 800 is 2.237300157546997\n",
      "Loss at Iteration @ 801 is 2.2853102684020996\n",
      "Loss at Iteration @ 802 is 2.454326868057251\n",
      "Loss at Iteration @ 803 is 2.441453218460083\n",
      "Loss at Iteration @ 804 is 2.257750988006592\n",
      "Loss at Iteration @ 805 is 2.1234869956970215\n",
      "Loss at Iteration @ 806 is 2.3771889209747314\n",
      "Loss at Iteration @ 807 is 2.2166011333465576\n",
      "Loss at Iteration @ 808 is 2.313871145248413\n",
      "Loss at Iteration @ 809 is 2.54526424407959\n",
      "Loss at Iteration @ 810 is 2.385820150375366\n",
      "Loss at Iteration @ 811 is 2.1990532875061035\n",
      "Loss at Iteration @ 812 is 2.550475835800171\n",
      "Loss at Iteration @ 813 is 2.1628592014312744\n",
      "Loss at Iteration @ 814 is 2.3332784175872803\n",
      "Loss at Iteration @ 815 is 2.1449828147888184\n",
      "Loss at Iteration @ 816 is 2.1113667488098145\n",
      "Loss at Iteration @ 817 is 2.4054930210113525\n",
      "Loss at Iteration @ 818 is 2.138866901397705\n",
      "Loss at Iteration @ 819 is 2.2521750926971436\n",
      "Loss at Iteration @ 820 is 2.206744432449341\n",
      "Loss at Iteration @ 821 is 2.167522430419922\n",
      "Loss at Iteration @ 822 is 2.083235263824463\n",
      "Loss at Iteration @ 823 is 2.0165271759033203\n",
      "Loss at Iteration @ 824 is 2.086927652359009\n",
      "Loss at Iteration @ 825 is 2.1221868991851807\n",
      "Loss at Iteration @ 826 is 2.3321590423583984\n",
      "Loss at Iteration @ 827 is 2.3656630516052246\n",
      "Loss at Iteration @ 828 is 2.1302151679992676\n",
      "Loss at Iteration @ 829 is 2.538599967956543\n",
      "Loss at Iteration @ 830 is 2.123549699783325\n",
      "Loss at Iteration @ 831 is 2.4879987239837646\n",
      "Loss at Iteration @ 832 is 2.152425527572632\n",
      "Loss at Iteration @ 833 is 2.41672420501709\n",
      "Loss at Iteration @ 834 is 2.217271566390991\n",
      "Loss at Iteration @ 835 is 1.8363169431686401\n",
      "Loss at Iteration @ 836 is 2.3575093746185303\n",
      "Loss at Iteration @ 837 is 2.286499500274658\n",
      "Loss at Iteration @ 838 is 2.3146843910217285\n",
      "Loss at Iteration @ 839 is 2.0862927436828613\n",
      "Loss at Iteration @ 840 is 2.531850576400757\n",
      "Loss at Iteration @ 841 is 1.879115343093872\n",
      "Loss at Iteration @ 842 is 2.198347330093384\n",
      "Loss at Iteration @ 843 is 2.2553234100341797\n",
      "Loss at Iteration @ 844 is 2.4864296913146973\n",
      "Loss at Iteration @ 845 is 2.1962387561798096\n",
      "Loss at Iteration @ 846 is 2.120363712310791\n",
      "Loss at Iteration @ 847 is 2.174116611480713\n",
      "Loss at Iteration @ 848 is 2.225801944732666\n",
      "Loss at Iteration @ 849 is 2.3202991485595703\n",
      "Loss at Iteration @ 850 is 2.18662691116333\n",
      "Loss at Iteration @ 851 is 2.071979284286499\n",
      "Loss at Iteration @ 852 is 2.2053141593933105\n",
      "Loss at Iteration @ 853 is 2.2606773376464844\n",
      "Loss at Iteration @ 854 is 2.2052624225616455\n",
      "Loss at Iteration @ 855 is 2.1131749153137207\n",
      "Loss at Iteration @ 856 is 1.9175935983657837\n",
      "Loss at Iteration @ 857 is 2.2905049324035645\n",
      "Loss at Iteration @ 858 is 2.2019290924072266\n",
      "Loss at Iteration @ 859 is 2.255875825881958\n",
      "Loss at Iteration @ 860 is 2.1102631092071533\n",
      "Loss at Iteration @ 861 is 2.3777875900268555\n",
      "Loss at Iteration @ 862 is 2.2547597885131836\n",
      "Loss at Iteration @ 863 is 2.4422032833099365\n",
      "Loss at Iteration @ 864 is 2.286519765853882\n",
      "Loss at Iteration @ 865 is 2.308570146560669\n",
      "Loss at Iteration @ 866 is 2.3029417991638184\n",
      "Loss at Iteration @ 867 is 2.187877655029297\n",
      "Loss at Iteration @ 868 is 2.1618199348449707\n",
      "Loss at Iteration @ 869 is 2.3445446491241455\n",
      "Loss at Iteration @ 870 is 2.1954896450042725\n",
      "Loss at Iteration @ 871 is 2.22436261177063\n",
      "Loss at Iteration @ 872 is 2.3720691204071045\n",
      "Loss at Iteration @ 873 is 2.2335150241851807\n",
      "Loss at Iteration @ 874 is 2.576707363128662\n",
      "Loss at Iteration @ 875 is 2.1098947525024414\n",
      "Loss at Iteration @ 876 is 2.3600270748138428\n",
      "Loss at Iteration @ 877 is 2.524245023727417\n",
      "Loss at Iteration @ 878 is 2.1236982345581055\n",
      "Loss at Iteration @ 879 is 2.434197425842285\n",
      "Loss at Iteration @ 880 is 2.2071118354797363\n",
      "Loss at Iteration @ 881 is 2.440488815307617\n",
      "Loss at Iteration @ 882 is 2.222592353820801\n",
      "Loss at Iteration @ 883 is 2.138946771621704\n",
      "Loss at Iteration @ 884 is 2.1933813095092773\n",
      "Loss at Iteration @ 885 is 2.1653897762298584\n",
      "Loss at Iteration @ 886 is 2.351330280303955\n",
      "Loss at Iteration @ 887 is 2.0843656063079834\n",
      "Loss at Iteration @ 888 is 1.9969474077224731\n",
      "Loss at Iteration @ 889 is 1.9703342914581299\n",
      "Loss at Iteration @ 890 is 2.13984751701355\n",
      "Loss at Iteration @ 891 is 2.390599250793457\n",
      "Loss at Iteration @ 892 is 2.23797345161438\n",
      "Loss at Iteration @ 893 is 2.228419303894043\n",
      "Loss at Iteration @ 894 is 2.260770082473755\n",
      "Loss at Iteration @ 895 is 2.155646800994873\n",
      "Loss at Iteration @ 896 is 2.3408827781677246\n",
      "Loss at Iteration @ 897 is 2.2405829429626465\n",
      "Loss at Iteration @ 898 is 2.2354023456573486\n",
      "Loss at Iteration @ 899 is 2.2870240211486816\n",
      "Loss at Iteration @ 900 is 2.218332290649414\n",
      "Loss at Iteration @ 901 is 2.41683030128479\n",
      "Loss at Iteration @ 902 is 2.0980377197265625\n",
      "Loss at Iteration @ 903 is 2.680307149887085\n",
      "Loss at Iteration @ 904 is 2.203821897506714\n",
      "Loss at Iteration @ 905 is 2.3130252361297607\n",
      "Loss at Iteration @ 906 is 2.1217410564422607\n",
      "Loss at Iteration @ 907 is 2.157954216003418\n",
      "Loss at Iteration @ 908 is 2.337345600128174\n",
      "Loss at Iteration @ 909 is 2.4366753101348877\n",
      "Loss at Iteration @ 910 is 2.034438133239746\n",
      "Loss at Iteration @ 911 is 2.194915533065796\n",
      "Loss at Iteration @ 912 is 2.6755948066711426\n",
      "Loss at Iteration @ 913 is 2.1863362789154053\n",
      "Loss at Iteration @ 914 is 2.1088688373565674\n",
      "Loss at Iteration @ 915 is 2.36505126953125\n",
      "Loss at Iteration @ 916 is 2.0895984172821045\n",
      "Loss at Iteration @ 917 is 2.1509196758270264\n",
      "Loss at Iteration @ 918 is 2.0343596935272217\n",
      "Loss at Iteration @ 919 is 2.281320333480835\n",
      "Loss at Iteration @ 920 is 2.1729423999786377\n",
      "Loss at Iteration @ 921 is 2.124147653579712\n",
      "Loss at Iteration @ 922 is 2.3555197715759277\n",
      "Loss at Iteration @ 923 is 2.5680923461914062\n",
      "Loss at Iteration @ 924 is 2.1857190132141113\n",
      "Loss at Iteration @ 925 is 2.3899998664855957\n",
      "Loss at Iteration @ 926 is 1.9718929529190063\n",
      "Loss at Iteration @ 927 is 2.426104784011841\n",
      "Loss at Iteration @ 928 is 2.2617478370666504\n",
      "Loss at Iteration @ 929 is 2.112938642501831\n",
      "Loss at Iteration @ 930 is 2.343118190765381\n",
      "Loss at Iteration @ 931 is 2.1552040576934814\n",
      "Loss at Iteration @ 932 is 2.1493771076202393\n",
      "Loss at Iteration @ 933 is 2.386990547180176\n",
      "Loss at Iteration @ 934 is 2.2269742488861084\n",
      "Loss at Iteration @ 935 is 2.2880680561065674\n",
      "Loss at Iteration @ 936 is 2.1425912380218506\n",
      "Loss at Iteration @ 937 is 2.052119016647339\n",
      "Loss at Iteration @ 938 is 2.1969640254974365\n",
      "Loss at Iteration @ 939 is 2.236456871032715\n",
      "Loss at Iteration @ 940 is 2.42299747467041\n",
      "Loss at Iteration @ 941 is 2.233844041824341\n",
      "Loss at Iteration @ 942 is 2.2051496505737305\n",
      "Loss at Iteration @ 943 is 2.125089168548584\n",
      "Loss at Iteration @ 944 is 2.7464029788970947\n",
      "Loss at Iteration @ 945 is 2.156028985977173\n",
      "Loss at Iteration @ 946 is 2.3722636699676514\n",
      "Loss at Iteration @ 947 is 2.5098986625671387\n",
      "Loss at Iteration @ 948 is 2.5261075496673584\n",
      "Loss at Iteration @ 949 is 2.4791512489318848\n",
      "Loss at Iteration @ 950 is 2.1184237003326416\n",
      "Loss at Iteration @ 951 is 2.2385528087615967\n",
      "Loss at Iteration @ 952 is 1.991896152496338\n",
      "Loss at Iteration @ 953 is 2.042170524597168\n",
      "Loss at Iteration @ 954 is 2.1873667240142822\n",
      "Loss at Iteration @ 955 is 2.2503838539123535\n",
      "Loss at Iteration @ 956 is 2.4309322834014893\n",
      "Loss at Iteration @ 957 is 2.3181684017181396\n",
      "Loss at Iteration @ 958 is 2.4245617389678955\n",
      "Loss at Iteration @ 959 is 2.1997299194335938\n",
      "Loss at Iteration @ 960 is 2.467221736907959\n",
      "Loss at Iteration @ 961 is 2.188554525375366\n",
      "Loss at Iteration @ 962 is 2.2347614765167236\n",
      "Loss at Iteration @ 963 is 2.504284381866455\n",
      "Loss at Iteration @ 964 is 2.170142412185669\n",
      "Loss at Iteration @ 965 is 2.414152145385742\n",
      "Loss at Iteration @ 966 is 2.070265531539917\n",
      "Loss at Iteration @ 967 is 2.1957430839538574\n",
      "Loss at Iteration @ 968 is 2.0092761516571045\n",
      "Loss at Iteration @ 969 is 2.2107503414154053\n",
      "Loss at Iteration @ 970 is 2.3804256916046143\n",
      "Loss at Iteration @ 971 is 2.067655086517334\n",
      "Loss at Iteration @ 972 is 2.160900592803955\n",
      "Loss at Iteration @ 973 is 2.1967735290527344\n",
      "Loss at Iteration @ 974 is 2.484940528869629\n",
      "Loss at Iteration @ 975 is 2.0888805389404297\n",
      "Loss at Iteration @ 976 is 2.2731218338012695\n",
      "Loss at Iteration @ 977 is 2.3413658142089844\n",
      "Loss at Iteration @ 978 is 2.3225104808807373\n",
      "Loss at Iteration @ 979 is 1.985162377357483\n",
      "Loss at Iteration @ 980 is 2.236246347427368\n",
      "Loss at Iteration @ 981 is 2.260165214538574\n",
      "Loss at Iteration @ 982 is 2.0602002143859863\n",
      "Loss at Iteration @ 983 is 2.298516273498535\n",
      "Loss at Iteration @ 984 is 2.1695706844329834\n",
      "Loss at Iteration @ 985 is 2.4037442207336426\n",
      "Loss at Iteration @ 986 is 2.129998207092285\n",
      "Loss at Iteration @ 987 is 2.397688150405884\n",
      "Loss at Iteration @ 988 is 2.179985761642456\n",
      "Loss at Iteration @ 989 is 2.0835697650909424\n",
      "Loss at Iteration @ 990 is 2.322455644607544\n",
      "Loss at Iteration @ 991 is 2.2162587642669678\n",
      "Loss at Iteration @ 992 is 2.2890894412994385\n",
      "Loss at Iteration @ 993 is 2.324125051498413\n",
      "Loss at Iteration @ 994 is 2.2327675819396973\n",
      "Loss at Iteration @ 995 is 2.214693069458008\n",
      "Loss at Iteration @ 996 is 2.4452033042907715\n",
      "Loss at Iteration @ 997 is 2.3015668392181396\n",
      "Loss at Iteration @ 998 is 2.3016815185546875\n",
      "Loss at Iteration @ 999 is 2.177762746810913\n",
      "Loss at Iteration @ 1000 is 2.2482268810272217\n",
      "Loss at Iteration @ 1001 is 2.1976308822631836\n",
      "Loss at Iteration @ 1002 is 2.224872350692749\n",
      "Loss at Iteration @ 1003 is 2.1090805530548096\n",
      "Loss at Iteration @ 1004 is 2.442810297012329\n",
      "Loss at Iteration @ 1005 is 2.26226806640625\n",
      "Loss at Iteration @ 1006 is 1.9729599952697754\n",
      "Loss at Iteration @ 1007 is 2.2458059787750244\n",
      "Loss at Iteration @ 1008 is 2.3611972332000732\n",
      "Loss at Iteration @ 1009 is 2.349905252456665\n",
      "Loss at Iteration @ 1010 is 2.259162664413452\n",
      "Loss at Iteration @ 1011 is 2.2206671237945557\n",
      "Loss at Iteration @ 1012 is 2.4495716094970703\n",
      "Loss at Iteration @ 1013 is 2.2178850173950195\n",
      "Loss at Iteration @ 1014 is 2.1041972637176514\n",
      "Loss at Iteration @ 1015 is 2.026845693588257\n",
      "Loss at Iteration @ 1016 is 2.2687060832977295\n",
      "Loss at Iteration @ 1017 is 2.5017995834350586\n",
      "Loss at Iteration @ 1018 is 2.217505693435669\n",
      "Loss at Iteration @ 1019 is 2.022228240966797\n",
      "Loss at Iteration @ 1020 is 2.1435344219207764\n",
      "Loss at Iteration @ 1021 is 2.382178783416748\n",
      "Loss at Iteration @ 1022 is 2.0144898891448975\n",
      "Loss at Iteration @ 1023 is 1.9886444807052612\n",
      "Loss at Iteration @ 1024 is 2.092588186264038\n",
      "Loss at Iteration @ 1025 is 2.207954168319702\n",
      "Loss at Iteration @ 1026 is 1.9884660243988037\n",
      "Loss at Iteration @ 1027 is 2.292266607284546\n",
      "Loss at Iteration @ 1028 is 2.2600743770599365\n",
      "Loss at Iteration @ 1029 is 2.218475341796875\n",
      "Loss at Iteration @ 1030 is 2.189286231994629\n",
      "Loss at Iteration @ 1031 is 2.355757474899292\n",
      "Loss at Iteration @ 1032 is 2.1373209953308105\n",
      "Loss at Iteration @ 1033 is 2.1637303829193115\n",
      "Loss at Iteration @ 1034 is 2.472970485687256\n",
      "Loss at Iteration @ 1035 is 2.2153704166412354\n",
      "Loss at Iteration @ 1036 is 2.3515608310699463\n",
      "Loss at Iteration @ 1037 is 2.2932777404785156\n",
      "Loss at Iteration @ 1038 is 2.085007429122925\n",
      "Loss at Iteration @ 1039 is 2.087358236312866\n",
      "Loss at Iteration @ 1040 is 2.274827480316162\n",
      "Loss at Iteration @ 1041 is 2.3478522300720215\n",
      "Loss at Iteration @ 1042 is 2.238713502883911\n",
      "Loss at Iteration @ 1043 is 2.3148109912872314\n",
      "Loss at Iteration @ 1044 is 2.066352367401123\n",
      "Loss at Iteration @ 1045 is 1.8916566371917725\n",
      "Loss at Iteration @ 1046 is 2.2231688499450684\n",
      "Loss at Iteration @ 1047 is 2.257718801498413\n",
      "Loss at Iteration @ 1048 is 2.3155629634857178\n",
      "Loss at Iteration @ 1049 is 2.368035078048706\n",
      "Loss at Iteration @ 1050 is 2.177642583847046\n",
      "Loss at Iteration @ 1051 is 2.5384438037872314\n",
      "Loss at Iteration @ 1052 is 2.390235185623169\n",
      "Loss at Iteration @ 1053 is 2.2042319774627686\n",
      "Loss at Iteration @ 1054 is 2.338766098022461\n",
      "Loss at Iteration @ 1055 is 2.284881591796875\n",
      "Loss at Iteration @ 1056 is 2.26385235786438\n",
      "Loss at Iteration @ 1057 is 2.0225281715393066\n",
      "Loss at Iteration @ 1058 is 2.082212209701538\n",
      "Loss at Iteration @ 1059 is 2.266899824142456\n",
      "Loss at Iteration @ 1060 is 2.3737058639526367\n",
      "Loss at Iteration @ 1061 is 2.064147710800171\n",
      "Loss at Iteration @ 1062 is 2.439014434814453\n",
      "Loss at Iteration @ 1063 is 2.4740262031555176\n",
      "Loss at Iteration @ 1064 is 2.480647325515747\n",
      "Loss at Iteration @ 1065 is 2.2292540073394775\n",
      "Loss at Iteration @ 1066 is 2.3153889179229736\n",
      "Loss at Iteration @ 1067 is 2.010701894760132\n",
      "Loss at Iteration @ 1068 is 2.297947406768799\n",
      "Loss at Iteration @ 1069 is 2.1837778091430664\n",
      "Loss at Iteration @ 1070 is 2.535147190093994\n",
      "Loss at Iteration @ 1071 is 2.2615463733673096\n",
      "Loss at Iteration @ 1072 is 2.343750238418579\n",
      "Loss at Iteration @ 1073 is 2.3392250537872314\n",
      "Loss at Iteration @ 1074 is 2.241952896118164\n",
      "Loss at Iteration @ 1075 is 2.099119186401367\n",
      "Loss at Iteration @ 1076 is 2.3305606842041016\n",
      "Loss at Iteration @ 1077 is 2.3077542781829834\n",
      "Loss at Iteration @ 1078 is 2.095667600631714\n",
      "Loss at Iteration @ 1079 is 2.1301231384277344\n",
      "Loss at Iteration @ 1080 is 2.221519947052002\n",
      "Loss at Iteration @ 1081 is 2.2085726261138916\n",
      "Loss at Iteration @ 1082 is 2.3245606422424316\n",
      "Loss at Iteration @ 1083 is 2.234036445617676\n",
      "Loss at Iteration @ 1084 is 2.2637007236480713\n",
      "Loss at Iteration @ 1085 is 2.2151176929473877\n",
      "Loss at Iteration @ 1086 is 2.374554395675659\n",
      "Loss at Iteration @ 1087 is 2.1419100761413574\n",
      "Loss at Iteration @ 1088 is 2.173187494277954\n",
      "Loss at Iteration @ 1089 is 2.4727048873901367\n",
      "Loss at Iteration @ 1090 is 2.2315866947174072\n",
      "Loss at Iteration @ 1091 is 2.1686015129089355\n",
      "Loss at Iteration @ 1092 is 2.281035900115967\n",
      "Loss at Iteration @ 1093 is 2.222651481628418\n",
      "Loss at Iteration @ 1094 is 2.276939630508423\n",
      "Loss at Iteration @ 1095 is 2.232926368713379\n",
      "Loss at Iteration @ 1096 is 2.1722936630249023\n",
      "Loss at Iteration @ 1097 is 2.133910894393921\n",
      "Loss at Iteration @ 1098 is 2.2277607917785645\n",
      "Loss at Iteration @ 1099 is 2.294663906097412\n",
      "Loss at Iteration @ 1100 is 2.2605221271514893\n",
      "Loss at Iteration @ 1101 is 2.3700616359710693\n",
      "Loss at Iteration @ 1102 is 2.4692986011505127\n",
      "Loss at Iteration @ 1103 is 2.295008659362793\n",
      "Loss at Iteration @ 1104 is 2.2800562381744385\n",
      "Loss at Iteration @ 1105 is 2.319777727127075\n",
      "Loss at Iteration @ 1106 is 2.126119375228882\n",
      "Loss at Iteration @ 1107 is 1.9442507028579712\n",
      "Loss at Iteration @ 1108 is 2.235400915145874\n",
      "Loss at Iteration @ 1109 is 2.1181111335754395\n",
      "Loss at Iteration @ 1110 is 2.2271621227264404\n",
      "Loss at Iteration @ 1111 is 2.5354979038238525\n",
      "Loss at Iteration @ 1112 is 2.1240928173065186\n",
      "Loss at Iteration @ 1113 is 2.0232157707214355\n",
      "Loss at Iteration @ 1114 is 2.4227030277252197\n",
      "Loss at Iteration @ 1115 is 2.0238184928894043\n",
      "Loss at Iteration @ 1116 is 2.188370943069458\n",
      "Loss at Iteration @ 1117 is 2.207307815551758\n",
      "Loss at Iteration @ 1118 is 2.303375720977783\n",
      "Loss at Iteration @ 1119 is 2.3565332889556885\n",
      "Loss at Iteration @ 1120 is 2.2361700534820557\n",
      "Loss at Iteration @ 1121 is 2.5258121490478516\n",
      "Loss at Iteration @ 1122 is 1.7690551280975342\n",
      "Loss at Iteration @ 1123 is 2.408942222595215\n",
      "Loss at Iteration @ 1124 is 2.0962507724761963\n",
      "Loss at Iteration @ 1125 is 2.294735908508301\n",
      "Loss at Iteration @ 1126 is 2.3373453617095947\n",
      "Loss at Iteration @ 1127 is 2.367899179458618\n",
      "Loss at Iteration @ 1128 is 2.4138903617858887\n",
      "Loss at Iteration @ 1129 is 2.4416229724884033\n",
      "Loss at Iteration @ 1130 is 2.3301010131835938\n",
      "Loss at Iteration @ 1131 is 2.1638083457946777\n",
      "Loss at Iteration @ 1132 is 2.1411337852478027\n",
      "Loss at Iteration @ 1133 is 2.3032007217407227\n",
      "Loss at Iteration @ 1134 is 2.421769142150879\n",
      "Loss at Iteration @ 1135 is 2.1925787925720215\n",
      "Loss at Iteration @ 1136 is 1.972602128982544\n",
      "Loss at Iteration @ 1137 is 2.344573497772217\n",
      "Loss at Iteration @ 1138 is 2.3501460552215576\n",
      "Loss at Iteration @ 1139 is 2.4013404846191406\n",
      "Loss at Iteration @ 1140 is 2.014834403991699\n",
      "Loss at Iteration @ 1141 is 2.2921149730682373\n",
      "Loss at Iteration @ 1142 is 2.0172922611236572\n",
      "Loss at Iteration @ 1143 is 1.9089542627334595\n",
      "Loss at Iteration @ 1144 is 2.4425101280212402\n",
      "Loss at Iteration @ 1145 is 2.2916831970214844\n",
      "Loss at Iteration @ 1146 is 2.1231911182403564\n",
      "Loss at Iteration @ 1147 is 2.43617844581604\n",
      "Loss at Iteration @ 1148 is 2.2375845909118652\n",
      "Loss at Iteration @ 1149 is 2.0203590393066406\n",
      "Loss at Iteration @ 1150 is 2.2031092643737793\n",
      "Loss at Iteration @ 1151 is 1.9780908823013306\n",
      "Loss at Iteration @ 1152 is 2.287480354309082\n",
      "Loss at Iteration @ 1153 is 2.129274368286133\n",
      "Loss at Iteration @ 1154 is 2.145955801010132\n",
      "Loss at Iteration @ 1155 is 2.2094967365264893\n",
      "Loss at Iteration @ 1156 is 2.1763648986816406\n",
      "Loss at Iteration @ 1157 is 2.2516355514526367\n",
      "Loss at Iteration @ 1158 is 2.3151044845581055\n",
      "Loss at Iteration @ 1159 is 2.4009604454040527\n",
      "Loss at Iteration @ 1160 is 2.4878087043762207\n",
      "Loss at Iteration @ 1161 is 1.9115551710128784\n",
      "Loss at Iteration @ 1162 is 2.235633611679077\n",
      "Loss at Iteration @ 1163 is 2.1079375743865967\n",
      "Loss at Iteration @ 1164 is 2.2725558280944824\n",
      "Loss at Iteration @ 1165 is 2.2503247261047363\n",
      "Loss at Iteration @ 1166 is 2.2742977142333984\n",
      "Loss at Iteration @ 1167 is 2.6064536571502686\n",
      "Loss at Iteration @ 1168 is 2.0034773349761963\n",
      "Loss at Iteration @ 1169 is 2.3038899898529053\n",
      "Loss at Iteration @ 1170 is 2.1856677532196045\n",
      "Loss at Iteration @ 1171 is 2.0610504150390625\n",
      "Loss at Iteration @ 1172 is 2.0981087684631348\n",
      "Loss at Iteration @ 1173 is 2.3003387451171875\n",
      "Loss at Iteration @ 1174 is 2.2296149730682373\n",
      "Loss at Iteration @ 1175 is 2.2946813106536865\n",
      "Loss at Iteration @ 1176 is 2.3609845638275146\n",
      "Loss at Iteration @ 1177 is 2.2143163681030273\n",
      "Loss at Iteration @ 1178 is 2.1995809078216553\n",
      "Loss at Iteration @ 1179 is 1.9818472862243652\n",
      "Loss at Iteration @ 1180 is 2.2131590843200684\n",
      "Loss at Iteration @ 1181 is 1.9350980520248413\n",
      "Loss at Iteration @ 1182 is 2.190493583679199\n",
      "Loss at Iteration @ 1183 is 2.2023074626922607\n",
      "Loss at Iteration @ 1184 is 2.3219807147979736\n",
      "Loss at Iteration @ 1185 is 2.549480676651001\n",
      "Loss at Iteration @ 1186 is 2.69170880317688\n",
      "Loss at Iteration @ 1187 is 2.1719558238983154\n",
      "Loss at Iteration @ 1188 is 2.1935622692108154\n",
      "Loss at Iteration @ 1189 is 2.1592986583709717\n",
      "Loss at Iteration @ 1190 is 2.3658463954925537\n",
      "Loss at Iteration @ 1191 is 2.0885276794433594\n",
      "Loss at Iteration @ 1192 is 2.3671255111694336\n",
      "Loss at Iteration @ 1193 is 2.086028575897217\n",
      "Loss at Iteration @ 1194 is 1.8610745668411255\n",
      "Loss at Iteration @ 1195 is 2.178673505783081\n",
      "Loss at Iteration @ 1196 is 2.202836751937866\n",
      "Loss at Iteration @ 1197 is 2.246278762817383\n",
      "Loss at Iteration @ 1198 is 2.2205429077148438\n",
      "Loss at Iteration @ 1199 is 2.236147403717041\n",
      "Loss at Iteration @ 1200 is 2.294079542160034\n",
      "Loss at Iteration @ 1201 is 2.328171730041504\n",
      "Loss at Iteration @ 1202 is 2.0370678901672363\n",
      "Loss at Iteration @ 1203 is 2.3172919750213623\n",
      "Loss at Iteration @ 1204 is 2.1163902282714844\n",
      "Loss at Iteration @ 1205 is 2.317786455154419\n",
      "Loss at Iteration @ 1206 is 2.3485665321350098\n",
      "Loss at Iteration @ 1207 is 2.4138693809509277\n",
      "Loss at Iteration @ 1208 is 2.2244627475738525\n",
      "Loss at Iteration @ 1209 is 2.0281412601470947\n",
      "Loss at Iteration @ 1210 is 2.207200527191162\n",
      "Loss at Iteration @ 1211 is 2.2161502838134766\n",
      "Loss at Iteration @ 1212 is 2.3819632530212402\n",
      "Loss at Iteration @ 1213 is 2.0197196006774902\n",
      "Loss at Iteration @ 1214 is 2.305924415588379\n",
      "Loss at Iteration @ 1215 is 2.163800001144409\n",
      "Loss at Iteration @ 1216 is 2.285098075866699\n",
      "Loss at Iteration @ 1217 is 2.5886216163635254\n",
      "Loss at Iteration @ 1218 is 2.2763898372650146\n",
      "Loss at Iteration @ 1219 is 2.400160074234009\n",
      "Loss at Iteration @ 1220 is 2.213192939758301\n",
      "Loss at Iteration @ 1221 is 2.2537295818328857\n",
      "Loss at Iteration @ 1222 is 2.2096827030181885\n",
      "Loss at Iteration @ 1223 is 2.2058680057525635\n",
      "Loss at Iteration @ 1224 is 2.1996419429779053\n",
      "Loss at Iteration @ 1225 is 2.519449472427368\n",
      "Loss at Iteration @ 1226 is 2.3618452548980713\n",
      "Loss at Iteration @ 1227 is 2.2569801807403564\n",
      "Loss at Iteration @ 1228 is 2.3009650707244873\n",
      "Loss at Iteration @ 1229 is 2.0552077293395996\n",
      "Loss at Iteration @ 1230 is 2.536130666732788\n",
      "Loss at Iteration @ 1231 is 2.2065021991729736\n",
      "Loss at Iteration @ 1232 is 2.07965350151062\n",
      "Loss at Iteration @ 1233 is 2.2889513969421387\n",
      "Loss at Iteration @ 1234 is 2.7911264896392822\n",
      "Loss at Iteration @ 1235 is 2.4042422771453857\n",
      "Loss at Iteration @ 1236 is 2.0034196376800537\n",
      "Loss at Iteration @ 1237 is 2.1517837047576904\n",
      "Loss at Iteration @ 1238 is 2.172067880630493\n",
      "Loss at Iteration @ 1239 is 2.3979671001434326\n",
      "Loss at Iteration @ 1240 is 2.3310818672180176\n",
      "Loss at Iteration @ 1241 is 2.374300718307495\n",
      "Loss at Iteration @ 1242 is 2.1510841846466064\n",
      "Loss at Iteration @ 1243 is 2.232611894607544\n",
      "Loss at Iteration @ 1244 is 2.1560263633728027\n",
      "Loss at Iteration @ 1245 is 2.081911325454712\n",
      "Loss at Iteration @ 1246 is 2.302043914794922\n",
      "Loss at Iteration @ 1247 is 2.159745216369629\n",
      "Loss at Iteration @ 1248 is 2.174734354019165\n",
      "Loss at Iteration @ 1249 is 2.2365872859954834\n",
      "Loss at Iteration @ 1250 is 2.02256441116333\n",
      "Loss at Iteration @ 1251 is 2.334855794906616\n",
      "Loss at Iteration @ 1252 is 1.8945696353912354\n",
      "Loss at Iteration @ 1253 is 2.4742679595947266\n",
      "Loss at Iteration @ 1254 is 2.1444027423858643\n",
      "Loss at Iteration @ 1255 is 2.1912713050842285\n",
      "Loss at Iteration @ 1256 is 2.1287786960601807\n",
      "Loss at Iteration @ 1257 is 2.076472520828247\n",
      "Loss at Iteration @ 1258 is 2.285428762435913\n",
      "Loss at Iteration @ 1259 is 2.1916890144348145\n",
      "Loss at Iteration @ 1260 is 2.3356194496154785\n",
      "Loss at Iteration @ 1261 is 2.4593210220336914\n",
      "Loss at Iteration @ 1262 is 2.1950788497924805\n",
      "Loss at Iteration @ 1263 is 2.205803632736206\n",
      "Loss at Iteration @ 1264 is 2.6109001636505127\n",
      "Loss at Iteration @ 1265 is 2.3692097663879395\n",
      "Loss at Iteration @ 1266 is 2.38368821144104\n",
      "Loss at Iteration @ 1267 is 2.0712947845458984\n",
      "Loss at Iteration @ 1268 is 2.3246898651123047\n",
      "Loss at Iteration @ 1269 is 2.3438963890075684\n",
      "Loss at Iteration @ 1270 is 2.2315618991851807\n",
      "Loss at Iteration @ 1271 is 2.4175169467926025\n",
      "Loss at Iteration @ 1272 is 2.1699583530426025\n",
      "Loss at Iteration @ 1273 is 2.445009469985962\n",
      "Loss at Iteration @ 1274 is 2.4664032459259033\n",
      "Loss at Iteration @ 1275 is 2.2560782432556152\n",
      "Loss at Iteration @ 1276 is 2.381456136703491\n",
      "Loss at Iteration @ 1277 is 1.9780237674713135\n",
      "Loss at Iteration @ 1278 is 2.564192533493042\n",
      "Loss at Iteration @ 1279 is 2.2843539714813232\n",
      "Loss at Iteration @ 1280 is 2.199671983718872\n",
      "Loss at Iteration @ 1281 is 2.1808106899261475\n",
      "Loss at Iteration @ 1282 is 2.5004072189331055\n",
      "Loss at Iteration @ 1283 is 2.474179744720459\n",
      "Loss at Iteration @ 1284 is 2.1882164478302\n",
      "Loss at Iteration @ 1285 is 2.3167309761047363\n",
      "Loss at Iteration @ 1286 is 2.1679797172546387\n",
      "Loss at Iteration @ 1287 is 2.131622076034546\n",
      "Loss at Iteration @ 1288 is 2.0288684368133545\n",
      "Loss at Iteration @ 1289 is 2.1079015731811523\n",
      "Loss at Iteration @ 1290 is 2.095319986343384\n",
      "Loss at Iteration @ 1291 is 2.1707069873809814\n",
      "Loss at Iteration @ 1292 is 2.103203773498535\n",
      "Loss at Iteration @ 1293 is 2.300536870956421\n",
      "Loss at Iteration @ 1294 is 1.8291813135147095\n",
      "Loss at Iteration @ 1295 is 2.181896448135376\n",
      "Loss at Iteration @ 1296 is 2.0289177894592285\n",
      "Loss at Iteration @ 1297 is 2.1640777587890625\n",
      "Loss at Iteration @ 1298 is 2.384469985961914\n",
      "Loss at Iteration @ 1299 is 2.327843189239502\n",
      "Loss at Iteration @ 1300 is 2.399296522140503\n",
      "Loss at Iteration @ 1301 is 2.333573341369629\n",
      "Loss at Iteration @ 1302 is 2.620480537414551\n",
      "Loss at Iteration @ 1303 is 2.051017999649048\n",
      "Loss at Iteration @ 1304 is 2.1689164638519287\n",
      "Loss at Iteration @ 1305 is 2.2178876399993896\n",
      "Loss at Iteration @ 1306 is 2.469722032546997\n",
      "Loss at Iteration @ 1307 is 2.295276641845703\n",
      "Loss at Iteration @ 1308 is 2.2552969455718994\n",
      "Loss at Iteration @ 1309 is 2.4778902530670166\n",
      "Loss at Iteration @ 1310 is 2.271977663040161\n",
      "Loss at Iteration @ 1311 is 2.567671298980713\n",
      "Loss at Iteration @ 1312 is 2.1333420276641846\n",
      "Loss at Iteration @ 1313 is 2.3032243251800537\n",
      "Loss at Iteration @ 1314 is 2.1199402809143066\n",
      "Loss at Iteration @ 1315 is 2.141047239303589\n",
      "Loss at Iteration @ 1316 is 2.359943389892578\n",
      "Loss at Iteration @ 1317 is 2.1678547859191895\n",
      "Loss at Iteration @ 1318 is 2.1210761070251465\n",
      "Loss at Iteration @ 1319 is 2.130396604537964\n",
      "Loss at Iteration @ 1320 is 2.360957145690918\n",
      "Loss at Iteration @ 1321 is 2.082261562347412\n",
      "Loss at Iteration @ 1322 is 2.2355053424835205\n",
      "Loss at Iteration @ 1323 is 2.2193992137908936\n",
      "Loss at Iteration @ 1324 is 2.3183987140655518\n",
      "Loss at Iteration @ 1325 is 2.1348092555999756\n",
      "Loss at Iteration @ 1326 is 2.0853803157806396\n",
      "Loss at Iteration @ 1327 is 2.1359918117523193\n",
      "Loss at Iteration @ 1328 is 2.2732813358306885\n",
      "Loss at Iteration @ 1329 is 2.282489538192749\n",
      "Loss at Iteration @ 1330 is 2.1660218238830566\n",
      "Loss at Iteration @ 1331 is 2.0137524604797363\n",
      "Loss at Iteration @ 1332 is 2.285602569580078\n",
      "Loss at Iteration @ 1333 is 2.0663857460021973\n",
      "Loss at Iteration @ 1334 is 2.498065710067749\n",
      "Loss at Iteration @ 1335 is 2.0106589794158936\n",
      "Loss at Iteration @ 1336 is 2.1324832439422607\n",
      "Loss at Iteration @ 1337 is 2.2468247413635254\n",
      "Loss at Iteration @ 1338 is 2.253556489944458\n",
      "Loss at Iteration @ 1339 is 2.086575508117676\n",
      "Loss at Iteration @ 1340 is 2.1810381412506104\n",
      "Loss at Iteration @ 1341 is 1.9287832975387573\n",
      "Loss at Iteration @ 1342 is 2.3558578491210938\n",
      "Loss at Iteration @ 1343 is 2.507819414138794\n",
      "Loss at Iteration @ 1344 is 2.501692056655884\n",
      "Loss at Iteration @ 1345 is 2.188230037689209\n",
      "Loss at Iteration @ 1346 is 2.2470927238464355\n",
      "Loss at Iteration @ 1347 is 2.0448732376098633\n",
      "Loss at Iteration @ 1348 is 2.3473286628723145\n",
      "Loss at Iteration @ 1349 is 2.4263925552368164\n",
      "Loss at Iteration @ 1350 is 2.2817718982696533\n",
      "Loss at Iteration @ 1351 is 2.583106279373169\n",
      "Loss at Iteration @ 1352 is 2.0006258487701416\n",
      "Loss at Iteration @ 1353 is 2.1824429035186768\n",
      "Loss at Iteration @ 1354 is 2.262129306793213\n",
      "Loss at Iteration @ 1355 is 2.32781720161438\n",
      "Loss at Iteration @ 1356 is 2.4437599182128906\n",
      "Loss at Iteration @ 1357 is 2.1132991313934326\n",
      "Loss at Iteration @ 1358 is 2.1765623092651367\n",
      "Loss at Iteration @ 1359 is 2.0485498905181885\n",
      "Loss at Iteration @ 1360 is 2.2118594646453857\n",
      "Loss at Iteration @ 1361 is 2.021696090698242\n",
      "Loss at Iteration @ 1362 is 2.307778835296631\n",
      "Loss at Iteration @ 1363 is 2.2112984657287598\n",
      "Loss at Iteration @ 1364 is 2.195747137069702\n",
      "Loss at Iteration @ 1365 is 2.2938575744628906\n",
      "Loss at Iteration @ 1366 is 2.3035614490509033\n",
      "Loss at Iteration @ 1367 is 2.307863712310791\n",
      "Loss at Iteration @ 1368 is 2.15389084815979\n",
      "Loss at Iteration @ 1369 is 2.458282709121704\n",
      "Loss at Iteration @ 1370 is 2.2954347133636475\n",
      "Loss at Iteration @ 1371 is 2.144089698791504\n",
      "Loss at Iteration @ 1372 is 2.279954433441162\n",
      "Loss at Iteration @ 1373 is 2.362786293029785\n",
      "Loss at Iteration @ 1374 is 2.1477067470550537\n",
      "Loss at Iteration @ 1375 is 2.2405662536621094\n",
      "Loss at Iteration @ 1376 is 2.4674723148345947\n",
      "Loss at Iteration @ 1377 is 2.220156192779541\n",
      "Loss at Iteration @ 1378 is 2.377680540084839\n",
      "Loss at Iteration @ 1379 is 2.101799249649048\n",
      "Loss at Iteration @ 1380 is 2.2499215602874756\n",
      "Loss at Iteration @ 1381 is 2.2659852504730225\n",
      "Loss at Iteration @ 1382 is 2.3810653686523438\n",
      "Loss at Iteration @ 1383 is 2.43204927444458\n",
      "Loss at Iteration @ 1384 is 2.225193738937378\n",
      "Loss at Iteration @ 1385 is 2.151419162750244\n",
      "Loss at Iteration @ 1386 is 1.884377360343933\n",
      "Loss at Iteration @ 1387 is 2.5121002197265625\n",
      "Loss at Iteration @ 1388 is 2.3351833820343018\n",
      "Loss at Iteration @ 1389 is 2.18320369720459\n",
      "Loss at Iteration @ 1390 is 2.052609443664551\n",
      "Loss at Iteration @ 1391 is 2.228739023208618\n",
      "Loss at Iteration @ 1392 is 2.442873239517212\n",
      "Loss at Iteration @ 1393 is 2.1973822116851807\n",
      "Loss at Iteration @ 1394 is 2.1244146823883057\n",
      "Loss at Iteration @ 1395 is 2.1928484439849854\n",
      "Loss at Iteration @ 1396 is 1.9623929262161255\n",
      "Loss at Iteration @ 1397 is 2.1478142738342285\n",
      "Loss at Iteration @ 1398 is 2.3293075561523438\n",
      "Loss at Iteration @ 1399 is 2.109361410140991\n",
      "Loss at Iteration @ 1400 is 2.2892956733703613\n",
      "Loss at Iteration @ 1401 is 2.502772808074951\n",
      "Loss at Iteration @ 1402 is 2.1167490482330322\n",
      "Loss at Iteration @ 1403 is 2.3609702587127686\n",
      "Loss at Iteration @ 1404 is 2.279109001159668\n",
      "Loss at Iteration @ 1405 is 2.1255381107330322\n",
      "Loss at Iteration @ 1406 is 2.339543581008911\n",
      "Loss at Iteration @ 1407 is 2.1767830848693848\n",
      "Loss at Iteration @ 1408 is 2.5823557376861572\n",
      "Loss at Iteration @ 1409 is 2.4813482761383057\n",
      "Loss at Iteration @ 1410 is 2.4478554725646973\n",
      "Loss at Iteration @ 1411 is 2.1054718494415283\n",
      "Loss at Iteration @ 1412 is 2.2226638793945312\n",
      "Loss at Iteration @ 1413 is 2.4926223754882812\n",
      "Loss at Iteration @ 1414 is 2.050598382949829\n",
      "Loss at Iteration @ 1415 is 2.254662036895752\n",
      "Loss at Iteration @ 1416 is 2.4064135551452637\n",
      "Loss at Iteration @ 1417 is 2.1093475818634033\n",
      "Loss at Iteration @ 1418 is 2.222850799560547\n",
      "Loss at Iteration @ 1419 is 2.1551592350006104\n",
      "Loss at Iteration @ 1420 is 2.1655378341674805\n",
      "Loss at Iteration @ 1421 is 2.2614400386810303\n",
      "Loss at Iteration @ 1422 is 2.3615126609802246\n",
      "Loss at Iteration @ 1423 is 2.2381844520568848\n",
      "Loss at Iteration @ 1424 is 2.058519124984741\n",
      "Loss at Iteration @ 1425 is 1.9560505151748657\n",
      "Loss at Iteration @ 1426 is 2.4483630657196045\n",
      "Loss at Iteration @ 1427 is 2.2978689670562744\n",
      "Loss at Iteration @ 1428 is 2.485938310623169\n",
      "Loss at Iteration @ 1429 is 2.1535632610321045\n",
      "Loss at Iteration @ 1430 is 2.1947169303894043\n",
      "Loss at Iteration @ 1431 is 2.187495470046997\n",
      "Loss at Iteration @ 1432 is 2.488187789916992\n",
      "Loss at Iteration @ 1433 is 2.149182081222534\n",
      "Loss at Iteration @ 1434 is 2.125239849090576\n",
      "Loss at Iteration @ 1435 is 2.284435987472534\n",
      "Loss at Iteration @ 1436 is 2.242039918899536\n",
      "Loss at Iteration @ 1437 is 2.2304129600524902\n",
      "Loss at Iteration @ 1438 is 2.2907512187957764\n",
      "Loss at Iteration @ 1439 is 2.1202187538146973\n",
      "Loss at Iteration @ 1440 is 2.28533673286438\n",
      "Loss at Iteration @ 1441 is 2.3171334266662598\n",
      "Loss at Iteration @ 1442 is 2.2019031047821045\n",
      "Loss at Iteration @ 1443 is 2.358144998550415\n",
      "Loss at Iteration @ 1444 is 1.995323896408081\n",
      "Loss at Iteration @ 1445 is 2.2340173721313477\n",
      "Loss at Iteration @ 1446 is 2.4070358276367188\n",
      "Loss at Iteration @ 1447 is 2.296767473220825\n",
      "Loss at Iteration @ 1448 is 2.2124061584472656\n",
      "Loss at Iteration @ 1449 is 2.3147404193878174\n",
      "Loss at Iteration @ 1450 is 2.1427903175354004\n",
      "Loss at Iteration @ 1451 is 2.16424822807312\n",
      "Loss at Iteration @ 1452 is 2.1767032146453857\n",
      "Loss at Iteration @ 1453 is 2.352130174636841\n",
      "Loss at Iteration @ 1454 is 2.0540919303894043\n",
      "Loss at Iteration @ 1455 is 2.18180513381958\n",
      "Loss at Iteration @ 1456 is 2.289172649383545\n",
      "Loss at Iteration @ 1457 is 2.188906192779541\n",
      "Loss at Iteration @ 1458 is 2.431851625442505\n",
      "Loss at Iteration @ 1459 is 2.2330448627471924\n",
      "Loss at Iteration @ 1460 is 2.4628348350524902\n",
      "Loss at Iteration @ 1461 is 2.131088972091675\n",
      "Loss at Iteration @ 1462 is 2.3443443775177\n",
      "Loss at Iteration @ 1463 is 2.0391032695770264\n",
      "Loss at Iteration @ 1464 is 2.084519624710083\n",
      "Loss at Iteration @ 1465 is 2.300940990447998\n",
      "Loss at Iteration @ 1466 is 2.062230110168457\n",
      "Loss at Iteration @ 1467 is 2.285386562347412\n",
      "Loss at Iteration @ 1468 is 2.2140591144561768\n",
      "Loss at Iteration @ 1469 is 2.282041549682617\n",
      "Loss at Iteration @ 1470 is 2.5432779788970947\n",
      "Loss at Iteration @ 1471 is 2.2966830730438232\n",
      "Loss at Iteration @ 1472 is 2.030073881149292\n",
      "Loss at Iteration @ 1473 is 2.2185275554656982\n",
      "Loss at Iteration @ 1474 is 2.293726682662964\n",
      "Loss at Iteration @ 1475 is 2.048295497894287\n",
      "Loss at Iteration @ 1476 is 2.267756462097168\n",
      "Loss at Iteration @ 1477 is 2.0555026531219482\n",
      "Loss at Iteration @ 1478 is 2.349999189376831\n",
      "Loss at Iteration @ 1479 is 2.233091115951538\n",
      "Loss at Iteration @ 1480 is 2.519040107727051\n",
      "Loss at Iteration @ 1481 is 2.3130569458007812\n",
      "Loss at Iteration @ 1482 is 2.198561668395996\n",
      "Loss at Iteration @ 1483 is 2.1663143634796143\n",
      "Loss at Iteration @ 1484 is 2.384398937225342\n",
      "Loss at Iteration @ 1485 is 1.9399569034576416\n",
      "Loss at Iteration @ 1486 is 2.3075459003448486\n",
      "Loss at Iteration @ 1487 is 2.144834518432617\n",
      "Loss at Iteration @ 1488 is 2.2035622596740723\n",
      "Loss at Iteration @ 1489 is 2.2114696502685547\n",
      "Loss at Iteration @ 1490 is 2.0729520320892334\n",
      "Loss at Iteration @ 1491 is 2.257333993911743\n",
      "Loss at Iteration @ 1492 is 2.305581569671631\n",
      "Loss at Iteration @ 1493 is 1.9317052364349365\n",
      "Loss at Iteration @ 1494 is 2.289538860321045\n",
      "Loss at Iteration @ 1495 is 2.4686965942382812\n",
      "Loss at Iteration @ 1496 is 2.383622884750366\n",
      "Loss at Iteration @ 1497 is 2.1798555850982666\n",
      "Loss at Iteration @ 1498 is 2.130030870437622\n",
      "Loss at Iteration @ 1499 is 2.23452091217041\n",
      "Loss at Iteration @ 1500 is 2.0682663917541504\n",
      "Loss at Iteration @ 1501 is 2.405381441116333\n",
      "Loss at Iteration @ 1502 is 2.2575738430023193\n",
      "Loss at Iteration @ 1503 is 2.27644419670105\n",
      "Loss at Iteration @ 1504 is 2.092643976211548\n",
      "Loss at Iteration @ 1505 is 2.402031421661377\n",
      "Loss at Iteration @ 1506 is 1.9946296215057373\n",
      "Loss at Iteration @ 1507 is 2.137209892272949\n",
      "Loss at Iteration @ 1508 is 1.9060354232788086\n",
      "Loss at Iteration @ 1509 is 2.129220724105835\n",
      "Loss at Iteration @ 1510 is 2.1618845462799072\n",
      "Loss at Iteration @ 1511 is 2.402150869369507\n",
      "Loss at Iteration @ 1512 is 2.0191657543182373\n",
      "Loss at Iteration @ 1513 is 2.2543070316314697\n",
      "Loss at Iteration @ 1514 is 2.2079224586486816\n",
      "Loss at Iteration @ 1515 is 2.360637903213501\n",
      "Loss at Iteration @ 1516 is 2.40134596824646\n",
      "Loss at Iteration @ 1517 is 2.182234764099121\n",
      "Loss at Iteration @ 1518 is 2.4023470878601074\n",
      "Loss at Iteration @ 1519 is 1.9230382442474365\n",
      "Loss at Iteration @ 1520 is 2.37493896484375\n",
      "Loss at Iteration @ 1521 is 1.9152010679244995\n",
      "Loss at Iteration @ 1522 is 2.1757891178131104\n",
      "Loss at Iteration @ 1523 is 2.2719180583953857\n",
      "Loss at Iteration @ 1524 is 2.140475273132324\n",
      "Loss at Iteration @ 1525 is 2.4051272869110107\n",
      "Loss at Iteration @ 1526 is 2.2412033081054688\n",
      "Loss at Iteration @ 1527 is 2.206127405166626\n",
      "Loss at Iteration @ 1528 is 2.115861654281616\n",
      "Loss at Iteration @ 1529 is 1.8967952728271484\n",
      "Loss at Iteration @ 1530 is 2.1674091815948486\n",
      "Loss at Iteration @ 1531 is 2.152475357055664\n",
      "Loss at Iteration @ 1532 is 2.142522096633911\n",
      "Loss at Iteration @ 1533 is 2.2152082920074463\n",
      "Loss at Iteration @ 1534 is 1.9544775485992432\n",
      "Loss at Iteration @ 1535 is 2.327298641204834\n",
      "Loss at Iteration @ 1536 is 2.3568496704101562\n",
      "Loss at Iteration @ 1537 is 2.253493547439575\n",
      "Loss at Iteration @ 1538 is 2.130741596221924\n",
      "Loss at Iteration @ 1539 is 2.242793560028076\n",
      "Loss at Iteration @ 1540 is 2.539289712905884\n",
      "Loss at Iteration @ 1541 is 2.553074598312378\n",
      "Loss at Iteration @ 1542 is 2.373755931854248\n",
      "Loss at Iteration @ 1543 is 2.0438919067382812\n",
      "Loss at Iteration @ 1544 is 2.252051830291748\n",
      "Loss at Iteration @ 1545 is 2.0565378665924072\n",
      "Loss at Iteration @ 1546 is 2.0405385494232178\n",
      "Loss at Iteration @ 1547 is 2.5201287269592285\n",
      "Loss at Iteration @ 1548 is 2.505434513092041\n",
      "Loss at Iteration @ 1549 is 2.2000033855438232\n",
      "Loss at Iteration @ 1550 is 2.291647434234619\n",
      "Loss at Iteration @ 1551 is 2.2501587867736816\n",
      "Loss at Iteration @ 1552 is 2.2820863723754883\n",
      "Loss at Iteration @ 1553 is 2.355304002761841\n",
      "Loss at Iteration @ 1554 is 2.427159070968628\n",
      "Loss at Iteration @ 1555 is 2.2606699466705322\n",
      "Loss at Iteration @ 1556 is 2.417616128921509\n",
      "Loss at Iteration @ 1557 is 2.519914150238037\n",
      "Loss at Iteration @ 1558 is 2.0753633975982666\n",
      "Loss at Iteration @ 1559 is 2.064486265182495\n",
      "Loss at Iteration @ 1560 is 2.2385027408599854\n",
      "Loss at Iteration @ 1561 is 2.1398305892944336\n",
      "Loss at Iteration @ 1562 is 2.3574914932250977\n",
      "Loss at Iteration @ 1563 is 2.2240688800811768\n",
      "Loss at Iteration @ 1564 is 2.333538770675659\n",
      "Loss at Iteration @ 1565 is 2.0706162452697754\n",
      "Loss at Iteration @ 1566 is 2.060741424560547\n",
      "Loss at Iteration @ 1567 is 2.14151668548584\n",
      "Loss at Iteration @ 1568 is 2.3717005252838135\n",
      "Loss at Iteration @ 1569 is 2.4039292335510254\n",
      "Loss at Iteration @ 1570 is 2.4214723110198975\n",
      "Loss at Iteration @ 1571 is 2.20662522315979\n",
      "Loss at Iteration @ 1572 is 2.3693482875823975\n",
      "Loss at Iteration @ 1573 is 2.3196678161621094\n",
      "Loss at Iteration @ 1574 is 2.1849381923675537\n",
      "Loss at Iteration @ 1575 is 2.3758394718170166\n",
      "Loss at Iteration @ 1576 is 2.6524949073791504\n",
      "Loss at Iteration @ 1577 is 2.4781792163848877\n",
      "Loss at Iteration @ 1578 is 2.2203030586242676\n",
      "Loss at Iteration @ 1579 is 2.371213436126709\n",
      "Loss at Iteration @ 1580 is 2.080501079559326\n",
      "Loss at Iteration @ 1581 is 2.2984867095947266\n",
      "Loss at Iteration @ 1582 is 2.0426950454711914\n",
      "Loss at Iteration @ 1583 is 2.2605512142181396\n",
      "Loss at Iteration @ 1584 is 2.4195358753204346\n",
      "Loss at Iteration @ 1585 is 2.234684467315674\n",
      "Loss at Iteration @ 1586 is 2.2235748767852783\n",
      "Loss at Iteration @ 1587 is 1.9933452606201172\n",
      "Loss at Iteration @ 1588 is 2.259831666946411\n",
      "Loss at Iteration @ 1589 is 2.4333276748657227\n",
      "Loss at Iteration @ 1590 is 2.2356772422790527\n",
      "Loss at Iteration @ 1591 is 2.193331241607666\n",
      "Loss at Iteration @ 1592 is 2.0733728408813477\n",
      "Loss at Iteration @ 1593 is 2.2856786251068115\n",
      "Loss at Iteration @ 1594 is 2.243722915649414\n",
      "Loss at Iteration @ 1595 is 2.219120502471924\n",
      "Loss at Iteration @ 1596 is 2.1320512294769287\n",
      "Loss at Iteration @ 1597 is 2.3697915077209473\n",
      "Loss at Iteration @ 1598 is 2.2113218307495117\n",
      "Loss at Iteration @ 1599 is 2.3455381393432617\n",
      "Loss at Iteration @ 1600 is 2.467733860015869\n",
      "Loss at Iteration @ 1601 is 2.177574872970581\n",
      "Loss at Iteration @ 1602 is 2.1871211528778076\n",
      "Loss at Iteration @ 1603 is 2.420088052749634\n",
      "Loss at Iteration @ 1604 is 2.480846405029297\n",
      "Loss at Iteration @ 1605 is 2.4840140342712402\n",
      "Loss at Iteration @ 1606 is 2.001793622970581\n",
      "Loss at Iteration @ 1607 is 2.1656503677368164\n",
      "Loss at Iteration @ 1608 is 2.166063070297241\n",
      "Loss at Iteration @ 1609 is 2.3581619262695312\n",
      "Loss at Iteration @ 1610 is 2.336759567260742\n",
      "Loss at Iteration @ 1611 is 2.5272066593170166\n",
      "Loss at Iteration @ 1612 is 2.0557448863983154\n",
      "Loss at Iteration @ 1613 is 2.1597330570220947\n",
      "Loss at Iteration @ 1614 is 2.297816753387451\n",
      "Loss at Iteration @ 1615 is 2.226905107498169\n",
      "Loss at Iteration @ 1616 is 2.1062381267547607\n",
      "Loss at Iteration @ 1617 is 2.2571840286254883\n",
      "Loss at Iteration @ 1618 is 1.9904251098632812\n",
      "Loss at Iteration @ 1619 is 2.3003499507904053\n",
      "Loss at Iteration @ 1620 is 2.407249927520752\n",
      "Loss at Iteration @ 1621 is 2.2531561851501465\n",
      "Loss at Iteration @ 1622 is 2.4498445987701416\n",
      "Loss at Iteration @ 1623 is 2.330827236175537\n",
      "Loss at Iteration @ 1624 is 2.1775500774383545\n",
      "Loss at Iteration @ 1625 is 2.115933656692505\n",
      "Loss at Iteration @ 1626 is 2.0963799953460693\n",
      "Loss at Iteration @ 1627 is 2.379701614379883\n",
      "Loss at Iteration @ 1628 is 2.2836053371429443\n",
      "Loss at Iteration @ 1629 is 2.1857521533966064\n",
      "Loss at Iteration @ 1630 is 2.2012486457824707\n",
      "Loss at Iteration @ 1631 is 1.9611865282058716\n",
      "Loss at Iteration @ 1632 is 2.1100246906280518\n",
      "Loss at Iteration @ 1633 is 2.241086483001709\n",
      "Loss at Iteration @ 1634 is 2.0926706790924072\n",
      "Loss at Iteration @ 1635 is 2.1200311183929443\n",
      "Loss at Iteration @ 1636 is 2.293938398361206\n",
      "Loss at Iteration @ 1637 is 2.4010252952575684\n",
      "Loss at Iteration @ 1638 is 2.3293182849884033\n",
      "Loss at Iteration @ 1639 is 2.359639883041382\n",
      "Loss at Iteration @ 1640 is 2.2078166007995605\n",
      "Loss at Iteration @ 1641 is 2.1953725814819336\n",
      "Loss at Iteration @ 1642 is 1.9648791551589966\n",
      "Loss at Iteration @ 1643 is 2.1422741413116455\n",
      "Loss at Iteration @ 1644 is 2.166501760482788\n",
      "Loss at Iteration @ 1645 is 2.1488776206970215\n",
      "Loss at Iteration @ 1646 is 2.0629680156707764\n",
      "Loss at Iteration @ 1647 is 2.231107711791992\n",
      "Loss at Iteration @ 1648 is 2.3255136013031006\n",
      "Loss at Iteration @ 1649 is 1.949534296989441\n",
      "Loss at Iteration @ 1650 is 2.151556968688965\n",
      "Loss at Iteration @ 1651 is 2.2730324268341064\n",
      "Loss at Iteration @ 1652 is 2.0420613288879395\n",
      "Loss at Iteration @ 1653 is 2.2652924060821533\n",
      "Loss at Iteration @ 1654 is 2.3968307971954346\n",
      "Loss at Iteration @ 1655 is 2.463533639907837\n",
      "Loss at Iteration @ 1656 is 2.069305658340454\n",
      "Loss at Iteration @ 1657 is 2.1606273651123047\n",
      "Loss at Iteration @ 1658 is 2.172351121902466\n",
      "Loss at Iteration @ 1659 is 2.4821574687957764\n",
      "Loss at Iteration @ 1660 is 2.3755908012390137\n",
      "Loss at Iteration @ 1661 is 2.207017660140991\n",
      "Loss at Iteration @ 1662 is 2.3206350803375244\n",
      "Loss at Iteration @ 1663 is 2.2156460285186768\n",
      "Loss at Iteration @ 1664 is 2.0609381198883057\n",
      "Loss at Iteration @ 1665 is 2.519862651824951\n",
      "Loss at Iteration @ 1666 is 2.3484609127044678\n",
      "Loss at Iteration @ 1667 is 2.3061718940734863\n",
      "Loss at Iteration @ 1668 is 2.271038770675659\n",
      "Loss at Iteration @ 1669 is 2.2541167736053467\n",
      "Loss at Iteration @ 1670 is 2.5515291690826416\n",
      "Loss at Iteration @ 1671 is 2.0997512340545654\n",
      "Loss at Iteration @ 1672 is 2.2853474617004395\n",
      "Loss at Iteration @ 1673 is 2.238546848297119\n",
      "Loss at Iteration @ 1674 is 2.1980974674224854\n",
      "Loss at Iteration @ 1675 is 2.30871844291687\n",
      "Loss at Iteration @ 1676 is 2.0427157878875732\n",
      "Loss at Iteration @ 1677 is 2.375258207321167\n",
      "Loss at Iteration @ 1678 is 2.188554525375366\n",
      "Loss at Iteration @ 1679 is 2.3460354804992676\n",
      "Loss at Iteration @ 1680 is 2.511458396911621\n",
      "Loss at Iteration @ 1681 is 2.4656572341918945\n",
      "Loss at Iteration @ 1682 is 2.3939545154571533\n",
      "Loss at Iteration @ 1683 is 2.2732510566711426\n",
      "Loss at Iteration @ 1684 is 2.24906849861145\n",
      "Loss at Iteration @ 1685 is 1.9496607780456543\n",
      "Loss at Iteration @ 1686 is 1.648390531539917\n",
      "Loss at Iteration @ 1687 is 2.275979995727539\n",
      "Loss at Iteration @ 1688 is 2.4038875102996826\n",
      "Loss at Iteration @ 1689 is 1.9381139278411865\n",
      "Loss at Iteration @ 1690 is 2.3275954723358154\n",
      "Loss at Iteration @ 1691 is 2.073211431503296\n",
      "Loss at Iteration @ 1692 is 2.4188783168792725\n",
      "Loss at Iteration @ 1693 is 2.3154256343841553\n",
      "Loss at Iteration @ 1694 is 2.3164665699005127\n",
      "Loss at Iteration @ 1695 is 2.462399482727051\n",
      "Loss at Iteration @ 1696 is 2.4474568367004395\n",
      "Loss at Iteration @ 1697 is 2.3606321811676025\n",
      "Loss at Iteration @ 1698 is 2.379035234451294\n",
      "Loss at Iteration @ 1699 is 2.2146427631378174\n",
      "Loss at Iteration @ 1700 is 2.5512428283691406\n",
      "Loss at Iteration @ 1701 is 2.1468405723571777\n",
      "Loss at Iteration @ 1702 is 2.196497678756714\n",
      "Loss at Iteration @ 1703 is 2.4537606239318848\n",
      "Loss at Iteration @ 1704 is 2.350893974304199\n",
      "Loss at Iteration @ 1705 is 2.2846903800964355\n",
      "Loss at Iteration @ 1706 is 2.1257853507995605\n",
      "Loss at Iteration @ 1707 is 1.8965920209884644\n",
      "Loss at Iteration @ 1708 is 2.391782283782959\n",
      "Loss at Iteration @ 1709 is 2.3678956031799316\n",
      "Loss at Iteration @ 1710 is 2.116816997528076\n",
      "Loss at Iteration @ 1711 is 2.441470146179199\n",
      "Loss at Iteration @ 1712 is 2.285226583480835\n",
      "Loss at Iteration @ 1713 is 2.1233744621276855\n",
      "Loss at Iteration @ 1714 is 2.232311964035034\n",
      "Loss at Iteration @ 1715 is 2.3209235668182373\n",
      "Loss at Iteration @ 1716 is 2.254390239715576\n",
      "Loss at Iteration @ 1717 is 2.1399030685424805\n",
      "Loss at Iteration @ 1718 is 2.338541269302368\n",
      "Loss at Iteration @ 1719 is 2.0389468669891357\n",
      "Loss at Iteration @ 1720 is 2.1861581802368164\n",
      "Loss at Iteration @ 1721 is 2.3115131855010986\n",
      "Loss at Iteration @ 1722 is 2.4001197814941406\n",
      "Loss at Iteration @ 1723 is 2.2751708030700684\n",
      "Loss at Iteration @ 1724 is 2.321054697036743\n",
      "Loss at Iteration @ 1725 is 2.3137478828430176\n",
      "Loss at Iteration @ 1726 is 2.3510282039642334\n",
      "Loss at Iteration @ 1727 is 2.2879562377929688\n",
      "Loss at Iteration @ 1728 is 2.293403148651123\n",
      "Loss at Iteration @ 1729 is 2.393043279647827\n",
      "Loss at Iteration @ 1730 is 2.484018564224243\n",
      "Loss at Iteration @ 1731 is 2.169344902038574\n",
      "Loss at Iteration @ 1732 is 2.0972402095794678\n",
      "Loss at Iteration @ 1733 is 2.2277159690856934\n",
      "Loss at Iteration @ 1734 is 2.147435188293457\n",
      "Loss at Iteration @ 1735 is 2.1176514625549316\n",
      "Loss at Iteration @ 1736 is 2.592994213104248\n",
      "Loss at Iteration @ 1737 is 2.259244680404663\n",
      "Loss at Iteration @ 1738 is 1.9797308444976807\n",
      "Loss at Iteration @ 1739 is 2.3020312786102295\n",
      "Loss at Iteration @ 1740 is 2.3910861015319824\n",
      "Loss at Iteration @ 1741 is 2.6057865619659424\n",
      "Loss at Iteration @ 1742 is 2.120156764984131\n",
      "Loss at Iteration @ 1743 is 2.2879064083099365\n",
      "Loss at Iteration @ 1744 is 2.232619524002075\n",
      "Loss at Iteration @ 1745 is 2.4285871982574463\n",
      "Loss at Iteration @ 1746 is 2.3700740337371826\n",
      "Loss at Iteration @ 1747 is 2.260516405105591\n",
      "Loss at Iteration @ 1748 is 2.2296767234802246\n",
      "Loss at Iteration @ 1749 is 2.0830929279327393\n",
      "Loss at Iteration @ 1750 is 2.0451533794403076\n",
      "Loss at Iteration @ 1751 is 2.035388231277466\n",
      "Loss at Iteration @ 1752 is 2.1119093894958496\n",
      "Loss at Iteration @ 1753 is 2.395242214202881\n",
      "Loss at Iteration @ 1754 is 2.2935495376586914\n",
      "Loss at Iteration @ 1755 is 2.451287031173706\n",
      "Loss at Iteration @ 1756 is 1.98716402053833\n",
      "Loss at Iteration @ 1757 is 2.032067060470581\n",
      "Loss at Iteration @ 1758 is 2.1921842098236084\n",
      "Loss at Iteration @ 1759 is 2.126142978668213\n",
      "Loss at Iteration @ 1760 is 2.5469818115234375\n",
      "Loss at Iteration @ 1761 is 2.0021045207977295\n",
      "Loss at Iteration @ 1762 is 2.2775347232818604\n",
      "Loss at Iteration @ 1763 is 1.8748890161514282\n",
      "Loss at Iteration @ 1764 is 2.4295315742492676\n",
      "Loss at Iteration @ 1765 is 2.481137752532959\n",
      "Loss at Iteration @ 1766 is 1.8949722051620483\n",
      "Loss at Iteration @ 1767 is 1.9625896215438843\n",
      "Loss at Iteration @ 1768 is 2.3093066215515137\n",
      "Loss at Iteration @ 1769 is 2.089348077774048\n",
      "Loss at Iteration @ 1770 is 2.0063016414642334\n",
      "Loss at Iteration @ 1771 is 2.402477502822876\n",
      "Loss at Iteration @ 1772 is 2.301438570022583\n",
      "Loss at Iteration @ 1773 is 2.260629653930664\n",
      "Loss at Iteration @ 1774 is 2.2717103958129883\n",
      "Loss at Iteration @ 1775 is 2.258760929107666\n",
      "Loss at Iteration @ 1776 is 2.3007888793945312\n",
      "Loss at Iteration @ 1777 is 2.3695592880249023\n",
      "Loss at Iteration @ 1778 is 2.261199951171875\n",
      "Loss at Iteration @ 1779 is 1.9092018604278564\n",
      "Loss at Iteration @ 1780 is 2.333413600921631\n",
      "Loss at Iteration @ 1781 is 2.1992316246032715\n",
      "Loss at Iteration @ 1782 is 1.9651634693145752\n",
      "Loss at Iteration @ 1783 is 2.180776596069336\n",
      "Loss at Iteration @ 1784 is 2.5647265911102295\n",
      "Loss at Iteration @ 1785 is 2.646904468536377\n",
      "Loss at Iteration @ 1786 is 2.1391329765319824\n",
      "Loss at Iteration @ 1787 is 2.1022748947143555\n",
      "Loss at Iteration @ 1788 is 2.3810367584228516\n",
      "Loss at Iteration @ 1789 is 2.0691254138946533\n",
      "Loss at Iteration @ 1790 is 2.179910898208618\n",
      "Loss at Iteration @ 1791 is 2.3183553218841553\n",
      "Loss at Iteration @ 1792 is 2.197570562362671\n",
      "Loss at Iteration @ 1793 is 2.3884494304656982\n",
      "Loss at Iteration @ 1794 is 2.326683521270752\n",
      "Loss at Iteration @ 1795 is 2.130605697631836\n",
      "Loss at Iteration @ 1796 is 1.871038794517517\n",
      "Loss at Iteration @ 1797 is 2.184061050415039\n",
      "Loss at Iteration @ 1798 is 2.1074252128601074\n",
      "Loss at Iteration @ 1799 is 2.4589524269104004\n",
      "Loss at Iteration @ 1800 is 2.5414130687713623\n",
      "Loss at Iteration @ 1801 is 2.293999433517456\n",
      "Loss at Iteration @ 1802 is 2.1026389598846436\n",
      "Loss at Iteration @ 1803 is 2.323383331298828\n",
      "Loss at Iteration @ 1804 is 2.281064987182617\n",
      "Loss at Iteration @ 1805 is 2.1899819374084473\n",
      "Loss at Iteration @ 1806 is 2.4144845008850098\n",
      "Loss at Iteration @ 1807 is 2.335696220397949\n",
      "Loss at Iteration @ 1808 is 2.354212522506714\n",
      "Loss at Iteration @ 1809 is 2.0591886043548584\n",
      "Loss at Iteration @ 1810 is 1.8348270654678345\n",
      "Loss at Iteration @ 1811 is 2.3589749336242676\n",
      "Loss at Iteration @ 1812 is 2.5706629753112793\n",
      "Loss at Iteration @ 1813 is 1.9656519889831543\n",
      "Loss at Iteration @ 1814 is 2.3394405841827393\n",
      "Loss at Iteration @ 1815 is 2.3154869079589844\n",
      "Loss at Iteration @ 1816 is 2.3551154136657715\n",
      "Loss at Iteration @ 1817 is 2.142672061920166\n",
      "Loss at Iteration @ 1818 is 2.2238690853118896\n",
      "Loss at Iteration @ 1819 is 2.191277027130127\n",
      "Loss at Iteration @ 1820 is 2.154543876647949\n",
      "Loss at Iteration @ 1821 is 2.5708420276641846\n",
      "Loss at Iteration @ 1822 is 2.3615942001342773\n",
      "Loss at Iteration @ 1823 is 2.1062405109405518\n",
      "Loss at Iteration @ 1824 is 2.5038583278656006\n",
      "Loss at Iteration @ 1825 is 2.111015796661377\n",
      "Loss at Iteration @ 1826 is 2.2584128379821777\n",
      "Loss at Iteration @ 1827 is 2.4791617393493652\n",
      "Loss at Iteration @ 1828 is 2.0260143280029297\n",
      "Loss at Iteration @ 1829 is 2.5736021995544434\n",
      "Loss at Iteration @ 1830 is 2.442256450653076\n",
      "Loss at Iteration @ 1831 is 2.2084522247314453\n",
      "Loss at Iteration @ 1832 is 1.902336835861206\n",
      "Loss at Iteration @ 1833 is 1.999734878540039\n",
      "Loss at Iteration @ 1834 is 2.264101505279541\n",
      "Loss at Iteration @ 1835 is 2.333470582962036\n",
      "Loss at Iteration @ 1836 is 2.3111088275909424\n",
      "Loss at Iteration @ 1837 is 2.2000107765197754\n",
      "Loss at Iteration @ 1838 is 2.168618679046631\n",
      "Loss at Iteration @ 1839 is 2.0796360969543457\n",
      "Loss at Iteration @ 1840 is 2.2858173847198486\n",
      "Loss at Iteration @ 1841 is 2.293579578399658\n",
      "Loss at Iteration @ 1842 is 2.179208517074585\n",
      "Loss at Iteration @ 1843 is 2.093763828277588\n",
      "Loss at Iteration @ 1844 is 2.5707292556762695\n",
      "Loss at Iteration @ 1845 is 2.3206264972686768\n",
      "Loss at Iteration @ 1846 is 2.26546311378479\n",
      "Loss at Iteration @ 1847 is 2.3860106468200684\n",
      "Loss at Iteration @ 1848 is 2.287435531616211\n",
      "Loss at Iteration @ 1849 is 1.8272159099578857\n",
      "Loss at Iteration @ 1850 is 2.236844062805176\n",
      "Loss at Iteration @ 1851 is 2.0936572551727295\n",
      "Loss at Iteration @ 1852 is 2.2839179039001465\n",
      "Loss at Iteration @ 1853 is 2.1559553146362305\n",
      "Loss at Iteration @ 1854 is 2.492924928665161\n",
      "Loss at Iteration @ 1855 is 2.5839731693267822\n",
      "Loss at Iteration @ 1856 is 2.3084917068481445\n",
      "Loss at Iteration @ 1857 is 2.155294418334961\n",
      "Loss at Iteration @ 1858 is 2.170050621032715\n",
      "Loss at Iteration @ 1859 is 2.1685993671417236\n",
      "Loss at Iteration @ 1860 is 2.378138303756714\n",
      "Loss at Iteration @ 1861 is 2.313011884689331\n",
      "Loss at Iteration @ 1862 is 2.337867021560669\n",
      "Loss at Iteration @ 1863 is 2.4713239669799805\n",
      "Loss at Iteration @ 1864 is 2.1501739025115967\n",
      "Loss at Iteration @ 1865 is 1.962111234664917\n",
      "Loss at Iteration @ 1866 is 2.3445329666137695\n",
      "Loss at Iteration @ 1867 is 2.205037832260132\n",
      "Loss at Iteration @ 1868 is 2.299522876739502\n",
      "Loss at Iteration @ 1869 is 2.1165637969970703\n",
      "Loss at Iteration @ 1870 is 2.3509979248046875\n",
      "Loss at Iteration @ 1871 is 2.3958070278167725\n",
      "Loss at Iteration @ 1872 is 2.2524774074554443\n",
      "Loss at Iteration @ 1873 is 2.300887107849121\n",
      "Loss at Iteration @ 1874 is 2.373288869857788\n",
      "Loss at Iteration @ 1875 is 2.296980857849121\n",
      "Loss at Iteration @ 1876 is 2.1147966384887695\n",
      "Loss at Iteration @ 1877 is 2.502507448196411\n",
      "Loss at Iteration @ 1878 is 2.170292377471924\n",
      "Loss at Iteration @ 1879 is 2.4094924926757812\n",
      "Loss at Iteration @ 1880 is 2.216162919998169\n",
      "Loss at Iteration @ 1881 is 2.314293622970581\n",
      "Loss at Iteration @ 1882 is 2.535123109817505\n",
      "Loss at Iteration @ 1883 is 2.3170082569122314\n",
      "Loss at Iteration @ 1884 is 2.1668214797973633\n",
      "Loss at Iteration @ 1885 is 2.2716686725616455\n",
      "Loss at Iteration @ 1886 is 2.496307849884033\n",
      "Loss at Iteration @ 1887 is 2.468519449234009\n",
      "Loss at Iteration @ 1888 is 2.103076457977295\n",
      "Loss at Iteration @ 1889 is 2.3713173866271973\n",
      "Loss at Iteration @ 1890 is 2.1777565479278564\n",
      "Loss at Iteration @ 1891 is 2.2808125019073486\n",
      "Loss at Iteration @ 1892 is 2.3736793994903564\n",
      "Loss at Iteration @ 1893 is 2.3069820404052734\n",
      "Loss at Iteration @ 1894 is 2.111888885498047\n",
      "Loss at Iteration @ 1895 is 2.353529930114746\n",
      "Loss at Iteration @ 1896 is 2.3209927082061768\n",
      "Loss at Iteration @ 1897 is 2.3184945583343506\n",
      "Loss at Iteration @ 1898 is 2.4543778896331787\n",
      "Loss at Iteration @ 1899 is 2.322035551071167\n",
      "Loss at Iteration @ 1900 is 2.2016584873199463\n",
      "Loss at Iteration @ 1901 is 2.0717639923095703\n",
      "Loss at Iteration @ 1902 is 1.9806604385375977\n",
      "Loss at Iteration @ 1903 is 2.4777870178222656\n",
      "Loss at Iteration @ 1904 is 2.1158089637756348\n",
      "Loss at Iteration @ 1905 is 2.1463115215301514\n",
      "Loss at Iteration @ 1906 is 2.2973201274871826\n",
      "Loss at Iteration @ 1907 is 2.1530182361602783\n",
      "Loss at Iteration @ 1908 is 2.252800703048706\n",
      "Loss at Iteration @ 1909 is 2.15218186378479\n",
      "Loss at Iteration @ 1910 is 2.5380144119262695\n",
      "Loss at Iteration @ 1911 is 2.377345561981201\n",
      "Loss at Iteration @ 1912 is 1.8634028434753418\n",
      "Loss at Iteration @ 1913 is 2.3419840335845947\n",
      "Loss at Iteration @ 1914 is 2.1272411346435547\n",
      "Loss at Iteration @ 1915 is 2.2341222763061523\n",
      "Loss at Iteration @ 1916 is 2.0960965156555176\n",
      "Loss at Iteration @ 1917 is 2.1503610610961914\n",
      "Loss at Iteration @ 1918 is 2.299670696258545\n",
      "Loss at Iteration @ 1919 is 2.283207416534424\n",
      "Loss at Iteration @ 1920 is 2.2768394947052\n",
      "Loss at Iteration @ 1921 is 2.329115152359009\n",
      "Loss at Iteration @ 1922 is 2.1531777381896973\n",
      "Loss at Iteration @ 1923 is 2.2240822315216064\n",
      "Loss at Iteration @ 1924 is 2.415243625640869\n",
      "Loss at Iteration @ 1925 is 1.9527086019515991\n",
      "Loss at Iteration @ 1926 is 2.133955240249634\n",
      "Loss at Iteration @ 1927 is 2.0826141834259033\n",
      "Loss at Iteration @ 1928 is 2.25703763961792\n",
      "Loss at Iteration @ 1929 is 2.196444034576416\n",
      "Loss at Iteration @ 1930 is 2.0484068393707275\n",
      "Loss at Iteration @ 1931 is 2.2755637168884277\n",
      "Loss at Iteration @ 1932 is 2.3446357250213623\n",
      "Loss at Iteration @ 1933 is 2.438929557800293\n",
      "Loss at Iteration @ 1934 is 2.220980167388916\n",
      "Loss at Iteration @ 1935 is 2.051330089569092\n",
      "Loss at Iteration @ 1936 is 2.4477641582489014\n",
      "Loss at Iteration @ 1937 is 2.252917528152466\n",
      "Loss at Iteration @ 1938 is 2.4379162788391113\n",
      "Loss at Iteration @ 1939 is 2.5775551795959473\n",
      "Loss at Iteration @ 1940 is 2.3696322441101074\n",
      "Loss at Iteration @ 1941 is 2.2101547718048096\n",
      "Loss at Iteration @ 1942 is 2.048754930496216\n",
      "Loss at Iteration @ 1943 is 2.058741569519043\n",
      "Loss at Iteration @ 1944 is 1.9559032917022705\n",
      "Loss at Iteration @ 1945 is 2.141716241836548\n",
      "Loss at Iteration @ 1946 is 2.1393985748291016\n",
      "Loss at Iteration @ 1947 is 2.267993450164795\n",
      "Loss at Iteration @ 1948 is 2.185459852218628\n",
      "Loss at Iteration @ 1949 is 2.2773945331573486\n",
      "Loss at Iteration @ 1950 is 2.1067872047424316\n",
      "Loss at Iteration @ 1951 is 2.272703170776367\n",
      "Loss at Iteration @ 1952 is 2.3510162830352783\n",
      "Loss at Iteration @ 1953 is 2.0250437259674072\n",
      "Loss at Iteration @ 1954 is 2.5830130577087402\n",
      "Loss at Iteration @ 1955 is 2.2488853931427\n",
      "Loss at Iteration @ 1956 is 2.2038626670837402\n",
      "Loss at Iteration @ 1957 is 2.3430752754211426\n",
      "Loss at Iteration @ 1958 is 2.123736619949341\n",
      "Loss at Iteration @ 1959 is 2.353999376296997\n",
      "Loss at Iteration @ 1960 is 2.1356239318847656\n",
      "Loss at Iteration @ 1961 is 2.2392125129699707\n",
      "Loss at Iteration @ 1962 is 2.2633109092712402\n",
      "Loss at Iteration @ 1963 is 2.4395275115966797\n",
      "Loss at Iteration @ 1964 is 2.404003143310547\n",
      "Loss at Iteration @ 1965 is 2.070671796798706\n",
      "Loss at Iteration @ 1966 is 2.2313621044158936\n",
      "Loss at Iteration @ 1967 is 2.2581305503845215\n",
      "Loss at Iteration @ 1968 is 2.1546554565429688\n",
      "Loss at Iteration @ 1969 is 2.109729051589966\n",
      "Loss at Iteration @ 1970 is 2.0100646018981934\n",
      "Loss at Iteration @ 1971 is 1.8654546737670898\n",
      "Loss at Iteration @ 1972 is 2.304940700531006\n",
      "Loss at Iteration @ 1973 is 2.3561151027679443\n",
      "Loss at Iteration @ 1974 is 2.345120668411255\n",
      "Loss at Iteration @ 1975 is 2.3195419311523438\n",
      "Loss at Iteration @ 1976 is 2.3308825492858887\n",
      "Loss at Iteration @ 1977 is 2.1923537254333496\n",
      "Loss at Iteration @ 1978 is 2.187601089477539\n",
      "Loss at Iteration @ 1979 is 2.34338116645813\n",
      "Loss at Iteration @ 1980 is 2.2579259872436523\n",
      "Loss at Iteration @ 1981 is 2.203077554702759\n",
      "Loss at Iteration @ 1982 is 2.2786123752593994\n",
      "Loss at Iteration @ 1983 is 2.30485200881958\n",
      "Loss at Iteration @ 1984 is 2.1388790607452393\n",
      "Loss at Iteration @ 1985 is 1.8311963081359863\n",
      "Loss at Iteration @ 1986 is 2.3202567100524902\n",
      "Loss at Iteration @ 1987 is 2.0811500549316406\n",
      "Loss at Iteration @ 1988 is 2.1096885204315186\n",
      "Loss at Iteration @ 1989 is 2.5685067176818848\n",
      "Loss at Iteration @ 1990 is 2.520150899887085\n",
      "Loss at Iteration @ 1991 is 2.0840680599212646\n",
      "Loss at Iteration @ 1992 is 2.2581958770751953\n",
      "Loss at Iteration @ 1993 is 2.2000584602355957\n",
      "Loss at Iteration @ 1994 is 2.196289539337158\n",
      "Loss at Iteration @ 1995 is 2.1760430335998535\n",
      "Loss at Iteration @ 1996 is 2.475710868835449\n",
      "Loss at Iteration @ 1997 is 2.194432020187378\n",
      "Loss at Iteration @ 1998 is 2.3624608516693115\n",
      "Loss at Iteration @ 1999 is 2.3972179889678955\n",
      "Loss at Iteration @ 2000 is 2.204719305038452\n",
      "Loss at Iteration @ 2001 is 2.248976469039917\n",
      "Loss at Iteration @ 2002 is 2.3628666400909424\n",
      "Loss at Iteration @ 2003 is 2.446150779724121\n",
      "Loss at Iteration @ 2004 is 2.0342800617218018\n",
      "Loss at Iteration @ 2005 is 1.954155683517456\n",
      "Loss at Iteration @ 2006 is 2.282815456390381\n",
      "Loss at Iteration @ 2007 is 2.4460625648498535\n",
      "Loss at Iteration @ 2008 is 2.300750494003296\n",
      "Loss at Iteration @ 2009 is 2.335026979446411\n",
      "Loss at Iteration @ 2010 is 2.226285696029663\n",
      "Loss at Iteration @ 2011 is 2.152616024017334\n",
      "Loss at Iteration @ 2012 is 2.2106831073760986\n",
      "Loss at Iteration @ 2013 is 2.4232449531555176\n",
      "Loss at Iteration @ 2014 is 2.184709072113037\n",
      "Loss at Iteration @ 2015 is 2.1680665016174316\n",
      "Loss at Iteration @ 2016 is 2.2844905853271484\n",
      "Loss at Iteration @ 2017 is 2.3395657539367676\n",
      "Loss at Iteration @ 2018 is 2.4303674697875977\n",
      "Loss at Iteration @ 2019 is 2.133910655975342\n",
      "Loss at Iteration @ 2020 is 2.20595383644104\n",
      "Loss at Iteration @ 2021 is 2.372509241104126\n",
      "Loss at Iteration @ 2022 is 2.3445749282836914\n",
      "Loss at Iteration @ 2023 is 2.1240952014923096\n",
      "Loss at Iteration @ 2024 is 2.439948320388794\n",
      "Loss at Iteration @ 2025 is 2.189751386642456\n",
      "Loss at Iteration @ 2026 is 2.1927573680877686\n",
      "Loss at Iteration @ 2027 is 2.4760522842407227\n",
      "Loss at Iteration @ 2028 is 2.443840742111206\n",
      "Loss at Iteration @ 2029 is 2.46864914894104\n",
      "Loss at Iteration @ 2030 is 2.2453229427337646\n",
      "Loss at Iteration @ 2031 is 2.0866165161132812\n",
      "Loss at Iteration @ 2032 is 2.0463342666625977\n",
      "Loss at Iteration @ 2033 is 2.502762794494629\n",
      "Loss at Iteration @ 2034 is 2.2505393028259277\n",
      "Loss at Iteration @ 2035 is 2.5485599040985107\n",
      "Loss at Iteration @ 2036 is 2.1862685680389404\n",
      "Loss at Iteration @ 2037 is 2.5033986568450928\n",
      "Loss at Iteration @ 2038 is 2.0688092708587646\n",
      "Loss at Iteration @ 2039 is 2.2759804725646973\n",
      "Loss at Iteration @ 2040 is 2.4805893898010254\n",
      "Loss at Iteration @ 2041 is 2.4635376930236816\n",
      "Loss at Iteration @ 2042 is 2.1685791015625\n",
      "Loss at Iteration @ 2043 is 2.1667678356170654\n",
      "Loss at Iteration @ 2044 is 1.9693152904510498\n",
      "Loss at Iteration @ 2045 is 1.9083527326583862\n",
      "Loss at Iteration @ 2046 is 2.41152024269104\n",
      "Loss at Iteration @ 2047 is 2.197232484817505\n",
      "Loss at Iteration @ 2048 is 2.2888481616973877\n",
      "Loss at Iteration @ 2049 is 2.350674629211426\n",
      "Loss at Iteration @ 2050 is 2.2108705043792725\n",
      "Loss at Iteration @ 2051 is 2.3507962226867676\n",
      "Loss at Iteration @ 2052 is 2.182384967803955\n",
      "Loss at Iteration @ 2053 is 2.0776138305664062\n",
      "Loss at Iteration @ 2054 is 2.1588733196258545\n",
      "Loss at Iteration @ 2055 is 2.5077621936798096\n",
      "Loss at Iteration @ 2056 is 2.4468648433685303\n",
      "Loss at Iteration @ 2057 is 2.1136868000030518\n",
      "Loss at Iteration @ 2058 is 2.0637142658233643\n",
      "Loss at Iteration @ 2059 is 2.067918539047241\n",
      "Loss at Iteration @ 2060 is 2.198390483856201\n",
      "Loss at Iteration @ 2061 is 2.1453146934509277\n",
      "Loss at Iteration @ 2062 is 2.1405205726623535\n",
      "Loss at Iteration @ 2063 is 2.4901015758514404\n",
      "Loss at Iteration @ 2064 is 1.91259765625\n",
      "Loss at Iteration @ 2065 is 2.128594398498535\n",
      "Loss at Iteration @ 2066 is 2.3895204067230225\n",
      "Loss at Iteration @ 2067 is 2.3537490367889404\n",
      "Loss at Iteration @ 2068 is 2.3637938499450684\n",
      "Loss at Iteration @ 2069 is 2.5757813453674316\n",
      "Loss at Iteration @ 2070 is 2.3855135440826416\n",
      "Loss at Iteration @ 2071 is 2.31306791305542\n",
      "Loss at Iteration @ 2072 is 2.1392271518707275\n",
      "Loss at Iteration @ 2073 is 2.122126340866089\n",
      "Loss at Iteration @ 2074 is 2.0998542308807373\n",
      "Loss at Iteration @ 2075 is 1.9603906869888306\n",
      "Loss at Iteration @ 2076 is 2.2318549156188965\n",
      "Loss at Iteration @ 2077 is 2.1791372299194336\n",
      "Loss at Iteration @ 2078 is 2.214291572570801\n",
      "Loss at Iteration @ 2079 is 2.32729434967041\n",
      "Loss at Iteration @ 2080 is 2.466587781906128\n",
      "Loss at Iteration @ 2081 is 2.252725601196289\n",
      "Loss at Iteration @ 2082 is 2.3665246963500977\n",
      "Loss at Iteration @ 2083 is 2.112405776977539\n",
      "Loss at Iteration @ 2084 is 2.1683051586151123\n",
      "Loss at Iteration @ 2085 is 2.1400110721588135\n",
      "Loss at Iteration @ 2086 is 2.545424461364746\n",
      "Loss at Iteration @ 2087 is 2.6592636108398438\n",
      "Loss at Iteration @ 2088 is 2.0666260719299316\n",
      "Loss at Iteration @ 2089 is 2.105084180831909\n",
      "Loss at Iteration @ 2090 is 2.444685220718384\n",
      "Loss at Iteration @ 2091 is 2.689033031463623\n",
      "Loss at Iteration @ 2092 is 2.0592565536499023\n",
      "Loss at Iteration @ 2093 is 1.902808427810669\n",
      "Loss at Iteration @ 2094 is 2.225231409072876\n",
      "Loss at Iteration @ 2095 is 2.1616413593292236\n",
      "Loss at Iteration @ 2096 is 2.330791473388672\n",
      "Loss at Iteration @ 2097 is 2.1378650665283203\n",
      "Loss at Iteration @ 2098 is 2.0275659561157227\n",
      "Loss at Iteration @ 2099 is 2.2132747173309326\n",
      "Loss at Iteration @ 2100 is 1.9793024063110352\n",
      "Loss at Iteration @ 2101 is 2.086233139038086\n",
      "Loss at Iteration @ 2102 is 2.1612062454223633\n",
      "Loss at Iteration @ 2103 is 2.3679897785186768\n",
      "Loss at Iteration @ 2104 is 2.398635149002075\n",
      "Loss at Iteration @ 2105 is 2.399568796157837\n",
      "Loss at Iteration @ 2106 is 2.347818613052368\n",
      "Loss at Iteration @ 2107 is 2.4897043704986572\n",
      "Loss at Iteration @ 2108 is 2.318222999572754\n",
      "Loss at Iteration @ 2109 is 2.2863330841064453\n",
      "Loss at Iteration @ 2110 is 2.2162909507751465\n",
      "Loss at Iteration @ 2111 is 2.183640480041504\n",
      "Loss at Iteration @ 2112 is 2.2686355113983154\n",
      "Loss at Iteration @ 2113 is 2.223472833633423\n",
      "Loss at Iteration @ 2114 is 2.2159488201141357\n",
      "Loss at Iteration @ 2115 is 2.178507089614868\n",
      "Loss at Iteration @ 2116 is 2.484480857849121\n",
      "Loss at Iteration @ 2117 is 2.160501718521118\n",
      "Loss at Iteration @ 2118 is 2.3664298057556152\n",
      "Loss at Iteration @ 2119 is 1.9946218729019165\n",
      "Loss at Iteration @ 2120 is 2.2193593978881836\n",
      "Loss at Iteration @ 2121 is 2.1155598163604736\n",
      "Loss at Iteration @ 2122 is 2.267942428588867\n",
      "Loss at Iteration @ 2123 is 2.3461833000183105\n",
      "Loss at Iteration @ 2124 is 2.470428943634033\n",
      "Loss at Iteration @ 2125 is 2.2315022945404053\n",
      "Loss at Iteration @ 2126 is 2.2111830711364746\n",
      "Loss at Iteration @ 2127 is 2.335113048553467\n",
      "Loss at Iteration @ 2128 is 2.476986885070801\n",
      "Loss at Iteration @ 2129 is 2.0013928413391113\n",
      "Loss at Iteration @ 2130 is 2.284931182861328\n",
      "Loss at Iteration @ 2131 is 2.1333348751068115\n",
      "Loss at Iteration @ 2132 is 2.275515556335449\n",
      "Loss at Iteration @ 2133 is 2.3216264247894287\n",
      "Loss at Iteration @ 2134 is 1.9860397577285767\n",
      "Loss at Iteration @ 2135 is 2.2654528617858887\n",
      "Loss at Iteration @ 2136 is 2.2308194637298584\n",
      "Loss at Iteration @ 2137 is 2.3917434215545654\n",
      "Loss at Iteration @ 2138 is 2.377129316329956\n",
      "Loss at Iteration @ 2139 is 1.9503942728042603\n",
      "Loss at Iteration @ 2140 is 2.5447161197662354\n",
      "Loss at Iteration @ 2141 is 2.015368700027466\n",
      "Loss at Iteration @ 2142 is 2.3097946643829346\n",
      "Loss at Iteration @ 2143 is 1.944257378578186\n",
      "Loss at Iteration @ 2144 is 2.30206036567688\n",
      "Loss at Iteration @ 2145 is 2.194438934326172\n",
      "Loss at Iteration @ 2146 is 2.2313621044158936\n",
      "Loss at Iteration @ 2147 is 2.5545156002044678\n",
      "Loss at Iteration @ 2148 is 2.1177892684936523\n",
      "Loss at Iteration @ 2149 is 2.3709628582000732\n",
      "Loss at Iteration @ 2150 is 2.441328525543213\n",
      "Loss at Iteration @ 2151 is 2.275966167449951\n",
      "Loss at Iteration @ 2152 is 2.1438498497009277\n",
      "Loss at Iteration @ 2153 is 2.068636655807495\n",
      "Loss at Iteration @ 2154 is 2.130999803543091\n",
      "Loss at Iteration @ 2155 is 2.25984787940979\n",
      "Loss at Iteration @ 2156 is 2.2933616638183594\n",
      "Loss at Iteration @ 2157 is 2.2617695331573486\n",
      "Loss at Iteration @ 2158 is 2.3729138374328613\n",
      "Loss at Iteration @ 2159 is 2.242751121520996\n",
      "Loss at Iteration @ 2160 is 2.0751938819885254\n",
      "Loss at Iteration @ 2161 is 2.1591262817382812\n",
      "Loss at Iteration @ 2162 is 2.205498695373535\n",
      "Loss at Iteration @ 2163 is 2.3520426750183105\n",
      "Loss at Iteration @ 2164 is 2.1758108139038086\n",
      "Loss at Iteration @ 2165 is 1.9640532732009888\n",
      "Loss at Iteration @ 2166 is 2.0834624767303467\n",
      "Loss at Iteration @ 2167 is 2.16007399559021\n",
      "Loss at Iteration @ 2168 is 2.128180503845215\n",
      "Loss at Iteration @ 2169 is 1.9515552520751953\n",
      "Loss at Iteration @ 2170 is 2.3685855865478516\n",
      "Loss at Iteration @ 2171 is 2.3825018405914307\n",
      "Loss at Iteration @ 2172 is 1.9097939729690552\n",
      "Loss at Iteration @ 2173 is 2.446773052215576\n",
      "Loss at Iteration @ 2174 is 2.2574431896209717\n",
      "Loss at Iteration @ 2175 is 2.0750327110290527\n",
      "Loss at Iteration @ 2176 is 2.089782238006592\n",
      "Loss at Iteration @ 2177 is 2.0645978450775146\n",
      "Loss at Iteration @ 2178 is 2.2902324199676514\n",
      "Loss at Iteration @ 2179 is 2.2189760208129883\n",
      "Loss at Iteration @ 2180 is 2.0088279247283936\n",
      "Loss at Iteration @ 2181 is 2.3456263542175293\n",
      "Loss at Iteration @ 2182 is 2.131679058074951\n",
      "Loss at Iteration @ 2183 is 2.532650947570801\n",
      "Loss at Iteration @ 2184 is 2.2251029014587402\n",
      "Loss at Iteration @ 2185 is 2.410926580429077\n",
      "Loss at Iteration @ 2186 is 2.1898674964904785\n",
      "Loss at Iteration @ 2187 is 2.5406410694122314\n",
      "Loss at Iteration @ 2188 is 2.0981740951538086\n",
      "Loss at Iteration @ 2189 is 2.201667547225952\n",
      "Loss at Iteration @ 2190 is 2.2888264656066895\n",
      "Loss at Iteration @ 2191 is 2.1219515800476074\n",
      "Loss at Iteration @ 2192 is 2.3163564205169678\n",
      "Loss at Iteration @ 2193 is 2.1294734477996826\n",
      "Loss at Iteration @ 2194 is 2.4586269855499268\n",
      "Loss at Iteration @ 2195 is 2.3786537647247314\n",
      "Loss at Iteration @ 2196 is 2.4569790363311768\n",
      "Loss at Iteration @ 2197 is 2.3510003089904785\n",
      "Loss at Iteration @ 2198 is 2.4313418865203857\n",
      "Loss at Iteration @ 2199 is 2.266655683517456\n",
      "Loss at Iteration @ 2200 is 2.2822742462158203\n",
      "Loss at Iteration @ 2201 is 2.1263482570648193\n",
      "Loss at Iteration @ 2202 is 2.2613894939422607\n",
      "Loss at Iteration @ 2203 is 2.154576063156128\n",
      "Loss at Iteration @ 2204 is 2.1623125076293945\n",
      "Loss at Iteration @ 2205 is 2.2121024131774902\n",
      "Loss at Iteration @ 2206 is 2.188352584838867\n",
      "Loss at Iteration @ 2207 is 2.353761911392212\n",
      "Loss at Iteration @ 2208 is 2.2384092807769775\n",
      "Loss at Iteration @ 2209 is 2.2336039543151855\n",
      "Loss at Iteration @ 2210 is 2.2762258052825928\n",
      "Loss at Iteration @ 2211 is 2.4304187297821045\n",
      "Loss at Iteration @ 2212 is 2.1925294399261475\n",
      "Loss at Iteration @ 2213 is 2.567718744277954\n",
      "Loss at Iteration @ 2214 is 2.124352216720581\n",
      "Loss at Iteration @ 2215 is 2.3225467205047607\n",
      "Loss at Iteration @ 2216 is 2.239455461502075\n",
      "Loss at Iteration @ 2217 is 2.2266809940338135\n",
      "Loss at Iteration @ 2218 is 2.230661153793335\n",
      "Loss at Iteration @ 2219 is 2.0618577003479004\n",
      "Loss at Iteration @ 2220 is 2.0033457279205322\n",
      "Loss at Iteration @ 2221 is 2.1748299598693848\n",
      "Loss at Iteration @ 2222 is 2.135446071624756\n",
      "Loss at Iteration @ 2223 is 2.264801025390625\n",
      "Loss at Iteration @ 2224 is 2.1677520275115967\n",
      "Loss at Iteration @ 2225 is 2.1437487602233887\n",
      "Loss at Iteration @ 2226 is 1.9753397703170776\n",
      "Loss at Iteration @ 2227 is 2.050492525100708\n",
      "Loss at Iteration @ 2228 is 2.3909764289855957\n",
      "Loss at Iteration @ 2229 is 2.12764835357666\n",
      "Loss at Iteration @ 2230 is 2.328702688217163\n",
      "Loss at Iteration @ 2231 is 2.420496702194214\n",
      "Loss at Iteration @ 2232 is 2.531895875930786\n",
      "Loss at Iteration @ 2233 is 2.3457727432250977\n",
      "Loss at Iteration @ 2234 is 2.281961679458618\n",
      "Loss at Iteration @ 2235 is 2.0866687297821045\n",
      "Loss at Iteration @ 2236 is 2.4160525798797607\n",
      "Loss at Iteration @ 2237 is 2.3156747817993164\n",
      "Loss at Iteration @ 2238 is 2.3912346363067627\n",
      "Loss at Iteration @ 2239 is 2.2125983238220215\n",
      "Loss at Iteration @ 2240 is 2.2002413272857666\n",
      "Loss at Iteration @ 2241 is 2.1536288261413574\n",
      "Loss at Iteration @ 2242 is 2.25732421875\n",
      "Loss at Iteration @ 2243 is 2.3027193546295166\n",
      "Loss at Iteration @ 2244 is 2.403780937194824\n",
      "Loss at Iteration @ 2245 is 2.2233173847198486\n",
      "Loss at Iteration @ 2246 is 2.401278018951416\n",
      "Loss at Iteration @ 2247 is 2.1295769214630127\n",
      "Loss at Iteration @ 2248 is 2.1989333629608154\n",
      "Loss at Iteration @ 2249 is 1.8295252323150635\n",
      "Loss at Iteration @ 2250 is 2.4515233039855957\n",
      "Loss at Iteration @ 2251 is 2.2752127647399902\n",
      "Loss at Iteration @ 2252 is 2.3727943897247314\n",
      "Loss at Iteration @ 2253 is 2.32080078125\n",
      "Loss at Iteration @ 2254 is 2.133248805999756\n",
      "Loss at Iteration @ 2255 is 2.408022880554199\n",
      "Loss at Iteration @ 2256 is 2.084242343902588\n",
      "Loss at Iteration @ 2257 is 2.2362234592437744\n",
      "Loss at Iteration @ 2258 is 2.169992446899414\n",
      "Loss at Iteration @ 2259 is 2.3344225883483887\n",
      "Loss at Iteration @ 2260 is 2.2634024620056152\n",
      "Loss at Iteration @ 2261 is 2.286792278289795\n",
      "Loss at Iteration @ 2262 is 2.531951665878296\n",
      "Loss at Iteration @ 2263 is 2.2652010917663574\n",
      "Loss at Iteration @ 2264 is 2.2988317012786865\n",
      "Loss at Iteration @ 2265 is 2.0502421855926514\n",
      "Loss at Iteration @ 2266 is 2.3103573322296143\n",
      "Loss at Iteration @ 2267 is 2.227043390274048\n",
      "Loss at Iteration @ 2268 is 2.0617408752441406\n",
      "Loss at Iteration @ 2269 is 2.14862322807312\n",
      "Loss at Iteration @ 2270 is 2.3291776180267334\n",
      "Loss at Iteration @ 2271 is 2.182119369506836\n",
      "Loss at Iteration @ 2272 is 1.9624873399734497\n",
      "Loss at Iteration @ 2273 is 2.435241460800171\n",
      "Loss at Iteration @ 2274 is 2.3512961864471436\n",
      "Loss at Iteration @ 2275 is 2.3412137031555176\n",
      "Loss at Iteration @ 2276 is 2.2385857105255127\n",
      "Loss at Iteration @ 2277 is 2.2565555572509766\n",
      "Loss at Iteration @ 2278 is 2.071371078491211\n",
      "Loss at Iteration @ 2279 is 2.3852603435516357\n",
      "Loss at Iteration @ 2280 is 2.0136451721191406\n",
      "Loss at Iteration @ 2281 is 2.194232225418091\n",
      "Loss at Iteration @ 2282 is 2.2116572856903076\n",
      "Loss at Iteration @ 2283 is 2.383249044418335\n",
      "Loss at Iteration @ 2284 is 1.9439071416854858\n",
      "Loss at Iteration @ 2285 is 2.0826966762542725\n",
      "Loss at Iteration @ 2286 is 2.268148899078369\n",
      "Loss at Iteration @ 2287 is 2.182587146759033\n",
      "Loss at Iteration @ 2288 is 2.289524793624878\n",
      "Loss at Iteration @ 2289 is 1.9769140481948853\n",
      "Loss at Iteration @ 2290 is 2.2569053173065186\n",
      "Loss at Iteration @ 2291 is 2.072383165359497\n",
      "Loss at Iteration @ 2292 is 2.0435099601745605\n",
      "Loss at Iteration @ 2293 is 2.166410446166992\n",
      "Loss at Iteration @ 2294 is 1.9019296169281006\n",
      "Loss at Iteration @ 2295 is 2.0428764820098877\n",
      "Loss at Iteration @ 2296 is 2.4395956993103027\n",
      "Loss at Iteration @ 2297 is 2.5889742374420166\n",
      "Loss at Iteration @ 2298 is 2.375782012939453\n",
      "Loss at Iteration @ 2299 is 2.1421492099761963\n",
      "Loss at Iteration @ 2300 is 2.0608696937561035\n",
      "Loss at Iteration @ 2301 is 2.398865222930908\n",
      "Loss at Iteration @ 2302 is 2.217606544494629\n",
      "Loss at Iteration @ 2303 is 2.1450626850128174\n",
      "Loss at Iteration @ 2304 is 2.314659833908081\n",
      "Loss at Iteration @ 2305 is 2.2422573566436768\n",
      "Loss at Iteration @ 2306 is 2.3393807411193848\n",
      "Loss at Iteration @ 2307 is 2.1540069580078125\n",
      "Loss at Iteration @ 2308 is 1.958994746208191\n",
      "Loss at Iteration @ 2309 is 2.3476157188415527\n",
      "Loss at Iteration @ 2310 is 2.0852997303009033\n",
      "Loss at Iteration @ 2311 is 2.2316806316375732\n",
      "Loss at Iteration @ 2312 is 2.59441876411438\n",
      "Loss at Iteration @ 2313 is 2.1879351139068604\n",
      "Loss at Iteration @ 2314 is 2.228863000869751\n",
      "Loss at Iteration @ 2315 is 2.2655434608459473\n",
      "Loss at Iteration @ 2316 is 2.2633585929870605\n",
      "Loss at Iteration @ 2317 is 2.3061161041259766\n",
      "Loss at Iteration @ 2318 is 2.096115827560425\n",
      "Loss at Iteration @ 2319 is 2.3523268699645996\n",
      "Loss at Iteration @ 2320 is 2.0876150131225586\n",
      "Loss at Iteration @ 2321 is 2.118567705154419\n",
      "Loss at Iteration @ 2322 is 2.453751802444458\n",
      "Loss at Iteration @ 2323 is 2.4322264194488525\n",
      "Loss at Iteration @ 2324 is 2.337134838104248\n",
      "Loss at Iteration @ 2325 is 2.376958131790161\n",
      "Loss at Iteration @ 2326 is 2.254781484603882\n",
      "Loss at Iteration @ 2327 is 2.163881540298462\n",
      "Loss at Iteration @ 2328 is 2.12878680229187\n",
      "Loss at Iteration @ 2329 is 2.137695074081421\n",
      "Loss at Iteration @ 2330 is 2.2775187492370605\n",
      "Loss at Iteration @ 2331 is 2.301584243774414\n",
      "Loss at Iteration @ 2332 is 2.1278061866760254\n",
      "Loss at Iteration @ 2333 is 2.34673810005188\n",
      "Loss at Iteration @ 2334 is 1.9137617349624634\n",
      "Loss at Iteration @ 2335 is 2.1390185356140137\n",
      "Loss at Iteration @ 2336 is 2.3982863426208496\n",
      "Loss at Iteration @ 2337 is 1.991964340209961\n",
      "Loss at Iteration @ 2338 is 2.268888235092163\n",
      "Loss at Iteration @ 2339 is 2.029250144958496\n",
      "Loss at Iteration @ 2340 is 2.112333059310913\n",
      "Loss at Iteration @ 2341 is 2.210339307785034\n",
      "Loss at Iteration @ 2342 is 2.3766191005706787\n",
      "Loss at Iteration @ 2343 is 2.116245746612549\n",
      "Loss at Iteration @ 2344 is 2.3008415699005127\n",
      "Loss at Iteration @ 2345 is 2.338315725326538\n",
      "Loss at Iteration @ 2346 is 2.076237916946411\n",
      "Loss at Iteration @ 2347 is 2.3726797103881836\n",
      "Loss at Iteration @ 2348 is 2.1432104110717773\n",
      "Loss at Iteration @ 2349 is 2.240924119949341\n",
      "Loss at Iteration @ 2350 is 2.3408203125\n",
      "Loss at Iteration @ 2351 is 2.3380868434906006\n",
      "Loss at Iteration @ 2352 is 2.1791462898254395\n",
      "Loss at Iteration @ 2353 is 2.3852829933166504\n",
      "Loss at Iteration @ 2354 is 2.10905385017395\n",
      "Loss at Iteration @ 2355 is 2.328660488128662\n",
      "Loss at Iteration @ 2356 is 2.032818078994751\n",
      "Loss at Iteration @ 2357 is 2.5671274662017822\n",
      "Loss at Iteration @ 2358 is 2.058868646621704\n",
      "Loss at Iteration @ 2359 is 2.138413906097412\n",
      "Loss at Iteration @ 2360 is 2.247600793838501\n",
      "Loss at Iteration @ 2361 is 2.373260259628296\n",
      "Loss at Iteration @ 2362 is 2.2384753227233887\n",
      "Loss at Iteration @ 2363 is 2.4804160594940186\n",
      "Loss at Iteration @ 2364 is 2.3713390827178955\n",
      "Loss at Iteration @ 2365 is 2.2108254432678223\n",
      "Loss at Iteration @ 2366 is 1.966844081878662\n",
      "Loss at Iteration @ 2367 is 2.2930023670196533\n",
      "Loss at Iteration @ 2368 is 2.291193962097168\n",
      "Loss at Iteration @ 2369 is 2.2029407024383545\n",
      "Loss at Iteration @ 2370 is 2.37870717048645\n",
      "Loss at Iteration @ 2371 is 2.059512138366699\n",
      "Loss at Iteration @ 2372 is 2.2952001094818115\n",
      "Loss at Iteration @ 2373 is 2.3152904510498047\n",
      "Loss at Iteration @ 2374 is 2.1818878650665283\n",
      "Loss at Iteration @ 2375 is 2.107790946960449\n",
      "Loss at Iteration @ 2376 is 2.100050449371338\n",
      "Loss at Iteration @ 2377 is 2.271379232406616\n",
      "Loss at Iteration @ 2378 is 2.411362886428833\n",
      "Loss at Iteration @ 2379 is 2.19071888923645\n",
      "Loss at Iteration @ 2380 is 1.9959882497787476\n",
      "Loss at Iteration @ 2381 is 2.0059890747070312\n",
      "Loss at Iteration @ 2382 is 2.1454081535339355\n",
      "Loss at Iteration @ 2383 is 2.5472426414489746\n",
      "Loss at Iteration @ 2384 is 2.2347559928894043\n",
      "Loss at Iteration @ 2385 is 2.405085802078247\n",
      "Loss at Iteration @ 2386 is 2.1567347049713135\n",
      "Loss at Iteration @ 2387 is 2.134221315383911\n",
      "Loss at Iteration @ 2388 is 2.290377140045166\n",
      "Loss at Iteration @ 2389 is 1.9392414093017578\n",
      "Loss at Iteration @ 2390 is 1.8289246559143066\n",
      "Loss at Iteration @ 2391 is 2.0842301845550537\n",
      "Loss at Iteration @ 2392 is 2.0830533504486084\n",
      "Loss at Iteration @ 2393 is 2.2017669677734375\n",
      "Loss at Iteration @ 2394 is 2.142455577850342\n",
      "Loss at Iteration @ 2395 is 2.3067691326141357\n",
      "Loss at Iteration @ 2396 is 1.9792205095291138\n",
      "Loss at Iteration @ 2397 is 2.1901116371154785\n",
      "Loss at Iteration @ 2398 is 2.247657299041748\n",
      "Loss at Iteration @ 2399 is 2.4641404151916504\n",
      "Loss at Iteration @ 2400 is 2.5449652671813965\n",
      "Loss at Iteration @ 2401 is 2.4202325344085693\n",
      "Loss at Iteration @ 2402 is 2.199739456176758\n",
      "Loss at Iteration @ 2403 is 2.116244077682495\n",
      "Loss at Iteration @ 2404 is 2.324878454208374\n",
      "Loss at Iteration @ 2405 is 2.275007486343384\n",
      "Loss at Iteration @ 2406 is 2.1753833293914795\n",
      "Loss at Iteration @ 2407 is 2.4171335697174072\n",
      "Loss at Iteration @ 2408 is 2.4795215129852295\n",
      "Loss at Iteration @ 2409 is 1.9902677536010742\n",
      "Loss at Iteration @ 2410 is 2.522696018218994\n",
      "Loss at Iteration @ 2411 is 2.5584352016448975\n",
      "Loss at Iteration @ 2412 is 2.3794374465942383\n",
      "Loss at Iteration @ 2413 is 2.1471073627471924\n",
      "Loss at Iteration @ 2414 is 2.383105754852295\n",
      "Loss at Iteration @ 2415 is 2.195768117904663\n",
      "Loss at Iteration @ 2416 is 2.1296000480651855\n",
      "Loss at Iteration @ 2417 is 2.2699317932128906\n",
      "Loss at Iteration @ 2418 is 2.325437545776367\n",
      "Loss at Iteration @ 2419 is 2.4498579502105713\n",
      "Loss at Iteration @ 2420 is 2.219015121459961\n",
      "Loss at Iteration @ 2421 is 2.2686874866485596\n",
      "Loss at Iteration @ 2422 is 1.9730494022369385\n",
      "Loss at Iteration @ 2423 is 2.22749924659729\n",
      "Loss at Iteration @ 2424 is 2.038809061050415\n",
      "Loss at Iteration @ 2425 is 2.1319942474365234\n",
      "Loss at Iteration @ 2426 is 2.2527709007263184\n",
      "Loss at Iteration @ 2427 is 2.1750295162200928\n",
      "Loss at Iteration @ 2428 is 2.120009660720825\n",
      "Loss at Iteration @ 2429 is 2.3839213848114014\n",
      "Loss at Iteration @ 2430 is 2.220839262008667\n",
      "Loss at Iteration @ 2431 is 2.4466958045959473\n",
      "Loss at Iteration @ 2432 is 2.108276128768921\n",
      "Loss at Iteration @ 2433 is 1.7713812589645386\n",
      "Loss at Iteration @ 2434 is 2.1999456882476807\n",
      "Loss at Iteration @ 2435 is 2.126727342605591\n",
      "Loss at Iteration @ 2436 is 2.240161657333374\n",
      "Loss at Iteration @ 2437 is 2.4357452392578125\n",
      "Loss at Iteration @ 2438 is 2.6937732696533203\n",
      "Loss at Iteration @ 2439 is 2.1525230407714844\n",
      "Loss at Iteration @ 2440 is 2.037975549697876\n",
      "Loss at Iteration @ 2441 is 2.170861005783081\n",
      "Loss at Iteration @ 2442 is 1.9771034717559814\n",
      "Loss at Iteration @ 2443 is 2.5378851890563965\n",
      "Loss at Iteration @ 2444 is 2.203587293624878\n",
      "Loss at Iteration @ 2445 is 1.9383784532546997\n",
      "Loss at Iteration @ 2446 is 2.195983409881592\n",
      "Loss at Iteration @ 2447 is 2.142317295074463\n",
      "Loss at Iteration @ 2448 is 2.136599540710449\n",
      "Loss at Iteration @ 2449 is 2.136587381362915\n",
      "Loss at Iteration @ 2450 is 2.5677902698516846\n",
      "Loss at Iteration @ 2451 is 2.322706937789917\n",
      "Loss at Iteration @ 2452 is 2.3505053520202637\n",
      "Loss at Iteration @ 2453 is 2.217759847640991\n",
      "Loss at Iteration @ 2454 is 2.47613525390625\n",
      "Loss at Iteration @ 2455 is 2.103736162185669\n",
      "Loss at Iteration @ 2456 is 2.2257869243621826\n",
      "Loss at Iteration @ 2457 is 1.9532753229141235\n",
      "Loss at Iteration @ 2458 is 1.9358587265014648\n",
      "Loss at Iteration @ 2459 is 2.1085336208343506\n",
      "Loss at Iteration @ 2460 is 2.359323501586914\n",
      "Loss at Iteration @ 2461 is 2.3296191692352295\n",
      "Loss at Iteration @ 2462 is 2.4429774284362793\n",
      "Loss at Iteration @ 2463 is 2.092367172241211\n",
      "Loss at Iteration @ 2464 is 2.1888861656188965\n",
      "Loss at Iteration @ 2465 is 2.307250738143921\n",
      "Loss at Iteration @ 2466 is 2.3173344135284424\n",
      "Loss at Iteration @ 2467 is 2.2948291301727295\n",
      "Loss at Iteration @ 2468 is 1.9589464664459229\n",
      "Loss at Iteration @ 2469 is 2.3885834217071533\n",
      "Loss at Iteration @ 2470 is 2.0987441539764404\n",
      "Loss at Iteration @ 2471 is 2.2084455490112305\n",
      "Loss at Iteration @ 2472 is 2.1433792114257812\n",
      "Loss at Iteration @ 2473 is 2.15838885307312\n",
      "Loss at Iteration @ 2474 is 2.3161914348602295\n",
      "Loss at Iteration @ 2475 is 2.488739013671875\n",
      "Loss at Iteration @ 2476 is 2.4703712463378906\n",
      "Loss at Iteration @ 2477 is 2.2934091091156006\n",
      "Loss at Iteration @ 2478 is 2.1860594749450684\n",
      "Loss at Iteration @ 2479 is 2.426132917404175\n",
      "Loss at Iteration @ 2480 is 2.1587204933166504\n",
      "Loss at Iteration @ 2481 is 2.273655891418457\n",
      "Loss at Iteration @ 2482 is 2.251903533935547\n",
      "Loss at Iteration @ 2483 is 2.1374685764312744\n",
      "Loss at Iteration @ 2484 is 2.4928219318389893\n",
      "Loss at Iteration @ 2485 is 2.6307356357574463\n",
      "Loss at Iteration @ 2486 is 2.2094366550445557\n",
      "Loss at Iteration @ 2487 is 2.3630809783935547\n",
      "Loss at Iteration @ 2488 is 2.4457507133483887\n",
      "Loss at Iteration @ 2489 is 2.257990837097168\n",
      "Loss at Iteration @ 2490 is 2.303213357925415\n",
      "Loss at Iteration @ 2491 is 2.3160767555236816\n",
      "Loss at Iteration @ 2492 is 2.1167409420013428\n",
      "Loss at Iteration @ 2493 is 2.1807868480682373\n",
      "Loss at Iteration @ 2494 is 2.233170509338379\n",
      "Loss at Iteration @ 2495 is 2.5427894592285156\n",
      "Loss at Iteration @ 2496 is 2.549449920654297\n",
      "Loss at Iteration @ 2497 is 2.1182777881622314\n",
      "Loss at Iteration @ 2498 is 2.0834429264068604\n",
      "Loss at Iteration @ 2499 is 2.4158854484558105\n",
      "Loss at Iteration @ 2500 is 2.2808685302734375\n",
      "Loss at Iteration @ 2501 is 2.2266316413879395\n",
      "Loss at Iteration @ 2502 is 2.579900026321411\n",
      "Loss at Iteration @ 2503 is 2.31978440284729\n",
      "Loss at Iteration @ 2504 is 2.272266149520874\n",
      "Loss at Iteration @ 2505 is 2.0720431804656982\n",
      "Loss at Iteration @ 2506 is 1.9028892517089844\n",
      "Loss at Iteration @ 2507 is 2.518646001815796\n",
      "Loss at Iteration @ 2508 is 2.149242877960205\n",
      "Loss at Iteration @ 2509 is 2.1653099060058594\n",
      "Loss at Iteration @ 2510 is 2.3422398567199707\n",
      "Loss at Iteration @ 2511 is 2.1311423778533936\n",
      "Loss at Iteration @ 2512 is 2.2214345932006836\n",
      "Loss at Iteration @ 2513 is 1.8447664976119995\n",
      "Loss at Iteration @ 2514 is 2.1966142654418945\n",
      "Loss at Iteration @ 2515 is 2.1012790203094482\n",
      "Loss at Iteration @ 2516 is 2.1145944595336914\n",
      "Loss at Iteration @ 2517 is 1.9956494569778442\n",
      "Loss at Iteration @ 2518 is 2.360847234725952\n",
      "Loss at Iteration @ 2519 is 2.315035104751587\n",
      "Loss at Iteration @ 2520 is 2.0821595191955566\n",
      "Loss at Iteration @ 2521 is 2.0097055435180664\n",
      "Loss at Iteration @ 2522 is 2.240818500518799\n",
      "Loss at Iteration @ 2523 is 2.2952089309692383\n",
      "Loss at Iteration @ 2524 is 1.9949612617492676\n",
      "Loss at Iteration @ 2525 is 2.2821731567382812\n",
      "Loss at Iteration @ 2526 is 1.9309767484664917\n",
      "Loss at Iteration @ 2527 is 2.243151903152466\n",
      "Loss at Iteration @ 2528 is 2.0007197856903076\n",
      "Loss at Iteration @ 2529 is 2.3533356189727783\n",
      "Loss at Iteration @ 2530 is 2.2163801193237305\n",
      "Loss at Iteration @ 2531 is 1.9391812086105347\n",
      "Loss at Iteration @ 2532 is 2.2438666820526123\n",
      "Loss at Iteration @ 2533 is 2.5316884517669678\n",
      "Loss at Iteration @ 2534 is 2.420527696609497\n",
      "Loss at Iteration @ 2535 is 2.251333713531494\n",
      "Loss at Iteration @ 2536 is 2.2389349937438965\n",
      "Loss at Iteration @ 2537 is 2.3579907417297363\n",
      "Loss at Iteration @ 2538 is 2.2313296794891357\n",
      "Loss at Iteration @ 2539 is 2.291825771331787\n",
      "Loss at Iteration @ 2540 is 2.061309814453125\n",
      "Loss at Iteration @ 2541 is 2.2653775215148926\n",
      "Loss at Iteration @ 2542 is 2.102773904800415\n",
      "Loss at Iteration @ 2543 is 2.05546236038208\n",
      "Loss at Iteration @ 2544 is 2.3840904235839844\n",
      "Loss at Iteration @ 2545 is 2.4782094955444336\n",
      "Loss at Iteration @ 2546 is 2.344730854034424\n",
      "Loss at Iteration @ 2547 is 2.382611036300659\n",
      "Loss at Iteration @ 2548 is 1.9703551530838013\n",
      "Loss at Iteration @ 2549 is 2.480288028717041\n",
      "Loss at Iteration @ 2550 is 2.2614800930023193\n",
      "Loss at Iteration @ 2551 is 2.319176197052002\n",
      "Loss at Iteration @ 2552 is 2.23704195022583\n",
      "Loss at Iteration @ 2553 is 2.2755417823791504\n",
      "Loss at Iteration @ 2554 is 2.0906105041503906\n",
      "Loss at Iteration @ 2555 is 2.1095197200775146\n",
      "Loss at Iteration @ 2556 is 2.5246522426605225\n",
      "Loss at Iteration @ 2557 is 2.0000550746917725\n",
      "Loss at Iteration @ 2558 is 2.305548906326294\n",
      "Loss at Iteration @ 2559 is 1.9829316139221191\n",
      "Loss at Iteration @ 2560 is 2.202108144760132\n",
      "Loss at Iteration @ 2561 is 2.3331878185272217\n",
      "Loss at Iteration @ 2562 is 2.1609034538269043\n",
      "Loss at Iteration @ 2563 is 2.271217107772827\n",
      "Loss at Iteration @ 2564 is 1.945655345916748\n",
      "Loss at Iteration @ 2565 is 2.466245412826538\n",
      "Loss at Iteration @ 2566 is 2.1551525592803955\n",
      "Loss at Iteration @ 2567 is 2.0045197010040283\n",
      "Loss at Iteration @ 2568 is 2.5507314205169678\n",
      "Loss at Iteration @ 2569 is 2.3575329780578613\n",
      "Loss at Iteration @ 2570 is 2.242919683456421\n",
      "Loss at Iteration @ 2571 is 2.3095850944519043\n",
      "Loss at Iteration @ 2572 is 2.3381855487823486\n",
      "Loss at Iteration @ 2573 is 2.24723219871521\n",
      "Loss at Iteration @ 2574 is 1.9534213542938232\n",
      "Loss at Iteration @ 2575 is 2.0033211708068848\n",
      "Loss at Iteration @ 2576 is 2.2073519229888916\n",
      "Loss at Iteration @ 2577 is 1.7274246215820312\n",
      "Loss at Iteration @ 2578 is 2.040095806121826\n",
      "Loss at Iteration @ 2579 is 2.215663433074951\n",
      "Loss at Iteration @ 2580 is 2.006844997406006\n",
      "Loss at Iteration @ 2581 is 2.2880351543426514\n",
      "Loss at Iteration @ 2582 is 2.0589613914489746\n",
      "Loss at Iteration @ 2583 is 2.6631107330322266\n",
      "Loss at Iteration @ 2584 is 2.1189839839935303\n",
      "Loss at Iteration @ 2585 is 2.4307756423950195\n",
      "Loss at Iteration @ 2586 is 2.4557108879089355\n",
      "Loss at Iteration @ 2587 is 2.2523446083068848\n",
      "Loss at Iteration @ 2588 is 2.202770233154297\n",
      "Loss at Iteration @ 2589 is 2.5525076389312744\n",
      "Loss at Iteration @ 2590 is 2.1777002811431885\n",
      "Loss at Iteration @ 2591 is 2.335400104522705\n",
      "Loss at Iteration @ 2592 is 2.2833902835845947\n",
      "Loss at Iteration @ 2593 is 2.1977181434631348\n",
      "Loss at Iteration @ 2594 is 2.442312479019165\n",
      "Loss at Iteration @ 2595 is 1.9771409034729004\n",
      "Loss at Iteration @ 2596 is 2.1230247020721436\n",
      "Loss at Iteration @ 2597 is 2.1004459857940674\n",
      "Loss at Iteration @ 2598 is 2.0420258045196533\n",
      "Loss at Iteration @ 2599 is 2.364001750946045\n",
      "Loss at Iteration @ 2600 is 2.481123924255371\n",
      "Loss at Iteration @ 2601 is 2.459164619445801\n",
      "Loss at Iteration @ 2602 is 2.1427063941955566\n",
      "Loss at Iteration @ 2603 is 2.5446038246154785\n",
      "Loss at Iteration @ 2604 is 2.1108851432800293\n",
      "Loss at Iteration @ 2605 is 1.965129017829895\n",
      "Loss at Iteration @ 2606 is 2.1013925075531006\n",
      "Loss at Iteration @ 2607 is 2.1300430297851562\n",
      "Loss at Iteration @ 2608 is 2.4916608333587646\n",
      "Loss at Iteration @ 2609 is 2.4360592365264893\n",
      "Loss at Iteration @ 2610 is 2.0671982765197754\n",
      "Loss at Iteration @ 2611 is 2.098954916000366\n",
      "Loss at Iteration @ 2612 is 2.1103668212890625\n",
      "Loss at Iteration @ 2613 is 2.2880518436431885\n",
      "Loss at Iteration @ 2614 is 2.501023054122925\n",
      "Loss at Iteration @ 2615 is 2.2403905391693115\n",
      "Loss at Iteration @ 2616 is 1.8576804399490356\n",
      "Loss at Iteration @ 2617 is 2.230567455291748\n",
      "Loss at Iteration @ 2618 is 2.1999213695526123\n",
      "Loss at Iteration @ 2619 is 2.079131841659546\n",
      "Loss at Iteration @ 2620 is 2.19761323928833\n",
      "Loss at Iteration @ 2621 is 2.316789388656616\n",
      "Loss at Iteration @ 2622 is 2.1726763248443604\n",
      "Loss at Iteration @ 2623 is 2.093956708908081\n",
      "Loss at Iteration @ 2624 is 2.270137071609497\n",
      "Loss at Iteration @ 2625 is 2.090101718902588\n",
      "Loss at Iteration @ 2626 is 2.2313547134399414\n",
      "Loss at Iteration @ 2627 is 2.177560806274414\n",
      "Loss at Iteration @ 2628 is 2.3068149089813232\n",
      "Loss at Iteration @ 2629 is 1.9906977415084839\n",
      "Loss at Iteration @ 2630 is 2.2929129600524902\n",
      "Loss at Iteration @ 2631 is 2.105694055557251\n",
      "Loss at Iteration @ 2632 is 2.4587531089782715\n",
      "Loss at Iteration @ 2633 is 2.2276453971862793\n",
      "Loss at Iteration @ 2634 is 2.278998613357544\n",
      "Loss at Iteration @ 2635 is 2.2597241401672363\n",
      "Loss at Iteration @ 2636 is 2.354753255844116\n",
      "Loss at Iteration @ 2637 is 2.408250331878662\n",
      "Loss at Iteration @ 2638 is 2.1642181873321533\n",
      "Loss at Iteration @ 2639 is 2.2290751934051514\n",
      "Loss at Iteration @ 2640 is 2.2976982593536377\n",
      "Loss at Iteration @ 2641 is 2.128596544265747\n",
      "Loss at Iteration @ 2642 is 2.1471354961395264\n",
      "Loss at Iteration @ 2643 is 2.110013246536255\n",
      "Loss at Iteration @ 2644 is 2.4355881214141846\n",
      "Loss at Iteration @ 2645 is 2.431821346282959\n",
      "Loss at Iteration @ 2646 is 2.2032272815704346\n",
      "Loss at Iteration @ 2647 is 2.625436782836914\n",
      "Loss at Iteration @ 2648 is 2.395573139190674\n",
      "Loss at Iteration @ 2649 is 2.136486291885376\n",
      "Loss at Iteration @ 2650 is 2.0931341648101807\n",
      "Loss at Iteration @ 2651 is 2.203915596008301\n",
      "Loss at Iteration @ 2652 is 2.0813612937927246\n",
      "Loss at Iteration @ 2653 is 2.404085874557495\n",
      "Loss at Iteration @ 2654 is 2.251268148422241\n",
      "Loss at Iteration @ 2655 is 2.0325984954833984\n",
      "Loss at Iteration @ 2656 is 2.5225820541381836\n",
      "Loss at Iteration @ 2657 is 2.2153470516204834\n",
      "Loss at Iteration @ 2658 is 2.5610108375549316\n",
      "Loss at Iteration @ 2659 is 1.9216997623443604\n",
      "Loss at Iteration @ 2660 is 2.056083917617798\n",
      "Loss at Iteration @ 2661 is 1.9540899991989136\n",
      "Loss at Iteration @ 2662 is 2.3537466526031494\n",
      "Loss at Iteration @ 2663 is 2.625627040863037\n",
      "Loss at Iteration @ 2664 is 2.040323257446289\n",
      "Loss at Iteration @ 2665 is 2.203234910964966\n",
      "Loss at Iteration @ 2666 is 2.2463788986206055\n",
      "Loss at Iteration @ 2667 is 1.91762113571167\n",
      "Loss at Iteration @ 2668 is 2.2372684478759766\n",
      "Loss at Iteration @ 2669 is 2.1875154972076416\n",
      "Loss at Iteration @ 2670 is 2.06970477104187\n",
      "Loss at Iteration @ 2671 is 2.1763551235198975\n",
      "Loss at Iteration @ 2672 is 2.1208763122558594\n",
      "Loss at Iteration @ 2673 is 2.567006826400757\n",
      "Loss at Iteration @ 2674 is 2.3241569995880127\n",
      "Loss at Iteration @ 2675 is 2.016857385635376\n",
      "Loss at Iteration @ 2676 is 2.2296197414398193\n",
      "Loss at Iteration @ 2677 is 2.1998918056488037\n",
      "Loss at Iteration @ 2678 is 2.2942001819610596\n",
      "Loss at Iteration @ 2679 is 2.337934970855713\n",
      "Loss at Iteration @ 2680 is 1.7965130805969238\n",
      "Loss at Iteration @ 2681 is 2.4088833332061768\n",
      "Loss at Iteration @ 2682 is 2.1850295066833496\n",
      "Loss at Iteration @ 2683 is 2.322242498397827\n",
      "Loss at Iteration @ 2684 is 2.1648011207580566\n",
      "Loss at Iteration @ 2685 is 2.2228455543518066\n",
      "Loss at Iteration @ 2686 is 2.6184682846069336\n",
      "Loss at Iteration @ 2687 is 2.6165738105773926\n",
      "Loss at Iteration @ 2688 is 2.1004412174224854\n",
      "Loss at Iteration @ 2689 is 2.1735899448394775\n",
      "Loss at Iteration @ 2690 is 2.2249763011932373\n",
      "Loss at Iteration @ 2691 is 2.269991874694824\n",
      "Loss at Iteration @ 2692 is 2.3013601303100586\n",
      "Loss at Iteration @ 2693 is 2.321507692337036\n",
      "Loss at Iteration @ 2694 is 2.1807138919830322\n",
      "Loss at Iteration @ 2695 is 1.9557899236679077\n",
      "Loss at Iteration @ 2696 is 2.2180893421173096\n",
      "Loss at Iteration @ 2697 is 2.300659656524658\n",
      "Loss at Iteration @ 2698 is 2.3743324279785156\n",
      "Loss at Iteration @ 2699 is 2.46791672706604\n",
      "Loss at Iteration @ 2700 is 2.259024143218994\n",
      "Loss at Iteration @ 2701 is 2.408129930496216\n",
      "Loss at Iteration @ 2702 is 2.2515077590942383\n",
      "Loss at Iteration @ 2703 is 2.0318188667297363\n",
      "Loss at Iteration @ 2704 is 2.16491436958313\n",
      "Loss at Iteration @ 2705 is 1.9723036289215088\n",
      "Loss at Iteration @ 2706 is 2.235637903213501\n",
      "Loss at Iteration @ 2707 is 2.220296621322632\n",
      "Loss at Iteration @ 2708 is 2.1869115829467773\n",
      "Loss at Iteration @ 2709 is 2.5344483852386475\n",
      "Loss at Iteration @ 2710 is 2.364321708679199\n",
      "Loss at Iteration @ 2711 is 2.163821220397949\n",
      "Loss at Iteration @ 2712 is 2.3765175342559814\n",
      "Loss at Iteration @ 2713 is 2.2507729530334473\n",
      "Loss at Iteration @ 2714 is 2.2515313625335693\n",
      "Loss at Iteration @ 2715 is 2.3080902099609375\n",
      "Loss at Iteration @ 2716 is 2.247918128967285\n",
      "Loss at Iteration @ 2717 is 2.377588987350464\n",
      "Loss at Iteration @ 2718 is 2.0891027450561523\n",
      "Loss at Iteration @ 2719 is 2.1382980346679688\n",
      "Loss at Iteration @ 2720 is 2.4260005950927734\n",
      "Loss at Iteration @ 2721 is 2.423069477081299\n",
      "Loss at Iteration @ 2722 is 2.218567132949829\n",
      "Loss at Iteration @ 2723 is 2.3099827766418457\n",
      "Loss at Iteration @ 2724 is 2.1299781799316406\n",
      "Loss at Iteration @ 2725 is 2.068016767501831\n",
      "Loss at Iteration @ 2726 is 2.3625457286834717\n",
      "Loss at Iteration @ 2727 is 2.252889394760132\n",
      "Loss at Iteration @ 2728 is 2.374635696411133\n",
      "Loss at Iteration @ 2729 is 2.190416097640991\n",
      "Loss at Iteration @ 2730 is 2.214022159576416\n",
      "Loss at Iteration @ 2731 is 2.312045097351074\n",
      "Loss at Iteration @ 2732 is 2.2386040687561035\n",
      "Loss at Iteration @ 2733 is 2.178143262863159\n",
      "Loss at Iteration @ 2734 is 2.294718027114868\n",
      "Loss at Iteration @ 2735 is 2.380521059036255\n",
      "Loss at Iteration @ 2736 is 1.9847928285598755\n",
      "Loss at Iteration @ 2737 is 2.3358113765716553\n",
      "Loss at Iteration @ 2738 is 2.1445820331573486\n",
      "Loss at Iteration @ 2739 is 2.1963415145874023\n",
      "Loss at Iteration @ 2740 is 2.253284215927124\n",
      "Loss at Iteration @ 2741 is 2.079435348510742\n",
      "Loss at Iteration @ 2742 is 2.0887928009033203\n",
      "Loss at Iteration @ 2743 is 2.122141122817993\n",
      "Loss at Iteration @ 2744 is 2.1633987426757812\n",
      "Loss at Iteration @ 2745 is 2.2366302013397217\n",
      "Loss at Iteration @ 2746 is 2.2346248626708984\n",
      "Loss at Iteration @ 2747 is 2.220745086669922\n",
      "Loss at Iteration @ 2748 is 2.0759005546569824\n",
      "Loss at Iteration @ 2749 is 2.3410565853118896\n",
      "Loss at Iteration @ 2750 is 2.2380006313323975\n",
      "Loss at Iteration @ 2751 is 2.193694591522217\n",
      "Loss at Iteration @ 2752 is 2.080765962600708\n",
      "Loss at Iteration @ 2753 is 2.5668551921844482\n",
      "Loss at Iteration @ 2754 is 2.293086290359497\n",
      "Loss at Iteration @ 2755 is 2.4306282997131348\n",
      "Loss at Iteration @ 2756 is 2.3638105392456055\n",
      "Loss at Iteration @ 2757 is 2.1802749633789062\n",
      "Loss at Iteration @ 2758 is 2.277710437774658\n",
      "Loss at Iteration @ 2759 is 2.2564663887023926\n",
      "Loss at Iteration @ 2760 is 2.609079360961914\n",
      "Loss at Iteration @ 2761 is 2.3812053203582764\n",
      "Loss at Iteration @ 2762 is 2.2693111896514893\n",
      "Loss at Iteration @ 2763 is 2.321258544921875\n",
      "Loss at Iteration @ 2764 is 2.3819429874420166\n",
      "Loss at Iteration @ 2765 is 2.392878770828247\n",
      "Loss at Iteration @ 2766 is 2.245323657989502\n",
      "Loss at Iteration @ 2767 is 2.2318358421325684\n",
      "Loss at Iteration @ 2768 is 2.3551833629608154\n",
      "Loss at Iteration @ 2769 is 2.2043204307556152\n",
      "Loss at Iteration @ 2770 is 2.477201223373413\n",
      "Loss at Iteration @ 2771 is 2.083411693572998\n",
      "Loss at Iteration @ 2772 is 2.489835739135742\n",
      "Loss at Iteration @ 2773 is 2.3317861557006836\n",
      "Loss at Iteration @ 2774 is 2.209179401397705\n",
      "Loss at Iteration @ 2775 is 1.93770170211792\n",
      "Loss at Iteration @ 2776 is 2.3254806995391846\n",
      "Loss at Iteration @ 2777 is 2.272437334060669\n",
      "Loss at Iteration @ 2778 is 2.2245500087738037\n",
      "Loss at Iteration @ 2779 is 2.310750722885132\n",
      "Loss at Iteration @ 2780 is 2.0735719203948975\n",
      "Loss at Iteration @ 2781 is 2.05863094329834\n",
      "Loss at Iteration @ 2782 is 2.2705492973327637\n",
      "Loss at Iteration @ 2783 is 2.125091075897217\n",
      "Loss at Iteration @ 2784 is 2.0905821323394775\n",
      "Loss at Iteration @ 2785 is 2.2879490852355957\n",
      "Loss at Iteration @ 2786 is 2.5476279258728027\n",
      "Loss at Iteration @ 2787 is 2.333916425704956\n",
      "Loss at Iteration @ 2788 is 2.0433361530303955\n",
      "Loss at Iteration @ 2789 is 2.490769386291504\n",
      "Loss at Iteration @ 2790 is 2.2498440742492676\n",
      "Loss at Iteration @ 2791 is 2.120638847351074\n",
      "Loss at Iteration @ 2792 is 2.0973098278045654\n",
      "Loss at Iteration @ 2793 is 2.2490172386169434\n",
      "Loss at Iteration @ 2794 is 2.3326416015625\n",
      "Loss at Iteration @ 2795 is 2.2641758918762207\n",
      "Loss at Iteration @ 2796 is 1.9739067554473877\n",
      "Loss at Iteration @ 2797 is 2.3915481567382812\n",
      "Loss at Iteration @ 2798 is 2.4192426204681396\n",
      "Loss at Iteration @ 2799 is 2.267983913421631\n",
      "Loss at Iteration @ 2800 is 2.2040646076202393\n",
      "Loss at Iteration @ 2801 is 1.9790030717849731\n",
      "Loss at Iteration @ 2802 is 2.2397682666778564\n",
      "Loss at Iteration @ 2803 is 2.3305819034576416\n",
      "Loss at Iteration @ 2804 is 2.3071680068969727\n",
      "Loss at Iteration @ 2805 is 2.1412575244903564\n",
      "Loss at Iteration @ 2806 is 2.2284159660339355\n",
      "Loss at Iteration @ 2807 is 2.3963234424591064\n",
      "Loss at Iteration @ 2808 is 2.392765522003174\n",
      "Loss at Iteration @ 2809 is 2.209063768386841\n",
      "Loss at Iteration @ 2810 is 2.395735263824463\n",
      "Loss at Iteration @ 2811 is 2.5210630893707275\n",
      "Loss at Iteration @ 2812 is 2.196993589401245\n",
      "Loss at Iteration @ 2813 is 2.3244380950927734\n",
      "Loss at Iteration @ 2814 is 2.243133544921875\n",
      "Loss at Iteration @ 2815 is 2.3018600940704346\n",
      "Loss at Iteration @ 2816 is 2.0760934352874756\n",
      "Loss at Iteration @ 2817 is 2.203007221221924\n",
      "Loss at Iteration @ 2818 is 2.163520574569702\n",
      "Loss at Iteration @ 2819 is 2.4785125255584717\n",
      "Loss at Iteration @ 2820 is 2.2180540561676025\n",
      "Loss at Iteration @ 2821 is 2.2846641540527344\n",
      "Loss at Iteration @ 2822 is 2.388564348220825\n",
      "Loss at Iteration @ 2823 is 2.3725600242614746\n",
      "Loss at Iteration @ 2824 is 2.031741142272949\n",
      "Loss at Iteration @ 2825 is 1.9950884580612183\n",
      "Loss at Iteration @ 2826 is 2.141181230545044\n",
      "Loss at Iteration @ 2827 is 2.171757936477661\n",
      "Loss at Iteration @ 2828 is 1.9339385032653809\n",
      "Loss at Iteration @ 2829 is 2.3594088554382324\n",
      "Loss at Iteration @ 2830 is 2.342655658721924\n",
      "Loss at Iteration @ 2831 is 2.174757957458496\n",
      "Loss at Iteration @ 2832 is 2.253338575363159\n",
      "Loss at Iteration @ 2833 is 2.4095613956451416\n",
      "Loss at Iteration @ 2834 is 2.1891393661499023\n",
      "Loss at Iteration @ 2835 is 1.9616093635559082\n",
      "Loss at Iteration @ 2836 is 2.318838119506836\n",
      "Loss at Iteration @ 2837 is 2.442190647125244\n",
      "Loss at Iteration @ 2838 is 2.35441255569458\n",
      "Loss at Iteration @ 2839 is 2.1358110904693604\n",
      "Loss at Iteration @ 2840 is 2.5668208599090576\n",
      "Loss at Iteration @ 2841 is 2.5326201915740967\n",
      "Loss at Iteration @ 2842 is 2.507784366607666\n",
      "Loss at Iteration @ 2843 is 2.237309217453003\n",
      "Loss at Iteration @ 2844 is 2.130246639251709\n",
      "Loss at Iteration @ 2845 is 2.3152904510498047\n",
      "Loss at Iteration @ 2846 is 2.4924895763397217\n",
      "Loss at Iteration @ 2847 is 2.116915225982666\n",
      "Loss at Iteration @ 2848 is 2.221285820007324\n",
      "Loss at Iteration @ 2849 is 2.2084295749664307\n",
      "Loss at Iteration @ 2850 is 2.4437005519866943\n",
      "Loss at Iteration @ 2851 is 2.3608264923095703\n",
      "Loss at Iteration @ 2852 is 2.0688509941101074\n",
      "Loss at Iteration @ 2853 is 2.189427137374878\n",
      "Loss at Iteration @ 2854 is 2.08748197555542\n",
      "Loss at Iteration @ 2855 is 2.5101888179779053\n",
      "Loss at Iteration @ 2856 is 2.18772029876709\n",
      "Loss at Iteration @ 2857 is 1.9764851331710815\n",
      "Loss at Iteration @ 2858 is 2.0973422527313232\n",
      "Loss at Iteration @ 2859 is 2.3086369037628174\n",
      "Loss at Iteration @ 2860 is 2.1982171535491943\n",
      "Loss at Iteration @ 2861 is 2.404759407043457\n",
      "Loss at Iteration @ 2862 is 2.1098902225494385\n",
      "Loss at Iteration @ 2863 is 2.0840561389923096\n",
      "Loss at Iteration @ 2864 is 2.1530864238739014\n",
      "Loss at Iteration @ 2865 is 2.1911847591400146\n",
      "Loss at Iteration @ 2866 is 2.242421865463257\n",
      "Loss at Iteration @ 2867 is 2.1869428157806396\n",
      "Loss at Iteration @ 2868 is 2.26959228515625\n",
      "Loss at Iteration @ 2869 is 2.233262538909912\n",
      "Loss at Iteration @ 2870 is 2.0442662239074707\n",
      "Loss at Iteration @ 2871 is 2.172569990158081\n",
      "Loss at Iteration @ 2872 is 2.0893352031707764\n",
      "Loss at Iteration @ 2873 is 2.3101601600646973\n",
      "Loss at Iteration @ 2874 is 2.18768048286438\n",
      "Loss at Iteration @ 2875 is 2.1619956493377686\n",
      "Loss at Iteration @ 2876 is 2.464311361312866\n",
      "Loss at Iteration @ 2877 is 2.1909139156341553\n",
      "Loss at Iteration @ 2878 is 2.2627816200256348\n",
      "Loss at Iteration @ 2879 is 2.2979695796966553\n",
      "Loss at Iteration @ 2880 is 2.367971897125244\n",
      "Loss at Iteration @ 2881 is 2.0592458248138428\n",
      "Loss at Iteration @ 2882 is 2.0442521572113037\n",
      "Loss at Iteration @ 2883 is 2.0593364238739014\n",
      "Loss at Iteration @ 2884 is 2.1190199851989746\n",
      "Loss at Iteration @ 2885 is 2.0400078296661377\n",
      "Loss at Iteration @ 2886 is 2.075258731842041\n",
      "Loss at Iteration @ 2887 is 2.0273561477661133\n",
      "Loss at Iteration @ 2888 is 2.7727901935577393\n",
      "Loss at Iteration @ 2889 is 2.269986629486084\n",
      "Loss at Iteration @ 2890 is 2.52476167678833\n",
      "Loss at Iteration @ 2891 is 2.496833324432373\n",
      "Loss at Iteration @ 2892 is 2.0268726348876953\n",
      "Loss at Iteration @ 2893 is 2.4180567264556885\n",
      "Loss at Iteration @ 2894 is 2.4128870964050293\n",
      "Loss at Iteration @ 2895 is 2.2893640995025635\n",
      "Loss at Iteration @ 2896 is 2.1239511966705322\n",
      "Loss at Iteration @ 2897 is 2.426748037338257\n",
      "Loss at Iteration @ 2898 is 2.3921637535095215\n",
      "Loss at Iteration @ 2899 is 2.1403846740722656\n",
      "Loss at Iteration @ 2900 is 2.2664425373077393\n",
      "Loss at Iteration @ 2901 is 2.2755327224731445\n",
      "Loss at Iteration @ 2902 is 2.1298227310180664\n",
      "Loss at Iteration @ 2903 is 2.296421527862549\n",
      "Loss at Iteration @ 2904 is 2.3295700550079346\n",
      "Loss at Iteration @ 2905 is 2.0546112060546875\n",
      "Loss at Iteration @ 2906 is 2.4224798679351807\n",
      "Loss at Iteration @ 2907 is 2.466218948364258\n",
      "Loss at Iteration @ 2908 is 2.2455718517303467\n",
      "Loss at Iteration @ 2909 is 2.210313558578491\n",
      "Loss at Iteration @ 2910 is 2.4550929069519043\n",
      "Loss at Iteration @ 2911 is 1.991729497909546\n",
      "Loss at Iteration @ 2912 is 2.2531051635742188\n",
      "Loss at Iteration @ 2913 is 2.0215280055999756\n",
      "Loss at Iteration @ 2914 is 2.2702207565307617\n",
      "Loss at Iteration @ 2915 is 2.108295202255249\n",
      "Loss at Iteration @ 2916 is 2.1203415393829346\n",
      "Loss at Iteration @ 2917 is 2.1581320762634277\n",
      "Loss at Iteration @ 2918 is 2.2825207710266113\n",
      "Loss at Iteration @ 2919 is 2.240626096725464\n",
      "Loss at Iteration @ 2920 is 2.356083869934082\n",
      "Loss at Iteration @ 2921 is 1.8149569034576416\n",
      "Loss at Iteration @ 2922 is 2.241528272628784\n",
      "Loss at Iteration @ 2923 is 2.092362880706787\n",
      "Loss at Iteration @ 2924 is 2.32263445854187\n",
      "Loss at Iteration @ 2925 is 2.0703155994415283\n",
      "Loss at Iteration @ 2926 is 2.061988592147827\n",
      "Loss at Iteration @ 2927 is 2.178792715072632\n",
      "Loss at Iteration @ 2928 is 2.4675328731536865\n",
      "Loss at Iteration @ 2929 is 2.2418158054351807\n",
      "Loss at Iteration @ 2930 is 2.0445640087127686\n",
      "Loss at Iteration @ 2931 is 2.4478044509887695\n",
      "Loss at Iteration @ 2932 is 2.2273237705230713\n",
      "Loss at Iteration @ 2933 is 1.9141647815704346\n",
      "Loss at Iteration @ 2934 is 2.2788808345794678\n",
      "Loss at Iteration @ 2935 is 2.004558801651001\n",
      "Loss at Iteration @ 2936 is 2.278508186340332\n",
      "Loss at Iteration @ 2937 is 2.200106620788574\n",
      "Loss at Iteration @ 2938 is 2.5900492668151855\n",
      "Loss at Iteration @ 2939 is 2.148951292037964\n",
      "Loss at Iteration @ 2940 is 2.2382946014404297\n",
      "Loss at Iteration @ 2941 is 2.092012405395508\n",
      "Loss at Iteration @ 2942 is 2.1135945320129395\n",
      "Loss at Iteration @ 2943 is 2.325241804122925\n",
      "Loss at Iteration @ 2944 is 2.299842119216919\n",
      "Loss at Iteration @ 2945 is 2.0690460205078125\n",
      "Loss at Iteration @ 2946 is 2.278043031692505\n",
      "Loss at Iteration @ 2947 is 2.072486162185669\n",
      "Loss at Iteration @ 2948 is 2.1944754123687744\n",
      "Loss at Iteration @ 2949 is 2.003478765487671\n",
      "Loss at Iteration @ 2950 is 2.209491491317749\n",
      "Loss at Iteration @ 2951 is 2.289041519165039\n",
      "Loss at Iteration @ 2952 is 2.091557025909424\n",
      "Loss at Iteration @ 2953 is 2.3115344047546387\n",
      "Loss at Iteration @ 2954 is 2.0916757583618164\n",
      "Loss at Iteration @ 2955 is 1.7407209873199463\n",
      "Loss at Iteration @ 2956 is 2.361659288406372\n",
      "Loss at Iteration @ 2957 is 2.3083648681640625\n",
      "Loss at Iteration @ 2958 is 2.4401967525482178\n",
      "Loss at Iteration @ 2959 is 2.199897527694702\n",
      "Loss at Iteration @ 2960 is 2.2842984199523926\n",
      "Loss at Iteration @ 2961 is 2.349600315093994\n",
      "Loss at Iteration @ 2962 is 2.3736073970794678\n",
      "Loss at Iteration @ 2963 is 2.2857906818389893\n",
      "Loss at Iteration @ 2964 is 2.321631669998169\n",
      "Loss at Iteration @ 2965 is 2.126335382461548\n",
      "Loss at Iteration @ 2966 is 2.0569214820861816\n",
      "Loss at Iteration @ 2967 is 2.260185956954956\n",
      "Loss at Iteration @ 2968 is 1.9320274591445923\n",
      "Loss at Iteration @ 2969 is 2.200488805770874\n",
      "Loss at Iteration @ 2970 is 2.01116681098938\n",
      "Loss at Iteration @ 2971 is 2.1107113361358643\n",
      "Loss at Iteration @ 2972 is 2.4554152488708496\n",
      "Loss at Iteration @ 2973 is 2.1989145278930664\n",
      "Loss at Iteration @ 2974 is 2.3776350021362305\n",
      "Loss at Iteration @ 2975 is 2.3920159339904785\n",
      "Loss at Iteration @ 2976 is 2.25722336769104\n",
      "Loss at Iteration @ 2977 is 2.3772966861724854\n",
      "Loss at Iteration @ 2978 is 2.3488872051239014\n",
      "Loss at Iteration @ 2979 is 2.0180811882019043\n",
      "Loss at Iteration @ 2980 is 2.0353333950042725\n",
      "Loss at Iteration @ 2981 is 2.3978121280670166\n",
      "Loss at Iteration @ 2982 is 2.5063512325286865\n",
      "Loss at Iteration @ 2983 is 2.3908369541168213\n",
      "Loss at Iteration @ 2984 is 2.4458346366882324\n",
      "Loss at Iteration @ 2985 is 2.059183359146118\n",
      "Loss at Iteration @ 2986 is 2.1839678287506104\n",
      "Loss at Iteration @ 2987 is 2.1972222328186035\n",
      "Loss at Iteration @ 2988 is 2.515371322631836\n",
      "Loss at Iteration @ 2989 is 2.329559803009033\n",
      "Loss at Iteration @ 2990 is 1.9625613689422607\n",
      "Loss at Iteration @ 2991 is 2.6560654640197754\n",
      "Loss at Iteration @ 2992 is 2.1703219413757324\n",
      "Loss at Iteration @ 2993 is 2.5495097637176514\n",
      "Loss at Iteration @ 2994 is 2.386502742767334\n",
      "Loss at Iteration @ 2995 is 2.188978433609009\n",
      "Loss at Iteration @ 2996 is 2.292001247406006\n",
      "Loss at Iteration @ 2997 is 2.3994009494781494\n",
      "Loss at Iteration @ 2998 is 2.0362656116485596\n",
      "Loss at Iteration @ 2999 is 2.3634748458862305\n",
      "Loss at Iteration @ 3000 is 1.9641432762145996\n",
      "Loss at Iteration @ 3001 is 2.193493604660034\n",
      "Loss at Iteration @ 3002 is 2.0694708824157715\n",
      "Loss at Iteration @ 3003 is 2.473839521408081\n",
      "Loss at Iteration @ 3004 is 1.9732141494750977\n",
      "Loss at Iteration @ 3005 is 2.309136390686035\n",
      "Loss at Iteration @ 3006 is 2.2824199199676514\n",
      "Loss at Iteration @ 3007 is 1.966003656387329\n",
      "Loss at Iteration @ 3008 is 2.164220094680786\n",
      "Loss at Iteration @ 3009 is 2.296931743621826\n",
      "Loss at Iteration @ 3010 is 2.036012887954712\n",
      "Loss at Iteration @ 3011 is 2.145716428756714\n",
      "Loss at Iteration @ 3012 is 2.1297385692596436\n",
      "Loss at Iteration @ 3013 is 2.5307133197784424\n",
      "Loss at Iteration @ 3014 is 2.15813946723938\n",
      "Loss at Iteration @ 3015 is 1.8708207607269287\n",
      "Loss at Iteration @ 3016 is 2.093656063079834\n",
      "Loss at Iteration @ 3017 is 2.14211368560791\n",
      "Loss at Iteration @ 3018 is 2.136538505554199\n",
      "Loss at Iteration @ 3019 is 2.2801289558410645\n",
      "Loss at Iteration @ 3020 is 2.4035558700561523\n",
      "Loss at Iteration @ 3021 is 2.408454179763794\n",
      "Loss at Iteration @ 3022 is 2.4154396057128906\n",
      "Loss at Iteration @ 3023 is 2.009796380996704\n",
      "Loss at Iteration @ 3024 is 2.0967137813568115\n",
      "Loss at Iteration @ 3025 is 2.1074841022491455\n",
      "Loss at Iteration @ 3026 is 2.208958148956299\n",
      "Loss at Iteration @ 3027 is 2.2755632400512695\n",
      "Loss at Iteration @ 3028 is 2.2919600009918213\n",
      "Loss at Iteration @ 3029 is 2.3211143016815186\n",
      "Loss at Iteration @ 3030 is 2.240797281265259\n",
      "Loss at Iteration @ 3031 is 2.2805750370025635\n",
      "Loss at Iteration @ 3032 is 2.5617337226867676\n",
      "Loss at Iteration @ 3033 is 2.2060210704803467\n",
      "Loss at Iteration @ 3034 is 2.1734671592712402\n",
      "Loss at Iteration @ 3035 is 2.3456437587738037\n",
      "Loss at Iteration @ 3036 is 2.2539734840393066\n",
      "Loss at Iteration @ 3037 is 2.367896556854248\n",
      "Loss at Iteration @ 3038 is 2.265376091003418\n",
      "Loss at Iteration @ 3039 is 1.976539969444275\n",
      "Loss at Iteration @ 3040 is 2.3539600372314453\n",
      "Loss at Iteration @ 3041 is 2.2374463081359863\n",
      "Loss at Iteration @ 3042 is 2.324256658554077\n",
      "Loss at Iteration @ 3043 is 2.239483594894409\n",
      "Loss at Iteration @ 3044 is 2.0196244716644287\n",
      "Loss at Iteration @ 3045 is 2.3465659618377686\n",
      "Loss at Iteration @ 3046 is 2.1315605640411377\n",
      "Loss at Iteration @ 3047 is 2.23679518699646\n",
      "Loss at Iteration @ 3048 is 2.4418725967407227\n",
      "Loss at Iteration @ 3049 is 2.0208065509796143\n",
      "Loss at Iteration @ 3050 is 1.9667092561721802\n",
      "Loss at Iteration @ 3051 is 2.175023317337036\n",
      "Loss at Iteration @ 3052 is 1.8165466785430908\n",
      "Loss at Iteration @ 3053 is 2.2426257133483887\n",
      "Loss at Iteration @ 3054 is 2.408586263656616\n",
      "Loss at Iteration @ 3055 is 2.2853879928588867\n",
      "Loss at Iteration @ 3056 is 2.2380645275115967\n",
      "Loss at Iteration @ 3057 is 2.018339157104492\n",
      "Loss at Iteration @ 3058 is 1.9793280363082886\n",
      "Loss at Iteration @ 3059 is 2.263897657394409\n",
      "Loss at Iteration @ 3060 is 2.4247097969055176\n",
      "Loss at Iteration @ 3061 is 2.5076749324798584\n",
      "Loss at Iteration @ 3062 is 2.2817912101745605\n",
      "Loss at Iteration @ 3063 is 2.111858606338501\n",
      "Loss at Iteration @ 3064 is 2.4439857006073\n",
      "Loss at Iteration @ 3065 is 2.222388744354248\n",
      "Loss at Iteration @ 3066 is 2.3422889709472656\n",
      "Loss at Iteration @ 3067 is 2.1013238430023193\n",
      "Loss at Iteration @ 3068 is 2.1588220596313477\n",
      "Loss at Iteration @ 3069 is 2.32804536819458\n",
      "Loss at Iteration @ 3070 is 2.1282131671905518\n",
      "Loss at Iteration @ 3071 is 2.177340269088745\n",
      "Loss at Iteration @ 3072 is 2.209981918334961\n",
      "Loss at Iteration @ 3073 is 2.4307305812835693\n",
      "Loss at Iteration @ 3074 is 1.9668993949890137\n",
      "Loss at Iteration @ 3075 is 2.464580535888672\n",
      "Loss at Iteration @ 3076 is 2.0946500301361084\n",
      "Loss at Iteration @ 3077 is 2.0696349143981934\n",
      "Loss at Iteration @ 3078 is 2.36814284324646\n",
      "Loss at Iteration @ 3079 is 2.369842529296875\n",
      "Loss at Iteration @ 3080 is 2.2482011318206787\n",
      "Loss at Iteration @ 3081 is 2.433577299118042\n",
      "Loss at Iteration @ 3082 is 2.232974052429199\n",
      "Loss at Iteration @ 3083 is 2.2018239498138428\n",
      "Loss at Iteration @ 3084 is 2.5467605590820312\n",
      "Loss at Iteration @ 3085 is 2.049215793609619\n",
      "Loss at Iteration @ 3086 is 2.4061546325683594\n",
      "Loss at Iteration @ 3087 is 2.3338544368743896\n",
      "Loss at Iteration @ 3088 is 2.293175220489502\n",
      "Loss at Iteration @ 3089 is 2.0066239833831787\n",
      "Loss at Iteration @ 3090 is 2.2245113849639893\n",
      "Loss at Iteration @ 3091 is 2.3195748329162598\n",
      "Loss at Iteration @ 3092 is 2.1845884323120117\n",
      "Loss at Iteration @ 3093 is 2.2275784015655518\n",
      "Loss at Iteration @ 3094 is 2.384409189224243\n",
      "Loss at Iteration @ 3095 is 2.1590025424957275\n",
      "Loss at Iteration @ 3096 is 2.4378738403320312\n",
      "Loss at Iteration @ 3097 is 2.1750364303588867\n",
      "Loss at Iteration @ 3098 is 2.2139153480529785\n",
      "Loss at Iteration @ 3099 is 2.4487533569335938\n",
      "Loss at Iteration @ 3100 is 2.22982120513916\n",
      "Loss at Iteration @ 3101 is 2.030531406402588\n",
      "Loss at Iteration @ 3102 is 2.2606444358825684\n",
      "Loss at Iteration @ 3103 is 2.1068854331970215\n",
      "Loss at Iteration @ 3104 is 2.2414209842681885\n",
      "Loss at Iteration @ 3105 is 2.282733201980591\n",
      "Loss at Iteration @ 3106 is 2.254836320877075\n",
      "Loss at Iteration @ 3107 is 2.099957227706909\n",
      "Loss at Iteration @ 3108 is 2.3527116775512695\n",
      "Loss at Iteration @ 3109 is 1.868471384048462\n",
      "Loss at Iteration @ 3110 is 2.3387603759765625\n",
      "Loss at Iteration @ 3111 is 2.2256057262420654\n",
      "Loss at Iteration @ 3112 is 2.312488555908203\n",
      "Loss at Iteration @ 3113 is 2.0059187412261963\n",
      "Loss at Iteration @ 3114 is 2.6448988914489746\n",
      "Loss at Iteration @ 3115 is 1.9083739519119263\n",
      "Loss at Iteration @ 3116 is 2.2016100883483887\n",
      "Loss at Iteration @ 3117 is 2.2458231449127197\n",
      "Loss at Iteration @ 3118 is 2.2882049083709717\n",
      "Loss at Iteration @ 3119 is 2.3530426025390625\n",
      "Loss at Iteration @ 3120 is 2.246497869491577\n",
      "Loss at Iteration @ 3121 is 2.0497546195983887\n",
      "Loss at Iteration @ 3122 is 2.200392723083496\n",
      "Loss at Iteration @ 3123 is 1.7882269620895386\n",
      "Loss at Iteration @ 3124 is 2.055957555770874\n",
      "Loss at Iteration @ 3125 is 2.355273723602295\n",
      "Loss at Iteration @ 3126 is 2.093827724456787\n",
      "Loss at Iteration @ 3127 is 2.323148012161255\n",
      "Loss at Iteration @ 3128 is 2.490022659301758\n",
      "Loss at Iteration @ 3129 is 2.2161223888397217\n",
      "Loss at Iteration @ 3130 is 2.2675082683563232\n",
      "Loss at Iteration @ 3131 is 2.163862943649292\n",
      "Loss at Iteration @ 3132 is 2.0600743293762207\n",
      "Loss at Iteration @ 3133 is 2.2026572227478027\n",
      "Loss at Iteration @ 3134 is 2.0198395252227783\n",
      "Loss at Iteration @ 3135 is 2.362119197845459\n",
      "Loss at Iteration @ 3136 is 2.0090792179107666\n",
      "Loss at Iteration @ 3137 is 2.1774275302886963\n",
      "Loss at Iteration @ 3138 is 2.5759546756744385\n",
      "Loss at Iteration @ 3139 is 2.2234044075012207\n",
      "Loss at Iteration @ 3140 is 2.0995545387268066\n",
      "Loss at Iteration @ 3141 is 2.367786169052124\n",
      "Loss at Iteration @ 3142 is 2.3052761554718018\n",
      "Loss at Iteration @ 3143 is 2.096475839614868\n",
      "Loss at Iteration @ 3144 is 2.218658447265625\n",
      "Loss at Iteration @ 3145 is 2.357229232788086\n",
      "Loss at Iteration @ 3146 is 2.1411893367767334\n",
      "Loss at Iteration @ 3147 is 2.096601963043213\n",
      "Loss at Iteration @ 3148 is 2.4505553245544434\n",
      "Loss at Iteration @ 3149 is 2.309415578842163\n",
      "Loss at Iteration @ 3150 is 2.0979361534118652\n",
      "Loss at Iteration @ 3151 is 2.155869245529175\n",
      "Loss at Iteration @ 3152 is 2.185804605484009\n",
      "Loss at Iteration @ 3153 is 1.9690876007080078\n",
      "Loss at Iteration @ 3154 is 2.164140462875366\n",
      "Loss at Iteration @ 3155 is 2.1396162509918213\n",
      "Loss at Iteration @ 3156 is 2.3480350971221924\n",
      "Loss at Iteration @ 3157 is 2.3698174953460693\n",
      "Loss at Iteration @ 3158 is 2.449294328689575\n",
      "Loss at Iteration @ 3159 is 2.1783082485198975\n",
      "Loss at Iteration @ 3160 is 2.2447755336761475\n",
      "Loss at Iteration @ 3161 is 2.5041000843048096\n",
      "Loss at Iteration @ 3162 is 2.0529091358184814\n",
      "Loss at Iteration @ 3163 is 2.5057051181793213\n",
      "Loss at Iteration @ 3164 is 2.220992088317871\n",
      "Loss at Iteration @ 3165 is 2.0254316329956055\n",
      "Loss at Iteration @ 3166 is 2.0638015270233154\n",
      "Loss at Iteration @ 3167 is 2.377713441848755\n",
      "Loss at Iteration @ 3168 is 2.0695366859436035\n",
      "Loss at Iteration @ 3169 is 2.145656108856201\n",
      "Loss at Iteration @ 3170 is 2.269200325012207\n",
      "Loss at Iteration @ 3171 is 2.4142215251922607\n",
      "Loss at Iteration @ 3172 is 2.545557737350464\n",
      "Loss at Iteration @ 3173 is 2.3039684295654297\n",
      "Loss at Iteration @ 3174 is 2.2439076900482178\n",
      "Loss at Iteration @ 3175 is 2.3596277236938477\n",
      "Loss at Iteration @ 3176 is 2.147620677947998\n",
      "Loss at Iteration @ 3177 is 2.001662492752075\n",
      "Loss at Iteration @ 3178 is 2.533390522003174\n",
      "Loss at Iteration @ 3179 is 2.4919703006744385\n",
      "Loss at Iteration @ 3180 is 2.0374536514282227\n",
      "Loss at Iteration @ 3181 is 2.261533260345459\n",
      "Loss at Iteration @ 3182 is 2.348662853240967\n",
      "Loss at Iteration @ 3183 is 2.1130685806274414\n",
      "Loss at Iteration @ 3184 is 2.039161443710327\n",
      "Loss at Iteration @ 3185 is 2.2420692443847656\n",
      "Loss at Iteration @ 3186 is 2.2238829135894775\n",
      "Loss at Iteration @ 3187 is 2.4727296829223633\n",
      "Loss at Iteration @ 3188 is 2.1294777393341064\n",
      "Loss at Iteration @ 3189 is 2.233036518096924\n",
      "Loss at Iteration @ 3190 is 2.291041374206543\n",
      "Loss at Iteration @ 3191 is 2.2467899322509766\n",
      "Loss at Iteration @ 3192 is 2.2578847408294678\n",
      "Loss at Iteration @ 3193 is 2.0242462158203125\n",
      "Loss at Iteration @ 3194 is 2.3389830589294434\n",
      "Loss at Iteration @ 3195 is 2.518009662628174\n",
      "Loss at Iteration @ 3196 is 2.5156712532043457\n",
      "Loss at Iteration @ 3197 is 2.4651927947998047\n",
      "Loss at Iteration @ 3198 is 2.2394683361053467\n",
      "Loss at Iteration @ 3199 is 2.1414682865142822\n",
      "Loss at Iteration @ 3200 is 2.0498850345611572\n",
      "Loss at Iteration @ 3201 is 2.3847787380218506\n",
      "Loss at Iteration @ 3202 is 2.583266019821167\n",
      "Loss at Iteration @ 3203 is 1.9690910577774048\n",
      "Loss at Iteration @ 3204 is 2.1941099166870117\n",
      "Loss at Iteration @ 3205 is 2.2083730697631836\n",
      "Loss at Iteration @ 3206 is 2.1035006046295166\n",
      "Loss at Iteration @ 3207 is 2.2611045837402344\n",
      "Loss at Iteration @ 3208 is 2.2898364067077637\n",
      "Loss at Iteration @ 3209 is 2.2304880619049072\n",
      "Loss at Iteration @ 3210 is 2.2576544284820557\n",
      "Loss at Iteration @ 3211 is 2.2828726768493652\n",
      "Loss at Iteration @ 3212 is 2.078312635421753\n",
      "Loss at Iteration @ 3213 is 2.263516426086426\n",
      "Loss at Iteration @ 3214 is 2.337897777557373\n",
      "Loss at Iteration @ 3215 is 2.067223072052002\n",
      "Loss at Iteration @ 3216 is 1.878159761428833\n",
      "Loss at Iteration @ 3217 is 2.3084218502044678\n",
      "Loss at Iteration @ 3218 is 2.039562940597534\n",
      "Loss at Iteration @ 3219 is 2.4330286979675293\n",
      "Loss at Iteration @ 3220 is 2.2286314964294434\n",
      "Loss at Iteration @ 3221 is 2.2457118034362793\n",
      "Loss at Iteration @ 3222 is 2.298766613006592\n",
      "Loss at Iteration @ 3223 is 1.959388256072998\n",
      "Loss at Iteration @ 3224 is 2.0506908893585205\n",
      "Loss at Iteration @ 3225 is 2.1793482303619385\n",
      "Loss at Iteration @ 3226 is 2.3166139125823975\n",
      "Loss at Iteration @ 3227 is 2.169118881225586\n",
      "Loss at Iteration @ 3228 is 2.2887775897979736\n",
      "Loss at Iteration @ 3229 is 2.3364293575286865\n",
      "Loss at Iteration @ 3230 is 2.294440269470215\n",
      "Loss at Iteration @ 3231 is 2.357771873474121\n",
      "Loss at Iteration @ 3232 is 2.085775375366211\n",
      "Loss at Iteration @ 3233 is 2.3970119953155518\n",
      "Loss at Iteration @ 3234 is 2.0678818225860596\n",
      "Loss at Iteration @ 3235 is 2.5146751403808594\n",
      "Loss at Iteration @ 3236 is 2.439915180206299\n",
      "Loss at Iteration @ 3237 is 2.201300621032715\n",
      "Loss at Iteration @ 3238 is 2.3922994136810303\n",
      "Loss at Iteration @ 3239 is 2.2891416549682617\n",
      "Loss at Iteration @ 3240 is 2.4277682304382324\n",
      "Loss at Iteration @ 3241 is 2.235063314437866\n",
      "Loss at Iteration @ 3242 is 2.2982683181762695\n",
      "Loss at Iteration @ 3243 is 2.2854957580566406\n",
      "Loss at Iteration @ 3244 is 2.352480173110962\n",
      "Loss at Iteration @ 3245 is 2.1122517585754395\n",
      "Loss at Iteration @ 3246 is 2.59355092048645\n",
      "Loss at Iteration @ 3247 is 2.4889800548553467\n",
      "Loss at Iteration @ 3248 is 2.116178512573242\n",
      "Loss at Iteration @ 3249 is 2.1975901126861572\n",
      "Loss at Iteration @ 3250 is 2.1137406826019287\n",
      "Loss at Iteration @ 3251 is 2.4119255542755127\n",
      "Loss at Iteration @ 3252 is 1.8476876020431519\n",
      "Loss at Iteration @ 3253 is 2.0719664096832275\n",
      "Loss at Iteration @ 3254 is 2.242374897003174\n",
      "Loss at Iteration @ 3255 is 2.1376593112945557\n",
      "Loss at Iteration @ 3256 is 2.2206366062164307\n",
      "Loss at Iteration @ 3257 is 2.3613855838775635\n",
      "Loss at Iteration @ 3258 is 2.3987555503845215\n",
      "Loss at Iteration @ 3259 is 2.151050090789795\n",
      "Loss at Iteration @ 3260 is 2.2001278400421143\n",
      "Loss at Iteration @ 3261 is 2.2626640796661377\n",
      "Loss at Iteration @ 3262 is 2.154996633529663\n",
      "Loss at Iteration @ 3263 is 2.3113837242126465\n",
      "Loss at Iteration @ 3264 is 2.490309476852417\n",
      "Loss at Iteration @ 3265 is 2.1463685035705566\n",
      "Loss at Iteration @ 3266 is 2.011509895324707\n",
      "Loss at Iteration @ 3267 is 2.2136948108673096\n",
      "Loss at Iteration @ 3268 is 2.223210096359253\n",
      "Loss at Iteration @ 3269 is 2.305166721343994\n",
      "Loss at Iteration @ 3270 is 2.282628059387207\n",
      "Loss at Iteration @ 3271 is 2.288733959197998\n",
      "Loss at Iteration @ 3272 is 2.3073761463165283\n",
      "Loss at Iteration @ 3273 is 2.490795135498047\n",
      "Loss at Iteration @ 3274 is 2.3687801361083984\n",
      "Loss at Iteration @ 3275 is 2.117307662963867\n",
      "Loss at Iteration @ 3276 is 2.1468584537506104\n",
      "Loss at Iteration @ 3277 is 2.288595199584961\n",
      "Loss at Iteration @ 3278 is 2.190196990966797\n",
      "Loss at Iteration @ 3279 is 2.2326550483703613\n",
      "Loss at Iteration @ 3280 is 2.288034439086914\n",
      "Loss at Iteration @ 3281 is 2.468646764755249\n",
      "Loss at Iteration @ 3282 is 2.0643463134765625\n",
      "Loss at Iteration @ 3283 is 2.232503652572632\n",
      "Loss at Iteration @ 3284 is 2.2389614582061768\n",
      "Loss at Iteration @ 3285 is 2.0329370498657227\n",
      "Loss at Iteration @ 3286 is 2.127629041671753\n",
      "Loss at Iteration @ 3287 is 2.2810568809509277\n",
      "Loss at Iteration @ 3288 is 2.29160475730896\n",
      "Loss at Iteration @ 3289 is 2.29618239402771\n",
      "Loss at Iteration @ 3290 is 1.92299222946167\n",
      "Loss at Iteration @ 3291 is 1.9775718450546265\n",
      "Loss at Iteration @ 3292 is 2.37770938873291\n",
      "Loss at Iteration @ 3293 is 2.489802360534668\n",
      "Loss at Iteration @ 3294 is 2.353551149368286\n",
      "Loss at Iteration @ 3295 is 1.9611238241195679\n",
      "Loss at Iteration @ 3296 is 2.237014055252075\n",
      "Loss at Iteration @ 3297 is 2.185049533843994\n",
      "Loss at Iteration @ 3298 is 2.1622209548950195\n",
      "Loss at Iteration @ 3299 is 2.3260178565979004\n",
      "Loss at Iteration @ 3300 is 2.3252103328704834\n",
      "Loss at Iteration @ 3301 is 2.3118879795074463\n",
      "Loss at Iteration @ 3302 is 2.1886539459228516\n",
      "Loss at Iteration @ 3303 is 2.0149126052856445\n",
      "Loss at Iteration @ 3304 is 2.2669837474823\n",
      "Loss at Iteration @ 3305 is 2.250539541244507\n",
      "Loss at Iteration @ 3306 is 2.3620691299438477\n",
      "Loss at Iteration @ 3307 is 2.3260245323181152\n",
      "Loss at Iteration @ 3308 is 2.21517014503479\n",
      "Loss at Iteration @ 3309 is 1.9441744089126587\n",
      "Loss at Iteration @ 3310 is 2.0103445053100586\n",
      "Loss at Iteration @ 3311 is 2.0131523609161377\n",
      "Loss at Iteration @ 3312 is 2.3803861141204834\n",
      "Loss at Iteration @ 3313 is 2.0557198524475098\n",
      "Loss at Iteration @ 3314 is 2.040343761444092\n",
      "Loss at Iteration @ 3315 is 1.9804517030715942\n",
      "Loss at Iteration @ 3316 is 1.989434003829956\n",
      "Loss at Iteration @ 3317 is 2.295320510864258\n",
      "Loss at Iteration @ 3318 is 2.239924907684326\n",
      "Loss at Iteration @ 3319 is 2.052429676055908\n",
      "Loss at Iteration @ 3320 is 2.0339958667755127\n",
      "Loss at Iteration @ 3321 is 2.115015983581543\n",
      "Loss at Iteration @ 3322 is 2.3062479496002197\n",
      "Loss at Iteration @ 3323 is 2.2650930881500244\n",
      "Loss at Iteration @ 3324 is 2.0965206623077393\n",
      "Loss at Iteration @ 3325 is 2.010875940322876\n",
      "Loss at Iteration @ 3326 is 2.6689722537994385\n",
      "Loss at Iteration @ 3327 is 2.098851203918457\n",
      "Loss at Iteration @ 3328 is 2.2154884338378906\n",
      "Loss at Iteration @ 3329 is 2.1322262287139893\n",
      "Loss at Iteration @ 3330 is 2.1868722438812256\n",
      "Loss at Iteration @ 3331 is 2.4620320796966553\n",
      "Loss at Iteration @ 3332 is 2.28273868560791\n",
      "Loss at Iteration @ 3333 is 2.2802674770355225\n",
      "Loss at Iteration @ 3334 is 2.55037522315979\n",
      "Loss at Iteration @ 3335 is 2.261787176132202\n",
      "Loss at Iteration @ 3336 is 2.2254323959350586\n",
      "Loss at Iteration @ 3337 is 2.187169313430786\n",
      "Loss at Iteration @ 3338 is 2.150439500808716\n",
      "Loss at Iteration @ 3339 is 2.335888385772705\n",
      "Loss at Iteration @ 3340 is 2.417017936706543\n",
      "Loss at Iteration @ 3341 is 2.4843363761901855\n",
      "Loss at Iteration @ 3342 is 2.4864118099212646\n",
      "Loss at Iteration @ 3343 is 2.3766331672668457\n",
      "Loss at Iteration @ 3344 is 1.9577218294143677\n",
      "Loss at Iteration @ 3345 is 2.348886251449585\n",
      "Loss at Iteration @ 3346 is 2.2562623023986816\n",
      "Loss at Iteration @ 3347 is 2.4964239597320557\n",
      "Loss at Iteration @ 3348 is 2.178016185760498\n",
      "Loss at Iteration @ 3349 is 2.4816577434539795\n",
      "Loss at Iteration @ 3350 is 2.549199342727661\n",
      "Loss at Iteration @ 3351 is 2.3961944580078125\n",
      "Loss at Iteration @ 3352 is 2.0594747066497803\n",
      "Loss at Iteration @ 3353 is 2.3199667930603027\n",
      "Loss at Iteration @ 3354 is 2.555943250656128\n",
      "Loss at Iteration @ 3355 is 2.385110378265381\n",
      "Loss at Iteration @ 3356 is 2.720717430114746\n",
      "Loss at Iteration @ 3357 is 2.0594375133514404\n",
      "Loss at Iteration @ 3358 is 2.301348924636841\n",
      "Loss at Iteration @ 3359 is 2.4305789470672607\n",
      "Loss at Iteration @ 3360 is 2.0369393825531006\n",
      "Loss at Iteration @ 3361 is 2.1931779384613037\n",
      "Loss at Iteration @ 3362 is 2.2245094776153564\n",
      "Loss at Iteration @ 3363 is 2.028891086578369\n",
      "Loss at Iteration @ 3364 is 2.07943058013916\n",
      "Loss at Iteration @ 3365 is 2.4818453788757324\n",
      "Loss at Iteration @ 3366 is 2.440025806427002\n",
      "Loss at Iteration @ 3367 is 2.4542593955993652\n",
      "Loss at Iteration @ 3368 is 2.3618526458740234\n",
      "Loss at Iteration @ 3369 is 2.3827993869781494\n",
      "Loss at Iteration @ 3370 is 1.9822897911071777\n",
      "Loss at Iteration @ 3371 is 2.351233959197998\n",
      "Loss at Iteration @ 3372 is 2.130423069000244\n",
      "Loss at Iteration @ 3373 is 2.4594898223876953\n",
      "Loss at Iteration @ 3374 is 2.1635823249816895\n",
      "Loss at Iteration @ 3375 is 2.329503297805786\n",
      "Loss at Iteration @ 3376 is 2.073601722717285\n",
      "Loss at Iteration @ 3377 is 2.3244168758392334\n",
      "Loss at Iteration @ 3378 is 2.146165370941162\n",
      "Loss at Iteration @ 3379 is 2.584259033203125\n",
      "Loss at Iteration @ 3380 is 2.4114623069763184\n",
      "Loss at Iteration @ 3381 is 2.120863914489746\n",
      "Loss at Iteration @ 3382 is 2.04490065574646\n",
      "Loss at Iteration @ 3383 is 2.095691204071045\n",
      "Loss at Iteration @ 3384 is 1.9795665740966797\n",
      "Loss at Iteration @ 3385 is 2.2099623680114746\n",
      "Loss at Iteration @ 3386 is 2.1653265953063965\n",
      "Loss at Iteration @ 3387 is 2.275994300842285\n",
      "Loss at Iteration @ 3388 is 2.2308425903320312\n",
      "Loss at Iteration @ 3389 is 2.2253103256225586\n",
      "Loss at Iteration @ 3390 is 2.3921334743499756\n",
      "Loss at Iteration @ 3391 is 2.0876801013946533\n",
      "Loss at Iteration @ 3392 is 2.3919034004211426\n",
      "Loss at Iteration @ 3393 is 2.419750213623047\n",
      "Loss at Iteration @ 3394 is 2.3918089866638184\n",
      "Loss at Iteration @ 3395 is 2.4503958225250244\n",
      "Loss at Iteration @ 3396 is 2.3320295810699463\n",
      "Loss at Iteration @ 3397 is 2.186296224594116\n",
      "Loss at Iteration @ 3398 is 2.146543025970459\n",
      "Loss at Iteration @ 3399 is 2.5118367671966553\n",
      "Loss at Iteration @ 3400 is 2.0652804374694824\n",
      "Loss at Iteration @ 3401 is 2.354630470275879\n",
      "Loss at Iteration @ 3402 is 2.363208055496216\n",
      "Loss at Iteration @ 3403 is 2.0687856674194336\n",
      "Loss at Iteration @ 3404 is 2.3261375427246094\n",
      "Loss at Iteration @ 3405 is 2.15995717048645\n",
      "Loss at Iteration @ 3406 is 2.3294413089752197\n",
      "Loss at Iteration @ 3407 is 2.277646541595459\n",
      "Loss at Iteration @ 3408 is 2.4297890663146973\n",
      "Loss at Iteration @ 3409 is 2.0757174491882324\n",
      "Loss at Iteration @ 3410 is 2.224721670150757\n",
      "Loss at Iteration @ 3411 is 2.0874509811401367\n",
      "Loss at Iteration @ 3412 is 2.0364367961883545\n",
      "Loss at Iteration @ 3413 is 2.2803149223327637\n",
      "Loss at Iteration @ 3414 is 2.2940735816955566\n",
      "Loss at Iteration @ 3415 is 2.0694684982299805\n",
      "Loss at Iteration @ 3416 is 2.2162370681762695\n",
      "Loss at Iteration @ 3417 is 2.5069332122802734\n",
      "Loss at Iteration @ 3418 is 2.4138753414154053\n",
      "Loss at Iteration @ 3419 is 1.9920704364776611\n",
      "Loss at Iteration @ 3420 is 2.25468373298645\n",
      "Loss at Iteration @ 3421 is 2.13497257232666\n",
      "Loss at Iteration @ 3422 is 2.020294666290283\n",
      "Loss at Iteration @ 3423 is 2.146822929382324\n",
      "Loss at Iteration @ 3424 is 2.2668821811676025\n",
      "Loss at Iteration @ 3425 is 2.2367537021636963\n",
      "Loss at Iteration @ 3426 is 2.1207919120788574\n",
      "Loss at Iteration @ 3427 is 1.895336627960205\n",
      "Loss at Iteration @ 3428 is 2.2706127166748047\n",
      "Loss at Iteration @ 3429 is 2.215894937515259\n",
      "Loss at Iteration @ 3430 is 2.2755939960479736\n",
      "Loss at Iteration @ 3431 is 2.2514729499816895\n",
      "Loss at Iteration @ 3432 is 2.2384657859802246\n",
      "Loss at Iteration @ 3433 is 2.530144453048706\n",
      "Loss at Iteration @ 3434 is 2.2784550189971924\n",
      "Loss at Iteration @ 3435 is 2.436026096343994\n",
      "Loss at Iteration @ 3436 is 2.4465157985687256\n",
      "Loss at Iteration @ 3437 is 2.1980865001678467\n",
      "Loss at Iteration @ 3438 is 2.044029951095581\n",
      "Loss at Iteration @ 3439 is 2.3343665599823\n",
      "Loss at Iteration @ 3440 is 2.32840633392334\n",
      "Loss at Iteration @ 3441 is 2.124488115310669\n",
      "Loss at Iteration @ 3442 is 2.0185458660125732\n",
      "Loss at Iteration @ 3443 is 2.330481767654419\n",
      "Loss at Iteration @ 3444 is 1.962108850479126\n",
      "Loss at Iteration @ 3445 is 2.241013526916504\n",
      "Loss at Iteration @ 3446 is 2.2675375938415527\n",
      "Loss at Iteration @ 3447 is 2.313373327255249\n",
      "Loss at Iteration @ 3448 is 2.4889707565307617\n",
      "Loss at Iteration @ 3449 is 2.370976209640503\n",
      "Loss at Iteration @ 3450 is 2.2126264572143555\n",
      "Loss at Iteration @ 3451 is 2.207759141921997\n",
      "Loss at Iteration @ 3452 is 2.310131788253784\n",
      "Loss at Iteration @ 3453 is 2.3501834869384766\n",
      "Loss at Iteration @ 3454 is 2.2341370582580566\n",
      "Loss at Iteration @ 3455 is 2.287334680557251\n",
      "Loss at Iteration @ 3456 is 2.096527576446533\n",
      "Loss at Iteration @ 3457 is 2.3598792552948\n",
      "Loss at Iteration @ 3458 is 2.153336524963379\n",
      "Loss at Iteration @ 3459 is 2.051352024078369\n",
      "Loss at Iteration @ 3460 is 2.4183311462402344\n",
      "Loss at Iteration @ 3461 is 2.262239456176758\n",
      "Loss at Iteration @ 3462 is 2.0939786434173584\n",
      "Loss at Iteration @ 3463 is 2.4322211742401123\n",
      "Loss at Iteration @ 3464 is 2.194127321243286\n",
      "Loss at Iteration @ 3465 is 2.422175645828247\n",
      "Loss at Iteration @ 3466 is 2.3810641765594482\n",
      "Loss at Iteration @ 3467 is 2.1251986026763916\n",
      "Loss at Iteration @ 3468 is 2.248777151107788\n",
      "Loss at Iteration @ 3469 is 2.0149829387664795\n",
      "Loss at Iteration @ 3470 is 2.3106706142425537\n",
      "Loss at Iteration @ 3471 is 2.256598472595215\n",
      "Loss at Iteration @ 3472 is 2.2865488529205322\n",
      "Loss at Iteration @ 3473 is 2.039015531539917\n",
      "Loss at Iteration @ 3474 is 2.0910444259643555\n",
      "Loss at Iteration @ 3475 is 2.219660758972168\n",
      "Loss at Iteration @ 3476 is 2.5321598052978516\n",
      "Loss at Iteration @ 3477 is 2.3421411514282227\n",
      "Loss at Iteration @ 3478 is 2.1083767414093018\n",
      "Loss at Iteration @ 3479 is 2.2705633640289307\n",
      "Loss at Iteration @ 3480 is 2.2968504428863525\n",
      "Loss at Iteration @ 3481 is 2.25105357170105\n",
      "Loss at Iteration @ 3482 is 2.2868950366973877\n",
      "Loss at Iteration @ 3483 is 2.166208028793335\n",
      "Loss at Iteration @ 3484 is 2.2937631607055664\n",
      "Loss at Iteration @ 3485 is 2.3222129344940186\n",
      "Loss at Iteration @ 3486 is 2.500330686569214\n",
      "Loss at Iteration @ 3487 is 2.237635612487793\n",
      "Loss at Iteration @ 3488 is 2.338963747024536\n",
      "Loss at Iteration @ 3489 is 2.3914079666137695\n",
      "Loss at Iteration @ 3490 is 2.692350387573242\n",
      "Loss at Iteration @ 3491 is 2.5663583278656006\n",
      "Loss at Iteration @ 3492 is 2.221346139907837\n",
      "Loss at Iteration @ 3493 is 2.201486349105835\n",
      "Loss at Iteration @ 3494 is 2.158909320831299\n",
      "Loss at Iteration @ 3495 is 2.3880343437194824\n",
      "Loss at Iteration @ 3496 is 2.31158447265625\n",
      "Loss at Iteration @ 3497 is 2.2552270889282227\n",
      "Loss at Iteration @ 3498 is 2.0328619480133057\n",
      "Loss at Iteration @ 3499 is 2.1803641319274902\n",
      "Loss at Iteration @ 3500 is 2.529203176498413\n",
      "Loss at Iteration @ 3501 is 2.2315759658813477\n",
      "Loss at Iteration @ 3502 is 2.326568841934204\n",
      "Loss at Iteration @ 3503 is 2.474748373031616\n",
      "Loss at Iteration @ 3504 is 2.0300958156585693\n",
      "Loss at Iteration @ 3505 is 2.3113412857055664\n",
      "Loss at Iteration @ 3506 is 1.9499160051345825\n",
      "Loss at Iteration @ 3507 is 2.306450128555298\n",
      "Loss at Iteration @ 3508 is 2.1627960205078125\n",
      "Loss at Iteration @ 3509 is 2.241685390472412\n",
      "Loss at Iteration @ 3510 is 2.165419578552246\n",
      "Loss at Iteration @ 3511 is 2.0987207889556885\n",
      "Loss at Iteration @ 3512 is 2.10099196434021\n",
      "Loss at Iteration @ 3513 is 2.131671667098999\n",
      "Loss at Iteration @ 3514 is 2.1305992603302\n",
      "Loss at Iteration @ 3515 is 2.5414555072784424\n",
      "Loss at Iteration @ 3516 is 2.399437189102173\n",
      "Loss at Iteration @ 3517 is 2.187028169631958\n",
      "Loss at Iteration @ 3518 is 2.1891167163848877\n",
      "Loss at Iteration @ 3519 is 2.2554030418395996\n",
      "Loss at Iteration @ 3520 is 2.0797598361968994\n",
      "Loss at Iteration @ 3521 is 2.240229606628418\n",
      "Loss at Iteration @ 3522 is 2.354360580444336\n",
      "Loss at Iteration @ 3523 is 2.159372568130493\n",
      "Loss at Iteration @ 3524 is 2.31847882270813\n",
      "Loss at Iteration @ 3525 is 2.010291576385498\n",
      "Loss at Iteration @ 3526 is 2.0196802616119385\n",
      "Loss at Iteration @ 3527 is 2.0020763874053955\n",
      "Loss at Iteration @ 3528 is 2.291471242904663\n",
      "Loss at Iteration @ 3529 is 1.9237184524536133\n",
      "Loss at Iteration @ 3530 is 2.245851755142212\n",
      "Loss at Iteration @ 3531 is 1.852220892906189\n",
      "Loss at Iteration @ 3532 is 1.9182510375976562\n",
      "Loss at Iteration @ 3533 is 2.246232748031616\n",
      "Loss at Iteration @ 3534 is 2.215524435043335\n",
      "Loss at Iteration @ 3535 is 2.5340590476989746\n",
      "Loss at Iteration @ 3536 is 2.3164329528808594\n",
      "Loss at Iteration @ 3537 is 2.3320131301879883\n",
      "Loss at Iteration @ 3538 is 2.1466057300567627\n",
      "Loss at Iteration @ 3539 is 2.2452898025512695\n",
      "Loss at Iteration @ 3540 is 2.4741828441619873\n",
      "Loss at Iteration @ 3541 is 2.1077005863189697\n",
      "Loss at Iteration @ 3542 is 1.9379432201385498\n",
      "Loss at Iteration @ 3543 is 2.005577325820923\n",
      "Loss at Iteration @ 3544 is 2.18288254737854\n",
      "Loss at Iteration @ 3545 is 2.2813849449157715\n",
      "Loss at Iteration @ 3546 is 2.1920485496520996\n",
      "Loss at Iteration @ 3547 is 2.3769052028656006\n",
      "Loss at Iteration @ 3548 is 2.1406161785125732\n",
      "Loss at Iteration @ 3549 is 2.2024946212768555\n",
      "Loss at Iteration @ 3550 is 2.1142494678497314\n",
      "Loss at Iteration @ 3551 is 2.3282458782196045\n",
      "Loss at Iteration @ 3552 is 2.0811760425567627\n",
      "Loss at Iteration @ 3553 is 2.1799066066741943\n",
      "Loss at Iteration @ 3554 is 2.309597969055176\n",
      "Loss at Iteration @ 3555 is 2.3589298725128174\n",
      "Loss at Iteration @ 3556 is 2.2186453342437744\n",
      "Loss at Iteration @ 3557 is 2.1191062927246094\n",
      "Loss at Iteration @ 3558 is 2.1286065578460693\n",
      "Loss at Iteration @ 3559 is 1.980193853378296\n",
      "Loss at Iteration @ 3560 is 2.0429422855377197\n",
      "Loss at Iteration @ 3561 is 2.250356435775757\n",
      "Loss at Iteration @ 3562 is 2.1451988220214844\n",
      "Loss at Iteration @ 3563 is 2.047520399093628\n",
      "Loss at Iteration @ 3564 is 2.2807843685150146\n",
      "Loss at Iteration @ 3565 is 2.288764476776123\n",
      "Loss at Iteration @ 3566 is 2.024632692337036\n",
      "Loss at Iteration @ 3567 is 2.4672799110412598\n",
      "Loss at Iteration @ 3568 is 2.199031114578247\n",
      "Loss at Iteration @ 3569 is 2.077650547027588\n",
      "Loss at Iteration @ 3570 is 2.2095906734466553\n",
      "Loss at Iteration @ 3571 is 2.141150951385498\n",
      "Loss at Iteration @ 3572 is 2.1168484687805176\n",
      "Loss at Iteration @ 3573 is 2.1531827449798584\n",
      "Loss at Iteration @ 3574 is 2.440898895263672\n",
      "Loss at Iteration @ 3575 is 2.304494619369507\n",
      "Loss at Iteration @ 3576 is 2.4371581077575684\n",
      "Loss at Iteration @ 3577 is 2.2024950981140137\n",
      "Loss at Iteration @ 3578 is 2.2630276679992676\n",
      "Loss at Iteration @ 3579 is 2.4134795665740967\n",
      "Loss at Iteration @ 3580 is 2.1127700805664062\n",
      "Loss at Iteration @ 3581 is 2.5701420307159424\n",
      "Loss at Iteration @ 3582 is 1.9740262031555176\n",
      "Loss at Iteration @ 3583 is 2.054257869720459\n",
      "Loss at Iteration @ 3584 is 2.217280626296997\n",
      "Loss at Iteration @ 3585 is 2.0446434020996094\n",
      "Loss at Iteration @ 3586 is 2.0024988651275635\n",
      "Loss at Iteration @ 3587 is 2.4043216705322266\n",
      "Loss at Iteration @ 3588 is 2.3490281105041504\n",
      "Loss at Iteration @ 3589 is 2.1375319957733154\n",
      "Loss at Iteration @ 3590 is 2.034173011779785\n",
      "Loss at Iteration @ 3591 is 2.6447079181671143\n",
      "Loss at Iteration @ 3592 is 2.4182546138763428\n",
      "Loss at Iteration @ 3593 is 2.2706212997436523\n",
      "Loss at Iteration @ 3594 is 2.212271213531494\n",
      "Loss at Iteration @ 3595 is 2.2397358417510986\n",
      "Loss at Iteration @ 3596 is 2.381290912628174\n",
      "Loss at Iteration @ 3597 is 2.036864995956421\n",
      "Loss at Iteration @ 3598 is 1.9710445404052734\n",
      "Loss at Iteration @ 3599 is 2.2677860260009766\n",
      "Loss at Iteration @ 3600 is 2.1662392616271973\n",
      "Loss at Iteration @ 3601 is 1.8373863697052002\n",
      "Loss at Iteration @ 3602 is 2.2383503913879395\n",
      "Loss at Iteration @ 3603 is 2.456907033920288\n",
      "Loss at Iteration @ 3604 is 2.284679412841797\n",
      "Loss at Iteration @ 3605 is 2.3303754329681396\n",
      "Loss at Iteration @ 3606 is 2.344346046447754\n",
      "Loss at Iteration @ 3607 is 2.3534297943115234\n",
      "Loss at Iteration @ 3608 is 2.57413649559021\n",
      "Loss at Iteration @ 3609 is 2.1381101608276367\n",
      "Loss at Iteration @ 3610 is 2.155841827392578\n",
      "Loss at Iteration @ 3611 is 2.2240254878997803\n",
      "Loss at Iteration @ 3612 is 2.1706693172454834\n",
      "Loss at Iteration @ 3613 is 2.1274805068969727\n",
      "Loss at Iteration @ 3614 is 2.4899086952209473\n",
      "Loss at Iteration @ 3615 is 1.958603024482727\n",
      "Loss at Iteration @ 3616 is 2.3552513122558594\n",
      "Loss at Iteration @ 3617 is 1.9857330322265625\n",
      "Loss at Iteration @ 3618 is 1.9489328861236572\n",
      "Loss at Iteration @ 3619 is 2.125960111618042\n",
      "Loss at Iteration @ 3620 is 2.208658456802368\n",
      "Loss at Iteration @ 3621 is 2.415114402770996\n",
      "Loss at Iteration @ 3622 is 2.0937132835388184\n",
      "Loss at Iteration @ 3623 is 2.2242040634155273\n",
      "Loss at Iteration @ 3624 is 2.2979068756103516\n",
      "Loss at Iteration @ 3625 is 2.250302314758301\n",
      "Loss at Iteration @ 3626 is 2.249284267425537\n",
      "Loss at Iteration @ 3627 is 2.1557812690734863\n",
      "Loss at Iteration @ 3628 is 2.2650387287139893\n",
      "Loss at Iteration @ 3629 is 2.0993094444274902\n",
      "Loss at Iteration @ 3630 is 2.459691286087036\n",
      "Loss at Iteration @ 3631 is 2.118037223815918\n",
      "Loss at Iteration @ 3632 is 2.233295440673828\n",
      "Loss at Iteration @ 3633 is 1.996261715888977\n",
      "Loss at Iteration @ 3634 is 1.9980465173721313\n",
      "Loss at Iteration @ 3635 is 1.930741786956787\n",
      "Loss at Iteration @ 3636 is 2.025120258331299\n",
      "Loss at Iteration @ 3637 is 2.2740378379821777\n",
      "Loss at Iteration @ 3638 is 2.2516722679138184\n",
      "Loss at Iteration @ 3639 is 2.2324271202087402\n",
      "Loss at Iteration @ 3640 is 2.362856864929199\n",
      "Loss at Iteration @ 3641 is 2.3888754844665527\n",
      "Loss at Iteration @ 3642 is 2.5040690898895264\n",
      "Loss at Iteration @ 3643 is 1.896011471748352\n",
      "Loss at Iteration @ 3644 is 2.3340303897857666\n",
      "Loss at Iteration @ 3645 is 2.257561445236206\n",
      "Loss at Iteration @ 3646 is 1.9451427459716797\n",
      "Loss at Iteration @ 3647 is 2.2080461978912354\n",
      "Loss at Iteration @ 3648 is 2.022723436355591\n",
      "Loss at Iteration @ 3649 is 2.08837890625\n",
      "Loss at Iteration @ 3650 is 2.299701452255249\n",
      "Loss at Iteration @ 3651 is 2.2455456256866455\n",
      "Loss at Iteration @ 3652 is 2.364278554916382\n",
      "Loss at Iteration @ 3653 is 2.4350571632385254\n",
      "Loss at Iteration @ 3654 is 2.3055403232574463\n",
      "Loss at Iteration @ 3655 is 2.1130244731903076\n",
      "Loss at Iteration @ 3656 is 2.189596176147461\n",
      "Loss at Iteration @ 3657 is 2.077083110809326\n",
      "Loss at Iteration @ 3658 is 2.07509446144104\n",
      "Loss at Iteration @ 3659 is 2.2603659629821777\n",
      "Loss at Iteration @ 3660 is 2.458125591278076\n",
      "Loss at Iteration @ 3661 is 2.4207918643951416\n",
      "Loss at Iteration @ 3662 is 2.0981364250183105\n",
      "Loss at Iteration @ 3663 is 2.296327590942383\n",
      "Loss at Iteration @ 3664 is 2.4615542888641357\n",
      "Loss at Iteration @ 3665 is 2.31905198097229\n",
      "Loss at Iteration @ 3666 is 2.2608795166015625\n",
      "Loss at Iteration @ 3667 is 2.2666053771972656\n",
      "Loss at Iteration @ 3668 is 2.3114147186279297\n",
      "Loss at Iteration @ 3669 is 2.0948824882507324\n",
      "Loss at Iteration @ 3670 is 2.413973093032837\n",
      "Loss at Iteration @ 3671 is 2.1205973625183105\n",
      "Loss at Iteration @ 3672 is 2.3845088481903076\n",
      "Loss at Iteration @ 3673 is 2.4283242225646973\n",
      "Loss at Iteration @ 3674 is 2.3440160751342773\n",
      "Loss at Iteration @ 3675 is 2.4647278785705566\n",
      "Loss at Iteration @ 3676 is 2.2934703826904297\n",
      "Loss at Iteration @ 3677 is 2.38280987739563\n",
      "Loss at Iteration @ 3678 is 2.2280430793762207\n",
      "Loss at Iteration @ 3679 is 2.131985664367676\n",
      "Loss at Iteration @ 3680 is 2.109714984893799\n",
      "Loss at Iteration @ 3681 is 2.1824371814727783\n",
      "Loss at Iteration @ 3682 is 2.395738363265991\n",
      "Loss at Iteration @ 3683 is 2.2930757999420166\n",
      "Loss at Iteration @ 3684 is 2.3543360233306885\n",
      "Loss at Iteration @ 3685 is 2.443655014038086\n",
      "Loss at Iteration @ 3686 is 2.295095205307007\n",
      "Loss at Iteration @ 3687 is 2.11017107963562\n",
      "Loss at Iteration @ 3688 is 2.285191774368286\n",
      "Loss at Iteration @ 3689 is 2.286846160888672\n",
      "Loss at Iteration @ 3690 is 2.368344306945801\n",
      "Loss at Iteration @ 3691 is 2.332616090774536\n",
      "Loss at Iteration @ 3692 is 2.051549196243286\n",
      "Loss at Iteration @ 3693 is 1.956537127494812\n",
      "Loss at Iteration @ 3694 is 2.1292011737823486\n",
      "Loss at Iteration @ 3695 is 2.428812026977539\n",
      "Loss at Iteration @ 3696 is 2.0966556072235107\n",
      "Loss at Iteration @ 3697 is 2.098294496536255\n",
      "Loss at Iteration @ 3698 is 2.1873013973236084\n",
      "Loss at Iteration @ 3699 is 2.364229202270508\n",
      "Loss at Iteration @ 3700 is 2.2375564575195312\n",
      "Loss at Iteration @ 3701 is 2.1594865322113037\n",
      "Loss at Iteration @ 3702 is 2.26241397857666\n",
      "Loss at Iteration @ 3703 is 1.9733469486236572\n",
      "Loss at Iteration @ 3704 is 2.324983596801758\n",
      "Loss at Iteration @ 3705 is 2.186464548110962\n",
      "Loss at Iteration @ 3706 is 2.245100975036621\n",
      "Loss at Iteration @ 3707 is 2.36763858795166\n",
      "Loss at Iteration @ 3708 is 2.014226198196411\n",
      "Loss at Iteration @ 3709 is 2.2141175270080566\n",
      "Loss at Iteration @ 3710 is 2.0348479747772217\n",
      "Loss at Iteration @ 3711 is 2.226130723953247\n",
      "Loss at Iteration @ 3712 is 2.1679675579071045\n",
      "Loss at Iteration @ 3713 is 2.2017569541931152\n",
      "Loss at Iteration @ 3714 is 2.275205373764038\n",
      "Loss at Iteration @ 3715 is 2.3306877613067627\n",
      "Loss at Iteration @ 3716 is 2.284717559814453\n",
      "Loss at Iteration @ 3717 is 2.5244357585906982\n",
      "Loss at Iteration @ 3718 is 2.4452028274536133\n",
      "Loss at Iteration @ 3719 is 1.9997791051864624\n",
      "Loss at Iteration @ 3720 is 2.380248546600342\n",
      "Loss at Iteration @ 3721 is 2.089526414871216\n",
      "Loss at Iteration @ 3722 is 2.4578466415405273\n",
      "Loss at Iteration @ 3723 is 2.228898048400879\n",
      "Loss at Iteration @ 3724 is 2.245659351348877\n",
      "Loss at Iteration @ 3725 is 2.409893035888672\n",
      "Loss at Iteration @ 3726 is 2.2445852756500244\n",
      "Loss at Iteration @ 3727 is 2.324653148651123\n",
      "Loss at Iteration @ 3728 is 2.1582140922546387\n",
      "Loss at Iteration @ 3729 is 2.4113595485687256\n",
      "Loss at Iteration @ 3730 is 2.1968727111816406\n",
      "Loss at Iteration @ 3731 is 2.211059093475342\n",
      "Loss at Iteration @ 3732 is 2.311624526977539\n",
      "Loss at Iteration @ 3733 is 2.354810953140259\n",
      "Loss at Iteration @ 3734 is 2.2469263076782227\n",
      "Loss at Iteration @ 3735 is 1.954816460609436\n",
      "Loss at Iteration @ 3736 is 2.1733577251434326\n",
      "Loss at Iteration @ 3737 is 2.1206886768341064\n",
      "Loss at Iteration @ 3738 is 2.3248631954193115\n",
      "Loss at Iteration @ 3739 is 2.554652452468872\n",
      "Loss at Iteration @ 3740 is 2.413367509841919\n",
      "Loss at Iteration @ 3741 is 2.211813449859619\n",
      "Loss at Iteration @ 3742 is 2.3661746978759766\n",
      "Loss at Iteration @ 3743 is 2.438136100769043\n",
      "Loss at Iteration @ 3744 is 2.0017852783203125\n",
      "Loss at Iteration @ 3745 is 2.253679037094116\n",
      "Loss at Iteration @ 3746 is 2.1142752170562744\n",
      "Loss at Iteration @ 3747 is 2.427621364593506\n",
      "Loss at Iteration @ 3748 is 2.341602087020874\n",
      "Loss at Iteration @ 3749 is 2.121978998184204\n",
      "Loss at Iteration @ 3750 is 2.00437593460083\n",
      "Loss at Iteration @ 3751 is 2.2595784664154053\n",
      "Loss at Iteration @ 3752 is 2.4917197227478027\n",
      "Loss at Iteration @ 3753 is 2.305669069290161\n",
      "Loss at Iteration @ 3754 is 2.004791736602783\n",
      "Loss at Iteration @ 3755 is 1.91681706905365\n",
      "Loss at Iteration @ 3756 is 2.275568962097168\n",
      "Loss at Iteration @ 3757 is 2.0465660095214844\n",
      "Loss at Iteration @ 3758 is 2.087916851043701\n",
      "Loss at Iteration @ 3759 is 2.104673147201538\n",
      "Loss at Iteration @ 3760 is 2.3571066856384277\n",
      "Loss at Iteration @ 3761 is 2.3860862255096436\n",
      "Loss at Iteration @ 3762 is 2.413925886154175\n",
      "Loss at Iteration @ 3763 is 2.4010097980499268\n",
      "Loss at Iteration @ 3764 is 2.064131021499634\n",
      "Loss at Iteration @ 3765 is 2.292149066925049\n",
      "Loss at Iteration @ 3766 is 2.2876248359680176\n",
      "Loss at Iteration @ 3767 is 2.1680400371551514\n",
      "Loss at Iteration @ 3768 is 1.9727370738983154\n",
      "Loss at Iteration @ 3769 is 2.043823003768921\n",
      "Loss at Iteration @ 3770 is 2.3243536949157715\n",
      "Loss at Iteration @ 3771 is 2.3069310188293457\n",
      "Loss at Iteration @ 3772 is 2.078838586807251\n",
      "Loss at Iteration @ 3773 is 2.3037095069885254\n",
      "Loss at Iteration @ 3774 is 2.3540267944335938\n",
      "Loss at Iteration @ 3775 is 2.220655679702759\n",
      "Loss at Iteration @ 3776 is 2.1596779823303223\n",
      "Loss at Iteration @ 3777 is 2.1552484035491943\n",
      "Loss at Iteration @ 3778 is 1.9797133207321167\n",
      "Loss at Iteration @ 3779 is 2.1613521575927734\n",
      "Loss at Iteration @ 3780 is 2.092633008956909\n",
      "Loss at Iteration @ 3781 is 2.3038623332977295\n",
      "Loss at Iteration @ 3782 is 2.1298987865448\n",
      "Loss at Iteration @ 3783 is 2.660416841506958\n",
      "Loss at Iteration @ 3784 is 2.299680233001709\n",
      "Loss at Iteration @ 3785 is 2.264066219329834\n",
      "Loss at Iteration @ 3786 is 1.9091367721557617\n",
      "Loss at Iteration @ 3787 is 2.215766429901123\n",
      "Loss at Iteration @ 3788 is 2.3359055519104004\n",
      "Loss at Iteration @ 3789 is 2.0532891750335693\n",
      "Loss at Iteration @ 3790 is 2.2253072261810303\n",
      "Loss at Iteration @ 3791 is 2.272564172744751\n",
      "Loss at Iteration @ 3792 is 2.201373338699341\n",
      "Loss at Iteration @ 3793 is 2.3930795192718506\n",
      "Loss at Iteration @ 3794 is 2.3108816146850586\n",
      "Loss at Iteration @ 3795 is 2.2845540046691895\n",
      "Loss at Iteration @ 3796 is 2.5190377235412598\n",
      "Loss at Iteration @ 3797 is 2.219813346862793\n",
      "Loss at Iteration @ 3798 is 2.300471544265747\n",
      "Loss at Iteration @ 3799 is 2.089425563812256\n",
      "Loss at Iteration @ 3800 is 2.237532138824463\n",
      "Loss at Iteration @ 3801 is 2.127094030380249\n",
      "Loss at Iteration @ 3802 is 2.133920431137085\n",
      "Loss at Iteration @ 3803 is 2.2715625762939453\n",
      "Loss at Iteration @ 3804 is 2.466123104095459\n",
      "Loss at Iteration @ 3805 is 2.2789270877838135\n",
      "Loss at Iteration @ 3806 is 2.11797833442688\n",
      "Loss at Iteration @ 3807 is 2.195286273956299\n",
      "Loss at Iteration @ 3808 is 2.397127628326416\n",
      "Loss at Iteration @ 3809 is 2.266956090927124\n",
      "Loss at Iteration @ 3810 is 2.1464242935180664\n",
      "Loss at Iteration @ 3811 is 2.6707916259765625\n",
      "Loss at Iteration @ 3812 is 2.3309361934661865\n",
      "Loss at Iteration @ 3813 is 2.0481386184692383\n",
      "Loss at Iteration @ 3814 is 2.165280818939209\n",
      "Loss at Iteration @ 3815 is 2.3595283031463623\n",
      "Loss at Iteration @ 3816 is 2.227855920791626\n",
      "Loss at Iteration @ 3817 is 2.5025203227996826\n",
      "Loss at Iteration @ 3818 is 2.1022980213165283\n",
      "Loss at Iteration @ 3819 is 2.255596160888672\n",
      "Loss at Iteration @ 3820 is 2.097996711730957\n",
      "Loss at Iteration @ 3821 is 2.4909822940826416\n",
      "Loss at Iteration @ 3822 is 2.0581562519073486\n",
      "Loss at Iteration @ 3823 is 2.3276877403259277\n",
      "Loss at Iteration @ 3824 is 2.561091184616089\n",
      "Loss at Iteration @ 3825 is 2.2923293113708496\n",
      "Loss at Iteration @ 3826 is 2.162541151046753\n",
      "Loss at Iteration @ 3827 is 2.2698724269866943\n",
      "Loss at Iteration @ 3828 is 1.9214173555374146\n",
      "Loss at Iteration @ 3829 is 2.4713022708892822\n",
      "Loss at Iteration @ 3830 is 2.4430289268493652\n",
      "Loss at Iteration @ 3831 is 2.3753631114959717\n",
      "Loss at Iteration @ 3832 is 2.226602792739868\n",
      "Loss at Iteration @ 3833 is 2.27297043800354\n",
      "Loss at Iteration @ 3834 is 2.089681625366211\n",
      "Loss at Iteration @ 3835 is 2.6067380905151367\n",
      "Loss at Iteration @ 3836 is 2.5281708240509033\n",
      "Loss at Iteration @ 3837 is 2.169041156768799\n",
      "Loss at Iteration @ 3838 is 2.0679121017456055\n",
      "Loss at Iteration @ 3839 is 2.170567512512207\n",
      "Loss at Iteration @ 3840 is 2.1106133460998535\n",
      "Loss at Iteration @ 3841 is 2.3664708137512207\n",
      "Loss at Iteration @ 3842 is 1.9393645524978638\n",
      "Loss at Iteration @ 3843 is 2.2360568046569824\n",
      "Loss at Iteration @ 3844 is 2.1351242065429688\n",
      "Loss at Iteration @ 3845 is 2.3030872344970703\n",
      "Loss at Iteration @ 3846 is 2.155815601348877\n",
      "Loss at Iteration @ 3847 is 2.1859447956085205\n",
      "Loss at Iteration @ 3848 is 2.127511978149414\n",
      "Loss at Iteration @ 3849 is 2.4586308002471924\n",
      "Loss at Iteration @ 3850 is 2.1146390438079834\n",
      "Loss at Iteration @ 3851 is 2.26455020904541\n",
      "Loss at Iteration @ 3852 is 2.4053378105163574\n",
      "Loss at Iteration @ 3853 is 2.1949191093444824\n",
      "Loss at Iteration @ 3854 is 2.1664817333221436\n",
      "Loss at Iteration @ 3855 is 2.398010492324829\n",
      "Loss at Iteration @ 3856 is 2.2799525260925293\n",
      "Loss at Iteration @ 3857 is 2.296271562576294\n",
      "Loss at Iteration @ 3858 is 2.299459218978882\n",
      "Loss at Iteration @ 3859 is 2.225922107696533\n",
      "Loss at Iteration @ 3860 is 2.0544798374176025\n",
      "Loss at Iteration @ 3861 is 2.3382771015167236\n",
      "Loss at Iteration @ 3862 is 2.38718843460083\n",
      "Loss at Iteration @ 3863 is 2.3132286071777344\n",
      "Loss at Iteration @ 3864 is 2.116252899169922\n",
      "Loss at Iteration @ 3865 is 2.4589970111846924\n",
      "Loss at Iteration @ 3866 is 2.397035598754883\n",
      "Loss at Iteration @ 3867 is 2.5604493618011475\n",
      "Loss at Iteration @ 3868 is 2.3802490234375\n",
      "Loss at Iteration @ 3869 is 2.2019643783569336\n",
      "Loss at Iteration @ 3870 is 2.3492586612701416\n",
      "Loss at Iteration @ 3871 is 2.0733721256256104\n",
      "Loss at Iteration @ 3872 is 2.332056760787964\n",
      "Loss at Iteration @ 3873 is 2.373387098312378\n",
      "Loss at Iteration @ 3874 is 2.181992292404175\n",
      "Loss at Iteration @ 3875 is 2.050832509994507\n",
      "Loss at Iteration @ 3876 is 2.323997974395752\n",
      "Loss at Iteration @ 3877 is 2.2975404262542725\n",
      "Loss at Iteration @ 3878 is 2.5877256393432617\n",
      "Loss at Iteration @ 3879 is 2.324622392654419\n",
      "Loss at Iteration @ 3880 is 2.376812696456909\n",
      "Loss at Iteration @ 3881 is 1.9471296072006226\n",
      "Loss at Iteration @ 3882 is 2.27164626121521\n",
      "Loss at Iteration @ 3883 is 2.2366814613342285\n",
      "Loss at Iteration @ 3884 is 2.3243048191070557\n",
      "Loss at Iteration @ 3885 is 2.1801795959472656\n",
      "Loss at Iteration @ 3886 is 2.456044912338257\n",
      "Loss at Iteration @ 3887 is 2.4338645935058594\n",
      "Loss at Iteration @ 3888 is 2.33526611328125\n",
      "Loss at Iteration @ 3889 is 1.8934613466262817\n",
      "Loss at Iteration @ 3890 is 2.4302642345428467\n",
      "Loss at Iteration @ 3891 is 2.243945360183716\n",
      "Loss at Iteration @ 3892 is 2.284970760345459\n",
      "Loss at Iteration @ 3893 is 2.078498125076294\n",
      "Loss at Iteration @ 3894 is 2.381798267364502\n",
      "Loss at Iteration @ 3895 is 2.14502215385437\n",
      "Loss at Iteration @ 3896 is 2.330296277999878\n",
      "Loss at Iteration @ 3897 is 2.3112006187438965\n",
      "Loss at Iteration @ 3898 is 2.327129364013672\n",
      "Loss at Iteration @ 3899 is 2.4027934074401855\n",
      "Loss at Iteration @ 3900 is 2.0813345909118652\n",
      "Loss at Iteration @ 3901 is 2.0251355171203613\n",
      "Loss at Iteration @ 3902 is 2.1860640048980713\n",
      "Loss at Iteration @ 3903 is 2.327934741973877\n",
      "Loss at Iteration @ 3904 is 2.1723484992980957\n",
      "Loss at Iteration @ 3905 is 2.252390146255493\n",
      "Loss at Iteration @ 3906 is 2.429645299911499\n",
      "Loss at Iteration @ 3907 is 2.301071882247925\n",
      "Loss at Iteration @ 3908 is 2.1950836181640625\n",
      "Loss at Iteration @ 3909 is 2.0905706882476807\n",
      "Loss at Iteration @ 3910 is 2.3942155838012695\n",
      "Loss at Iteration @ 3911 is 2.5230419635772705\n",
      "Loss at Iteration @ 3912 is 2.3019397258758545\n",
      "Loss at Iteration @ 3913 is 2.175856113433838\n",
      "Loss at Iteration @ 3914 is 2.3427224159240723\n",
      "Loss at Iteration @ 3915 is 2.192582845687866\n",
      "Loss at Iteration @ 3916 is 2.263953685760498\n",
      "Loss at Iteration @ 3917 is 2.423666477203369\n",
      "Loss at Iteration @ 3918 is 2.4355201721191406\n",
      "Loss at Iteration @ 3919 is 1.9381966590881348\n",
      "Loss at Iteration @ 3920 is 2.161435604095459\n",
      "Loss at Iteration @ 3921 is 1.9825351238250732\n",
      "Loss at Iteration @ 3922 is 2.5072133541107178\n",
      "Loss at Iteration @ 3923 is 2.258143424987793\n",
      "Loss at Iteration @ 3924 is 2.4074151515960693\n",
      "Loss at Iteration @ 3925 is 2.0095293521881104\n",
      "Loss at Iteration @ 3926 is 2.442119598388672\n",
      "Loss at Iteration @ 3927 is 1.9971110820770264\n",
      "Loss at Iteration @ 3928 is 2.2379744052886963\n",
      "Loss at Iteration @ 3929 is 2.2027347087860107\n",
      "Loss at Iteration @ 3930 is 1.9479705095291138\n",
      "Loss at Iteration @ 3931 is 2.3073604106903076\n",
      "Loss at Iteration @ 3932 is 2.2400975227355957\n",
      "Loss at Iteration @ 3933 is 2.2771482467651367\n",
      "Loss at Iteration @ 3934 is 2.126390218734741\n",
      "Loss at Iteration @ 3935 is 2.15620493888855\n",
      "Loss at Iteration @ 3936 is 2.0902271270751953\n",
      "Loss at Iteration @ 3937 is 2.10341477394104\n",
      "Loss at Iteration @ 3938 is 1.9864259958267212\n",
      "Loss at Iteration @ 3939 is 2.126957654953003\n",
      "Loss at Iteration @ 3940 is 2.4022042751312256\n",
      "Loss at Iteration @ 3941 is 2.3292157649993896\n",
      "Loss at Iteration @ 3942 is 2.026898145675659\n",
      "Loss at Iteration @ 3943 is 2.3473997116088867\n",
      "Loss at Iteration @ 3944 is 2.549241304397583\n",
      "Loss at Iteration @ 3945 is 2.4070496559143066\n",
      "Loss at Iteration @ 3946 is 2.242375373840332\n",
      "Loss at Iteration @ 3947 is 2.4839863777160645\n",
      "Loss at Iteration @ 3948 is 2.2940611839294434\n",
      "Loss at Iteration @ 3949 is 2.256916046142578\n",
      "Loss at Iteration @ 3950 is 2.2767553329467773\n",
      "Loss at Iteration @ 3951 is 2.1494710445404053\n",
      "Loss at Iteration @ 3952 is 2.353027582168579\n",
      "Loss at Iteration @ 3953 is 2.1252026557922363\n",
      "Loss at Iteration @ 3954 is 2.0844736099243164\n",
      "Loss at Iteration @ 3955 is 2.095999240875244\n",
      "Loss at Iteration @ 3956 is 2.2535197734832764\n",
      "Loss at Iteration @ 3957 is 2.1796493530273438\n",
      "Loss at Iteration @ 3958 is 2.361116886138916\n",
      "Loss at Iteration @ 3959 is 2.400467872619629\n",
      "Loss at Iteration @ 3960 is 2.241208791732788\n",
      "Loss at Iteration @ 3961 is 2.339491605758667\n",
      "Loss at Iteration @ 3962 is 2.1320579051971436\n",
      "Loss at Iteration @ 3963 is 1.9940431118011475\n",
      "Loss at Iteration @ 3964 is 2.3246946334838867\n",
      "Loss at Iteration @ 3965 is 2.136974811553955\n",
      "Loss at Iteration @ 3966 is 2.167921781539917\n",
      "Loss at Iteration @ 3967 is 2.1215498447418213\n",
      "Loss at Iteration @ 3968 is 2.3353264331817627\n",
      "Loss at Iteration @ 3969 is 2.5217366218566895\n",
      "Loss at Iteration @ 3970 is 2.4000344276428223\n",
      "Loss at Iteration @ 3971 is 2.301388740539551\n",
      "Loss at Iteration @ 3972 is 2.3550260066986084\n",
      "Loss at Iteration @ 3973 is 2.3569703102111816\n",
      "Loss at Iteration @ 3974 is 2.086916923522949\n",
      "Loss at Iteration @ 3975 is 1.996040940284729\n",
      "Loss at Iteration @ 3976 is 2.344003438949585\n",
      "Loss at Iteration @ 3977 is 2.1712722778320312\n",
      "Loss at Iteration @ 3978 is 1.951122522354126\n",
      "Loss at Iteration @ 3979 is 2.379624605178833\n",
      "Loss at Iteration @ 3980 is 2.0062851905822754\n",
      "Loss at Iteration @ 3981 is 1.8663208484649658\n",
      "Loss at Iteration @ 3982 is 2.2629554271698\n",
      "Loss at Iteration @ 3983 is 2.1289000511169434\n",
      "Loss at Iteration @ 3984 is 2.2658302783966064\n",
      "Loss at Iteration @ 3985 is 2.0398991107940674\n",
      "Loss at Iteration @ 3986 is 2.2141356468200684\n",
      "Loss at Iteration @ 3987 is 2.0927517414093018\n",
      "Loss at Iteration @ 3988 is 2.0825066566467285\n",
      "Loss at Iteration @ 3989 is 2.4148244857788086\n",
      "Loss at Iteration @ 3990 is 2.104527711868286\n",
      "Loss at Iteration @ 3991 is 2.0842583179473877\n",
      "Loss at Iteration @ 3992 is 2.196739673614502\n",
      "Loss at Iteration @ 3993 is 2.0593953132629395\n",
      "Loss at Iteration @ 3994 is 2.212779998779297\n",
      "Loss at Iteration @ 3995 is 2.127335548400879\n",
      "Loss at Iteration @ 3996 is 2.2309439182281494\n",
      "Loss at Iteration @ 3997 is 2.283217191696167\n",
      "Loss at Iteration @ 3998 is 2.2997617721557617\n",
      "Loss at Iteration @ 3999 is 2.2544655799865723\n",
      "Loss at Iteration @ 4000 is 2.130704402923584\n",
      "Loss at Iteration @ 4001 is 2.1811656951904297\n",
      "Loss at Iteration @ 4002 is 2.4013822078704834\n",
      "Loss at Iteration @ 4003 is 2.1965465545654297\n",
      "Loss at Iteration @ 4004 is 2.490650177001953\n",
      "Loss at Iteration @ 4005 is 2.2629499435424805\n",
      "Loss at Iteration @ 4006 is 2.099010705947876\n",
      "Loss at Iteration @ 4007 is 2.138486623764038\n",
      "Loss at Iteration @ 4008 is 2.178326368331909\n",
      "Loss at Iteration @ 4009 is 2.138766050338745\n",
      "Loss at Iteration @ 4010 is 2.2137701511383057\n",
      "Loss at Iteration @ 4011 is 2.307478427886963\n",
      "Loss at Iteration @ 4012 is 2.350958824157715\n",
      "Loss at Iteration @ 4013 is 2.2467663288116455\n",
      "Loss at Iteration @ 4014 is 2.4009928703308105\n",
      "Loss at Iteration @ 4015 is 2.0801801681518555\n",
      "Loss at Iteration @ 4016 is 2.281360626220703\n",
      "Loss at Iteration @ 4017 is 2.342935800552368\n",
      "Loss at Iteration @ 4018 is 2.3018555641174316\n",
      "Loss at Iteration @ 4019 is 1.9922983646392822\n",
      "Loss at Iteration @ 4020 is 2.186323404312134\n",
      "Loss at Iteration @ 4021 is 2.2606451511383057\n",
      "Loss at Iteration @ 4022 is 2.122284412384033\n",
      "Loss at Iteration @ 4023 is 2.2039995193481445\n",
      "Loss at Iteration @ 4024 is 2.2206923961639404\n",
      "Loss at Iteration @ 4025 is 2.170807361602783\n",
      "Loss at Iteration @ 4026 is 2.065903902053833\n",
      "Loss at Iteration @ 4027 is 2.3224475383758545\n",
      "Loss at Iteration @ 4028 is 2.0334420204162598\n",
      "Loss at Iteration @ 4029 is 2.1940701007843018\n",
      "Loss at Iteration @ 4030 is 2.3476948738098145\n",
      "Loss at Iteration @ 4031 is 2.502331495285034\n",
      "Loss at Iteration @ 4032 is 2.177056074142456\n",
      "Loss at Iteration @ 4033 is 2.0147705078125\n",
      "Loss at Iteration @ 4034 is 2.2890844345092773\n",
      "Loss at Iteration @ 4035 is 2.2252490520477295\n",
      "Loss at Iteration @ 4036 is 2.3122711181640625\n",
      "Loss at Iteration @ 4037 is 2.3351378440856934\n",
      "Loss at Iteration @ 4038 is 2.3503291606903076\n",
      "Loss at Iteration @ 4039 is 2.2358341217041016\n",
      "Loss at Iteration @ 4040 is 2.3889753818511963\n",
      "Loss at Iteration @ 4041 is 2.1980669498443604\n",
      "Loss at Iteration @ 4042 is 2.0988078117370605\n",
      "Loss at Iteration @ 4043 is 2.2319624423980713\n",
      "Loss at Iteration @ 4044 is 2.2006452083587646\n",
      "Loss at Iteration @ 4045 is 2.2213854789733887\n",
      "Loss at Iteration @ 4046 is 2.3648579120635986\n",
      "Loss at Iteration @ 4047 is 2.0713210105895996\n",
      "Loss at Iteration @ 4048 is 2.247239351272583\n",
      "Loss at Iteration @ 4049 is 2.121344566345215\n",
      "Loss at Iteration @ 4050 is 2.2757680416107178\n",
      "Loss at Iteration @ 4051 is 2.130819797515869\n",
      "Loss at Iteration @ 4052 is 2.3478424549102783\n",
      "Loss at Iteration @ 4053 is 2.462559700012207\n",
      "Loss at Iteration @ 4054 is 2.0958731174468994\n",
      "Loss at Iteration @ 4055 is 2.145185947418213\n",
      "Loss at Iteration @ 4056 is 2.1841726303100586\n",
      "Loss at Iteration @ 4057 is 2.361870765686035\n",
      "Loss at Iteration @ 4058 is 2.0681395530700684\n",
      "Loss at Iteration @ 4059 is 1.9955711364746094\n",
      "Loss at Iteration @ 4060 is 2.407845973968506\n",
      "Loss at Iteration @ 4061 is 2.397993803024292\n",
      "Loss at Iteration @ 4062 is 2.2888436317443848\n",
      "Loss at Iteration @ 4063 is 2.0360376834869385\n",
      "Loss at Iteration @ 4064 is 2.3189456462860107\n",
      "Loss at Iteration @ 4065 is 2.0852227210998535\n",
      "Loss at Iteration @ 4066 is 2.2442803382873535\n",
      "Loss at Iteration @ 4067 is 2.0517020225524902\n",
      "Loss at Iteration @ 4068 is 2.057701349258423\n",
      "Loss at Iteration @ 4069 is 2.209212064743042\n",
      "Loss at Iteration @ 4070 is 2.0976903438568115\n",
      "Loss at Iteration @ 4071 is 2.6055874824523926\n",
      "Loss at Iteration @ 4072 is 2.305086612701416\n",
      "Loss at Iteration @ 4073 is 2.1481850147247314\n",
      "Loss at Iteration @ 4074 is 2.1428029537200928\n",
      "Loss at Iteration @ 4075 is 2.240600109100342\n",
      "Loss at Iteration @ 4076 is 2.2659566402435303\n",
      "Loss at Iteration @ 4077 is 2.303302526473999\n",
      "Loss at Iteration @ 4078 is 2.1006317138671875\n",
      "Loss at Iteration @ 4079 is 2.293949604034424\n",
      "Loss at Iteration @ 4080 is 2.136321783065796\n",
      "Loss at Iteration @ 4081 is 2.1259498596191406\n",
      "Loss at Iteration @ 4082 is 2.1647427082061768\n",
      "Loss at Iteration @ 4083 is 2.1911673545837402\n",
      "Loss at Iteration @ 4084 is 2.028168201446533\n",
      "Loss at Iteration @ 4085 is 2.432021379470825\n",
      "Loss at Iteration @ 4086 is 2.0492124557495117\n",
      "Loss at Iteration @ 4087 is 2.286512613296509\n",
      "Loss at Iteration @ 4088 is 2.389375686645508\n",
      "Loss at Iteration @ 4089 is 2.275756597518921\n",
      "Loss at Iteration @ 4090 is 2.3431947231292725\n",
      "Loss at Iteration @ 4091 is 2.272033929824829\n",
      "Loss at Iteration @ 4092 is 2.5260727405548096\n",
      "Loss at Iteration @ 4093 is 2.2297520637512207\n",
      "Loss at Iteration @ 4094 is 2.3260645866394043\n",
      "Loss at Iteration @ 4095 is 2.1588964462280273\n",
      "Loss at Iteration @ 4096 is 2.197859764099121\n",
      "Loss at Iteration @ 4097 is 2.135636329650879\n",
      "Loss at Iteration @ 4098 is 2.4045958518981934\n",
      "Loss at Iteration @ 4099 is 2.2589924335479736\n",
      "Loss at Iteration @ 4100 is 2.1177399158477783\n",
      "Loss at Iteration @ 4101 is 2.474442958831787\n",
      "Loss at Iteration @ 4102 is 2.1850593090057373\n",
      "Loss at Iteration @ 4103 is 2.429823637008667\n",
      "Loss at Iteration @ 4104 is 2.3314387798309326\n",
      "Loss at Iteration @ 4105 is 2.2593507766723633\n",
      "Loss at Iteration @ 4106 is 2.0352182388305664\n",
      "Loss at Iteration @ 4107 is 2.3862192630767822\n",
      "Loss at Iteration @ 4108 is 1.9598852396011353\n",
      "Loss at Iteration @ 4109 is 2.099766492843628\n",
      "Loss at Iteration @ 4110 is 2.181716203689575\n",
      "Loss at Iteration @ 4111 is 2.1560449600219727\n",
      "Loss at Iteration @ 4112 is 2.262876033782959\n",
      "Loss at Iteration @ 4113 is 2.35243821144104\n",
      "Loss at Iteration @ 4114 is 2.2221710681915283\n",
      "Loss at Iteration @ 4115 is 2.7017078399658203\n",
      "Loss at Iteration @ 4116 is 1.852254033088684\n",
      "Loss at Iteration @ 4117 is 2.275416135787964\n",
      "Loss at Iteration @ 4118 is 2.0907723903656006\n",
      "Loss at Iteration @ 4119 is 2.174123525619507\n",
      "Loss at Iteration @ 4120 is 2.178358793258667\n",
      "Loss at Iteration @ 4121 is 2.4772307872772217\n",
      "Loss at Iteration @ 4122 is 2.3009414672851562\n",
      "Loss at Iteration @ 4123 is 2.366985559463501\n",
      "Loss at Iteration @ 4124 is 1.9543988704681396\n",
      "Loss at Iteration @ 4125 is 2.1619341373443604\n",
      "Loss at Iteration @ 4126 is 2.352400302886963\n",
      "Loss at Iteration @ 4127 is 2.176448345184326\n",
      "Loss at Iteration @ 4128 is 2.0899364948272705\n",
      "Loss at Iteration @ 4129 is 2.2990024089813232\n",
      "Loss at Iteration @ 4130 is 2.2221570014953613\n",
      "Loss at Iteration @ 4131 is 2.3104114532470703\n",
      "Loss at Iteration @ 4132 is 2.246676206588745\n",
      "Loss at Iteration @ 4133 is 2.455254316329956\n",
      "Loss at Iteration @ 4134 is 2.4945948123931885\n",
      "Loss at Iteration @ 4135 is 2.5500497817993164\n",
      "Loss at Iteration @ 4136 is 2.3221709728240967\n",
      "Loss at Iteration @ 4137 is 2.2842319011688232\n",
      "Loss at Iteration @ 4138 is 2.0016629695892334\n",
      "Loss at Iteration @ 4139 is 2.23067569732666\n",
      "Loss at Iteration @ 4140 is 2.0798401832580566\n",
      "Loss at Iteration @ 4141 is 2.116999626159668\n",
      "Loss at Iteration @ 4142 is 2.497758388519287\n",
      "Loss at Iteration @ 4143 is 2.2082865238189697\n",
      "Loss at Iteration @ 4144 is 2.1243698596954346\n",
      "Loss at Iteration @ 4145 is 2.29677414894104\n",
      "Loss at Iteration @ 4146 is 2.347712993621826\n",
      "Loss at Iteration @ 4147 is 2.343630313873291\n",
      "Loss at Iteration @ 4148 is 2.338951826095581\n",
      "Loss at Iteration @ 4149 is 2.4803466796875\n",
      "Loss at Iteration @ 4150 is 2.2350287437438965\n",
      "Loss at Iteration @ 4151 is 2.426118850708008\n",
      "Loss at Iteration @ 4152 is 2.199023485183716\n",
      "Loss at Iteration @ 4153 is 2.1717565059661865\n",
      "Loss at Iteration @ 4154 is 2.3140578269958496\n",
      "Loss at Iteration @ 4155 is 2.373573064804077\n",
      "Loss at Iteration @ 4156 is 2.237724542617798\n",
      "Loss at Iteration @ 4157 is 2.4679415225982666\n",
      "Loss at Iteration @ 4158 is 2.4707283973693848\n",
      "Loss at Iteration @ 4159 is 2.303405523300171\n",
      "Loss at Iteration @ 4160 is 2.0349960327148438\n",
      "Loss at Iteration @ 4161 is 2.1939220428466797\n",
      "Loss at Iteration @ 4162 is 2.090179443359375\n",
      "Loss at Iteration @ 4163 is 2.2119815349578857\n",
      "Loss at Iteration @ 4164 is 2.0387604236602783\n",
      "Loss at Iteration @ 4165 is 2.1056196689605713\n",
      "Loss at Iteration @ 4166 is 2.135496139526367\n",
      "Loss at Iteration @ 4167 is 1.9415031671524048\n",
      "Loss at Iteration @ 4168 is 2.416841745376587\n",
      "Loss at Iteration @ 4169 is 2.0945327281951904\n",
      "Loss at Iteration @ 4170 is 2.332002878189087\n",
      "Loss at Iteration @ 4171 is 2.014045476913452\n",
      "Loss at Iteration @ 4172 is 2.289310932159424\n",
      "Loss at Iteration @ 4173 is 1.8814727067947388\n",
      "Loss at Iteration @ 4174 is 2.196873664855957\n",
      "Loss at Iteration @ 4175 is 2.276576042175293\n",
      "Loss at Iteration @ 4176 is 2.178658962249756\n",
      "Loss at Iteration @ 4177 is 2.194589376449585\n",
      "Loss at Iteration @ 4178 is 2.4332149028778076\n",
      "Loss at Iteration @ 4179 is 2.2012228965759277\n",
      "Loss at Iteration @ 4180 is 2.2713449001312256\n",
      "Loss at Iteration @ 4181 is 2.142934560775757\n",
      "Loss at Iteration @ 4182 is 2.358668327331543\n",
      "Loss at Iteration @ 4183 is 2.091470956802368\n",
      "Loss at Iteration @ 4184 is 2.3713202476501465\n",
      "Loss at Iteration @ 4185 is 2.436584234237671\n",
      "Loss at Iteration @ 4186 is 2.265303611755371\n",
      "Loss at Iteration @ 4187 is 2.081082820892334\n",
      "Loss at Iteration @ 4188 is 2.21278715133667\n",
      "Loss at Iteration @ 4189 is 2.1612110137939453\n",
      "Loss at Iteration @ 4190 is 2.2794158458709717\n",
      "Loss at Iteration @ 4191 is 2.163468599319458\n",
      "Loss at Iteration @ 4192 is 2.273207426071167\n",
      "Loss at Iteration @ 4193 is 2.153169870376587\n",
      "Loss at Iteration @ 4194 is 2.256471872329712\n",
      "Loss at Iteration @ 4195 is 2.3689630031585693\n",
      "Loss at Iteration @ 4196 is 2.1344189643859863\n",
      "Loss at Iteration @ 4197 is 2.1613411903381348\n",
      "Loss at Iteration @ 4198 is 2.2478291988372803\n",
      "Loss at Iteration @ 4199 is 2.225983142852783\n",
      "Loss at Iteration @ 4200 is 2.1373345851898193\n",
      "Loss at Iteration @ 4201 is 2.13983416557312\n",
      "Loss at Iteration @ 4202 is 2.235865592956543\n",
      "Loss at Iteration @ 4203 is 2.494013786315918\n",
      "Loss at Iteration @ 4204 is 2.3353943824768066\n",
      "Loss at Iteration @ 4205 is 2.1709344387054443\n",
      "Loss at Iteration @ 4206 is 2.246727228164673\n",
      "Loss at Iteration @ 4207 is 2.3898890018463135\n",
      "Loss at Iteration @ 4208 is 1.971642255783081\n",
      "Loss at Iteration @ 4209 is 2.1694929599761963\n",
      "Loss at Iteration @ 4210 is 2.131845474243164\n",
      "Loss at Iteration @ 4211 is 2.336644172668457\n",
      "Loss at Iteration @ 4212 is 2.197077512741089\n",
      "Loss at Iteration @ 4213 is 2.2741971015930176\n",
      "Loss at Iteration @ 4214 is 2.111147165298462\n",
      "Loss at Iteration @ 4215 is 2.2682783603668213\n",
      "Loss at Iteration @ 4216 is 2.020124673843384\n",
      "Loss at Iteration @ 4217 is 2.1766746044158936\n",
      "Loss at Iteration @ 4218 is 2.146369457244873\n",
      "Loss at Iteration @ 4219 is 2.1990294456481934\n",
      "Loss at Iteration @ 4220 is 2.419452667236328\n",
      "Loss at Iteration @ 4221 is 2.3838443756103516\n",
      "Loss at Iteration @ 4222 is 2.3557841777801514\n",
      "Loss at Iteration @ 4223 is 2.5104241371154785\n",
      "Loss at Iteration @ 4224 is 2.0800490379333496\n",
      "Loss at Iteration @ 4225 is 2.0856146812438965\n",
      "Loss at Iteration @ 4226 is 1.9155797958374023\n",
      "Loss at Iteration @ 4227 is 2.270843982696533\n",
      "Loss at Iteration @ 4228 is 2.419189929962158\n",
      "Loss at Iteration @ 4229 is 2.4611408710479736\n",
      "Loss at Iteration @ 4230 is 2.0834410190582275\n",
      "Loss at Iteration @ 4231 is 2.0249176025390625\n",
      "Loss at Iteration @ 4232 is 2.271022319793701\n",
      "Loss at Iteration @ 4233 is 2.271606206893921\n",
      "Loss at Iteration @ 4234 is 2.094644784927368\n",
      "Loss at Iteration @ 4235 is 2.5322158336639404\n",
      "Loss at Iteration @ 4236 is 2.348114013671875\n",
      "Loss at Iteration @ 4237 is 2.08390474319458\n",
      "Loss at Iteration @ 4238 is 2.3050076961517334\n",
      "Loss at Iteration @ 4239 is 2.0893678665161133\n",
      "Loss at Iteration @ 4240 is 2.308971643447876\n",
      "Loss at Iteration @ 4241 is 2.2616589069366455\n",
      "Loss at Iteration @ 4242 is 2.3653738498687744\n",
      "Loss at Iteration @ 4243 is 2.2999536991119385\n",
      "Loss at Iteration @ 4244 is 2.3929691314697266\n",
      "Loss at Iteration @ 4245 is 2.301196336746216\n",
      "Loss at Iteration @ 4246 is 2.1385834217071533\n",
      "Loss at Iteration @ 4247 is 2.261470317840576\n",
      "Loss at Iteration @ 4248 is 2.027357816696167\n",
      "Loss at Iteration @ 4249 is 2.215574264526367\n",
      "Loss at Iteration @ 4250 is 2.1052653789520264\n",
      "Loss at Iteration @ 4251 is 2.1122865676879883\n",
      "Loss at Iteration @ 4252 is 2.3144655227661133\n",
      "Loss at Iteration @ 4253 is 2.26237416267395\n",
      "Loss at Iteration @ 4254 is 1.878482699394226\n",
      "Loss at Iteration @ 4255 is 2.069298505783081\n",
      "Loss at Iteration @ 4256 is 2.480797052383423\n",
      "Loss at Iteration @ 4257 is 2.3011651039123535\n",
      "Loss at Iteration @ 4258 is 2.2650749683380127\n",
      "Loss at Iteration @ 4259 is 2.3128490447998047\n",
      "Loss at Iteration @ 4260 is 2.02789568901062\n",
      "Loss at Iteration @ 4261 is 2.2874667644500732\n",
      "Loss at Iteration @ 4262 is 2.242171287536621\n",
      "Loss at Iteration @ 4263 is 2.2739880084991455\n",
      "Loss at Iteration @ 4264 is 2.128988027572632\n",
      "Loss at Iteration @ 4265 is 2.07791805267334\n",
      "Loss at Iteration @ 4266 is 2.153181314468384\n",
      "Loss at Iteration @ 4267 is 2.310732841491699\n",
      "Loss at Iteration @ 4268 is 2.26759934425354\n",
      "Loss at Iteration @ 4269 is 2.431569814682007\n",
      "Loss at Iteration @ 4270 is 2.449355125427246\n",
      "Loss at Iteration @ 4271 is 2.2732369899749756\n",
      "Loss at Iteration @ 4272 is 2.0714147090911865\n",
      "Loss at Iteration @ 4273 is 2.212744951248169\n",
      "Loss at Iteration @ 4274 is 2.34324312210083\n",
      "Loss at Iteration @ 4275 is 2.133946180343628\n",
      "Loss at Iteration @ 4276 is 2.3575599193573\n",
      "Loss at Iteration @ 4277 is 2.181177854537964\n",
      "Loss at Iteration @ 4278 is 2.2525722980499268\n",
      "Loss at Iteration @ 4279 is 2.2523066997528076\n",
      "Loss at Iteration @ 4280 is 2.316668748855591\n",
      "Loss at Iteration @ 4281 is 2.3617405891418457\n",
      "Loss at Iteration @ 4282 is 1.9186450242996216\n",
      "Loss at Iteration @ 4283 is 2.225808620452881\n",
      "Loss at Iteration @ 4284 is 2.2393300533294678\n",
      "Loss at Iteration @ 4285 is 2.2066781520843506\n",
      "Loss at Iteration @ 4286 is 2.128014087677002\n",
      "Loss at Iteration @ 4287 is 2.3567843437194824\n",
      "Loss at Iteration @ 4288 is 2.0081214904785156\n",
      "Loss at Iteration @ 4289 is 2.0358495712280273\n",
      "Loss at Iteration @ 4290 is 2.2686071395874023\n",
      "Loss at Iteration @ 4291 is 2.163649797439575\n",
      "Loss at Iteration @ 4292 is 2.090669631958008\n",
      "Loss at Iteration @ 4293 is 2.346320629119873\n",
      "Loss at Iteration @ 4294 is 2.516244649887085\n",
      "Loss at Iteration @ 4295 is 2.145296096801758\n",
      "Loss at Iteration @ 4296 is 2.274648666381836\n",
      "Loss at Iteration @ 4297 is 2.09208345413208\n",
      "Loss at Iteration @ 4298 is 2.1314914226531982\n",
      "Loss at Iteration @ 4299 is 2.2627410888671875\n",
      "Loss at Iteration @ 4300 is 2.274357557296753\n",
      "Loss at Iteration @ 4301 is 2.1939921379089355\n",
      "Loss at Iteration @ 4302 is 2.318683624267578\n",
      "Loss at Iteration @ 4303 is 2.40728497505188\n",
      "Loss at Iteration @ 4304 is 2.3804192543029785\n",
      "Loss at Iteration @ 4305 is 2.16587495803833\n",
      "Loss at Iteration @ 4306 is 2.2763235569000244\n",
      "Loss at Iteration @ 4307 is 2.140284538269043\n",
      "Loss at Iteration @ 4308 is 2.0972979068756104\n",
      "Loss at Iteration @ 4309 is 2.616553544998169\n",
      "Loss at Iteration @ 4310 is 2.49525785446167\n",
      "Loss at Iteration @ 4311 is 2.3877992630004883\n",
      "Loss at Iteration @ 4312 is 2.2955830097198486\n",
      "Loss at Iteration @ 4313 is 2.248326539993286\n",
      "Loss at Iteration @ 4314 is 2.01090407371521\n",
      "Loss at Iteration @ 4315 is 2.3599298000335693\n",
      "Loss at Iteration @ 4316 is 2.3053324222564697\n",
      "Loss at Iteration @ 4317 is 2.3424580097198486\n",
      "Loss at Iteration @ 4318 is 2.5277938842773438\n",
      "Loss at Iteration @ 4319 is 2.2818143367767334\n",
      "Loss at Iteration @ 4320 is 2.2175114154815674\n",
      "Loss at Iteration @ 4321 is 2.1893603801727295\n",
      "Loss at Iteration @ 4322 is 2.138866901397705\n",
      "Loss at Iteration @ 4323 is 2.2861146926879883\n",
      "Loss at Iteration @ 4324 is 2.047337293624878\n",
      "Loss at Iteration @ 4325 is 2.3588454723358154\n",
      "Loss at Iteration @ 4326 is 2.0794639587402344\n",
      "Loss at Iteration @ 4327 is 2.17690110206604\n",
      "Loss at Iteration @ 4328 is 2.3052937984466553\n",
      "Loss at Iteration @ 4329 is 2.314150810241699\n",
      "Loss at Iteration @ 4330 is 2.5582640171051025\n",
      "Loss at Iteration @ 4331 is 2.260643243789673\n",
      "Loss at Iteration @ 4332 is 2.2420601844787598\n",
      "Loss at Iteration @ 4333 is 1.8965072631835938\n",
      "Loss at Iteration @ 4334 is 2.4520726203918457\n",
      "Loss at Iteration @ 4335 is 2.241744041442871\n",
      "Loss at Iteration @ 4336 is 2.1301112174987793\n",
      "Loss at Iteration @ 4337 is 2.471503257751465\n",
      "Loss at Iteration @ 4338 is 2.130722999572754\n",
      "Loss at Iteration @ 4339 is 2.1910977363586426\n",
      "Loss at Iteration @ 4340 is 2.3037900924682617\n",
      "Loss at Iteration @ 4341 is 2.2856390476226807\n",
      "Loss at Iteration @ 4342 is 2.1048498153686523\n",
      "Loss at Iteration @ 4343 is 2.238039493560791\n",
      "Loss at Iteration @ 4344 is 2.1876816749572754\n",
      "Loss at Iteration @ 4345 is 2.457134962081909\n",
      "Loss at Iteration @ 4346 is 2.186373472213745\n",
      "Loss at Iteration @ 4347 is 2.160555124282837\n",
      "Loss at Iteration @ 4348 is 2.3164875507354736\n",
      "Loss at Iteration @ 4349 is 2.256727933883667\n",
      "Loss at Iteration @ 4350 is 2.0218684673309326\n",
      "Loss at Iteration @ 4351 is 2.391507148742676\n",
      "Loss at Iteration @ 4352 is 2.4458444118499756\n",
      "Loss at Iteration @ 4353 is 2.21431303024292\n",
      "Loss at Iteration @ 4354 is 2.251736879348755\n",
      "Loss at Iteration @ 4355 is 1.8716174364089966\n",
      "Loss at Iteration @ 4356 is 2.1515462398529053\n",
      "Loss at Iteration @ 4357 is 2.470874309539795\n",
      "Loss at Iteration @ 4358 is 2.232931137084961\n",
      "Loss at Iteration @ 4359 is 2.193004608154297\n",
      "Loss at Iteration @ 4360 is 2.315140724182129\n",
      "Loss at Iteration @ 4361 is 2.1266114711761475\n",
      "Loss at Iteration @ 4362 is 2.2756595611572266\n",
      "Loss at Iteration @ 4363 is 2.4205167293548584\n",
      "Loss at Iteration @ 4364 is 2.1412599086761475\n",
      "Loss at Iteration @ 4365 is 2.1989173889160156\n",
      "Loss at Iteration @ 4366 is 2.3983755111694336\n",
      "Loss at Iteration @ 4367 is 2.0845248699188232\n",
      "Loss at Iteration @ 4368 is 2.171489953994751\n",
      "Loss at Iteration @ 4369 is 2.135572671890259\n",
      "Loss at Iteration @ 4370 is 1.9796247482299805\n",
      "Loss at Iteration @ 4371 is 2.055419921875\n",
      "Loss at Iteration @ 4372 is 1.9690040349960327\n",
      "Loss at Iteration @ 4373 is 2.491637706756592\n",
      "Loss at Iteration @ 4374 is 2.053917169570923\n",
      "Loss at Iteration @ 4375 is 2.129279375076294\n",
      "Loss at Iteration @ 4376 is 2.42899489402771\n",
      "Loss at Iteration @ 4377 is 2.016950845718384\n",
      "Loss at Iteration @ 4378 is 2.280493974685669\n",
      "Loss at Iteration @ 4379 is 2.578104257583618\n",
      "Loss at Iteration @ 4380 is 2.219618797302246\n",
      "Loss at Iteration @ 4381 is 1.8554846048355103\n",
      "Loss at Iteration @ 4382 is 2.0423946380615234\n",
      "Loss at Iteration @ 4383 is 2.3840794563293457\n",
      "Loss at Iteration @ 4384 is 2.255229949951172\n",
      "Loss at Iteration @ 4385 is 2.14848256111145\n",
      "Loss at Iteration @ 4386 is 2.177870035171509\n",
      "Loss at Iteration @ 4387 is 2.225816488265991\n",
      "Loss at Iteration @ 4388 is 2.6069161891937256\n",
      "Loss at Iteration @ 4389 is 2.247779130935669\n",
      "Loss at Iteration @ 4390 is 2.196200132369995\n",
      "Loss at Iteration @ 4391 is 2.4933078289031982\n",
      "Loss at Iteration @ 4392 is 2.367708683013916\n",
      "Loss at Iteration @ 4393 is 1.9921523332595825\n",
      "Loss at Iteration @ 4394 is 2.1757922172546387\n",
      "Loss at Iteration @ 4395 is 2.130073070526123\n",
      "Loss at Iteration @ 4396 is 2.2254269123077393\n",
      "Loss at Iteration @ 4397 is 2.0722134113311768\n",
      "Loss at Iteration @ 4398 is 2.1857874393463135\n",
      "Loss at Iteration @ 4399 is 2.1895313262939453\n",
      "Loss at Iteration @ 4400 is 1.9025983810424805\n",
      "Loss at Iteration @ 4401 is 2.3044872283935547\n",
      "Loss at Iteration @ 4402 is 2.140714406967163\n",
      "Loss at Iteration @ 4403 is 2.4571902751922607\n",
      "Loss at Iteration @ 4404 is 2.039882183074951\n",
      "Loss at Iteration @ 4405 is 2.1565117835998535\n",
      "Loss at Iteration @ 4406 is 2.230804443359375\n",
      "Loss at Iteration @ 4407 is 2.1719918251037598\n",
      "Loss at Iteration @ 4408 is 1.9602867364883423\n",
      "Loss at Iteration @ 4409 is 2.3180227279663086\n",
      "Loss at Iteration @ 4410 is 2.292567253112793\n",
      "Loss at Iteration @ 4411 is 2.4252545833587646\n",
      "Loss at Iteration @ 4412 is 2.6344895362854004\n",
      "Loss at Iteration @ 4413 is 2.411710262298584\n",
      "Loss at Iteration @ 4414 is 1.9251513481140137\n",
      "Loss at Iteration @ 4415 is 2.2300827503204346\n",
      "Loss at Iteration @ 4416 is 2.168802499771118\n",
      "Loss at Iteration @ 4417 is 2.166624069213867\n",
      "Loss at Iteration @ 4418 is 2.3874096870422363\n",
      "Loss at Iteration @ 4419 is 2.1489310264587402\n",
      "Loss at Iteration @ 4420 is 2.3539488315582275\n",
      "Loss at Iteration @ 4421 is 2.1436331272125244\n",
      "Loss at Iteration @ 4422 is 2.052339553833008\n",
      "Loss at Iteration @ 4423 is 2.187267303466797\n",
      "Loss at Iteration @ 4424 is 2.129755735397339\n",
      "Loss at Iteration @ 4425 is 2.192420244216919\n",
      "Loss at Iteration @ 4426 is 2.1422245502471924\n",
      "Loss at Iteration @ 4427 is 2.235769510269165\n",
      "Loss at Iteration @ 4428 is 2.070207357406616\n",
      "Loss at Iteration @ 4429 is 2.392047882080078\n",
      "Loss at Iteration @ 4430 is 2.3181183338165283\n",
      "Loss at Iteration @ 4431 is 2.2911789417266846\n",
      "Loss at Iteration @ 4432 is 1.9166905879974365\n",
      "Loss at Iteration @ 4433 is 2.1948065757751465\n",
      "Loss at Iteration @ 4434 is 2.260392189025879\n",
      "Loss at Iteration @ 4435 is 2.3026883602142334\n",
      "Loss at Iteration @ 4436 is 2.129329204559326\n",
      "Loss at Iteration @ 4437 is 2.166316032409668\n",
      "Loss at Iteration @ 4438 is 2.279232978820801\n",
      "Loss at Iteration @ 4439 is 2.609185218811035\n",
      "Loss at Iteration @ 4440 is 2.1459670066833496\n",
      "Loss at Iteration @ 4441 is 2.1584370136260986\n",
      "Loss at Iteration @ 4442 is 2.159252166748047\n",
      "Loss at Iteration @ 4443 is 2.020334482192993\n",
      "Loss at Iteration @ 4444 is 2.0945823192596436\n",
      "Loss at Iteration @ 4445 is 2.6874582767486572\n",
      "Loss at Iteration @ 4446 is 2.2119460105895996\n",
      "Loss at Iteration @ 4447 is 2.1019234657287598\n",
      "Loss at Iteration @ 4448 is 2.144139528274536\n",
      "Loss at Iteration @ 4449 is 2.3230741024017334\n",
      "Loss at Iteration @ 4450 is 2.322662115097046\n",
      "Loss at Iteration @ 4451 is 2.348862409591675\n",
      "Loss at Iteration @ 4452 is 2.31864070892334\n",
      "Loss at Iteration @ 4453 is 2.285858154296875\n",
      "Loss at Iteration @ 4454 is 2.1393110752105713\n",
      "Loss at Iteration @ 4455 is 2.161404609680176\n",
      "Loss at Iteration @ 4456 is 2.3237006664276123\n",
      "Loss at Iteration @ 4457 is 2.049405336380005\n",
      "Loss at Iteration @ 4458 is 2.306118965148926\n",
      "Loss at Iteration @ 4459 is 2.120864152908325\n",
      "Loss at Iteration @ 4460 is 2.246556520462036\n",
      "Loss at Iteration @ 4461 is 2.486119270324707\n",
      "Loss at Iteration @ 4462 is 2.1986374855041504\n",
      "Loss at Iteration @ 4463 is 2.1817121505737305\n",
      "Loss at Iteration @ 4464 is 2.0370028018951416\n",
      "Loss at Iteration @ 4465 is 2.352461099624634\n",
      "Loss at Iteration @ 4466 is 2.4253134727478027\n",
      "Loss at Iteration @ 4467 is 2.164889335632324\n",
      "Loss at Iteration @ 4468 is 2.181688070297241\n",
      "Loss at Iteration @ 4469 is 2.414388418197632\n",
      "Loss at Iteration @ 4470 is 2.0511157512664795\n",
      "Loss at Iteration @ 4471 is 2.3348586559295654\n",
      "Loss at Iteration @ 4472 is 2.1924307346343994\n",
      "Loss at Iteration @ 4473 is 2.1669130325317383\n",
      "Loss at Iteration @ 4474 is 2.3203744888305664\n",
      "Loss at Iteration @ 4475 is 2.418635845184326\n",
      "Loss at Iteration @ 4476 is 1.9255322217941284\n",
      "Loss at Iteration @ 4477 is 2.2353978157043457\n",
      "Loss at Iteration @ 4478 is 2.1698977947235107\n",
      "Loss at Iteration @ 4479 is 2.323923110961914\n",
      "Loss at Iteration @ 4480 is 2.28625226020813\n",
      "Loss at Iteration @ 4481 is 2.416342258453369\n",
      "Loss at Iteration @ 4482 is 2.640449047088623\n",
      "Loss at Iteration @ 4483 is 2.6904468536376953\n",
      "Loss at Iteration @ 4484 is 2.236755132675171\n",
      "Loss at Iteration @ 4485 is 2.312779188156128\n",
      "Loss at Iteration @ 4486 is 2.377368450164795\n",
      "Loss at Iteration @ 4487 is 2.3059980869293213\n",
      "Loss at Iteration @ 4488 is 2.2158241271972656\n",
      "Loss at Iteration @ 4489 is 1.9287742376327515\n",
      "Loss at Iteration @ 4490 is 2.065795421600342\n",
      "Loss at Iteration @ 4491 is 2.1255338191986084\n",
      "Loss at Iteration @ 4492 is 2.456698179244995\n",
      "Loss at Iteration @ 4493 is 1.97832453250885\n",
      "Loss at Iteration @ 4494 is 2.2319211959838867\n",
      "Loss at Iteration @ 4495 is 2.242664098739624\n",
      "Loss at Iteration @ 4496 is 2.43534255027771\n",
      "Loss at Iteration @ 4497 is 2.0620415210723877\n",
      "Loss at Iteration @ 4498 is 2.237635612487793\n",
      "Loss at Iteration @ 4499 is 2.303445816040039\n",
      "Loss at Iteration @ 4500 is 2.427396535873413\n",
      "Loss at Iteration @ 4501 is 2.1764750480651855\n",
      "Loss at Iteration @ 4502 is 1.9294366836547852\n",
      "Loss at Iteration @ 4503 is 2.288731098175049\n",
      "Loss at Iteration @ 4504 is 2.0533995628356934\n",
      "Loss at Iteration @ 4505 is 2.2665326595306396\n",
      "Loss at Iteration @ 4506 is 1.963735580444336\n",
      "Loss at Iteration @ 4507 is 2.050104856491089\n",
      "Loss at Iteration @ 4508 is 2.3699095249176025\n",
      "Loss at Iteration @ 4509 is 2.231581687927246\n",
      "Loss at Iteration @ 4510 is 2.348705768585205\n",
      "Loss at Iteration @ 4511 is 2.445509910583496\n",
      "Loss at Iteration @ 4512 is 2.0394675731658936\n",
      "Loss at Iteration @ 4513 is 2.0238940715789795\n",
      "Loss at Iteration @ 4514 is 2.3426430225372314\n",
      "Loss at Iteration @ 4515 is 2.1975085735321045\n",
      "Loss at Iteration @ 4516 is 2.1899523735046387\n",
      "Loss at Iteration @ 4517 is 1.9766408205032349\n",
      "Loss at Iteration @ 4518 is 2.6262118816375732\n",
      "Loss at Iteration @ 4519 is 2.501817464828491\n",
      "Loss at Iteration @ 4520 is 2.464759349822998\n",
      "Loss at Iteration @ 4521 is 2.3152079582214355\n",
      "Loss at Iteration @ 4522 is 2.179382562637329\n",
      "Loss at Iteration @ 4523 is 2.2669339179992676\n",
      "Loss at Iteration @ 4524 is 2.1594204902648926\n",
      "Loss at Iteration @ 4525 is 2.2144243717193604\n",
      "Loss at Iteration @ 4526 is 2.2058169841766357\n",
      "Loss at Iteration @ 4527 is 2.525245189666748\n",
      "Loss at Iteration @ 4528 is 2.3236241340637207\n",
      "Loss at Iteration @ 4529 is 2.3304944038391113\n",
      "Loss at Iteration @ 4530 is 2.42525577545166\n",
      "Loss at Iteration @ 4531 is 2.4944915771484375\n",
      "Loss at Iteration @ 4532 is 2.132981538772583\n",
      "Loss at Iteration @ 4533 is 2.217491865158081\n",
      "Loss at Iteration @ 4534 is 2.287501335144043\n",
      "Loss at Iteration @ 4535 is 2.497653007507324\n",
      "Loss at Iteration @ 4536 is 2.348179578781128\n",
      "Loss at Iteration @ 4537 is 2.4008936882019043\n",
      "Loss at Iteration @ 4538 is 2.440854787826538\n",
      "Loss at Iteration @ 4539 is 2.1601696014404297\n",
      "Loss at Iteration @ 4540 is 2.415325880050659\n",
      "Loss at Iteration @ 4541 is 2.11173939704895\n",
      "Loss at Iteration @ 4542 is 2.344045639038086\n",
      "Loss at Iteration @ 4543 is 2.3194782733917236\n",
      "Loss at Iteration @ 4544 is 2.2099225521087646\n",
      "Loss at Iteration @ 4545 is 2.427576780319214\n",
      "Loss at Iteration @ 4546 is 2.02913236618042\n",
      "Loss at Iteration @ 4547 is 2.2264609336853027\n",
      "Loss at Iteration @ 4548 is 2.2651209831237793\n",
      "Loss at Iteration @ 4549 is 2.111997127532959\n",
      "Loss at Iteration @ 4550 is 2.1533522605895996\n",
      "Loss at Iteration @ 4551 is 2.265368700027466\n",
      "Loss at Iteration @ 4552 is 2.040727138519287\n",
      "Loss at Iteration @ 4553 is 2.4256367683410645\n",
      "Loss at Iteration @ 4554 is 2.2664051055908203\n",
      "Loss at Iteration @ 4555 is 2.3921446800231934\n",
      "Loss at Iteration @ 4556 is 2.260324716567993\n",
      "Loss at Iteration @ 4557 is 2.238218069076538\n",
      "Loss at Iteration @ 4558 is 2.2756781578063965\n",
      "Loss at Iteration @ 4559 is 2.4754276275634766\n",
      "Loss at Iteration @ 4560 is 2.261681079864502\n",
      "Loss at Iteration @ 4561 is 2.196242332458496\n",
      "Loss at Iteration @ 4562 is 2.213606357574463\n",
      "Loss at Iteration @ 4563 is 2.3766276836395264\n",
      "Loss at Iteration @ 4564 is 2.254626512527466\n",
      "Loss at Iteration @ 4565 is 2.2750351428985596\n",
      "Loss at Iteration @ 4566 is 2.31762957572937\n",
      "Loss at Iteration @ 4567 is 2.3463590145111084\n",
      "Loss at Iteration @ 4568 is 2.1621756553649902\n",
      "Loss at Iteration @ 4569 is 2.053969383239746\n",
      "Loss at Iteration @ 4570 is 2.1269948482513428\n",
      "Loss at Iteration @ 4571 is 2.504744052886963\n",
      "Loss at Iteration @ 4572 is 2.298858404159546\n",
      "Loss at Iteration @ 4573 is 2.1486847400665283\n",
      "Loss at Iteration @ 4574 is 2.194838523864746\n",
      "Loss at Iteration @ 4575 is 2.282118797302246\n",
      "Loss at Iteration @ 4576 is 2.203468084335327\n",
      "Loss at Iteration @ 4577 is 2.3423564434051514\n",
      "Loss at Iteration @ 4578 is 2.0859944820404053\n",
      "Loss at Iteration @ 4579 is 2.017791271209717\n",
      "Loss at Iteration @ 4580 is 2.4888644218444824\n",
      "Loss at Iteration @ 4581 is 2.3201048374176025\n",
      "Loss at Iteration @ 4582 is 2.3481221199035645\n",
      "Loss at Iteration @ 4583 is 2.28312087059021\n",
      "Loss at Iteration @ 4584 is 1.929641842842102\n",
      "Loss at Iteration @ 4585 is 2.426342248916626\n",
      "Loss at Iteration @ 4586 is 2.181729555130005\n",
      "Loss at Iteration @ 4587 is 2.3066744804382324\n",
      "Loss at Iteration @ 4588 is 2.087965488433838\n",
      "Loss at Iteration @ 4589 is 2.3712961673736572\n",
      "Loss at Iteration @ 4590 is 2.3708059787750244\n",
      "Loss at Iteration @ 4591 is 2.3492774963378906\n",
      "Loss at Iteration @ 4592 is 2.398242235183716\n",
      "Loss at Iteration @ 4593 is 2.3299872875213623\n",
      "Loss at Iteration @ 4594 is 2.3095312118530273\n",
      "Loss at Iteration @ 4595 is 2.3227813243865967\n",
      "Loss at Iteration @ 4596 is 2.217953681945801\n",
      "Loss at Iteration @ 4597 is 2.0805630683898926\n",
      "Loss at Iteration @ 4598 is 1.9262751340866089\n",
      "Loss at Iteration @ 4599 is 2.425328493118286\n",
      "Loss at Iteration @ 4600 is 2.210599184036255\n",
      "Loss at Iteration @ 4601 is 1.9708635807037354\n",
      "Loss at Iteration @ 4602 is 2.010876417160034\n",
      "Loss at Iteration @ 4603 is 2.2880332469940186\n",
      "Loss at Iteration @ 4604 is 2.2458178997039795\n",
      "Loss at Iteration @ 4605 is 2.307725429534912\n",
      "Loss at Iteration @ 4606 is 2.317704439163208\n",
      "Loss at Iteration @ 4607 is 2.2922966480255127\n",
      "Loss at Iteration @ 4608 is 2.0094008445739746\n",
      "Loss at Iteration @ 4609 is 2.2015905380249023\n",
      "Loss at Iteration @ 4610 is 2.329291343688965\n",
      "Loss at Iteration @ 4611 is 2.04360294342041\n",
      "Loss at Iteration @ 4612 is 2.4485979080200195\n",
      "Loss at Iteration @ 4613 is 2.2874820232391357\n",
      "Loss at Iteration @ 4614 is 2.1864821910858154\n",
      "Loss at Iteration @ 4615 is 2.164020538330078\n",
      "Loss at Iteration @ 4616 is 2.091874122619629\n",
      "Loss at Iteration @ 4617 is 2.210322618484497\n",
      "Loss at Iteration @ 4618 is 2.37176775932312\n",
      "Loss at Iteration @ 4619 is 2.533020257949829\n",
      "Loss at Iteration @ 4620 is 2.2744216918945312\n",
      "Loss at Iteration @ 4621 is 2.1051273345947266\n",
      "Loss at Iteration @ 4622 is 2.3666656017303467\n",
      "Loss at Iteration @ 4623 is 2.108943223953247\n",
      "Loss at Iteration @ 4624 is 2.155566930770874\n",
      "Loss at Iteration @ 4625 is 2.150812864303589\n",
      "Loss at Iteration @ 4626 is 2.3491618633270264\n",
      "Loss at Iteration @ 4627 is 2.2008702754974365\n",
      "Loss at Iteration @ 4628 is 2.332928419113159\n",
      "Loss at Iteration @ 4629 is 2.3897616863250732\n",
      "Loss at Iteration @ 4630 is 2.5300960540771484\n",
      "Loss at Iteration @ 4631 is 2.274632215499878\n",
      "Loss at Iteration @ 4632 is 2.3295600414276123\n",
      "Loss at Iteration @ 4633 is 2.265930652618408\n",
      "Loss at Iteration @ 4634 is 2.457594871520996\n",
      "Loss at Iteration @ 4635 is 2.356066942214966\n",
      "Loss at Iteration @ 4636 is 2.165203809738159\n",
      "Loss at Iteration @ 4637 is 2.1351070404052734\n",
      "Loss at Iteration @ 4638 is 2.4679958820343018\n",
      "Loss at Iteration @ 4639 is 2.270983934402466\n",
      "Loss at Iteration @ 4640 is 2.157012701034546\n",
      "Loss at Iteration @ 4641 is 2.1731536388397217\n",
      "Loss at Iteration @ 4642 is 2.2887673377990723\n",
      "Loss at Iteration @ 4643 is 2.384153366088867\n",
      "Loss at Iteration @ 4644 is 2.137413263320923\n",
      "Loss at Iteration @ 4645 is 2.2081563472747803\n",
      "Loss at Iteration @ 4646 is 2.3922314643859863\n",
      "Loss at Iteration @ 4647 is 2.162682294845581\n",
      "Loss at Iteration @ 4648 is 2.212792158126831\n",
      "Loss at Iteration @ 4649 is 2.003267765045166\n",
      "Loss at Iteration @ 4650 is 2.392188310623169\n",
      "Loss at Iteration @ 4651 is 2.323845624923706\n",
      "Loss at Iteration @ 4652 is 2.2294881343841553\n",
      "Loss at Iteration @ 4653 is 2.1834428310394287\n",
      "Loss at Iteration @ 4654 is 2.065152645111084\n",
      "Loss at Iteration @ 4655 is 2.0804998874664307\n",
      "Loss at Iteration @ 4656 is 2.639368772506714\n",
      "Loss at Iteration @ 4657 is 2.3654537200927734\n",
      "Loss at Iteration @ 4658 is 2.5022144317626953\n",
      "Loss at Iteration @ 4659 is 2.2143993377685547\n",
      "Loss at Iteration @ 4660 is 2.2795557975769043\n",
      "Loss at Iteration @ 4661 is 2.387028932571411\n",
      "Loss at Iteration @ 4662 is 2.583784818649292\n",
      "Loss at Iteration @ 4663 is 2.1392924785614014\n",
      "Loss at Iteration @ 4664 is 2.6591641902923584\n",
      "Loss at Iteration @ 4665 is 2.184666633605957\n",
      "Loss at Iteration @ 4666 is 2.505962610244751\n",
      "Loss at Iteration @ 4667 is 2.478137254714966\n",
      "Loss at Iteration @ 4668 is 2.1459999084472656\n",
      "Loss at Iteration @ 4669 is 2.2902679443359375\n",
      "Loss at Iteration @ 4670 is 2.4427812099456787\n",
      "Loss at Iteration @ 4671 is 2.3863770961761475\n",
      "Loss at Iteration @ 4672 is 2.228909969329834\n",
      "Loss at Iteration @ 4673 is 2.4151992797851562\n",
      "Loss at Iteration @ 4674 is 2.256464958190918\n",
      "Loss at Iteration @ 4675 is 2.325265884399414\n",
      "Loss at Iteration @ 4676 is 2.1108577251434326\n",
      "Loss at Iteration @ 4677 is 2.030946969985962\n",
      "Loss at Iteration @ 4678 is 1.8959943056106567\n",
      "Loss at Iteration @ 4679 is 2.4898831844329834\n",
      "Loss at Iteration @ 4680 is 2.0891611576080322\n",
      "Loss at Iteration @ 4681 is 2.3250739574432373\n",
      "Loss at Iteration @ 4682 is 2.3825366497039795\n",
      "Loss at Iteration @ 4683 is 2.508416175842285\n",
      "Loss at Iteration @ 4684 is 2.30536150932312\n",
      "Loss at Iteration @ 4685 is 2.0525271892547607\n",
      "Loss at Iteration @ 4686 is 2.2556700706481934\n",
      "Loss at Iteration @ 4687 is 2.012752056121826\n",
      "Loss at Iteration @ 4688 is 2.154067277908325\n",
      "Loss at Iteration @ 4689 is 2.250352621078491\n",
      "Loss at Iteration @ 4690 is 2.2874717712402344\n",
      "Loss at Iteration @ 4691 is 2.1333186626434326\n",
      "Loss at Iteration @ 4692 is 2.1805036067962646\n",
      "Loss at Iteration @ 4693 is 2.552460193634033\n",
      "Loss at Iteration @ 4694 is 2.1715238094329834\n",
      "Loss at Iteration @ 4695 is 2.2024059295654297\n",
      "Loss at Iteration @ 4696 is 2.3127880096435547\n",
      "Loss at Iteration @ 4697 is 2.177783489227295\n",
      "Loss at Iteration @ 4698 is 2.1548259258270264\n",
      "Loss at Iteration @ 4699 is 2.129239559173584\n",
      "Loss at Iteration @ 4700 is 2.327005386352539\n",
      "Loss at Iteration @ 4701 is 2.124290943145752\n",
      "Loss at Iteration @ 4702 is 2.1568548679351807\n",
      "Loss at Iteration @ 4703 is 2.152345895767212\n",
      "Loss at Iteration @ 4704 is 2.1467413902282715\n",
      "Loss at Iteration @ 4705 is 2.258653402328491\n",
      "Loss at Iteration @ 4706 is 2.2986698150634766\n",
      "Loss at Iteration @ 4707 is 2.1832425594329834\n",
      "Loss at Iteration @ 4708 is 2.3820831775665283\n",
      "Loss at Iteration @ 4709 is 2.4555742740631104\n",
      "Loss at Iteration @ 4710 is 2.0977184772491455\n",
      "Loss at Iteration @ 4711 is 2.5647666454315186\n",
      "Loss at Iteration @ 4712 is 2.261420249938965\n",
      "Loss at Iteration @ 4713 is 1.9604125022888184\n",
      "Loss at Iteration @ 4714 is 2.0870139598846436\n",
      "Loss at Iteration @ 4715 is 2.311906576156616\n",
      "Loss at Iteration @ 4716 is 2.0806188583374023\n",
      "Loss at Iteration @ 4717 is 2.2549521923065186\n",
      "Loss at Iteration @ 4718 is 2.284475326538086\n",
      "Loss at Iteration @ 4719 is 2.29703688621521\n",
      "Loss at Iteration @ 4720 is 2.2191922664642334\n",
      "Loss at Iteration @ 4721 is 2.191472291946411\n",
      "Loss at Iteration @ 4722 is 2.3557612895965576\n",
      "Loss at Iteration @ 4723 is 2.261448383331299\n",
      "Loss at Iteration @ 4724 is 2.2856242656707764\n",
      "Loss at Iteration @ 4725 is 2.233661413192749\n",
      "Loss at Iteration @ 4726 is 2.073984146118164\n",
      "Loss at Iteration @ 4727 is 2.2562952041625977\n",
      "Loss at Iteration @ 4728 is 2.457756757736206\n",
      "Loss at Iteration @ 4729 is 1.9926958084106445\n",
      "Loss at Iteration @ 4730 is 2.2241451740264893\n",
      "Loss at Iteration @ 4731 is 2.1698391437530518\n",
      "Loss at Iteration @ 4732 is 2.5169312953948975\n",
      "Loss at Iteration @ 4733 is 2.4190144538879395\n",
      "Loss at Iteration @ 4734 is 2.0557563304901123\n",
      "Loss at Iteration @ 4735 is 2.0401132106781006\n",
      "Loss at Iteration @ 4736 is 2.2890825271606445\n",
      "Loss at Iteration @ 4737 is 2.1211719512939453\n",
      "Loss at Iteration @ 4738 is 2.1621205806732178\n",
      "Loss at Iteration @ 4739 is 2.107923984527588\n",
      "Loss at Iteration @ 4740 is 2.0964696407318115\n",
      "Loss at Iteration @ 4741 is 2.225332260131836\n",
      "Loss at Iteration @ 4742 is 2.2873916625976562\n",
      "Loss at Iteration @ 4743 is 2.5771050453186035\n",
      "Loss at Iteration @ 4744 is 1.953879952430725\n",
      "Loss at Iteration @ 4745 is 2.353339195251465\n",
      "Loss at Iteration @ 4746 is 2.3240537643432617\n",
      "Loss at Iteration @ 4747 is 2.5738210678100586\n",
      "Loss at Iteration @ 4748 is 2.0404117107391357\n",
      "Loss at Iteration @ 4749 is 2.1140668392181396\n",
      "Loss at Iteration @ 4750 is 1.9172619581222534\n",
      "Loss at Iteration @ 4751 is 2.319072961807251\n",
      "Loss at Iteration @ 4752 is 2.165771245956421\n",
      "Loss at Iteration @ 4753 is 2.2435989379882812\n",
      "Loss at Iteration @ 4754 is 2.206890821456909\n",
      "Loss at Iteration @ 4755 is 2.1896305084228516\n",
      "Loss at Iteration @ 4756 is 2.64249849319458\n",
      "Loss at Iteration @ 4757 is 2.308181047439575\n",
      "Loss at Iteration @ 4758 is 2.0406954288482666\n",
      "Loss at Iteration @ 4759 is 2.2447686195373535\n",
      "Loss at Iteration @ 4760 is 2.284672975540161\n",
      "Loss at Iteration @ 4761 is 2.5229010581970215\n",
      "Loss at Iteration @ 4762 is 1.9911049604415894\n",
      "Loss at Iteration @ 4763 is 2.0648953914642334\n",
      "Loss at Iteration @ 4764 is 1.9916619062423706\n",
      "Loss at Iteration @ 4765 is 2.312781810760498\n",
      "Loss at Iteration @ 4766 is 2.4823780059814453\n",
      "Loss at Iteration @ 4767 is 2.3557658195495605\n",
      "Loss at Iteration @ 4768 is 2.347066879272461\n",
      "Loss at Iteration @ 4769 is 2.402656316757202\n",
      "Loss at Iteration @ 4770 is 2.1317403316497803\n",
      "Loss at Iteration @ 4771 is 2.336427927017212\n",
      "Loss at Iteration @ 4772 is 2.320227861404419\n",
      "Loss at Iteration @ 4773 is 2.362762212753296\n",
      "Loss at Iteration @ 4774 is 2.31821346282959\n",
      "Loss at Iteration @ 4775 is 2.456143379211426\n",
      "Loss at Iteration @ 4776 is 2.6559042930603027\n",
      "Loss at Iteration @ 4777 is 2.1313929557800293\n",
      "Loss at Iteration @ 4778 is 2.402047872543335\n",
      "Loss at Iteration @ 4779 is 2.1419057846069336\n",
      "Loss at Iteration @ 4780 is 2.2060561180114746\n",
      "Loss at Iteration @ 4781 is 1.95844304561615\n",
      "Loss at Iteration @ 4782 is 2.498012065887451\n",
      "Loss at Iteration @ 4783 is 2.244525909423828\n",
      "Loss at Iteration @ 4784 is 2.3482275009155273\n",
      "Loss at Iteration @ 4785 is 2.4006285667419434\n",
      "Loss at Iteration @ 4786 is 2.18485426902771\n",
      "Loss at Iteration @ 4787 is 2.4423904418945312\n",
      "Loss at Iteration @ 4788 is 2.4991655349731445\n",
      "Loss at Iteration @ 4789 is 2.169337034225464\n",
      "Loss at Iteration @ 4790 is 2.318901300430298\n",
      "Loss at Iteration @ 4791 is 2.479586124420166\n",
      "Loss at Iteration @ 4792 is 2.3938522338867188\n",
      "Loss at Iteration @ 4793 is 2.215857982635498\n",
      "Loss at Iteration @ 4794 is 2.2375433444976807\n",
      "Loss at Iteration @ 4795 is 1.945015549659729\n",
      "Loss at Iteration @ 4796 is 2.3308632373809814\n",
      "Loss at Iteration @ 4797 is 2.2327680587768555\n",
      "Loss at Iteration @ 4798 is 2.311645746231079\n",
      "Loss at Iteration @ 4799 is 2.3411128520965576\n",
      "Loss at Iteration @ 4800 is 2.3605220317840576\n",
      "Loss at Iteration @ 4801 is 2.1014199256896973\n",
      "Loss at Iteration @ 4802 is 2.1543962955474854\n",
      "Loss at Iteration @ 4803 is 2.2948124408721924\n",
      "Loss at Iteration @ 4804 is 2.363635301589966\n",
      "Loss at Iteration @ 4805 is 2.113800048828125\n",
      "Loss at Iteration @ 4806 is 2.225911855697632\n",
      "Loss at Iteration @ 4807 is 2.062418222427368\n",
      "Loss at Iteration @ 4808 is 2.0893261432647705\n",
      "Loss at Iteration @ 4809 is 2.061457872390747\n",
      "Loss at Iteration @ 4810 is 2.654705286026001\n",
      "Loss at Iteration @ 4811 is 2.3527286052703857\n",
      "Loss at Iteration @ 4812 is 2.1094141006469727\n",
      "Loss at Iteration @ 4813 is 2.35569429397583\n",
      "Loss at Iteration @ 4814 is 2.239799737930298\n",
      "Loss at Iteration @ 4815 is 2.3743178844451904\n",
      "Loss at Iteration @ 4816 is 2.213928461074829\n",
      "Loss at Iteration @ 4817 is 2.162757396697998\n",
      "Loss at Iteration @ 4818 is 2.1676955223083496\n",
      "Loss at Iteration @ 4819 is 2.5993762016296387\n",
      "Loss at Iteration @ 4820 is 2.1093432903289795\n",
      "Loss at Iteration @ 4821 is 2.4452099800109863\n",
      "Loss at Iteration @ 4822 is 2.1890389919281006\n",
      "Loss at Iteration @ 4823 is 2.013765335083008\n",
      "Loss at Iteration @ 4824 is 2.3495054244995117\n",
      "Loss at Iteration @ 4825 is 2.1142454147338867\n",
      "Loss at Iteration @ 4826 is 2.292419910430908\n",
      "Loss at Iteration @ 4827 is 2.2946369647979736\n",
      "Loss at Iteration @ 4828 is 2.0686957836151123\n",
      "Loss at Iteration @ 4829 is 2.172919750213623\n",
      "Loss at Iteration @ 4830 is 2.421469211578369\n",
      "Loss at Iteration @ 4831 is 1.9912689924240112\n",
      "Loss at Iteration @ 4832 is 2.216618299484253\n",
      "Loss at Iteration @ 4833 is 2.077484607696533\n",
      "Loss at Iteration @ 4834 is 2.3757059574127197\n",
      "Loss at Iteration @ 4835 is 2.036623239517212\n",
      "Loss at Iteration @ 4836 is 2.174105405807495\n",
      "Loss at Iteration @ 4837 is 2.2200310230255127\n",
      "Loss at Iteration @ 4838 is 1.915408968925476\n",
      "Loss at Iteration @ 4839 is 2.395110607147217\n",
      "Loss at Iteration @ 4840 is 2.010568141937256\n",
      "Loss at Iteration @ 4841 is 2.2312545776367188\n",
      "Loss at Iteration @ 4842 is 2.574556589126587\n",
      "Loss at Iteration @ 4843 is 2.3659963607788086\n",
      "Loss at Iteration @ 4844 is 2.3858017921447754\n",
      "Loss at Iteration @ 4845 is 2.5706796646118164\n",
      "Loss at Iteration @ 4846 is 2.2732059955596924\n",
      "Loss at Iteration @ 4847 is 2.1775267124176025\n",
      "Loss at Iteration @ 4848 is 1.9386584758758545\n",
      "Loss at Iteration @ 4849 is 2.2508251667022705\n",
      "Loss at Iteration @ 4850 is 2.349867820739746\n",
      "Loss at Iteration @ 4851 is 2.2587037086486816\n",
      "Loss at Iteration @ 4852 is 2.5861856937408447\n",
      "Loss at Iteration @ 4853 is 2.0983242988586426\n",
      "Loss at Iteration @ 4854 is 2.4620490074157715\n",
      "Loss at Iteration @ 4855 is 2.2207634449005127\n",
      "Loss at Iteration @ 4856 is 2.3431396484375\n",
      "Loss at Iteration @ 4857 is 2.266240119934082\n",
      "Loss at Iteration @ 4858 is 2.1528451442718506\n",
      "Loss at Iteration @ 4859 is 2.5759525299072266\n",
      "Loss at Iteration @ 4860 is 2.252558469772339\n",
      "Loss at Iteration @ 4861 is 2.406992197036743\n",
      "Loss at Iteration @ 4862 is 2.268315315246582\n",
      "Loss at Iteration @ 4863 is 2.435269355773926\n",
      "Loss at Iteration @ 4864 is 2.3461358547210693\n",
      "Loss at Iteration @ 4865 is 2.247164487838745\n",
      "Loss at Iteration @ 4866 is 2.4579455852508545\n",
      "Loss at Iteration @ 4867 is 2.3182036876678467\n",
      "Loss at Iteration @ 4868 is 2.1811234951019287\n",
      "Loss at Iteration @ 4869 is 2.3153011798858643\n",
      "Loss at Iteration @ 4870 is 2.3865368366241455\n",
      "Loss at Iteration @ 4871 is 2.2723448276519775\n",
      "Loss at Iteration @ 4872 is 2.243241548538208\n",
      "Loss at Iteration @ 4873 is 2.273175001144409\n",
      "Loss at Iteration @ 4874 is 2.3050789833068848\n",
      "Loss at Iteration @ 4875 is 2.357743501663208\n",
      "Loss at Iteration @ 4876 is 2.315135955810547\n",
      "Loss at Iteration @ 4877 is 2.3091564178466797\n",
      "Loss at Iteration @ 4878 is 2.2559256553649902\n",
      "Loss at Iteration @ 4879 is 2.2379260063171387\n",
      "Loss at Iteration @ 4880 is 2.0643882751464844\n",
      "Loss at Iteration @ 4881 is 2.1575958728790283\n",
      "Loss at Iteration @ 4882 is 2.2608494758605957\n",
      "Loss at Iteration @ 4883 is 2.2001430988311768\n",
      "Loss at Iteration @ 4884 is 2.1651811599731445\n",
      "Loss at Iteration @ 4885 is 2.0153958797454834\n",
      "Loss at Iteration @ 4886 is 2.1863372325897217\n",
      "Loss at Iteration @ 4887 is 2.298715353012085\n",
      "Loss at Iteration @ 4888 is 2.0977885723114014\n",
      "Loss at Iteration @ 4889 is 1.9939172267913818\n",
      "Loss at Iteration @ 4890 is 2.349069595336914\n",
      "Loss at Iteration @ 4891 is 2.2415614128112793\n",
      "Loss at Iteration @ 4892 is 1.9221376180648804\n",
      "Loss at Iteration @ 4893 is 2.2644166946411133\n",
      "Loss at Iteration @ 4894 is 2.1952197551727295\n",
      "Loss at Iteration @ 4895 is 2.1221792697906494\n",
      "Loss at Iteration @ 4896 is 1.9515881538391113\n",
      "Loss at Iteration @ 4897 is 2.334183692932129\n",
      "Loss at Iteration @ 4898 is 2.413001298904419\n",
      "Loss at Iteration @ 4899 is 1.9166704416275024\n",
      "Loss at Iteration @ 4900 is 2.4046361446380615\n",
      "Loss at Iteration @ 4901 is 2.3999013900756836\n",
      "Loss at Iteration @ 4902 is 2.4085006713867188\n",
      "Loss at Iteration @ 4903 is 2.1991100311279297\n",
      "Loss at Iteration @ 4904 is 2.2056422233581543\n",
      "Loss at Iteration @ 4905 is 2.2579777240753174\n",
      "Loss at Iteration @ 4906 is 2.2491250038146973\n",
      "Loss at Iteration @ 4907 is 2.434677839279175\n",
      "Loss at Iteration @ 4908 is 2.286285161972046\n",
      "Loss at Iteration @ 4909 is 2.162433624267578\n",
      "Loss at Iteration @ 4910 is 2.406473159790039\n",
      "Loss at Iteration @ 4911 is 2.0499234199523926\n",
      "Loss at Iteration @ 4912 is 2.0861692428588867\n",
      "Loss at Iteration @ 4913 is 2.5406641960144043\n",
      "Loss at Iteration @ 4914 is 2.324509620666504\n",
      "Loss at Iteration @ 4915 is 2.196773052215576\n",
      "Loss at Iteration @ 4916 is 2.1331655979156494\n",
      "Loss at Iteration @ 4917 is 2.760796070098877\n",
      "Loss at Iteration @ 4918 is 2.2132418155670166\n",
      "Loss at Iteration @ 4919 is 2.1776974201202393\n",
      "Loss at Iteration @ 4920 is 1.976887822151184\n",
      "Loss at Iteration @ 4921 is 2.2628135681152344\n",
      "Loss at Iteration @ 4922 is 1.964503526687622\n",
      "Loss at Iteration @ 4923 is 2.1050057411193848\n",
      "Loss at Iteration @ 4924 is 2.3788983821868896\n",
      "Loss at Iteration @ 4925 is 2.4015750885009766\n",
      "Loss at Iteration @ 4926 is 2.2987117767333984\n",
      "Loss at Iteration @ 4927 is 2.3008124828338623\n",
      "Loss at Iteration @ 4928 is 2.0816638469696045\n",
      "Loss at Iteration @ 4929 is 2.465865135192871\n",
      "Loss at Iteration @ 4930 is 2.2042746543884277\n",
      "Loss at Iteration @ 4931 is 2.031632900238037\n",
      "Loss at Iteration @ 4932 is 2.0826961994171143\n",
      "Loss at Iteration @ 4933 is 2.0835652351379395\n",
      "Loss at Iteration @ 4934 is 2.0549662113189697\n",
      "Loss at Iteration @ 4935 is 2.1321444511413574\n",
      "Loss at Iteration @ 4936 is 2.457773208618164\n",
      "Loss at Iteration @ 4937 is 2.3833682537078857\n",
      "Loss at Iteration @ 4938 is 2.5087103843688965\n",
      "Loss at Iteration @ 4939 is 2.1960015296936035\n",
      "Loss at Iteration @ 4940 is 2.4675989151000977\n",
      "Loss at Iteration @ 4941 is 2.114121198654175\n",
      "Loss at Iteration @ 4942 is 2.4217069149017334\n",
      "Loss at Iteration @ 4943 is 2.1355698108673096\n",
      "Loss at Iteration @ 4944 is 2.2175965309143066\n",
      "Loss at Iteration @ 4945 is 2.617152690887451\n",
      "Loss at Iteration @ 4946 is 2.426975965499878\n",
      "Loss at Iteration @ 4947 is 2.1008129119873047\n",
      "Loss at Iteration @ 4948 is 2.324082374572754\n",
      "Loss at Iteration @ 4949 is 2.015455961227417\n",
      "Loss at Iteration @ 4950 is 2.401343584060669\n",
      "Loss at Iteration @ 4951 is 2.3884057998657227\n",
      "Loss at Iteration @ 4952 is 2.069988489151001\n",
      "Loss at Iteration @ 4953 is 2.164527654647827\n",
      "Loss at Iteration @ 4954 is 2.0689332485198975\n",
      "Loss at Iteration @ 4955 is 2.3631787300109863\n",
      "Loss at Iteration @ 4956 is 2.1236379146575928\n",
      "Loss at Iteration @ 4957 is 2.2458574771881104\n",
      "Loss at Iteration @ 4958 is 2.306466817855835\n",
      "Loss at Iteration @ 4959 is 2.127718448638916\n",
      "Loss at Iteration @ 4960 is 2.293283224105835\n",
      "Loss at Iteration @ 4961 is 2.176326036453247\n",
      "Loss at Iteration @ 4962 is 2.105447769165039\n",
      "Loss at Iteration @ 4963 is 2.0482566356658936\n",
      "Loss at Iteration @ 4964 is 2.5794036388397217\n",
      "Loss at Iteration @ 4965 is 2.181792736053467\n",
      "Loss at Iteration @ 4966 is 2.144312858581543\n",
      "Loss at Iteration @ 4967 is 2.2795488834381104\n",
      "Loss at Iteration @ 4968 is 2.287476062774658\n",
      "Loss at Iteration @ 4969 is 2.11433744430542\n",
      "Loss at Iteration @ 4970 is 2.022001028060913\n",
      "Loss at Iteration @ 4971 is 2.0862085819244385\n",
      "Loss at Iteration @ 4972 is 2.344921112060547\n",
      "Loss at Iteration @ 4973 is 2.125312328338623\n",
      "Loss at Iteration @ 4974 is 2.0661630630493164\n",
      "Loss at Iteration @ 4975 is 2.2847352027893066\n",
      "Loss at Iteration @ 4976 is 2.0011613368988037\n",
      "Loss at Iteration @ 4977 is 2.2424113750457764\n",
      "Loss at Iteration @ 4978 is 2.3931992053985596\n",
      "Loss at Iteration @ 4979 is 2.1065680980682373\n",
      "Loss at Iteration @ 4980 is 2.4646120071411133\n",
      "Loss at Iteration @ 4981 is 2.2563560009002686\n",
      "Loss at Iteration @ 4982 is 2.195324420928955\n",
      "Loss at Iteration @ 4983 is 2.3429148197174072\n",
      "Loss at Iteration @ 4984 is 2.455767869949341\n",
      "Loss at Iteration @ 4985 is 2.277998447418213\n",
      "Loss at Iteration @ 4986 is 2.222747325897217\n",
      "Loss at Iteration @ 4987 is 2.2053287029266357\n",
      "Loss at Iteration @ 4988 is 2.502081871032715\n",
      "Loss at Iteration @ 4989 is 1.9923887252807617\n",
      "Loss at Iteration @ 4990 is 1.9048019647598267\n",
      "Loss at Iteration @ 4991 is 2.284965753555298\n",
      "Loss at Iteration @ 4992 is 2.2456588745117188\n",
      "Loss at Iteration @ 4993 is 2.181318759918213\n",
      "Loss at Iteration @ 4994 is 2.1272194385528564\n",
      "Loss at Iteration @ 4995 is 2.036346197128296\n",
      "Loss at Iteration @ 4996 is 1.8658565282821655\n",
      "Loss at Iteration @ 4997 is 2.3168628215789795\n",
      "Loss at Iteration @ 4998 is 1.9980614185333252\n",
      "Loss at Iteration @ 4999 is 2.4911770820617676\n",
      "Loss at Iteration @ 5000 is 2.0401952266693115\n",
      "Loss at Iteration @ 5001 is 1.9992568492889404\n",
      "Evaluation Loss at Iteration @ 5001 is 2.1947391033172607\n",
      "Loss at Iteration @ 5002 is 2.43692684173584\n",
      "Evaluation Loss at Iteration @ 5002 is 2.2401175498962402\n",
      "Loss at Iteration @ 5003 is 2.1126155853271484\n",
      "Evaluation Loss at Iteration @ 5003 is 2.255882978439331\n",
      "Loss at Iteration @ 5004 is 2.111452102661133\n",
      "Evaluation Loss at Iteration @ 5004 is 2.228276014328003\n",
      "Loss at Iteration @ 5005 is 2.280667781829834\n",
      "Evaluation Loss at Iteration @ 5005 is 2.2464962005615234\n",
      "Loss at Iteration @ 5006 is 2.377329111099243\n",
      "Evaluation Loss at Iteration @ 5006 is 2.2486019134521484\n",
      "Loss at Iteration @ 5007 is 2.2229790687561035\n",
      "Evaluation Loss at Iteration @ 5007 is 2.214545488357544\n",
      "Loss at Iteration @ 5008 is 2.2093076705932617\n",
      "Evaluation Loss at Iteration @ 5008 is 2.238264322280884\n",
      "Loss at Iteration @ 5009 is 2.5132555961608887\n",
      "Evaluation Loss at Iteration @ 5009 is 2.2556402683258057\n",
      "Loss at Iteration @ 5010 is 2.0235040187835693\n",
      "Evaluation Loss at Iteration @ 5010 is 2.2341902256011963\n",
      "Loss at Iteration @ 5011 is 2.1902241706848145\n",
      "Evaluation Loss at Iteration @ 5011 is 2.264590263366699\n",
      "Loss at Iteration @ 5012 is 2.0283682346343994\n",
      "Evaluation Loss at Iteration @ 5012 is 2.2382683753967285\n",
      "Loss at Iteration @ 5013 is 2.2638800144195557\n",
      "Evaluation Loss at Iteration @ 5013 is 2.266949415206909\n",
      "Loss at Iteration @ 5014 is 2.138054370880127\n",
      "Evaluation Loss at Iteration @ 5014 is 2.305281162261963\n",
      "Loss at Iteration @ 5015 is 2.0561254024505615\n",
      "Evaluation Loss at Iteration @ 5015 is 2.2351014614105225\n",
      "Loss at Iteration @ 5016 is 2.27541446685791\n",
      "Evaluation Loss at Iteration @ 5016 is 2.274007797241211\n",
      "Loss at Iteration @ 5017 is 2.1247129440307617\n",
      "Evaluation Loss at Iteration @ 5017 is 2.2412662506103516\n",
      "Loss at Iteration @ 5018 is 2.4997501373291016\n",
      "Evaluation Loss at Iteration @ 5018 is 2.2321465015411377\n",
      "Loss at Iteration @ 5019 is 2.2120697498321533\n",
      "Evaluation Loss at Iteration @ 5019 is 2.285609006881714\n",
      "Loss at Iteration @ 5020 is 2.4540040493011475\n",
      "Evaluation Loss at Iteration @ 5020 is 2.21266508102417\n",
      "Loss at Iteration @ 5021 is 2.231226921081543\n",
      "Evaluation Loss at Iteration @ 5021 is 2.286691665649414\n",
      "Loss at Iteration @ 5022 is 2.189815044403076\n",
      "Evaluation Loss at Iteration @ 5022 is 2.2680187225341797\n",
      "Loss at Iteration @ 5023 is 2.324254035949707\n",
      "Evaluation Loss at Iteration @ 5023 is 2.248288154602051\n",
      "Loss at Iteration @ 5024 is 1.914427638053894\n",
      "Evaluation Loss at Iteration @ 5024 is 2.3009653091430664\n",
      "Loss at Iteration @ 5025 is 2.2989680767059326\n",
      "Evaluation Loss at Iteration @ 5025 is 2.2729079723358154\n",
      "Loss at Iteration @ 5026 is 2.188933849334717\n",
      "Evaluation Loss at Iteration @ 5026 is 2.263340473175049\n",
      "Loss at Iteration @ 5027 is 2.344331741333008\n",
      "Evaluation Loss at Iteration @ 5027 is 2.2730813026428223\n",
      "Loss at Iteration @ 5028 is 2.117002010345459\n",
      "Evaluation Loss at Iteration @ 5028 is 2.232707977294922\n",
      "Loss at Iteration @ 5029 is 2.2739272117614746\n",
      "Evaluation Loss at Iteration @ 5029 is 2.2193007469177246\n",
      "Loss at Iteration @ 5030 is 2.5568315982818604\n",
      "Evaluation Loss at Iteration @ 5030 is 2.2504100799560547\n",
      "Loss at Iteration @ 5031 is 2.4360103607177734\n",
      "Evaluation Loss at Iteration @ 5031 is 2.2693376541137695\n",
      "Loss at Iteration @ 5032 is 2.217479705810547\n",
      "Evaluation Loss at Iteration @ 5032 is 2.232332944869995\n",
      "Loss at Iteration @ 5033 is 2.0180418491363525\n",
      "Evaluation Loss at Iteration @ 5033 is 2.264307737350464\n",
      "Loss at Iteration @ 5034 is 2.25677752494812\n",
      "Evaluation Loss at Iteration @ 5034 is 2.3213729858398438\n",
      "Loss at Iteration @ 5035 is 2.3494412899017334\n",
      "Evaluation Loss at Iteration @ 5035 is 2.259932041168213\n",
      "Loss at Iteration @ 5036 is 2.439091205596924\n",
      "Evaluation Loss at Iteration @ 5036 is 2.258509635925293\n",
      "Loss at Iteration @ 5037 is 2.2006664276123047\n",
      "Evaluation Loss at Iteration @ 5037 is 2.2442004680633545\n",
      "Loss at Iteration @ 5038 is 2.0564937591552734\n",
      "Evaluation Loss at Iteration @ 5038 is 2.2367029190063477\n",
      "Loss at Iteration @ 5039 is 2.1477627754211426\n",
      "Evaluation Loss at Iteration @ 5039 is 2.2771928310394287\n",
      "Loss at Iteration @ 5040 is 2.249932289123535\n",
      "Evaluation Loss at Iteration @ 5040 is 2.2465457916259766\n",
      "Loss at Iteration @ 5041 is 2.3464133739471436\n",
      "Evaluation Loss at Iteration @ 5041 is 2.242706298828125\n",
      "Loss at Iteration @ 5042 is 1.9236267805099487\n",
      "Evaluation Loss at Iteration @ 5042 is 2.1999170780181885\n",
      "Loss at Iteration @ 5043 is 2.1478490829467773\n",
      "Evaluation Loss at Iteration @ 5043 is 2.296373128890991\n",
      "Loss at Iteration @ 5044 is 2.2395823001861572\n",
      "Evaluation Loss at Iteration @ 5044 is 2.258286714553833\n",
      "Loss at Iteration @ 5045 is 2.20957088470459\n",
      "Evaluation Loss at Iteration @ 5045 is 2.239093780517578\n",
      "Loss at Iteration @ 5046 is 2.4591705799102783\n",
      "Evaluation Loss at Iteration @ 5046 is 2.243811845779419\n",
      "Loss at Iteration @ 5047 is 2.1478359699249268\n",
      "Evaluation Loss at Iteration @ 5047 is 2.262368679046631\n",
      "Loss at Iteration @ 5048 is 2.245703935623169\n",
      "Evaluation Loss at Iteration @ 5048 is 2.2427523136138916\n",
      "Loss at Iteration @ 5049 is 2.1881513595581055\n",
      "Evaluation Loss at Iteration @ 5049 is 2.2670135498046875\n",
      "Loss at Iteration @ 5050 is 2.2737746238708496\n",
      "Evaluation Loss at Iteration @ 5050 is 2.2451822757720947\n",
      "Loss at Iteration @ 5051 is 2.124358892440796\n",
      "Evaluation Loss at Iteration @ 5051 is 2.271409511566162\n",
      "Loss at Iteration @ 5052 is 2.251899480819702\n",
      "Evaluation Loss at Iteration @ 5052 is 2.2612075805664062\n",
      "Loss at Iteration @ 5053 is 2.2110660076141357\n",
      "Evaluation Loss at Iteration @ 5053 is 2.234328508377075\n",
      "Loss at Iteration @ 5054 is 2.390918731689453\n",
      "Evaluation Loss at Iteration @ 5054 is 2.2453439235687256\n",
      "Loss at Iteration @ 5055 is 2.4929230213165283\n",
      "Evaluation Loss at Iteration @ 5055 is 2.189582109451294\n",
      "Loss at Iteration @ 5056 is 2.041414737701416\n",
      "Evaluation Loss at Iteration @ 5056 is 2.2718939781188965\n",
      "Loss at Iteration @ 5057 is 2.132668972015381\n",
      "Evaluation Loss at Iteration @ 5057 is 2.2510499954223633\n",
      "Loss at Iteration @ 5058 is 2.119927406311035\n",
      "Evaluation Loss at Iteration @ 5058 is 2.2824528217315674\n",
      "Loss at Iteration @ 5059 is 2.084057092666626\n",
      "Evaluation Loss at Iteration @ 5059 is 2.2376861572265625\n",
      "Loss at Iteration @ 5060 is 2.118529796600342\n",
      "Evaluation Loss at Iteration @ 5060 is 2.2398221492767334\n",
      "Loss at Iteration @ 5061 is 2.192380666732788\n",
      "Evaluation Loss at Iteration @ 5061 is 2.2872958183288574\n",
      "Loss at Iteration @ 5062 is 2.1397292613983154\n",
      "Evaluation Loss at Iteration @ 5062 is 2.227940320968628\n",
      "Loss at Iteration @ 5063 is 2.2533671855926514\n",
      "Evaluation Loss at Iteration @ 5063 is 2.293060302734375\n",
      "Loss at Iteration @ 5064 is 2.2184810638427734\n",
      "Evaluation Loss at Iteration @ 5064 is 2.2218124866485596\n",
      "Loss at Iteration @ 5065 is 2.039741277694702\n",
      "Evaluation Loss at Iteration @ 5065 is 2.2756991386413574\n",
      "Loss at Iteration @ 5066 is 2.3231592178344727\n",
      "Evaluation Loss at Iteration @ 5066 is 2.227170705795288\n",
      "Loss at Iteration @ 5067 is 2.178744077682495\n",
      "Evaluation Loss at Iteration @ 5067 is 2.2980475425720215\n",
      "Loss at Iteration @ 5068 is 2.532850503921509\n",
      "Evaluation Loss at Iteration @ 5068 is 2.2405989170074463\n",
      "Loss at Iteration @ 5069 is 2.3440332412719727\n",
      "Evaluation Loss at Iteration @ 5069 is 2.2284998893737793\n",
      "Loss at Iteration @ 5070 is 2.15708327293396\n",
      "Evaluation Loss at Iteration @ 5070 is 2.23903489112854\n",
      "Loss at Iteration @ 5071 is 2.175729990005493\n",
      "Evaluation Loss at Iteration @ 5071 is 2.235574245452881\n",
      "Loss at Iteration @ 5072 is 2.581186532974243\n",
      "Evaluation Loss at Iteration @ 5072 is 2.285677671432495\n",
      "Loss at Iteration @ 5073 is 2.2704849243164062\n",
      "Evaluation Loss at Iteration @ 5073 is 2.262178659439087\n",
      "Loss at Iteration @ 5074 is 2.46560001373291\n",
      "Evaluation Loss at Iteration @ 5074 is 2.234072685241699\n",
      "Loss at Iteration @ 5075 is 2.1412851810455322\n",
      "Evaluation Loss at Iteration @ 5075 is 2.2403416633605957\n",
      "Loss at Iteration @ 5076 is 2.2004940509796143\n",
      "Evaluation Loss at Iteration @ 5076 is 2.2445387840270996\n",
      "Loss at Iteration @ 5077 is 2.157866954803467\n",
      "Evaluation Loss at Iteration @ 5077 is 2.288947105407715\n",
      "Loss at Iteration @ 5078 is 2.4622225761413574\n",
      "Evaluation Loss at Iteration @ 5078 is 2.300351619720459\n",
      "Loss at Iteration @ 5079 is 2.2169244289398193\n",
      "Evaluation Loss at Iteration @ 5079 is 2.2001514434814453\n",
      "Loss at Iteration @ 5080 is 2.4519379138946533\n",
      "Evaluation Loss at Iteration @ 5080 is 2.2596356868743896\n",
      "Loss at Iteration @ 5081 is 2.157749652862549\n",
      "Evaluation Loss at Iteration @ 5081 is 2.2904744148254395\n",
      "Loss at Iteration @ 5082 is 2.0214357376098633\n",
      "Evaluation Loss at Iteration @ 5082 is 2.2593557834625244\n",
      "Loss at Iteration @ 5083 is 2.5554580688476562\n",
      "Evaluation Loss at Iteration @ 5083 is 2.284543037414551\n",
      "Loss at Iteration @ 5084 is 2.3501574993133545\n",
      "Evaluation Loss at Iteration @ 5084 is 2.2374916076660156\n",
      "Loss at Iteration @ 5085 is 2.4575436115264893\n",
      "Evaluation Loss at Iteration @ 5085 is 2.2806107997894287\n",
      "Loss at Iteration @ 5086 is 2.0619349479675293\n",
      "Evaluation Loss at Iteration @ 5086 is 2.2734787464141846\n",
      "Loss at Iteration @ 5087 is 2.141144037246704\n",
      "Evaluation Loss at Iteration @ 5087 is 2.288769006729126\n",
      "Loss at Iteration @ 5088 is 2.499868392944336\n",
      "Evaluation Loss at Iteration @ 5088 is 2.2302069664001465\n",
      "Loss at Iteration @ 5089 is 2.2078700065612793\n",
      "Evaluation Loss at Iteration @ 5089 is 2.2832956314086914\n",
      "Loss at Iteration @ 5090 is 1.9094500541687012\n",
      "Evaluation Loss at Iteration @ 5090 is 2.257655382156372\n",
      "Loss at Iteration @ 5091 is 2.247955799102783\n",
      "Evaluation Loss at Iteration @ 5091 is 2.2930684089660645\n",
      "Loss at Iteration @ 5092 is 2.2364003658294678\n",
      "Evaluation Loss at Iteration @ 5092 is 2.2817091941833496\n",
      "Loss at Iteration @ 5093 is 2.181852340698242\n",
      "Evaluation Loss at Iteration @ 5093 is 2.259936809539795\n",
      "Loss at Iteration @ 5094 is 2.439380168914795\n",
      "Evaluation Loss at Iteration @ 5094 is 2.2267022132873535\n",
      "Loss at Iteration @ 5095 is 2.0590503215789795\n",
      "Evaluation Loss at Iteration @ 5095 is 2.278068780899048\n",
      "Loss at Iteration @ 5096 is 2.3957748413085938\n",
      "Evaluation Loss at Iteration @ 5096 is 2.239684581756592\n",
      "Loss at Iteration @ 5097 is 2.204139471054077\n",
      "Evaluation Loss at Iteration @ 5097 is 2.244690179824829\n",
      "Loss at Iteration @ 5098 is 2.470787763595581\n",
      "Evaluation Loss at Iteration @ 5098 is 2.226285457611084\n",
      "Loss at Iteration @ 5099 is 2.3192059993743896\n",
      "Evaluation Loss at Iteration @ 5099 is 2.165395736694336\n",
      "Loss at Iteration @ 5100 is 2.099722146987915\n",
      "Evaluation Loss at Iteration @ 5100 is 2.224609613418579\n",
      "Loss at Iteration @ 5101 is 2.231562376022339\n",
      "Evaluation Loss at Iteration @ 5101 is 2.2294609546661377\n",
      "Loss at Iteration @ 5102 is 2.2861883640289307\n",
      "Evaluation Loss at Iteration @ 5102 is 2.2363526821136475\n",
      "Loss at Iteration @ 5103 is 2.4409584999084473\n",
      "Evaluation Loss at Iteration @ 5103 is 2.2476823329925537\n",
      "Loss at Iteration @ 5104 is 2.228290557861328\n",
      "Evaluation Loss at Iteration @ 5104 is 2.227433443069458\n",
      "Loss at Iteration @ 5105 is 2.0629091262817383\n",
      "Evaluation Loss at Iteration @ 5105 is 2.2470500469207764\n",
      "Loss at Iteration @ 5106 is 2.072213649749756\n",
      "Evaluation Loss at Iteration @ 5106 is 2.2568202018737793\n",
      "Loss at Iteration @ 5107 is 2.170072555541992\n",
      "Evaluation Loss at Iteration @ 5107 is 2.267359972000122\n",
      "Loss at Iteration @ 5108 is 2.3888251781463623\n",
      "Evaluation Loss at Iteration @ 5108 is 2.232923984527588\n",
      "Loss at Iteration @ 5109 is 2.292706251144409\n",
      "Evaluation Loss at Iteration @ 5109 is 2.276515483856201\n",
      "Loss at Iteration @ 5110 is 2.1449332237243652\n",
      "Evaluation Loss at Iteration @ 5110 is 2.2463841438293457\n",
      "Loss at Iteration @ 5111 is 2.0990891456604004\n",
      "Evaluation Loss at Iteration @ 5111 is 2.2461538314819336\n",
      "Loss at Iteration @ 5112 is 2.2014424800872803\n",
      "Evaluation Loss at Iteration @ 5112 is 2.273232936859131\n",
      "Loss at Iteration @ 5113 is 2.2823452949523926\n",
      "Evaluation Loss at Iteration @ 5113 is 2.2798163890838623\n",
      "Loss at Iteration @ 5114 is 2.014981985092163\n",
      "Evaluation Loss at Iteration @ 5114 is 2.321047306060791\n",
      "Loss at Iteration @ 5115 is 2.411134958267212\n",
      "Evaluation Loss at Iteration @ 5115 is 2.280325412750244\n",
      "Loss at Iteration @ 5116 is 2.264207363128662\n",
      "Evaluation Loss at Iteration @ 5116 is 2.2408480644226074\n",
      "Loss at Iteration @ 5117 is 2.2150955200195312\n",
      "Evaluation Loss at Iteration @ 5117 is 2.259411334991455\n",
      "Loss at Iteration @ 5118 is 2.0342836380004883\n",
      "Evaluation Loss at Iteration @ 5118 is 2.2264785766601562\n",
      "Loss at Iteration @ 5119 is 2.434016227722168\n",
      "Evaluation Loss at Iteration @ 5119 is 2.2313196659088135\n",
      "Loss at Iteration @ 5120 is 2.142127752304077\n",
      "Evaluation Loss at Iteration @ 5120 is 2.2586984634399414\n",
      "Loss at Iteration @ 5121 is 2.382513999938965\n",
      "Evaluation Loss at Iteration @ 5121 is 2.243812084197998\n",
      "Loss at Iteration @ 5122 is 1.9347604513168335\n",
      "Evaluation Loss at Iteration @ 5122 is 2.243359088897705\n",
      "Loss at Iteration @ 5123 is 2.1413440704345703\n",
      "Evaluation Loss at Iteration @ 5123 is 2.2405877113342285\n",
      "Loss at Iteration @ 5124 is 2.38728666305542\n",
      "Evaluation Loss at Iteration @ 5124 is 2.269195556640625\n",
      "Loss at Iteration @ 5125 is 1.9290279150009155\n",
      "Evaluation Loss at Iteration @ 5125 is 2.2465388774871826\n",
      "Loss at Iteration @ 5126 is 2.290071725845337\n",
      "Evaluation Loss at Iteration @ 5126 is 2.2587621212005615\n",
      "Loss at Iteration @ 5127 is 1.9075684547424316\n",
      "Evaluation Loss at Iteration @ 5127 is 2.25566029548645\n",
      "Loss at Iteration @ 5128 is 2.1322522163391113\n",
      "Evaluation Loss at Iteration @ 5128 is 2.2405004501342773\n",
      "Loss at Iteration @ 5129 is 2.577542781829834\n",
      "Evaluation Loss at Iteration @ 5129 is 2.247929573059082\n",
      "Loss at Iteration @ 5130 is 2.225855827331543\n",
      "Evaluation Loss at Iteration @ 5130 is 2.2507567405700684\n",
      "Loss at Iteration @ 5131 is 2.2526397705078125\n",
      "Evaluation Loss at Iteration @ 5131 is 2.219883680343628\n",
      "Loss at Iteration @ 5132 is 2.3784828186035156\n",
      "Evaluation Loss at Iteration @ 5132 is 2.278128147125244\n",
      "Loss at Iteration @ 5133 is 2.0801055431365967\n",
      "Evaluation Loss at Iteration @ 5133 is 2.266061544418335\n",
      "Loss at Iteration @ 5134 is 2.1415443420410156\n",
      "Evaluation Loss at Iteration @ 5134 is 2.2718682289123535\n",
      "Loss at Iteration @ 5135 is 2.5780880451202393\n",
      "Evaluation Loss at Iteration @ 5135 is 2.2708213329315186\n",
      "Loss at Iteration @ 5136 is 2.545349359512329\n",
      "Evaluation Loss at Iteration @ 5136 is 2.23394513130188\n",
      "Loss at Iteration @ 5137 is 2.521085023880005\n",
      "Evaluation Loss at Iteration @ 5137 is 2.282202959060669\n",
      "Loss at Iteration @ 5138 is 2.155360698699951\n",
      "Evaluation Loss at Iteration @ 5138 is 2.277207136154175\n",
      "Loss at Iteration @ 5139 is 2.4365177154541016\n",
      "Evaluation Loss at Iteration @ 5139 is 2.3040599822998047\n",
      "Loss at Iteration @ 5140 is 2.416902780532837\n",
      "Evaluation Loss at Iteration @ 5140 is 2.254161834716797\n",
      "Loss at Iteration @ 5141 is 2.223386526107788\n",
      "Evaluation Loss at Iteration @ 5141 is 2.2309486865997314\n",
      "Loss at Iteration @ 5142 is 2.0990588665008545\n",
      "Evaluation Loss at Iteration @ 5142 is 2.2109365463256836\n",
      "Loss at Iteration @ 5143 is 2.3078339099884033\n",
      "Evaluation Loss at Iteration @ 5143 is 2.284733533859253\n",
      "Loss at Iteration @ 5144 is 1.9215179681777954\n",
      "Evaluation Loss at Iteration @ 5144 is 2.2527945041656494\n",
      "Loss at Iteration @ 5145 is 2.1615939140319824\n",
      "Evaluation Loss at Iteration @ 5145 is 2.2131457328796387\n",
      "Loss at Iteration @ 5146 is 2.1958670616149902\n",
      "Evaluation Loss at Iteration @ 5146 is 2.2574005126953125\n",
      "Loss at Iteration @ 5147 is 1.946540355682373\n",
      "Evaluation Loss at Iteration @ 5147 is 2.2830240726470947\n",
      "Loss at Iteration @ 5148 is 2.3362820148468018\n",
      "Evaluation Loss at Iteration @ 5148 is 2.282466173171997\n",
      "Loss at Iteration @ 5149 is 2.3230879306793213\n",
      "Evaluation Loss at Iteration @ 5149 is 2.287635564804077\n",
      "Loss at Iteration @ 5150 is 2.5949490070343018\n",
      "Evaluation Loss at Iteration @ 5150 is 2.2435665130615234\n",
      "Loss at Iteration @ 5151 is 1.945202112197876\n",
      "Evaluation Loss at Iteration @ 5151 is 2.2513427734375\n",
      "Loss at Iteration @ 5152 is 2.350013494491577\n",
      "Evaluation Loss at Iteration @ 5152 is 2.2449638843536377\n",
      "Loss at Iteration @ 5153 is 2.3090105056762695\n",
      "Evaluation Loss at Iteration @ 5153 is 2.2484350204467773\n",
      "Loss at Iteration @ 5154 is 2.4413912296295166\n",
      "Evaluation Loss at Iteration @ 5154 is 2.273993730545044\n",
      "Loss at Iteration @ 5155 is 2.5506458282470703\n",
      "Evaluation Loss at Iteration @ 5155 is 2.2949676513671875\n",
      "Loss at Iteration @ 5156 is 2.2436022758483887\n",
      "Evaluation Loss at Iteration @ 5156 is 2.2530040740966797\n",
      "Loss at Iteration @ 5157 is 2.2073402404785156\n",
      "Evaluation Loss at Iteration @ 5157 is 2.204972743988037\n",
      "Loss at Iteration @ 5158 is 2.2693753242492676\n",
      "Evaluation Loss at Iteration @ 5158 is 2.2459535598754883\n",
      "Loss at Iteration @ 5159 is 2.429861068725586\n",
      "Evaluation Loss at Iteration @ 5159 is 2.219433546066284\n",
      "Loss at Iteration @ 5160 is 2.2779974937438965\n",
      "Evaluation Loss at Iteration @ 5160 is 2.2708418369293213\n",
      "Loss at Iteration @ 5161 is 2.229520082473755\n",
      "Evaluation Loss at Iteration @ 5161 is 2.2161989212036133\n",
      "Loss at Iteration @ 5162 is 2.23270845413208\n",
      "Evaluation Loss at Iteration @ 5162 is 2.2427093982696533\n",
      "Loss at Iteration @ 5163 is 2.2558844089508057\n",
      "Evaluation Loss at Iteration @ 5163 is 2.3079633712768555\n",
      "Loss at Iteration @ 5164 is 2.0800867080688477\n",
      "Evaluation Loss at Iteration @ 5164 is 2.2682385444641113\n",
      "Loss at Iteration @ 5165 is 2.3412234783172607\n",
      "Evaluation Loss at Iteration @ 5165 is 2.270505905151367\n",
      "Loss at Iteration @ 5166 is 2.0328736305236816\n",
      "Evaluation Loss at Iteration @ 5166 is 2.271332025527954\n",
      "Loss at Iteration @ 5167 is 2.301173686981201\n",
      "Evaluation Loss at Iteration @ 5167 is 2.234421968460083\n",
      "Loss at Iteration @ 5168 is 2.3712668418884277\n",
      "Evaluation Loss at Iteration @ 5168 is 2.244812488555908\n",
      "Loss at Iteration @ 5169 is 2.1576662063598633\n",
      "Evaluation Loss at Iteration @ 5169 is 2.253171443939209\n",
      "Loss at Iteration @ 5170 is 2.1923458576202393\n",
      "Evaluation Loss at Iteration @ 5170 is 2.2469966411590576\n",
      "Loss at Iteration @ 5171 is 2.3942625522613525\n",
      "Evaluation Loss at Iteration @ 5171 is 2.273324728012085\n",
      "Loss at Iteration @ 5172 is 2.3673605918884277\n",
      "Evaluation Loss at Iteration @ 5172 is 2.2420310974121094\n",
      "Loss at Iteration @ 5173 is 2.31322979927063\n",
      "Evaluation Loss at Iteration @ 5173 is 2.230397939682007\n",
      "Loss at Iteration @ 5174 is 2.574002742767334\n",
      "Evaluation Loss at Iteration @ 5174 is 2.2226526737213135\n",
      "Loss at Iteration @ 5175 is 2.2836291790008545\n",
      "Evaluation Loss at Iteration @ 5175 is 2.2494547367095947\n",
      "Loss at Iteration @ 5176 is 2.2150418758392334\n",
      "Evaluation Loss at Iteration @ 5176 is 2.2594761848449707\n",
      "Loss at Iteration @ 5177 is 2.104123830795288\n",
      "Evaluation Loss at Iteration @ 5177 is 2.2643325328826904\n",
      "Loss at Iteration @ 5178 is 2.3386950492858887\n",
      "Evaluation Loss at Iteration @ 5178 is 2.256681442260742\n",
      "Loss at Iteration @ 5179 is 2.2653865814208984\n",
      "Evaluation Loss at Iteration @ 5179 is 2.283281087875366\n",
      "Loss at Iteration @ 5180 is 2.3633813858032227\n",
      "Evaluation Loss at Iteration @ 5180 is 2.2296082973480225\n",
      "Loss at Iteration @ 5181 is 2.1257636547088623\n",
      "Evaluation Loss at Iteration @ 5181 is 2.267778158187866\n",
      "Loss at Iteration @ 5182 is 2.1969218254089355\n",
      "Evaluation Loss at Iteration @ 5182 is 2.2466602325439453\n",
      "Loss at Iteration @ 5183 is 2.264727830886841\n",
      "Evaluation Loss at Iteration @ 5183 is 2.234043836593628\n",
      "Loss at Iteration @ 5184 is 2.142458915710449\n",
      "Evaluation Loss at Iteration @ 5184 is 2.258148670196533\n",
      "Loss at Iteration @ 5185 is 2.3329918384552\n",
      "Evaluation Loss at Iteration @ 5185 is 2.2173256874084473\n",
      "Loss at Iteration @ 5186 is 2.30407452583313\n",
      "Evaluation Loss at Iteration @ 5186 is 2.2984793186187744\n",
      "Loss at Iteration @ 5187 is 2.115208148956299\n",
      "Evaluation Loss at Iteration @ 5187 is 2.282965898513794\n",
      "Loss at Iteration @ 5188 is 2.145380735397339\n",
      "Evaluation Loss at Iteration @ 5188 is 2.24387264251709\n",
      "Loss at Iteration @ 5189 is 2.23164439201355\n",
      "Evaluation Loss at Iteration @ 5189 is 2.258779287338257\n",
      "Loss at Iteration @ 5190 is 2.467484951019287\n",
      "Evaluation Loss at Iteration @ 5190 is 2.2552576065063477\n",
      "Loss at Iteration @ 5191 is 2.3239378929138184\n",
      "Evaluation Loss at Iteration @ 5191 is 2.259326219558716\n",
      "Loss at Iteration @ 5192 is 2.3014395236968994\n",
      "Evaluation Loss at Iteration @ 5192 is 2.2207958698272705\n",
      "Loss at Iteration @ 5193 is 2.1563827991485596\n",
      "Evaluation Loss at Iteration @ 5193 is 2.2739996910095215\n",
      "Loss at Iteration @ 5194 is 2.3410983085632324\n",
      "Evaluation Loss at Iteration @ 5194 is 2.2685062885284424\n",
      "Loss at Iteration @ 5195 is 2.116694211959839\n",
      "Evaluation Loss at Iteration @ 5195 is 2.214095115661621\n",
      "Loss at Iteration @ 5196 is 1.8676491975784302\n",
      "Evaluation Loss at Iteration @ 5196 is 2.248556613922119\n",
      "Loss at Iteration @ 5197 is 2.1642658710479736\n",
      "Evaluation Loss at Iteration @ 5197 is 2.228039503097534\n",
      "Loss at Iteration @ 5198 is 2.284310817718506\n",
      "Evaluation Loss at Iteration @ 5198 is 2.257509708404541\n",
      "Loss at Iteration @ 5199 is 2.3291831016540527\n",
      "Evaluation Loss at Iteration @ 5199 is 2.226590871810913\n",
      "Loss at Iteration @ 5200 is 2.271050214767456\n",
      "Evaluation Loss at Iteration @ 5200 is 2.3113853931427\n",
      "Loss at Iteration @ 5201 is 2.577768325805664\n",
      "Evaluation Loss at Iteration @ 5201 is 2.2386956214904785\n",
      "Loss at Iteration @ 5202 is 2.286728620529175\n",
      "Evaluation Loss at Iteration @ 5202 is 2.284393310546875\n",
      "Loss at Iteration @ 5203 is 2.438490629196167\n",
      "Evaluation Loss at Iteration @ 5203 is 2.2190170288085938\n",
      "Loss at Iteration @ 5204 is 2.3543453216552734\n",
      "Evaluation Loss at Iteration @ 5204 is 2.267746686935425\n",
      "Loss at Iteration @ 5205 is 2.3920443058013916\n",
      "Evaluation Loss at Iteration @ 5205 is 2.269237995147705\n",
      "Loss at Iteration @ 5206 is 2.0984814167022705\n",
      "Evaluation Loss at Iteration @ 5206 is 2.2427592277526855\n",
      "Loss at Iteration @ 5207 is 2.109875202178955\n",
      "Evaluation Loss at Iteration @ 5207 is 2.2750823497772217\n",
      "Loss at Iteration @ 5208 is 2.3046722412109375\n",
      "Evaluation Loss at Iteration @ 5208 is 2.289238691329956\n",
      "Loss at Iteration @ 5209 is 2.1196517944335938\n",
      "Evaluation Loss at Iteration @ 5209 is 2.2667322158813477\n",
      "Loss at Iteration @ 5210 is 2.184575080871582\n",
      "Evaluation Loss at Iteration @ 5210 is 2.248420000076294\n",
      "Loss at Iteration @ 5211 is 1.983863353729248\n",
      "Evaluation Loss at Iteration @ 5211 is 2.237673282623291\n",
      "Loss at Iteration @ 5212 is 2.3837661743164062\n",
      "Evaluation Loss at Iteration @ 5212 is 2.235618829727173\n",
      "Loss at Iteration @ 5213 is 2.1608242988586426\n",
      "Evaluation Loss at Iteration @ 5213 is 2.2676196098327637\n",
      "Loss at Iteration @ 5214 is 2.0376060009002686\n",
      "Evaluation Loss at Iteration @ 5214 is 2.264878988265991\n",
      "Loss at Iteration @ 5215 is 2.1760270595550537\n",
      "Evaluation Loss at Iteration @ 5215 is 2.2425639629364014\n",
      "Loss at Iteration @ 5216 is 2.034494161605835\n",
      "Evaluation Loss at Iteration @ 5216 is 2.281236410140991\n",
      "Loss at Iteration @ 5217 is 2.064861297607422\n",
      "Evaluation Loss at Iteration @ 5217 is 2.21258807182312\n",
      "Loss at Iteration @ 5218 is 2.035306453704834\n",
      "Evaluation Loss at Iteration @ 5218 is 2.213465452194214\n",
      "Loss at Iteration @ 5219 is 2.4059550762176514\n",
      "Evaluation Loss at Iteration @ 5219 is 2.207139253616333\n",
      "Loss at Iteration @ 5220 is 2.6099636554718018\n",
      "Evaluation Loss at Iteration @ 5220 is 2.278020143508911\n",
      "Loss at Iteration @ 5221 is 2.290424346923828\n",
      "Evaluation Loss at Iteration @ 5221 is 2.2153940200805664\n",
      "Loss at Iteration @ 5222 is 2.4429867267608643\n",
      "Evaluation Loss at Iteration @ 5222 is 2.2299997806549072\n",
      "Loss at Iteration @ 5223 is 2.197171449661255\n",
      "Evaluation Loss at Iteration @ 5223 is 2.220782995223999\n",
      "Loss at Iteration @ 5224 is 2.293121337890625\n",
      "Evaluation Loss at Iteration @ 5224 is 2.243255615234375\n",
      "Loss at Iteration @ 5225 is 2.3032543659210205\n",
      "Evaluation Loss at Iteration @ 5225 is 2.2531118392944336\n",
      "Loss at Iteration @ 5226 is 2.1707987785339355\n",
      "Evaluation Loss at Iteration @ 5226 is 2.307873010635376\n",
      "Loss at Iteration @ 5227 is 2.0211784839630127\n",
      "Evaluation Loss at Iteration @ 5227 is 2.2499423027038574\n",
      "Loss at Iteration @ 5228 is 2.0821690559387207\n",
      "Evaluation Loss at Iteration @ 5228 is 2.2270424365997314\n",
      "Loss at Iteration @ 5229 is 2.0917444229125977\n",
      "Evaluation Loss at Iteration @ 5229 is 2.2425293922424316\n",
      "Loss at Iteration @ 5230 is 2.603611469268799\n",
      "Evaluation Loss at Iteration @ 5230 is 2.2653679847717285\n",
      "Loss at Iteration @ 5231 is 2.3097989559173584\n",
      "Evaluation Loss at Iteration @ 5231 is 2.267486572265625\n",
      "Loss at Iteration @ 5232 is 1.971137523651123\n",
      "Evaluation Loss at Iteration @ 5232 is 2.2443418502807617\n",
      "Loss at Iteration @ 5233 is 2.4253482818603516\n",
      "Evaluation Loss at Iteration @ 5233 is 2.2255971431732178\n",
      "Loss at Iteration @ 5234 is 2.2028961181640625\n",
      "Evaluation Loss at Iteration @ 5234 is 2.266494035720825\n",
      "Loss at Iteration @ 5235 is 2.3639049530029297\n",
      "Evaluation Loss at Iteration @ 5235 is 2.2333991527557373\n",
      "Loss at Iteration @ 5236 is 2.37477445602417\n",
      "Evaluation Loss at Iteration @ 5236 is 2.251424789428711\n",
      "Loss at Iteration @ 5237 is 2.220247745513916\n",
      "Evaluation Loss at Iteration @ 5237 is 2.263939619064331\n",
      "Loss at Iteration @ 5238 is 2.352203607559204\n",
      "Evaluation Loss at Iteration @ 5238 is 2.272426128387451\n",
      "Loss at Iteration @ 5239 is 2.24745512008667\n",
      "Evaluation Loss at Iteration @ 5239 is 2.2074668407440186\n",
      "Loss at Iteration @ 5240 is 2.140005350112915\n",
      "Evaluation Loss at Iteration @ 5240 is 2.2362844944000244\n",
      "Loss at Iteration @ 5241 is 2.2194411754608154\n",
      "Evaluation Loss at Iteration @ 5241 is 2.2203094959259033\n",
      "Loss at Iteration @ 5242 is 2.2302188873291016\n",
      "Evaluation Loss at Iteration @ 5242 is 2.2792563438415527\n",
      "Loss at Iteration @ 5243 is 2.105738878250122\n",
      "Evaluation Loss at Iteration @ 5243 is 2.244386911392212\n",
      "Loss at Iteration @ 5244 is 2.165402412414551\n",
      "Evaluation Loss at Iteration @ 5244 is 2.2630646228790283\n",
      "Loss at Iteration @ 5245 is 2.5035834312438965\n",
      "Evaluation Loss at Iteration @ 5245 is 2.260283946990967\n",
      "Loss at Iteration @ 5246 is 2.184511184692383\n",
      "Evaluation Loss at Iteration @ 5246 is 2.258385419845581\n",
      "Loss at Iteration @ 5247 is 2.299635648727417\n",
      "Evaluation Loss at Iteration @ 5247 is 2.2728638648986816\n",
      "Loss at Iteration @ 5248 is 2.2987351417541504\n",
      "Evaluation Loss at Iteration @ 5248 is 2.224323034286499\n",
      "Loss at Iteration @ 5249 is 2.4146716594696045\n",
      "Evaluation Loss at Iteration @ 5249 is 2.2688968181610107\n",
      "Loss at Iteration @ 5250 is 2.0076160430908203\n",
      "Evaluation Loss at Iteration @ 5250 is 2.225637197494507\n",
      "Loss at Iteration @ 5251 is 2.3994805812835693\n",
      "Evaluation Loss at Iteration @ 5251 is 2.2387454509735107\n",
      "Loss at Iteration @ 5252 is 2.3654184341430664\n",
      "Evaluation Loss at Iteration @ 5252 is 2.2630672454833984\n",
      "Loss at Iteration @ 5253 is 2.306722402572632\n",
      "Evaluation Loss at Iteration @ 5253 is 2.2675058841705322\n",
      "Loss at Iteration @ 5254 is 1.9607230424880981\n",
      "Evaluation Loss at Iteration @ 5254 is 2.3205761909484863\n",
      "Loss at Iteration @ 5255 is 2.084591865539551\n",
      "Evaluation Loss at Iteration @ 5255 is 2.2000772953033447\n",
      "Loss at Iteration @ 5256 is 2.519615411758423\n",
      "Evaluation Loss at Iteration @ 5256 is 2.2265312671661377\n",
      "Loss at Iteration @ 5257 is 2.3259243965148926\n",
      "Evaluation Loss at Iteration @ 5257 is 2.2267744541168213\n",
      "Loss at Iteration @ 5258 is 2.2823355197906494\n",
      "Evaluation Loss at Iteration @ 5258 is 2.2735958099365234\n",
      "Loss at Iteration @ 5259 is 2.2914316654205322\n",
      "Evaluation Loss at Iteration @ 5259 is 2.251589298248291\n",
      "Loss at Iteration @ 5260 is 2.168219566345215\n",
      "Evaluation Loss at Iteration @ 5260 is 2.2684855461120605\n",
      "Loss at Iteration @ 5261 is 2.431678295135498\n",
      "Evaluation Loss at Iteration @ 5261 is 2.239314079284668\n",
      "Loss at Iteration @ 5262 is 2.2289648056030273\n",
      "Evaluation Loss at Iteration @ 5262 is 2.2651820182800293\n",
      "Loss at Iteration @ 5263 is 2.4954426288604736\n",
      "Evaluation Loss at Iteration @ 5263 is 2.221792697906494\n",
      "Loss at Iteration @ 5264 is 2.020050525665283\n",
      "Evaluation Loss at Iteration @ 5264 is 2.2287845611572266\n",
      "Loss at Iteration @ 5265 is 2.185565948486328\n",
      "Evaluation Loss at Iteration @ 5265 is 2.241231918334961\n",
      "Loss at Iteration @ 5266 is 2.2621638774871826\n",
      "Evaluation Loss at Iteration @ 5266 is 2.2061915397644043\n",
      "Loss at Iteration @ 5267 is 2.2322590351104736\n",
      "Evaluation Loss at Iteration @ 5267 is 2.2315783500671387\n",
      "Loss at Iteration @ 5268 is 2.219026803970337\n",
      "Evaluation Loss at Iteration @ 5268 is 2.2796881198883057\n",
      "Loss at Iteration @ 5269 is 1.9686861038208008\n",
      "Evaluation Loss at Iteration @ 5269 is 2.2161285877227783\n",
      "Loss at Iteration @ 5270 is 2.321213483810425\n",
      "Evaluation Loss at Iteration @ 5270 is 2.242783308029175\n",
      "Loss at Iteration @ 5271 is 2.398214817047119\n",
      "Evaluation Loss at Iteration @ 5271 is 2.270419120788574\n",
      "Loss at Iteration @ 5272 is 1.8952815532684326\n",
      "Evaluation Loss at Iteration @ 5272 is 2.268122673034668\n",
      "Loss at Iteration @ 5273 is 2.329979419708252\n",
      "Evaluation Loss at Iteration @ 5273 is 2.245398998260498\n",
      "Loss at Iteration @ 5274 is 2.3950374126434326\n",
      "Evaluation Loss at Iteration @ 5274 is 2.274397611618042\n",
      "Loss at Iteration @ 5275 is 2.2948787212371826\n",
      "Evaluation Loss at Iteration @ 5275 is 2.2588536739349365\n",
      "Loss at Iteration @ 5276 is 2.250728130340576\n",
      "Evaluation Loss at Iteration @ 5276 is 2.239647388458252\n",
      "Loss at Iteration @ 5277 is 2.2730937004089355\n",
      "Evaluation Loss at Iteration @ 5277 is 2.2473793029785156\n",
      "Loss at Iteration @ 5278 is 2.1403703689575195\n",
      "Evaluation Loss at Iteration @ 5278 is 2.294052839279175\n",
      "Loss at Iteration @ 5279 is 2.0415470600128174\n",
      "Evaluation Loss at Iteration @ 5279 is 2.236482620239258\n",
      "Loss at Iteration @ 5280 is 2.5362374782562256\n",
      "Evaluation Loss at Iteration @ 5280 is 2.2225022315979004\n",
      "Loss at Iteration @ 5281 is 2.322054147720337\n",
      "Evaluation Loss at Iteration @ 5281 is 2.2745425701141357\n",
      "Loss at Iteration @ 5282 is 2.3420956134796143\n",
      "Evaluation Loss at Iteration @ 5282 is 2.286355972290039\n",
      "Loss at Iteration @ 5283 is 2.0211267471313477\n",
      "Evaluation Loss at Iteration @ 5283 is 2.230727434158325\n",
      "Loss at Iteration @ 5284 is 2.297475814819336\n",
      "Evaluation Loss at Iteration @ 5284 is 2.270372152328491\n",
      "Loss at Iteration @ 5285 is 2.1088109016418457\n",
      "Evaluation Loss at Iteration @ 5285 is 2.280973196029663\n",
      "Loss at Iteration @ 5286 is 2.0925562381744385\n",
      "Evaluation Loss at Iteration @ 5286 is 2.2570960521698\n",
      "Loss at Iteration @ 5287 is 2.0876402854919434\n",
      "Evaluation Loss at Iteration @ 5287 is 2.224125862121582\n",
      "Loss at Iteration @ 5288 is 2.2656915187835693\n",
      "Evaluation Loss at Iteration @ 5288 is 2.247814893722534\n",
      "Loss at Iteration @ 5289 is 2.3067004680633545\n",
      "Evaluation Loss at Iteration @ 5289 is 2.2347617149353027\n",
      "Loss at Iteration @ 5290 is 2.3084352016448975\n",
      "Evaluation Loss at Iteration @ 5290 is 2.2539634704589844\n",
      "Loss at Iteration @ 5291 is 2.360628843307495\n",
      "Evaluation Loss at Iteration @ 5291 is 2.2978029251098633\n",
      "Loss at Iteration @ 5292 is 2.1775755882263184\n",
      "Evaluation Loss at Iteration @ 5292 is 2.279176950454712\n",
      "Loss at Iteration @ 5293 is 2.178178548812866\n",
      "Evaluation Loss at Iteration @ 5293 is 2.2411797046661377\n",
      "Loss at Iteration @ 5294 is 2.217158317565918\n",
      "Evaluation Loss at Iteration @ 5294 is 2.296410083770752\n",
      "Loss at Iteration @ 5295 is 2.0589799880981445\n",
      "Evaluation Loss at Iteration @ 5295 is 2.225292682647705\n",
      "Loss at Iteration @ 5296 is 2.4515442848205566\n",
      "Evaluation Loss at Iteration @ 5296 is 2.260467290878296\n",
      "Loss at Iteration @ 5297 is 2.254199981689453\n",
      "Evaluation Loss at Iteration @ 5297 is 2.269808292388916\n",
      "Loss at Iteration @ 5298 is 2.294584274291992\n",
      "Evaluation Loss at Iteration @ 5298 is 2.251225471496582\n",
      "Loss at Iteration @ 5299 is 2.1160693168640137\n",
      "Evaluation Loss at Iteration @ 5299 is 2.2303829193115234\n",
      "Loss at Iteration @ 5300 is 2.3069324493408203\n",
      "Evaluation Loss at Iteration @ 5300 is 2.267404079437256\n",
      "Loss at Iteration @ 5301 is 2.443074941635132\n",
      "Evaluation Loss at Iteration @ 5301 is 2.2349066734313965\n",
      "Loss at Iteration @ 5302 is 2.003488063812256\n",
      "Evaluation Loss at Iteration @ 5302 is 2.2357804775238037\n",
      "Loss at Iteration @ 5303 is 2.3411824703216553\n",
      "Evaluation Loss at Iteration @ 5303 is 2.2518389225006104\n",
      "Loss at Iteration @ 5304 is 2.3738930225372314\n",
      "Evaluation Loss at Iteration @ 5304 is 2.218959093093872\n",
      "Loss at Iteration @ 5305 is 2.3837645053863525\n",
      "Evaluation Loss at Iteration @ 5305 is 2.2615809440612793\n",
      "Loss at Iteration @ 5306 is 2.285409450531006\n",
      "Evaluation Loss at Iteration @ 5306 is 2.2547481060028076\n",
      "Loss at Iteration @ 5307 is 2.416327476501465\n",
      "Evaluation Loss at Iteration @ 5307 is 2.2605268955230713\n",
      "Loss at Iteration @ 5308 is 2.1533753871917725\n",
      "Evaluation Loss at Iteration @ 5308 is 2.2577459812164307\n",
      "Loss at Iteration @ 5309 is 2.2957286834716797\n",
      "Evaluation Loss at Iteration @ 5309 is 2.274409294128418\n",
      "Loss at Iteration @ 5310 is 2.17445707321167\n",
      "Evaluation Loss at Iteration @ 5310 is 2.2146687507629395\n",
      "Loss at Iteration @ 5311 is 2.2286102771759033\n",
      "Evaluation Loss at Iteration @ 5311 is 2.2295708656311035\n",
      "Loss at Iteration @ 5312 is 2.021357297897339\n",
      "Evaluation Loss at Iteration @ 5312 is 2.2773048877716064\n",
      "Loss at Iteration @ 5313 is 2.045262575149536\n",
      "Evaluation Loss at Iteration @ 5313 is 2.2451202869415283\n",
      "Loss at Iteration @ 5314 is 2.0516977310180664\n",
      "Evaluation Loss at Iteration @ 5314 is 2.2798500061035156\n",
      "Loss at Iteration @ 5315 is 2.5198893547058105\n",
      "Evaluation Loss at Iteration @ 5315 is 2.2537779808044434\n",
      "Loss at Iteration @ 5316 is 2.1087470054626465\n",
      "Evaluation Loss at Iteration @ 5316 is 2.2651140689849854\n",
      "Loss at Iteration @ 5317 is 2.0593156814575195\n",
      "Evaluation Loss at Iteration @ 5317 is 2.287309169769287\n",
      "Loss at Iteration @ 5318 is 2.3252806663513184\n",
      "Evaluation Loss at Iteration @ 5318 is 2.238046407699585\n",
      "Loss at Iteration @ 5319 is 2.4267308712005615\n",
      "Evaluation Loss at Iteration @ 5319 is 2.2498092651367188\n",
      "Loss at Iteration @ 5320 is 2.275749444961548\n",
      "Evaluation Loss at Iteration @ 5320 is 2.248206615447998\n",
      "Loss at Iteration @ 5321 is 2.122511148452759\n",
      "Evaluation Loss at Iteration @ 5321 is 2.269625663757324\n",
      "Loss at Iteration @ 5322 is 2.2776589393615723\n",
      "Evaluation Loss at Iteration @ 5322 is 2.2349696159362793\n",
      "Loss at Iteration @ 5323 is 2.3210911750793457\n",
      "Evaluation Loss at Iteration @ 5323 is 2.2294199466705322\n",
      "Loss at Iteration @ 5324 is 2.135777711868286\n",
      "Evaluation Loss at Iteration @ 5324 is 2.2886478900909424\n",
      "Loss at Iteration @ 5325 is 2.0279040336608887\n",
      "Evaluation Loss at Iteration @ 5325 is 2.2571280002593994\n",
      "Loss at Iteration @ 5326 is 2.3594632148742676\n",
      "Evaluation Loss at Iteration @ 5326 is 2.27939510345459\n",
      "Loss at Iteration @ 5327 is 2.2268927097320557\n",
      "Evaluation Loss at Iteration @ 5327 is 2.2298247814178467\n",
      "Loss at Iteration @ 5328 is 2.3352620601654053\n",
      "Evaluation Loss at Iteration @ 5328 is 2.246079444885254\n",
      "Loss at Iteration @ 5329 is 2.1488559246063232\n",
      "Evaluation Loss at Iteration @ 5329 is 2.2815463542938232\n",
      "Loss at Iteration @ 5330 is 2.2431702613830566\n",
      "Evaluation Loss at Iteration @ 5330 is 2.290283441543579\n",
      "Loss at Iteration @ 5331 is 2.2433857917785645\n",
      "Evaluation Loss at Iteration @ 5331 is 2.2251970767974854\n",
      "Loss at Iteration @ 5332 is 2.2734696865081787\n",
      "Evaluation Loss at Iteration @ 5332 is 2.244344711303711\n",
      "Loss at Iteration @ 5333 is 2.4126176834106445\n",
      "Evaluation Loss at Iteration @ 5333 is 2.2074005603790283\n",
      "Loss at Iteration @ 5334 is 2.0865368843078613\n",
      "Evaluation Loss at Iteration @ 5334 is 2.2450461387634277\n",
      "Loss at Iteration @ 5335 is 2.4390504360198975\n",
      "Evaluation Loss at Iteration @ 5335 is 2.266827344894409\n",
      "Loss at Iteration @ 5336 is 2.124098539352417\n",
      "Evaluation Loss at Iteration @ 5336 is 2.2514760494232178\n",
      "Loss at Iteration @ 5337 is 2.113657236099243\n",
      "Evaluation Loss at Iteration @ 5337 is 2.2822678089141846\n",
      "Loss at Iteration @ 5338 is 2.079906463623047\n",
      "Evaluation Loss at Iteration @ 5338 is 2.258376359939575\n",
      "Loss at Iteration @ 5339 is 2.520120143890381\n",
      "Evaluation Loss at Iteration @ 5339 is 2.2872679233551025\n",
      "Loss at Iteration @ 5340 is 2.0882439613342285\n",
      "Evaluation Loss at Iteration @ 5340 is 2.246795177459717\n",
      "Loss at Iteration @ 5341 is 2.2938437461853027\n",
      "Evaluation Loss at Iteration @ 5341 is 2.26235032081604\n",
      "Loss at Iteration @ 5342 is 2.497098445892334\n",
      "Evaluation Loss at Iteration @ 5342 is 2.236079454421997\n",
      "Loss at Iteration @ 5343 is 2.3890297412872314\n",
      "Evaluation Loss at Iteration @ 5343 is 2.245645046234131\n",
      "Loss at Iteration @ 5344 is 2.2994163036346436\n",
      "Evaluation Loss at Iteration @ 5344 is 2.2578964233398438\n",
      "Loss at Iteration @ 5345 is 2.160566568374634\n",
      "Evaluation Loss at Iteration @ 5345 is 2.2358601093292236\n",
      "Loss at Iteration @ 5346 is 2.1838974952697754\n",
      "Evaluation Loss at Iteration @ 5346 is 2.2792446613311768\n",
      "Loss at Iteration @ 5347 is 2.173118829727173\n",
      "Evaluation Loss at Iteration @ 5347 is 2.269205093383789\n",
      "Loss at Iteration @ 5348 is 2.1682040691375732\n",
      "Evaluation Loss at Iteration @ 5348 is 2.233116865158081\n",
      "Loss at Iteration @ 5349 is 2.23038387298584\n",
      "Evaluation Loss at Iteration @ 5349 is 2.256455183029175\n",
      "Loss at Iteration @ 5350 is 2.3757615089416504\n",
      "Evaluation Loss at Iteration @ 5350 is 2.2850027084350586\n",
      "Loss at Iteration @ 5351 is 2.339876651763916\n",
      "Evaluation Loss at Iteration @ 5351 is 2.2443783283233643\n",
      "Loss at Iteration @ 5352 is 2.1376898288726807\n",
      "Evaluation Loss at Iteration @ 5352 is 2.252950668334961\n",
      "Loss at Iteration @ 5353 is 2.0923681259155273\n",
      "Evaluation Loss at Iteration @ 5353 is 2.269570827484131\n",
      "Loss at Iteration @ 5354 is 2.2388246059417725\n",
      "Evaluation Loss at Iteration @ 5354 is 2.252462387084961\n",
      "Loss at Iteration @ 5355 is 2.084796190261841\n",
      "Evaluation Loss at Iteration @ 5355 is 2.2976691722869873\n",
      "Loss at Iteration @ 5356 is 2.2490358352661133\n",
      "Evaluation Loss at Iteration @ 5356 is 2.2491912841796875\n",
      "Loss at Iteration @ 5357 is 2.0896847248077393\n",
      "Evaluation Loss at Iteration @ 5357 is 2.20686936378479\n",
      "Loss at Iteration @ 5358 is 1.8540587425231934\n",
      "Evaluation Loss at Iteration @ 5358 is 2.247441530227661\n",
      "Loss at Iteration @ 5359 is 2.291699171066284\n",
      "Evaluation Loss at Iteration @ 5359 is 2.29009747505188\n",
      "Loss at Iteration @ 5360 is 2.312417507171631\n",
      "Evaluation Loss at Iteration @ 5360 is 2.2703475952148438\n",
      "Loss at Iteration @ 5361 is 2.3532934188842773\n",
      "Evaluation Loss at Iteration @ 5361 is 2.2476799488067627\n",
      "Loss at Iteration @ 5362 is 2.315958023071289\n",
      "Evaluation Loss at Iteration @ 5362 is 2.309006452560425\n",
      "Loss at Iteration @ 5363 is 2.1396658420562744\n",
      "Evaluation Loss at Iteration @ 5363 is 2.2579092979431152\n",
      "Loss at Iteration @ 5364 is 2.4324698448181152\n",
      "Evaluation Loss at Iteration @ 5364 is 2.2286465167999268\n",
      "Loss at Iteration @ 5365 is 2.165741443634033\n",
      "Evaluation Loss at Iteration @ 5365 is 2.226393938064575\n",
      "Loss at Iteration @ 5366 is 2.4410080909729004\n",
      "Evaluation Loss at Iteration @ 5366 is 2.233029842376709\n",
      "Loss at Iteration @ 5367 is 2.3160932064056396\n",
      "Evaluation Loss at Iteration @ 5367 is 2.248610019683838\n",
      "Loss at Iteration @ 5368 is 2.2199690341949463\n",
      "Evaluation Loss at Iteration @ 5368 is 2.2499678134918213\n",
      "Loss at Iteration @ 5369 is 2.22930645942688\n",
      "Evaluation Loss at Iteration @ 5369 is 2.2358057498931885\n",
      "Loss at Iteration @ 5370 is 2.2929258346557617\n",
      "Evaluation Loss at Iteration @ 5370 is 2.2437856197357178\n",
      "Loss at Iteration @ 5371 is 2.2812259197235107\n",
      "Evaluation Loss at Iteration @ 5371 is 2.2176897525787354\n",
      "Loss at Iteration @ 5372 is 2.0498836040496826\n",
      "Evaluation Loss at Iteration @ 5372 is 2.251035690307617\n",
      "Loss at Iteration @ 5373 is 2.148468255996704\n",
      "Evaluation Loss at Iteration @ 5373 is 2.244685173034668\n",
      "Loss at Iteration @ 5374 is 2.2623047828674316\n",
      "Evaluation Loss at Iteration @ 5374 is 2.2563979625701904\n",
      "Loss at Iteration @ 5375 is 2.2678425312042236\n",
      "Evaluation Loss at Iteration @ 5375 is 2.2971384525299072\n",
      "Loss at Iteration @ 5376 is 2.3409156799316406\n",
      "Evaluation Loss at Iteration @ 5376 is 2.242375373840332\n",
      "Loss at Iteration @ 5377 is 2.2793009281158447\n",
      "Evaluation Loss at Iteration @ 5377 is 2.2423062324523926\n",
      "Loss at Iteration @ 5378 is 2.364478588104248\n",
      "Evaluation Loss at Iteration @ 5378 is 2.2661757469177246\n",
      "Loss at Iteration @ 5379 is 2.0378358364105225\n",
      "Evaluation Loss at Iteration @ 5379 is 2.2873618602752686\n",
      "Loss at Iteration @ 5380 is 2.2200570106506348\n",
      "Evaluation Loss at Iteration @ 5380 is 2.2186038494110107\n",
      "Loss at Iteration @ 5381 is 2.4420652389526367\n",
      "Evaluation Loss at Iteration @ 5381 is 2.268218517303467\n",
      "Loss at Iteration @ 5382 is 2.537418842315674\n",
      "Evaluation Loss at Iteration @ 5382 is 2.236868143081665\n",
      "Loss at Iteration @ 5383 is 2.2359209060668945\n",
      "Evaluation Loss at Iteration @ 5383 is 2.228794574737549\n",
      "Loss at Iteration @ 5384 is 2.2859673500061035\n",
      "Evaluation Loss at Iteration @ 5384 is 2.2694742679595947\n",
      "Loss at Iteration @ 5385 is 1.9587332010269165\n",
      "Evaluation Loss at Iteration @ 5385 is 2.2429473400115967\n",
      "Loss at Iteration @ 5386 is 2.1207540035247803\n",
      "Evaluation Loss at Iteration @ 5386 is 2.2929775714874268\n",
      "Loss at Iteration @ 5387 is 2.0522801876068115\n",
      "Evaluation Loss at Iteration @ 5387 is 2.2890422344207764\n",
      "Loss at Iteration @ 5388 is 2.085675001144409\n",
      "Evaluation Loss at Iteration @ 5388 is 2.1834068298339844\n",
      "Loss at Iteration @ 5389 is 2.3193490505218506\n",
      "Evaluation Loss at Iteration @ 5389 is 2.216341018676758\n",
      "Loss at Iteration @ 5390 is 2.1222121715545654\n",
      "Evaluation Loss at Iteration @ 5390 is 2.1940927505493164\n",
      "Loss at Iteration @ 5391 is 2.030468702316284\n",
      "Evaluation Loss at Iteration @ 5391 is 2.214952230453491\n",
      "Loss at Iteration @ 5392 is 2.1756412982940674\n",
      "Evaluation Loss at Iteration @ 5392 is 2.2376391887664795\n",
      "Loss at Iteration @ 5393 is 2.1519882678985596\n",
      "Evaluation Loss at Iteration @ 5393 is 2.22407865524292\n",
      "Loss at Iteration @ 5394 is 2.328057289123535\n",
      "Evaluation Loss at Iteration @ 5394 is 2.2831544876098633\n",
      "Loss at Iteration @ 5395 is 2.135018825531006\n",
      "Evaluation Loss at Iteration @ 5395 is 2.262474298477173\n",
      "Loss at Iteration @ 5396 is 2.038332462310791\n",
      "Evaluation Loss at Iteration @ 5396 is 2.2565202713012695\n",
      "Loss at Iteration @ 5397 is 2.0031697750091553\n",
      "Evaluation Loss at Iteration @ 5397 is 2.314692735671997\n",
      "Loss at Iteration @ 5398 is 2.426604986190796\n",
      "Evaluation Loss at Iteration @ 5398 is 2.2479867935180664\n",
      "Loss at Iteration @ 5399 is 2.134814739227295\n",
      "Evaluation Loss at Iteration @ 5399 is 2.232912063598633\n",
      "Loss at Iteration @ 5400 is 2.21591854095459\n",
      "Evaluation Loss at Iteration @ 5400 is 2.2709760665893555\n",
      "Loss at Iteration @ 5401 is 2.1696512699127197\n",
      "Evaluation Loss at Iteration @ 5401 is 2.2193005084991455\n",
      "Loss at Iteration @ 5402 is 2.3864939212799072\n",
      "Evaluation Loss at Iteration @ 5402 is 2.267744779586792\n",
      "Loss at Iteration @ 5403 is 2.0969810485839844\n",
      "Evaluation Loss at Iteration @ 5403 is 2.252185583114624\n",
      "Loss at Iteration @ 5404 is 2.6123197078704834\n",
      "Evaluation Loss at Iteration @ 5404 is 2.277350902557373\n",
      "Loss at Iteration @ 5405 is 2.734835624694824\n",
      "Evaluation Loss at Iteration @ 5405 is 2.2066075801849365\n",
      "Loss at Iteration @ 5406 is 2.250157356262207\n",
      "Evaluation Loss at Iteration @ 5406 is 2.2862884998321533\n",
      "Loss at Iteration @ 5407 is 2.3666670322418213\n",
      "Evaluation Loss at Iteration @ 5407 is 2.296201705932617\n",
      "Loss at Iteration @ 5408 is 2.2708044052124023\n",
      "Evaluation Loss at Iteration @ 5408 is 2.250242233276367\n",
      "Loss at Iteration @ 5409 is 2.080740451812744\n",
      "Evaluation Loss at Iteration @ 5409 is 2.227559804916382\n",
      "Loss at Iteration @ 5410 is 2.3385205268859863\n",
      "Evaluation Loss at Iteration @ 5410 is 2.2682313919067383\n",
      "Loss at Iteration @ 5411 is 2.2679543495178223\n",
      "Evaluation Loss at Iteration @ 5411 is 2.2585060596466064\n",
      "Loss at Iteration @ 5412 is 2.167847156524658\n",
      "Evaluation Loss at Iteration @ 5412 is 2.241053819656372\n",
      "Loss at Iteration @ 5413 is 2.1705894470214844\n",
      "Evaluation Loss at Iteration @ 5413 is 2.2201082706451416\n",
      "Loss at Iteration @ 5414 is 2.2018964290618896\n",
      "Evaluation Loss at Iteration @ 5414 is 2.2446162700653076\n",
      "Loss at Iteration @ 5415 is 2.3956046104431152\n",
      "Evaluation Loss at Iteration @ 5415 is 2.2484676837921143\n",
      "Loss at Iteration @ 5416 is 2.169440746307373\n",
      "Evaluation Loss at Iteration @ 5416 is 2.2577755451202393\n",
      "Loss at Iteration @ 5417 is 2.0973262786865234\n",
      "Evaluation Loss at Iteration @ 5417 is 2.2749435901641846\n",
      "Loss at Iteration @ 5418 is 1.9514583349227905\n",
      "Evaluation Loss at Iteration @ 5418 is 2.237975597381592\n",
      "Loss at Iteration @ 5419 is 2.272752285003662\n",
      "Evaluation Loss at Iteration @ 5419 is 2.2318484783172607\n",
      "Loss at Iteration @ 5420 is 2.3308417797088623\n",
      "Evaluation Loss at Iteration @ 5420 is 2.2384192943573\n",
      "Loss at Iteration @ 5421 is 2.2702414989471436\n",
      "Evaluation Loss at Iteration @ 5421 is 2.296109199523926\n",
      "Loss at Iteration @ 5422 is 2.2870371341705322\n",
      "Evaluation Loss at Iteration @ 5422 is 2.270810842514038\n",
      "Loss at Iteration @ 5423 is 2.3087010383605957\n",
      "Evaluation Loss at Iteration @ 5423 is 2.271117925643921\n",
      "Loss at Iteration @ 5424 is 2.298050880432129\n",
      "Evaluation Loss at Iteration @ 5424 is 2.227572202682495\n",
      "Loss at Iteration @ 5425 is 2.307905912399292\n",
      "Evaluation Loss at Iteration @ 5425 is 2.3074536323547363\n",
      "Loss at Iteration @ 5426 is 2.1541781425476074\n",
      "Evaluation Loss at Iteration @ 5426 is 2.2342519760131836\n",
      "Loss at Iteration @ 5427 is 2.251443862915039\n",
      "Evaluation Loss at Iteration @ 5427 is 2.1929590702056885\n",
      "Loss at Iteration @ 5428 is 2.4925689697265625\n",
      "Evaluation Loss at Iteration @ 5428 is 2.273725986480713\n",
      "Loss at Iteration @ 5429 is 1.9566693305969238\n",
      "Evaluation Loss at Iteration @ 5429 is 2.245077133178711\n",
      "Loss at Iteration @ 5430 is 2.212339162826538\n",
      "Evaluation Loss at Iteration @ 5430 is 2.239049196243286\n",
      "Loss at Iteration @ 5431 is 2.1407270431518555\n",
      "Evaluation Loss at Iteration @ 5431 is 2.2460007667541504\n",
      "Loss at Iteration @ 5432 is 2.2566890716552734\n",
      "Evaluation Loss at Iteration @ 5432 is 2.226382255554199\n",
      "Loss at Iteration @ 5433 is 2.268022298812866\n",
      "Evaluation Loss at Iteration @ 5433 is 2.2581658363342285\n",
      "Loss at Iteration @ 5434 is 2.240103006362915\n",
      "Evaluation Loss at Iteration @ 5434 is 2.253774642944336\n",
      "Loss at Iteration @ 5435 is 2.3603262901306152\n",
      "Evaluation Loss at Iteration @ 5435 is 2.271735906600952\n",
      "Loss at Iteration @ 5436 is 2.1907734870910645\n",
      "Evaluation Loss at Iteration @ 5436 is 2.308323860168457\n",
      "Loss at Iteration @ 5437 is 2.0543413162231445\n",
      "Evaluation Loss at Iteration @ 5437 is 2.2762749195098877\n",
      "Loss at Iteration @ 5438 is 2.6411824226379395\n",
      "Evaluation Loss at Iteration @ 5438 is 2.2921597957611084\n",
      "Loss at Iteration @ 5439 is 2.2126080989837646\n",
      "Evaluation Loss at Iteration @ 5439 is 2.2987143993377686\n",
      "Loss at Iteration @ 5440 is 2.1317498683929443\n",
      "Evaluation Loss at Iteration @ 5440 is 2.2763772010803223\n",
      "Loss at Iteration @ 5441 is 2.144148588180542\n",
      "Evaluation Loss at Iteration @ 5441 is 2.232609510421753\n",
      "Loss at Iteration @ 5442 is 2.3419816493988037\n",
      "Evaluation Loss at Iteration @ 5442 is 2.242837905883789\n",
      "Loss at Iteration @ 5443 is 2.350529909133911\n",
      "Evaluation Loss at Iteration @ 5443 is 2.2660908699035645\n",
      "Loss at Iteration @ 5444 is 2.104597330093384\n",
      "Evaluation Loss at Iteration @ 5444 is 2.2311031818389893\n",
      "Loss at Iteration @ 5445 is 1.9711939096450806\n",
      "Evaluation Loss at Iteration @ 5445 is 2.283689022064209\n",
      "Loss at Iteration @ 5446 is 2.3094136714935303\n",
      "Evaluation Loss at Iteration @ 5446 is 2.2547998428344727\n",
      "Loss at Iteration @ 5447 is 2.109365224838257\n",
      "Evaluation Loss at Iteration @ 5447 is 2.291274309158325\n",
      "Loss at Iteration @ 5448 is 2.3882336616516113\n",
      "Evaluation Loss at Iteration @ 5448 is 2.258274555206299\n",
      "Loss at Iteration @ 5449 is 2.2249293327331543\n",
      "Evaluation Loss at Iteration @ 5449 is 2.2523815631866455\n",
      "Loss at Iteration @ 5450 is 1.9526026248931885\n",
      "Evaluation Loss at Iteration @ 5450 is 2.2427854537963867\n",
      "Loss at Iteration @ 5451 is 2.1040573120117188\n",
      "Evaluation Loss at Iteration @ 5451 is 2.2631473541259766\n",
      "Loss at Iteration @ 5452 is 2.405780076980591\n",
      "Evaluation Loss at Iteration @ 5452 is 2.22799015045166\n",
      "Loss at Iteration @ 5453 is 2.488654851913452\n",
      "Evaluation Loss at Iteration @ 5453 is 2.2342967987060547\n",
      "Loss at Iteration @ 5454 is 2.032057523727417\n",
      "Evaluation Loss at Iteration @ 5454 is 2.217123031616211\n",
      "Loss at Iteration @ 5455 is 1.9704229831695557\n",
      "Evaluation Loss at Iteration @ 5455 is 2.2276182174682617\n",
      "Loss at Iteration @ 5456 is 2.1996378898620605\n",
      "Evaluation Loss at Iteration @ 5456 is 2.2278642654418945\n",
      "Loss at Iteration @ 5457 is 2.2188525199890137\n",
      "Evaluation Loss at Iteration @ 5457 is 2.206233501434326\n",
      "Loss at Iteration @ 5458 is 2.2097787857055664\n",
      "Evaluation Loss at Iteration @ 5458 is 2.1995294094085693\n",
      "Loss at Iteration @ 5459 is 2.312155246734619\n",
      "Evaluation Loss at Iteration @ 5459 is 2.1959781646728516\n",
      "Loss at Iteration @ 5460 is 2.066873550415039\n",
      "Evaluation Loss at Iteration @ 5460 is 2.265604019165039\n",
      "Loss at Iteration @ 5461 is 2.212646961212158\n",
      "Evaluation Loss at Iteration @ 5461 is 2.2703654766082764\n",
      "Loss at Iteration @ 5462 is 2.425244092941284\n",
      "Evaluation Loss at Iteration @ 5462 is 2.2725112438201904\n",
      "Loss at Iteration @ 5463 is 1.9134299755096436\n",
      "Evaluation Loss at Iteration @ 5463 is 2.258659839630127\n",
      "Loss at Iteration @ 5464 is 2.1306681632995605\n",
      "Evaluation Loss at Iteration @ 5464 is 2.250800132751465\n",
      "Loss at Iteration @ 5465 is 2.7086479663848877\n",
      "Evaluation Loss at Iteration @ 5465 is 2.2644197940826416\n",
      "Loss at Iteration @ 5466 is 2.1879477500915527\n",
      "Evaluation Loss at Iteration @ 5466 is 2.2612054347991943\n",
      "Loss at Iteration @ 5467 is 2.3826510906219482\n",
      "Evaluation Loss at Iteration @ 5467 is 2.2305667400360107\n",
      "Loss at Iteration @ 5468 is 2.2591054439544678\n",
      "Evaluation Loss at Iteration @ 5468 is 2.261946439743042\n",
      "Loss at Iteration @ 5469 is 2.0565683841705322\n",
      "Evaluation Loss at Iteration @ 5469 is 2.232267379760742\n",
      "Loss at Iteration @ 5470 is 2.4272003173828125\n",
      "Evaluation Loss at Iteration @ 5470 is 2.2195091247558594\n",
      "Loss at Iteration @ 5471 is 2.3559839725494385\n",
      "Evaluation Loss at Iteration @ 5471 is 2.240349292755127\n",
      "Loss at Iteration @ 5472 is 2.2708444595336914\n",
      "Evaluation Loss at Iteration @ 5472 is 2.2645938396453857\n",
      "Loss at Iteration @ 5473 is 2.2810909748077393\n",
      "Evaluation Loss at Iteration @ 5473 is 2.2674520015716553\n",
      "Loss at Iteration @ 5474 is 2.477701425552368\n",
      "Evaluation Loss at Iteration @ 5474 is 2.261474847793579\n",
      "Loss at Iteration @ 5475 is 2.0137152671813965\n",
      "Evaluation Loss at Iteration @ 5475 is 2.2539165019989014\n",
      "Loss at Iteration @ 5476 is 2.199483633041382\n",
      "Evaluation Loss at Iteration @ 5476 is 2.2747561931610107\n",
      "Loss at Iteration @ 5477 is 2.04884934425354\n",
      "Evaluation Loss at Iteration @ 5477 is 2.2320706844329834\n",
      "Loss at Iteration @ 5478 is 2.1592917442321777\n",
      "Evaluation Loss at Iteration @ 5478 is 2.244997978210449\n",
      "Loss at Iteration @ 5479 is 2.5958447456359863\n",
      "Evaluation Loss at Iteration @ 5479 is 2.223639488220215\n",
      "Loss at Iteration @ 5480 is 2.1576855182647705\n",
      "Evaluation Loss at Iteration @ 5480 is 2.2401657104492188\n",
      "Loss at Iteration @ 5481 is 2.0962870121002197\n",
      "Evaluation Loss at Iteration @ 5481 is 2.264423131942749\n",
      "Loss at Iteration @ 5482 is 2.2639143466949463\n",
      "Evaluation Loss at Iteration @ 5482 is 2.2528913021087646\n",
      "Loss at Iteration @ 5483 is 2.237070322036743\n",
      "Evaluation Loss at Iteration @ 5483 is 2.2719497680664062\n",
      "Loss at Iteration @ 5484 is 2.157912254333496\n",
      "Evaluation Loss at Iteration @ 5484 is 2.2332112789154053\n",
      "Loss at Iteration @ 5485 is 2.455143690109253\n",
      "Evaluation Loss at Iteration @ 5485 is 2.1995327472686768\n",
      "Loss at Iteration @ 5486 is 2.1889913082122803\n",
      "Evaluation Loss at Iteration @ 5486 is 2.2434442043304443\n",
      "Loss at Iteration @ 5487 is 2.393138885498047\n",
      "Evaluation Loss at Iteration @ 5487 is 2.2761659622192383\n",
      "Loss at Iteration @ 5488 is 2.30342173576355\n",
      "Evaluation Loss at Iteration @ 5488 is 2.2219038009643555\n",
      "Loss at Iteration @ 5489 is 2.1738319396972656\n",
      "Evaluation Loss at Iteration @ 5489 is 2.2482900619506836\n",
      "Loss at Iteration @ 5490 is 2.407602310180664\n",
      "Evaluation Loss at Iteration @ 5490 is 2.266469717025757\n",
      "Loss at Iteration @ 5491 is 2.2116501331329346\n",
      "Evaluation Loss at Iteration @ 5491 is 2.2247986793518066\n",
      "Loss at Iteration @ 5492 is 2.2831783294677734\n",
      "Evaluation Loss at Iteration @ 5492 is 2.2417242527008057\n",
      "Loss at Iteration @ 5493 is 2.215898036956787\n",
      "Evaluation Loss at Iteration @ 5493 is 2.257678747177124\n",
      "Loss at Iteration @ 5494 is 2.3570661544799805\n",
      "Evaluation Loss at Iteration @ 5494 is 2.2153358459472656\n",
      "Loss at Iteration @ 5495 is 2.1359052658081055\n",
      "Evaluation Loss at Iteration @ 5495 is 2.249619722366333\n",
      "Loss at Iteration @ 5496 is 2.308196783065796\n",
      "Evaluation Loss at Iteration @ 5496 is 2.2143008708953857\n",
      "Loss at Iteration @ 5497 is 2.295485496520996\n",
      "Evaluation Loss at Iteration @ 5497 is 2.224299192428589\n",
      "Loss at Iteration @ 5498 is 2.251880168914795\n",
      "Evaluation Loss at Iteration @ 5498 is 2.272519588470459\n",
      "Loss at Iteration @ 5499 is 2.058459758758545\n",
      "Evaluation Loss at Iteration @ 5499 is 2.267781972885132\n",
      "Loss at Iteration @ 5500 is 2.2541396617889404\n",
      "Evaluation Loss at Iteration @ 5500 is 2.3088533878326416\n",
      "Loss at Iteration @ 5501 is 2.344871759414673\n",
      "Evaluation Loss at Iteration @ 5501 is 2.215640068054199\n",
      "Loss at Iteration @ 5502 is 2.450913429260254\n",
      "Evaluation Loss at Iteration @ 5502 is 2.2439703941345215\n",
      "Loss at Iteration @ 5503 is 2.6707491874694824\n",
      "Evaluation Loss at Iteration @ 5503 is 2.2475955486297607\n",
      "Loss at Iteration @ 5504 is 2.32501482963562\n",
      "Evaluation Loss at Iteration @ 5504 is 2.3321549892425537\n",
      "Loss at Iteration @ 5505 is 2.09232497215271\n",
      "Evaluation Loss at Iteration @ 5505 is 2.2421491146087646\n",
      "Loss at Iteration @ 5506 is 2.288461208343506\n",
      "Evaluation Loss at Iteration @ 5506 is 2.3263792991638184\n",
      "Loss at Iteration @ 5507 is 2.4836790561676025\n",
      "Evaluation Loss at Iteration @ 5507 is 2.2462544441223145\n",
      "Loss at Iteration @ 5508 is 2.3906586170196533\n",
      "Evaluation Loss at Iteration @ 5508 is 2.286456346511841\n",
      "Loss at Iteration @ 5509 is 2.3242900371551514\n",
      "Evaluation Loss at Iteration @ 5509 is 2.268170118331909\n",
      "Loss at Iteration @ 5510 is 2.2149200439453125\n",
      "Evaluation Loss at Iteration @ 5510 is 2.2351529598236084\n",
      "Loss at Iteration @ 5511 is 2.177877902984619\n",
      "Evaluation Loss at Iteration @ 5511 is 2.3117847442626953\n",
      "Loss at Iteration @ 5512 is 2.091308355331421\n",
      "Evaluation Loss at Iteration @ 5512 is 2.2936289310455322\n",
      "Loss at Iteration @ 5513 is 2.206746816635132\n",
      "Evaluation Loss at Iteration @ 5513 is 2.2560930252075195\n",
      "Loss at Iteration @ 5514 is 2.0320777893066406\n",
      "Evaluation Loss at Iteration @ 5514 is 2.2280712127685547\n",
      "Loss at Iteration @ 5515 is 2.3661937713623047\n",
      "Evaluation Loss at Iteration @ 5515 is 2.192214012145996\n",
      "Loss at Iteration @ 5516 is 2.4139106273651123\n",
      "Evaluation Loss at Iteration @ 5516 is 2.2324447631835938\n",
      "Loss at Iteration @ 5517 is 2.2259998321533203\n",
      "Evaluation Loss at Iteration @ 5517 is 2.255913734436035\n",
      "Loss at Iteration @ 5518 is 1.9500617980957031\n",
      "Evaluation Loss at Iteration @ 5518 is 2.2525269985198975\n",
      "Loss at Iteration @ 5519 is 2.230595350265503\n",
      "Evaluation Loss at Iteration @ 5519 is 2.21932053565979\n",
      "Loss at Iteration @ 5520 is 2.4793872833251953\n",
      "Evaluation Loss at Iteration @ 5520 is 2.2320399284362793\n",
      "Loss at Iteration @ 5521 is 2.158621311187744\n",
      "Evaluation Loss at Iteration @ 5521 is 2.203803539276123\n",
      "Loss at Iteration @ 5522 is 2.079366445541382\n",
      "Evaluation Loss at Iteration @ 5522 is 2.257185459136963\n",
      "Loss at Iteration @ 5523 is 2.439685821533203\n",
      "Evaluation Loss at Iteration @ 5523 is 2.322417736053467\n",
      "Loss at Iteration @ 5524 is 2.4194962978363037\n",
      "Evaluation Loss at Iteration @ 5524 is 2.2591185569763184\n",
      "Loss at Iteration @ 5525 is 2.2177295684814453\n",
      "Evaluation Loss at Iteration @ 5525 is 2.208193778991699\n",
      "Loss at Iteration @ 5526 is 2.3591129779815674\n",
      "Evaluation Loss at Iteration @ 5526 is 2.232731819152832\n",
      "Loss at Iteration @ 5527 is 2.2631139755249023\n",
      "Evaluation Loss at Iteration @ 5527 is 2.2369377613067627\n",
      "Loss at Iteration @ 5528 is 2.1911354064941406\n",
      "Evaluation Loss at Iteration @ 5528 is 2.274780750274658\n",
      "Loss at Iteration @ 5529 is 2.290794849395752\n",
      "Evaluation Loss at Iteration @ 5529 is 2.2392148971557617\n",
      "Loss at Iteration @ 5530 is 2.2413597106933594\n",
      "Evaluation Loss at Iteration @ 5530 is 2.2262415885925293\n",
      "Loss at Iteration @ 5531 is 2.215658187866211\n",
      "Evaluation Loss at Iteration @ 5531 is 2.2109782695770264\n",
      "Loss at Iteration @ 5532 is 2.117372512817383\n",
      "Evaluation Loss at Iteration @ 5532 is 2.248798370361328\n",
      "Loss at Iteration @ 5533 is 2.2848970890045166\n",
      "Evaluation Loss at Iteration @ 5533 is 2.2611804008483887\n",
      "Loss at Iteration @ 5534 is 2.0666697025299072\n",
      "Evaluation Loss at Iteration @ 5534 is 2.243242025375366\n",
      "Loss at Iteration @ 5535 is 2.2121386528015137\n",
      "Evaluation Loss at Iteration @ 5535 is 2.249709367752075\n",
      "Loss at Iteration @ 5536 is 2.37394380569458\n",
      "Evaluation Loss at Iteration @ 5536 is 2.225518226623535\n",
      "Loss at Iteration @ 5537 is 2.05509877204895\n",
      "Evaluation Loss at Iteration @ 5537 is 2.2548844814300537\n",
      "Loss at Iteration @ 5538 is 2.045741081237793\n",
      "Evaluation Loss at Iteration @ 5538 is 2.2334837913513184\n",
      "Loss at Iteration @ 5539 is 2.370187997817993\n",
      "Evaluation Loss at Iteration @ 5539 is 2.2621474266052246\n",
      "Loss at Iteration @ 5540 is 2.3651070594787598\n",
      "Evaluation Loss at Iteration @ 5540 is 2.2665457725524902\n",
      "Loss at Iteration @ 5541 is 2.181447744369507\n",
      "Evaluation Loss at Iteration @ 5541 is 2.2914741039276123\n",
      "Loss at Iteration @ 5542 is 2.5502007007598877\n",
      "Evaluation Loss at Iteration @ 5542 is 2.23195219039917\n",
      "Loss at Iteration @ 5543 is 2.2022740840911865\n",
      "Evaluation Loss at Iteration @ 5543 is 2.204357624053955\n",
      "Loss at Iteration @ 5544 is 2.255115509033203\n",
      "Evaluation Loss at Iteration @ 5544 is 2.223222494125366\n",
      "Loss at Iteration @ 5545 is 2.1667065620422363\n",
      "Evaluation Loss at Iteration @ 5545 is 2.2394776344299316\n",
      "Loss at Iteration @ 5546 is 2.1117024421691895\n",
      "Evaluation Loss at Iteration @ 5546 is 2.174537181854248\n",
      "Loss at Iteration @ 5547 is 2.1975600719451904\n",
      "Evaluation Loss at Iteration @ 5547 is 2.322061777114868\n",
      "Loss at Iteration @ 5548 is 2.285221815109253\n",
      "Evaluation Loss at Iteration @ 5548 is 2.2602691650390625\n",
      "Loss at Iteration @ 5549 is 2.324822187423706\n",
      "Evaluation Loss at Iteration @ 5549 is 2.2845089435577393\n",
      "Loss at Iteration @ 5550 is 2.0447237491607666\n",
      "Evaluation Loss at Iteration @ 5550 is 2.269582748413086\n",
      "Loss at Iteration @ 5551 is 2.3000829219818115\n",
      "Evaluation Loss at Iteration @ 5551 is 2.253248453140259\n",
      "Loss at Iteration @ 5552 is 2.3986868858337402\n",
      "Evaluation Loss at Iteration @ 5552 is 2.2799479961395264\n",
      "Loss at Iteration @ 5553 is 2.147141695022583\n",
      "Evaluation Loss at Iteration @ 5553 is 2.2010679244995117\n",
      "Loss at Iteration @ 5554 is 2.2532684803009033\n",
      "Evaluation Loss at Iteration @ 5554 is 2.2434401512145996\n",
      "Loss at Iteration @ 5555 is 2.1052122116088867\n",
      "Evaluation Loss at Iteration @ 5555 is 2.1728997230529785\n",
      "Loss at Iteration @ 5556 is 2.0172972679138184\n",
      "Evaluation Loss at Iteration @ 5556 is 2.255128860473633\n",
      "Loss at Iteration @ 5557 is 2.253918409347534\n",
      "Evaluation Loss at Iteration @ 5557 is 2.2150187492370605\n",
      "Loss at Iteration @ 5558 is 2.1759064197540283\n",
      "Evaluation Loss at Iteration @ 5558 is 2.240377902984619\n",
      "Loss at Iteration @ 5559 is 2.4033825397491455\n",
      "Evaluation Loss at Iteration @ 5559 is 2.2716257572174072\n",
      "Loss at Iteration @ 5560 is 2.373086452484131\n",
      "Evaluation Loss at Iteration @ 5560 is 2.2656843662261963\n",
      "Loss at Iteration @ 5561 is 2.3109631538391113\n",
      "Evaluation Loss at Iteration @ 5561 is 2.2136547565460205\n",
      "Loss at Iteration @ 5562 is 2.1163077354431152\n",
      "Evaluation Loss at Iteration @ 5562 is 2.263029098510742\n",
      "Loss at Iteration @ 5563 is 2.11130952835083\n",
      "Evaluation Loss at Iteration @ 5563 is 2.273127555847168\n",
      "Loss at Iteration @ 5564 is 2.0619945526123047\n",
      "Evaluation Loss at Iteration @ 5564 is 2.222938060760498\n",
      "Loss at Iteration @ 5565 is 2.0806517601013184\n",
      "Evaluation Loss at Iteration @ 5565 is 2.2796506881713867\n",
      "Loss at Iteration @ 5566 is 2.3657257556915283\n",
      "Evaluation Loss at Iteration @ 5566 is 2.222395658493042\n",
      "Loss at Iteration @ 5567 is 2.3084821701049805\n",
      "Evaluation Loss at Iteration @ 5567 is 2.251619577407837\n",
      "Loss at Iteration @ 5568 is 2.2711071968078613\n",
      "Evaluation Loss at Iteration @ 5568 is 2.2271881103515625\n",
      "Loss at Iteration @ 5569 is 2.18888783454895\n",
      "Evaluation Loss at Iteration @ 5569 is 2.235687255859375\n",
      "Loss at Iteration @ 5570 is 2.2596659660339355\n",
      "Evaluation Loss at Iteration @ 5570 is 2.2364885807037354\n",
      "Loss at Iteration @ 5571 is 2.4286587238311768\n",
      "Evaluation Loss at Iteration @ 5571 is 2.220303773880005\n",
      "Loss at Iteration @ 5572 is 2.211676597595215\n",
      "Evaluation Loss at Iteration @ 5572 is 2.233952522277832\n",
      "Loss at Iteration @ 5573 is 2.2133471965789795\n",
      "Evaluation Loss at Iteration @ 5573 is 2.2518608570098877\n",
      "Loss at Iteration @ 5574 is 2.1778721809387207\n",
      "Evaluation Loss at Iteration @ 5574 is 2.217184066772461\n",
      "Loss at Iteration @ 5575 is 2.130441188812256\n",
      "Evaluation Loss at Iteration @ 5575 is 2.318686008453369\n",
      "Loss at Iteration @ 5576 is 2.166778326034546\n",
      "Evaluation Loss at Iteration @ 5576 is 2.2876956462860107\n",
      "Loss at Iteration @ 5577 is 2.0341243743896484\n",
      "Evaluation Loss at Iteration @ 5577 is 2.275911808013916\n",
      "Loss at Iteration @ 5578 is 2.1353816986083984\n",
      "Evaluation Loss at Iteration @ 5578 is 2.2840158939361572\n",
      "Loss at Iteration @ 5579 is 2.1603891849517822\n",
      "Evaluation Loss at Iteration @ 5579 is 2.2403175830841064\n",
      "Loss at Iteration @ 5580 is 2.1781435012817383\n",
      "Evaluation Loss at Iteration @ 5580 is 2.2775087356567383\n",
      "Loss at Iteration @ 5581 is 2.160539150238037\n",
      "Evaluation Loss at Iteration @ 5581 is 2.3062808513641357\n",
      "Loss at Iteration @ 5582 is 2.430227756500244\n",
      "Evaluation Loss at Iteration @ 5582 is 2.2639310359954834\n",
      "Loss at Iteration @ 5583 is 2.5325536727905273\n",
      "Evaluation Loss at Iteration @ 5583 is 2.2224504947662354\n",
      "Loss at Iteration @ 5584 is 2.2904136180877686\n",
      "Evaluation Loss at Iteration @ 5584 is 2.2868950366973877\n",
      "Loss at Iteration @ 5585 is 2.1512351036071777\n",
      "Evaluation Loss at Iteration @ 5585 is 2.3117082118988037\n",
      "Loss at Iteration @ 5586 is 1.8978906869888306\n",
      "Evaluation Loss at Iteration @ 5586 is 2.242689371109009\n",
      "Loss at Iteration @ 5587 is 2.21429181098938\n",
      "Evaluation Loss at Iteration @ 5587 is 2.2561957836151123\n",
      "Loss at Iteration @ 5588 is 2.499765396118164\n",
      "Evaluation Loss at Iteration @ 5588 is 2.2502686977386475\n",
      "Loss at Iteration @ 5589 is 2.8705334663391113\n",
      "Evaluation Loss at Iteration @ 5589 is 2.2362964153289795\n",
      "Loss at Iteration @ 5590 is 2.0309560298919678\n",
      "Evaluation Loss at Iteration @ 5590 is 2.2486071586608887\n",
      "Loss at Iteration @ 5591 is 1.9727343320846558\n",
      "Evaluation Loss at Iteration @ 5591 is 2.2569174766540527\n",
      "Loss at Iteration @ 5592 is 2.1120617389678955\n",
      "Evaluation Loss at Iteration @ 5592 is 2.224705934524536\n",
      "Loss at Iteration @ 5593 is 2.3063766956329346\n",
      "Evaluation Loss at Iteration @ 5593 is 2.262085199356079\n",
      "Loss at Iteration @ 5594 is 2.1306233406066895\n",
      "Evaluation Loss at Iteration @ 5594 is 2.231083869934082\n",
      "Loss at Iteration @ 5595 is 2.36877703666687\n",
      "Evaluation Loss at Iteration @ 5595 is 2.234588623046875\n",
      "Loss at Iteration @ 5596 is 2.3985865116119385\n",
      "Evaluation Loss at Iteration @ 5596 is 2.2308719158172607\n",
      "Loss at Iteration @ 5597 is 2.4218668937683105\n",
      "Evaluation Loss at Iteration @ 5597 is 2.298919439315796\n",
      "Loss at Iteration @ 5598 is 2.285226345062256\n",
      "Evaluation Loss at Iteration @ 5598 is 2.2570297718048096\n",
      "Loss at Iteration @ 5599 is 2.315279483795166\n",
      "Evaluation Loss at Iteration @ 5599 is 2.24100399017334\n",
      "Loss at Iteration @ 5600 is 1.9797481298446655\n",
      "Evaluation Loss at Iteration @ 5600 is 2.2893624305725098\n",
      "Loss at Iteration @ 5601 is 2.235827922821045\n",
      "Evaluation Loss at Iteration @ 5601 is 2.261725664138794\n",
      "Loss at Iteration @ 5602 is 2.3389220237731934\n",
      "Evaluation Loss at Iteration @ 5602 is 2.2299435138702393\n",
      "Loss at Iteration @ 5603 is 2.2388877868652344\n",
      "Evaluation Loss at Iteration @ 5603 is 2.274749517440796\n",
      "Loss at Iteration @ 5604 is 2.297257900238037\n",
      "Evaluation Loss at Iteration @ 5604 is 2.197000503540039\n",
      "Loss at Iteration @ 5605 is 2.34407114982605\n",
      "Evaluation Loss at Iteration @ 5605 is 2.250774383544922\n",
      "Loss at Iteration @ 5606 is 2.174903154373169\n",
      "Evaluation Loss at Iteration @ 5606 is 2.2831859588623047\n",
      "Loss at Iteration @ 5607 is 2.5422801971435547\n",
      "Evaluation Loss at Iteration @ 5607 is 2.2270100116729736\n",
      "Loss at Iteration @ 5608 is 2.2825751304626465\n",
      "Evaluation Loss at Iteration @ 5608 is 2.2840261459350586\n",
      "Loss at Iteration @ 5609 is 1.9982426166534424\n",
      "Evaluation Loss at Iteration @ 5609 is 2.2724409103393555\n",
      "Loss at Iteration @ 5610 is 2.599677562713623\n",
      "Evaluation Loss at Iteration @ 5610 is 2.2362446784973145\n",
      "Loss at Iteration @ 5611 is 2.2123608589172363\n",
      "Evaluation Loss at Iteration @ 5611 is 2.2626845836639404\n",
      "Loss at Iteration @ 5612 is 1.8974348306655884\n",
      "Evaluation Loss at Iteration @ 5612 is 2.2924787998199463\n",
      "Loss at Iteration @ 5613 is 2.3031296730041504\n",
      "Evaluation Loss at Iteration @ 5613 is 2.2475650310516357\n",
      "Loss at Iteration @ 5614 is 2.3334455490112305\n",
      "Evaluation Loss at Iteration @ 5614 is 2.277486562728882\n",
      "Loss at Iteration @ 5615 is 2.3455615043640137\n",
      "Evaluation Loss at Iteration @ 5615 is 2.2968223094940186\n",
      "Loss at Iteration @ 5616 is 2.342207670211792\n",
      "Evaluation Loss at Iteration @ 5616 is 2.196483612060547\n",
      "Loss at Iteration @ 5617 is 2.405733585357666\n",
      "Evaluation Loss at Iteration @ 5617 is 2.269123077392578\n",
      "Loss at Iteration @ 5618 is 2.165799617767334\n",
      "Evaluation Loss at Iteration @ 5618 is 2.2541611194610596\n",
      "Loss at Iteration @ 5619 is 2.094430923461914\n",
      "Evaluation Loss at Iteration @ 5619 is 2.274125099182129\n",
      "Loss at Iteration @ 5620 is 2.3009800910949707\n",
      "Evaluation Loss at Iteration @ 5620 is 2.255880832672119\n",
      "Loss at Iteration @ 5621 is 2.352108955383301\n",
      "Evaluation Loss at Iteration @ 5621 is 2.2697882652282715\n",
      "Loss at Iteration @ 5622 is 2.1041736602783203\n",
      "Evaluation Loss at Iteration @ 5622 is 2.218947410583496\n",
      "Loss at Iteration @ 5623 is 2.1455142498016357\n",
      "Evaluation Loss at Iteration @ 5623 is 2.2232370376586914\n",
      "Loss at Iteration @ 5624 is 2.0732924938201904\n",
      "Evaluation Loss at Iteration @ 5624 is 2.256767511367798\n",
      "Loss at Iteration @ 5625 is 2.22102427482605\n",
      "Evaluation Loss at Iteration @ 5625 is 2.2104461193084717\n",
      "Loss at Iteration @ 5626 is 2.2622058391571045\n",
      "Evaluation Loss at Iteration @ 5626 is 2.240663528442383\n",
      "Loss at Iteration @ 5627 is 2.082594633102417\n",
      "Evaluation Loss at Iteration @ 5627 is 2.2689597606658936\n",
      "Loss at Iteration @ 5628 is 2.073063611984253\n",
      "Evaluation Loss at Iteration @ 5628 is 2.277531862258911\n",
      "Loss at Iteration @ 5629 is 2.225980758666992\n",
      "Evaluation Loss at Iteration @ 5629 is 2.271714687347412\n",
      "Loss at Iteration @ 5630 is 2.2023558616638184\n",
      "Evaluation Loss at Iteration @ 5630 is 2.203524351119995\n",
      "Loss at Iteration @ 5631 is 2.284169912338257\n",
      "Evaluation Loss at Iteration @ 5631 is 2.276951551437378\n",
      "Loss at Iteration @ 5632 is 2.2381961345672607\n",
      "Evaluation Loss at Iteration @ 5632 is 2.2371037006378174\n",
      "Loss at Iteration @ 5633 is 2.175079345703125\n",
      "Evaluation Loss at Iteration @ 5633 is 2.2555713653564453\n",
      "Loss at Iteration @ 5634 is 2.2607905864715576\n",
      "Evaluation Loss at Iteration @ 5634 is 2.278679847717285\n",
      "Loss at Iteration @ 5635 is 2.198615074157715\n",
      "Evaluation Loss at Iteration @ 5635 is 2.2264087200164795\n",
      "Loss at Iteration @ 5636 is 2.1369986534118652\n",
      "Evaluation Loss at Iteration @ 5636 is 2.21714448928833\n",
      "Loss at Iteration @ 5637 is 2.477980613708496\n",
      "Evaluation Loss at Iteration @ 5637 is 2.245915412902832\n",
      "Loss at Iteration @ 5638 is 2.1394195556640625\n",
      "Evaluation Loss at Iteration @ 5638 is 2.2971229553222656\n",
      "Loss at Iteration @ 5639 is 2.2802515029907227\n",
      "Evaluation Loss at Iteration @ 5639 is 2.250354051589966\n",
      "Loss at Iteration @ 5640 is 2.283111333847046\n",
      "Evaluation Loss at Iteration @ 5640 is 2.2101852893829346\n",
      "Loss at Iteration @ 5641 is 2.249929189682007\n",
      "Evaluation Loss at Iteration @ 5641 is 2.2445757389068604\n",
      "Loss at Iteration @ 5642 is 2.3442554473876953\n",
      "Evaluation Loss at Iteration @ 5642 is 2.2282297611236572\n",
      "Loss at Iteration @ 5643 is 2.121800422668457\n",
      "Evaluation Loss at Iteration @ 5643 is 2.284841537475586\n",
      "Loss at Iteration @ 5644 is 2.223735809326172\n",
      "Evaluation Loss at Iteration @ 5644 is 2.2743000984191895\n",
      "Loss at Iteration @ 5645 is 2.3627796173095703\n",
      "Evaluation Loss at Iteration @ 5645 is 2.227381944656372\n",
      "Loss at Iteration @ 5646 is 2.3559815883636475\n",
      "Evaluation Loss at Iteration @ 5646 is 2.2193267345428467\n",
      "Loss at Iteration @ 5647 is 2.231048107147217\n",
      "Evaluation Loss at Iteration @ 5647 is 2.279451847076416\n",
      "Loss at Iteration @ 5648 is 2.0881576538085938\n",
      "Evaluation Loss at Iteration @ 5648 is 2.236687421798706\n",
      "Loss at Iteration @ 5649 is 2.15759015083313\n",
      "Evaluation Loss at Iteration @ 5649 is 2.2638912200927734\n",
      "Loss at Iteration @ 5650 is 2.428863286972046\n",
      "Evaluation Loss at Iteration @ 5650 is 2.2607038021087646\n",
      "Loss at Iteration @ 5651 is 2.4381444454193115\n",
      "Evaluation Loss at Iteration @ 5651 is 2.2503411769866943\n",
      "Loss at Iteration @ 5652 is 2.232353925704956\n",
      "Evaluation Loss at Iteration @ 5652 is 2.2268877029418945\n",
      "Loss at Iteration @ 5653 is 1.9557123184204102\n",
      "Evaluation Loss at Iteration @ 5653 is 2.268183708190918\n",
      "Loss at Iteration @ 5654 is 1.9731101989746094\n",
      "Evaluation Loss at Iteration @ 5654 is 2.252624750137329\n",
      "Loss at Iteration @ 5655 is 2.2601964473724365\n",
      "Evaluation Loss at Iteration @ 5655 is 2.294142007827759\n",
      "Loss at Iteration @ 5656 is 2.4263837337493896\n",
      "Evaluation Loss at Iteration @ 5656 is 2.2460079193115234\n",
      "Loss at Iteration @ 5657 is 2.200052499771118\n",
      "Evaluation Loss at Iteration @ 5657 is 2.2392003536224365\n",
      "Loss at Iteration @ 5658 is 2.4832956790924072\n",
      "Evaluation Loss at Iteration @ 5658 is 2.2508702278137207\n",
      "Loss at Iteration @ 5659 is 2.0197315216064453\n",
      "Evaluation Loss at Iteration @ 5659 is 2.245049476623535\n",
      "Loss at Iteration @ 5660 is 2.253427028656006\n",
      "Evaluation Loss at Iteration @ 5660 is 2.2808749675750732\n",
      "Loss at Iteration @ 5661 is 2.1954615116119385\n",
      "Evaluation Loss at Iteration @ 5661 is 2.2792630195617676\n",
      "Loss at Iteration @ 5662 is 2.350074052810669\n",
      "Evaluation Loss at Iteration @ 5662 is 2.277250289916992\n",
      "Loss at Iteration @ 5663 is 2.1147711277008057\n",
      "Evaluation Loss at Iteration @ 5663 is 2.282120943069458\n",
      "Loss at Iteration @ 5664 is 1.821042776107788\n",
      "Evaluation Loss at Iteration @ 5664 is 2.272010326385498\n",
      "Loss at Iteration @ 5665 is 2.099851608276367\n",
      "Evaluation Loss at Iteration @ 5665 is 2.2581610679626465\n",
      "Loss at Iteration @ 5666 is 2.189807415008545\n",
      "Evaluation Loss at Iteration @ 5666 is 2.244093418121338\n",
      "Loss at Iteration @ 5667 is 2.5397965908050537\n",
      "Evaluation Loss at Iteration @ 5667 is 2.2039880752563477\n",
      "Loss at Iteration @ 5668 is 2.2333321571350098\n",
      "Evaluation Loss at Iteration @ 5668 is 2.242067337036133\n",
      "Loss at Iteration @ 5669 is 2.0014877319335938\n",
      "Evaluation Loss at Iteration @ 5669 is 2.2404515743255615\n",
      "Loss at Iteration @ 5670 is 2.140981674194336\n",
      "Evaluation Loss at Iteration @ 5670 is 2.27424955368042\n",
      "Loss at Iteration @ 5671 is 2.1796298027038574\n",
      "Evaluation Loss at Iteration @ 5671 is 2.2767679691314697\n",
      "Loss at Iteration @ 5672 is 2.1307590007781982\n",
      "Evaluation Loss at Iteration @ 5672 is 2.2688088417053223\n",
      "Loss at Iteration @ 5673 is 2.2895541191101074\n",
      "Evaluation Loss at Iteration @ 5673 is 2.2104456424713135\n",
      "Loss at Iteration @ 5674 is 2.1347639560699463\n",
      "Evaluation Loss at Iteration @ 5674 is 2.2720141410827637\n",
      "Loss at Iteration @ 5675 is 2.1156420707702637\n",
      "Evaluation Loss at Iteration @ 5675 is 2.247683048248291\n",
      "Loss at Iteration @ 5676 is 2.2635161876678467\n",
      "Evaluation Loss at Iteration @ 5676 is 2.2463388442993164\n",
      "Loss at Iteration @ 5677 is 2.163820743560791\n",
      "Evaluation Loss at Iteration @ 5677 is 2.2155187129974365\n",
      "Loss at Iteration @ 5678 is 2.135329484939575\n",
      "Evaluation Loss at Iteration @ 5678 is 2.233128309249878\n",
      "Loss at Iteration @ 5679 is 2.374025344848633\n",
      "Evaluation Loss at Iteration @ 5679 is 2.248279094696045\n",
      "Loss at Iteration @ 5680 is 2.0999433994293213\n",
      "Evaluation Loss at Iteration @ 5680 is 2.3035316467285156\n",
      "Loss at Iteration @ 5681 is 2.2375941276550293\n",
      "Evaluation Loss at Iteration @ 5681 is 2.2363152503967285\n",
      "Loss at Iteration @ 5682 is 2.1893529891967773\n",
      "Evaluation Loss at Iteration @ 5682 is 2.262474536895752\n",
      "Loss at Iteration @ 5683 is 2.1068615913391113\n",
      "Evaluation Loss at Iteration @ 5683 is 2.2560548782348633\n",
      "Loss at Iteration @ 5684 is 1.9974721670150757\n",
      "Evaluation Loss at Iteration @ 5684 is 2.3004326820373535\n",
      "Loss at Iteration @ 5685 is 2.3904900550842285\n",
      "Evaluation Loss at Iteration @ 5685 is 2.284147262573242\n",
      "Loss at Iteration @ 5686 is 2.6398427486419678\n",
      "Evaluation Loss at Iteration @ 5686 is 2.2500574588775635\n",
      "Loss at Iteration @ 5687 is 2.0995757579803467\n",
      "Evaluation Loss at Iteration @ 5687 is 2.225389003753662\n",
      "Loss at Iteration @ 5688 is 2.3910348415374756\n",
      "Evaluation Loss at Iteration @ 5688 is 2.2697792053222656\n",
      "Loss at Iteration @ 5689 is 2.2779808044433594\n",
      "Evaluation Loss at Iteration @ 5689 is 2.232154369354248\n",
      "Loss at Iteration @ 5690 is 2.0232207775115967\n",
      "Evaluation Loss at Iteration @ 5690 is 2.2583253383636475\n",
      "Loss at Iteration @ 5691 is 2.2549564838409424\n",
      "Evaluation Loss at Iteration @ 5691 is 2.197052478790283\n",
      "Loss at Iteration @ 5692 is 2.346776008605957\n",
      "Evaluation Loss at Iteration @ 5692 is 2.2424609661102295\n",
      "Loss at Iteration @ 5693 is 2.0914082527160645\n",
      "Evaluation Loss at Iteration @ 5693 is 2.2637569904327393\n",
      "Loss at Iteration @ 5694 is 2.327622175216675\n",
      "Evaluation Loss at Iteration @ 5694 is 2.2397851943969727\n",
      "Loss at Iteration @ 5695 is 2.312575101852417\n",
      "Evaluation Loss at Iteration @ 5695 is 2.2701995372772217\n",
      "Loss at Iteration @ 5696 is 2.3322882652282715\n",
      "Evaluation Loss at Iteration @ 5696 is 2.1946780681610107\n",
      "Loss at Iteration @ 5697 is 2.275885581970215\n",
      "Evaluation Loss at Iteration @ 5697 is 2.2076687812805176\n",
      "Loss at Iteration @ 5698 is 2.1802361011505127\n",
      "Evaluation Loss at Iteration @ 5698 is 2.2873384952545166\n",
      "Loss at Iteration @ 5699 is 2.5676839351654053\n",
      "Evaluation Loss at Iteration @ 5699 is 2.2578861713409424\n",
      "Loss at Iteration @ 5700 is 2.431697368621826\n",
      "Evaluation Loss at Iteration @ 5700 is 2.1709725856781006\n",
      "Loss at Iteration @ 5701 is 2.1120688915252686\n",
      "Evaluation Loss at Iteration @ 5701 is 2.247074842453003\n",
      "Loss at Iteration @ 5702 is 1.9617080688476562\n",
      "Evaluation Loss at Iteration @ 5702 is 2.2458744049072266\n",
      "Loss at Iteration @ 5703 is 2.2001700401306152\n",
      "Evaluation Loss at Iteration @ 5703 is 2.2406747341156006\n",
      "Loss at Iteration @ 5704 is 2.3247246742248535\n",
      "Evaluation Loss at Iteration @ 5704 is 2.225588083267212\n",
      "Loss at Iteration @ 5705 is 2.4299917221069336\n",
      "Evaluation Loss at Iteration @ 5705 is 2.2458581924438477\n",
      "Loss at Iteration @ 5706 is 2.133763551712036\n",
      "Evaluation Loss at Iteration @ 5706 is 2.2308948040008545\n",
      "Loss at Iteration @ 5707 is 2.217406988143921\n",
      "Evaluation Loss at Iteration @ 5707 is 2.2203257083892822\n",
      "Loss at Iteration @ 5708 is 2.129110813140869\n",
      "Evaluation Loss at Iteration @ 5708 is 2.240882158279419\n",
      "Loss at Iteration @ 5709 is 2.1534111499786377\n",
      "Evaluation Loss at Iteration @ 5709 is 2.281348466873169\n",
      "Loss at Iteration @ 5710 is 2.471336603164673\n",
      "Evaluation Loss at Iteration @ 5710 is 2.2889721393585205\n",
      "Loss at Iteration @ 5711 is 2.4218590259552\n",
      "Evaluation Loss at Iteration @ 5711 is 2.2384836673736572\n",
      "Loss at Iteration @ 5712 is 2.281219244003296\n",
      "Evaluation Loss at Iteration @ 5712 is 2.237508535385132\n",
      "Loss at Iteration @ 5713 is 2.3726868629455566\n",
      "Evaluation Loss at Iteration @ 5713 is 2.2616779804229736\n",
      "Loss at Iteration @ 5714 is 2.2391693592071533\n",
      "Evaluation Loss at Iteration @ 5714 is 2.2472598552703857\n",
      "Loss at Iteration @ 5715 is 2.406843662261963\n",
      "Evaluation Loss at Iteration @ 5715 is 2.2799558639526367\n",
      "Loss at Iteration @ 5716 is 2.320678234100342\n",
      "Evaluation Loss at Iteration @ 5716 is 2.2562692165374756\n",
      "Loss at Iteration @ 5717 is 2.1436593532562256\n",
      "Evaluation Loss at Iteration @ 5717 is 2.2816765308380127\n",
      "Loss at Iteration @ 5718 is 2.328864336013794\n",
      "Evaluation Loss at Iteration @ 5718 is 2.2375128269195557\n",
      "Loss at Iteration @ 5719 is 2.0818965435028076\n",
      "Evaluation Loss at Iteration @ 5719 is 2.269320487976074\n",
      "Loss at Iteration @ 5720 is 2.1109910011291504\n",
      "Evaluation Loss at Iteration @ 5720 is 2.284644842147827\n",
      "Loss at Iteration @ 5721 is 2.2861499786376953\n",
      "Evaluation Loss at Iteration @ 5721 is 2.278285026550293\n",
      "Loss at Iteration @ 5722 is 2.105083703994751\n",
      "Evaluation Loss at Iteration @ 5722 is 2.240511178970337\n",
      "Loss at Iteration @ 5723 is 1.9900500774383545\n",
      "Evaluation Loss at Iteration @ 5723 is 2.2543294429779053\n",
      "Loss at Iteration @ 5724 is 2.396172523498535\n",
      "Evaluation Loss at Iteration @ 5724 is 2.2422616481781006\n",
      "Loss at Iteration @ 5725 is 2.1862735748291016\n",
      "Evaluation Loss at Iteration @ 5725 is 2.2813541889190674\n",
      "Loss at Iteration @ 5726 is 2.3050947189331055\n",
      "Evaluation Loss at Iteration @ 5726 is 2.2390646934509277\n",
      "Loss at Iteration @ 5727 is 1.9864741563796997\n",
      "Evaluation Loss at Iteration @ 5727 is 2.266594171524048\n",
      "Loss at Iteration @ 5728 is 2.1843631267547607\n",
      "Evaluation Loss at Iteration @ 5728 is 2.1964972019195557\n",
      "Loss at Iteration @ 5729 is 2.203223466873169\n",
      "Evaluation Loss at Iteration @ 5729 is 2.267012596130371\n",
      "Loss at Iteration @ 5730 is 2.0447168350219727\n",
      "Evaluation Loss at Iteration @ 5730 is 2.218012809753418\n",
      "Loss at Iteration @ 5731 is 2.2527248859405518\n",
      "Evaluation Loss at Iteration @ 5731 is 2.2627618312835693\n",
      "Loss at Iteration @ 5732 is 2.6265408992767334\n",
      "Evaluation Loss at Iteration @ 5732 is 2.245203971862793\n",
      "Loss at Iteration @ 5733 is 2.367678642272949\n",
      "Evaluation Loss at Iteration @ 5733 is 2.262845993041992\n",
      "Loss at Iteration @ 5734 is 2.300609588623047\n",
      "Evaluation Loss at Iteration @ 5734 is 2.2367570400238037\n",
      "Loss at Iteration @ 5735 is 2.403981924057007\n",
      "Evaluation Loss at Iteration @ 5735 is 2.248821496963501\n",
      "Loss at Iteration @ 5736 is 2.430729866027832\n",
      "Evaluation Loss at Iteration @ 5736 is 2.254589080810547\n",
      "Loss at Iteration @ 5737 is 2.120755672454834\n",
      "Evaluation Loss at Iteration @ 5737 is 2.2327213287353516\n",
      "Loss at Iteration @ 5738 is 2.3579845428466797\n",
      "Evaluation Loss at Iteration @ 5738 is 2.301254987716675\n",
      "Loss at Iteration @ 5739 is 2.478400468826294\n",
      "Evaluation Loss at Iteration @ 5739 is 2.2266039848327637\n",
      "Loss at Iteration @ 5740 is 2.4654719829559326\n",
      "Evaluation Loss at Iteration @ 5740 is 2.3009042739868164\n",
      "Loss at Iteration @ 5741 is 2.0885848999023438\n",
      "Evaluation Loss at Iteration @ 5741 is 2.2036497592926025\n",
      "Loss at Iteration @ 5742 is 2.2525949478149414\n",
      "Evaluation Loss at Iteration @ 5742 is 2.260066509246826\n",
      "Loss at Iteration @ 5743 is 2.4554922580718994\n",
      "Evaluation Loss at Iteration @ 5743 is 2.2012970447540283\n",
      "Loss at Iteration @ 5744 is 2.426730155944824\n",
      "Evaluation Loss at Iteration @ 5744 is 2.2290053367614746\n",
      "Loss at Iteration @ 5745 is 2.0166525840759277\n",
      "Evaluation Loss at Iteration @ 5745 is 2.2485907077789307\n",
      "Loss at Iteration @ 5746 is 2.321396589279175\n",
      "Evaluation Loss at Iteration @ 5746 is 2.2401351928710938\n",
      "Loss at Iteration @ 5747 is 2.133368968963623\n",
      "Evaluation Loss at Iteration @ 5747 is 2.2442567348480225\n",
      "Loss at Iteration @ 5748 is 2.100926637649536\n",
      "Evaluation Loss at Iteration @ 5748 is 2.2578210830688477\n",
      "Loss at Iteration @ 5749 is 2.3761813640594482\n",
      "Evaluation Loss at Iteration @ 5749 is 2.2430529594421387\n",
      "Loss at Iteration @ 5750 is 2.199082136154175\n",
      "Evaluation Loss at Iteration @ 5750 is 2.29093861579895\n",
      "Loss at Iteration @ 5751 is 2.098379611968994\n",
      "Evaluation Loss at Iteration @ 5751 is 2.237175941467285\n",
      "Loss at Iteration @ 5752 is 2.422025203704834\n",
      "Evaluation Loss at Iteration @ 5752 is 2.192605972290039\n",
      "Loss at Iteration @ 5753 is 2.1900737285614014\n",
      "Evaluation Loss at Iteration @ 5753 is 2.2681615352630615\n",
      "Loss at Iteration @ 5754 is 2.0736186504364014\n",
      "Evaluation Loss at Iteration @ 5754 is 2.2032902240753174\n",
      "Loss at Iteration @ 5755 is 2.19561505317688\n",
      "Evaluation Loss at Iteration @ 5755 is 2.2442405223846436\n",
      "Loss at Iteration @ 5756 is 2.0244016647338867\n",
      "Evaluation Loss at Iteration @ 5756 is 2.2346861362457275\n",
      "Loss at Iteration @ 5757 is 2.153733968734741\n",
      "Evaluation Loss at Iteration @ 5757 is 2.2396862506866455\n",
      "Loss at Iteration @ 5758 is 2.1942474842071533\n",
      "Evaluation Loss at Iteration @ 5758 is 2.287493944168091\n",
      "Loss at Iteration @ 5759 is 2.2622108459472656\n",
      "Evaluation Loss at Iteration @ 5759 is 2.3173930644989014\n",
      "Loss at Iteration @ 5760 is 1.8190327882766724\n",
      "Evaluation Loss at Iteration @ 5760 is 2.17781138420105\n",
      "Loss at Iteration @ 5761 is 2.5307395458221436\n",
      "Evaluation Loss at Iteration @ 5761 is 2.2387850284576416\n",
      "Loss at Iteration @ 5762 is 2.5395450592041016\n",
      "Evaluation Loss at Iteration @ 5762 is 2.271987199783325\n",
      "Loss at Iteration @ 5763 is 2.3209097385406494\n",
      "Evaluation Loss at Iteration @ 5763 is 2.2354328632354736\n",
      "Loss at Iteration @ 5764 is 2.5414693355560303\n",
      "Evaluation Loss at Iteration @ 5764 is 2.2509007453918457\n",
      "Loss at Iteration @ 5765 is 2.257340669631958\n",
      "Evaluation Loss at Iteration @ 5765 is 2.256863832473755\n",
      "Loss at Iteration @ 5766 is 2.2985100746154785\n",
      "Evaluation Loss at Iteration @ 5766 is 2.2688348293304443\n",
      "Loss at Iteration @ 5767 is 2.4443519115448\n",
      "Evaluation Loss at Iteration @ 5767 is 2.2811126708984375\n",
      "Loss at Iteration @ 5768 is 2.4251320362091064\n",
      "Evaluation Loss at Iteration @ 5768 is 2.2546274662017822\n",
      "Loss at Iteration @ 5769 is 2.097562074661255\n",
      "Evaluation Loss at Iteration @ 5769 is 2.2652828693389893\n",
      "Loss at Iteration @ 5770 is 2.7385644912719727\n",
      "Evaluation Loss at Iteration @ 5770 is 2.247952461242676\n",
      "Loss at Iteration @ 5771 is 2.038452386856079\n",
      "Evaluation Loss at Iteration @ 5771 is 2.2104713916778564\n",
      "Loss at Iteration @ 5772 is 2.2526073455810547\n",
      "Evaluation Loss at Iteration @ 5772 is 2.2728869915008545\n",
      "Loss at Iteration @ 5773 is 2.292259693145752\n",
      "Evaluation Loss at Iteration @ 5773 is 2.2516391277313232\n",
      "Loss at Iteration @ 5774 is 2.305511236190796\n",
      "Evaluation Loss at Iteration @ 5774 is 2.26440691947937\n",
      "Loss at Iteration @ 5775 is 2.2320356369018555\n",
      "Evaluation Loss at Iteration @ 5775 is 2.285163164138794\n",
      "Loss at Iteration @ 5776 is 2.1942965984344482\n",
      "Evaluation Loss at Iteration @ 5776 is 2.283827304840088\n",
      "Loss at Iteration @ 5777 is 2.370950937271118\n",
      "Evaluation Loss at Iteration @ 5777 is 2.2771761417388916\n",
      "Loss at Iteration @ 5778 is 2.2807295322418213\n",
      "Evaluation Loss at Iteration @ 5778 is 2.226569175720215\n",
      "Loss at Iteration @ 5779 is 2.281122922897339\n",
      "Evaluation Loss at Iteration @ 5779 is 2.3013594150543213\n",
      "Loss at Iteration @ 5780 is 2.3654541969299316\n",
      "Evaluation Loss at Iteration @ 5780 is 2.241020441055298\n",
      "Loss at Iteration @ 5781 is 2.190552234649658\n",
      "Evaluation Loss at Iteration @ 5781 is 2.2939443588256836\n",
      "Loss at Iteration @ 5782 is 2.190412759780884\n",
      "Evaluation Loss at Iteration @ 5782 is 2.2905218601226807\n",
      "Loss at Iteration @ 5783 is 2.398862838745117\n",
      "Evaluation Loss at Iteration @ 5783 is 2.2453532218933105\n",
      "Loss at Iteration @ 5784 is 2.1152048110961914\n",
      "Evaluation Loss at Iteration @ 5784 is 2.261017322540283\n",
      "Loss at Iteration @ 5785 is 2.1624932289123535\n",
      "Evaluation Loss at Iteration @ 5785 is 2.2648403644561768\n",
      "Loss at Iteration @ 5786 is 2.067506790161133\n",
      "Evaluation Loss at Iteration @ 5786 is 2.2808351516723633\n",
      "Loss at Iteration @ 5787 is 2.4307427406311035\n",
      "Evaluation Loss at Iteration @ 5787 is 2.2195451259613037\n",
      "Loss at Iteration @ 5788 is 2.671574831008911\n",
      "Evaluation Loss at Iteration @ 5788 is 2.208022356033325\n",
      "Loss at Iteration @ 5789 is 2.193143844604492\n",
      "Evaluation Loss at Iteration @ 5789 is 2.2233948707580566\n",
      "Loss at Iteration @ 5790 is 2.3297982215881348\n",
      "Evaluation Loss at Iteration @ 5790 is 2.1954715251922607\n",
      "Loss at Iteration @ 5791 is 2.158160924911499\n",
      "Evaluation Loss at Iteration @ 5791 is 2.2607033252716064\n",
      "Loss at Iteration @ 5792 is 2.2727062702178955\n",
      "Evaluation Loss at Iteration @ 5792 is 2.2465715408325195\n",
      "Loss at Iteration @ 5793 is 2.3636157512664795\n",
      "Evaluation Loss at Iteration @ 5793 is 2.2290520668029785\n",
      "Loss at Iteration @ 5794 is 2.236116409301758\n",
      "Evaluation Loss at Iteration @ 5794 is 2.233595848083496\n",
      "Loss at Iteration @ 5795 is 2.4157803058624268\n",
      "Evaluation Loss at Iteration @ 5795 is 2.2576305866241455\n",
      "Loss at Iteration @ 5796 is 1.929776906967163\n",
      "Evaluation Loss at Iteration @ 5796 is 2.2637031078338623\n",
      "Loss at Iteration @ 5797 is 2.3484699726104736\n",
      "Evaluation Loss at Iteration @ 5797 is 2.222062826156616\n",
      "Loss at Iteration @ 5798 is 1.9036798477172852\n",
      "Evaluation Loss at Iteration @ 5798 is 2.2464466094970703\n",
      "Loss at Iteration @ 5799 is 2.2381651401519775\n",
      "Evaluation Loss at Iteration @ 5799 is 2.197408437728882\n",
      "Loss at Iteration @ 5800 is 2.049290418624878\n",
      "Evaluation Loss at Iteration @ 5800 is 2.241231918334961\n",
      "Loss at Iteration @ 5801 is 2.1889734268188477\n",
      "Evaluation Loss at Iteration @ 5801 is 2.214254379272461\n",
      "Loss at Iteration @ 5802 is 1.9267802238464355\n",
      "Evaluation Loss at Iteration @ 5802 is 2.2515108585357666\n",
      "Loss at Iteration @ 5803 is 2.241804361343384\n",
      "Evaluation Loss at Iteration @ 5803 is 2.2394137382507324\n",
      "Loss at Iteration @ 5804 is 2.3154006004333496\n",
      "Evaluation Loss at Iteration @ 5804 is 2.291934013366699\n",
      "Loss at Iteration @ 5805 is 2.155017614364624\n",
      "Evaluation Loss at Iteration @ 5805 is 2.2852256298065186\n",
      "Loss at Iteration @ 5806 is 2.4281728267669678\n",
      "Evaluation Loss at Iteration @ 5806 is 2.2515785694122314\n",
      "Loss at Iteration @ 5807 is 2.3022408485412598\n",
      "Evaluation Loss at Iteration @ 5807 is 2.2518532276153564\n",
      "Loss at Iteration @ 5808 is 2.2358505725860596\n",
      "Evaluation Loss at Iteration @ 5808 is 2.256089687347412\n",
      "Loss at Iteration @ 5809 is 1.9526238441467285\n",
      "Evaluation Loss at Iteration @ 5809 is 2.2231547832489014\n",
      "Loss at Iteration @ 5810 is 2.160193920135498\n",
      "Evaluation Loss at Iteration @ 5810 is 2.287156343460083\n",
      "Loss at Iteration @ 5811 is 2.1444458961486816\n",
      "Evaluation Loss at Iteration @ 5811 is 2.285046100616455\n",
      "Loss at Iteration @ 5812 is 2.119124412536621\n",
      "Evaluation Loss at Iteration @ 5812 is 2.2597105503082275\n",
      "Loss at Iteration @ 5813 is 2.164719820022583\n",
      "Evaluation Loss at Iteration @ 5813 is 2.2183473110198975\n",
      "Loss at Iteration @ 5814 is 2.1647346019744873\n",
      "Evaluation Loss at Iteration @ 5814 is 2.24082350730896\n",
      "Loss at Iteration @ 5815 is 2.1716606616973877\n",
      "Evaluation Loss at Iteration @ 5815 is 2.2592735290527344\n",
      "Loss at Iteration @ 5816 is 2.3345768451690674\n",
      "Evaluation Loss at Iteration @ 5816 is 2.225937843322754\n",
      "Loss at Iteration @ 5817 is 2.313070774078369\n",
      "Evaluation Loss at Iteration @ 5817 is 2.252028226852417\n",
      "Loss at Iteration @ 5818 is 2.4906129837036133\n",
      "Evaluation Loss at Iteration @ 5818 is 2.256605625152588\n",
      "Loss at Iteration @ 5819 is 2.003746509552002\n",
      "Evaluation Loss at Iteration @ 5819 is 2.198270320892334\n",
      "Loss at Iteration @ 5820 is 2.209409236907959\n",
      "Evaluation Loss at Iteration @ 5820 is 2.2835099697113037\n",
      "Loss at Iteration @ 5821 is 2.2372124195098877\n",
      "Evaluation Loss at Iteration @ 5821 is 2.2924981117248535\n",
      "Loss at Iteration @ 5822 is 2.4143311977386475\n",
      "Evaluation Loss at Iteration @ 5822 is 2.265397548675537\n",
      "Loss at Iteration @ 5823 is 2.2895114421844482\n",
      "Evaluation Loss at Iteration @ 5823 is 2.273641586303711\n",
      "Loss at Iteration @ 5824 is 2.270453453063965\n",
      "Evaluation Loss at Iteration @ 5824 is 2.275787115097046\n",
      "Loss at Iteration @ 5825 is 2.1341946125030518\n",
      "Evaluation Loss at Iteration @ 5825 is 2.271716594696045\n",
      "Loss at Iteration @ 5826 is 2.29237699508667\n",
      "Evaluation Loss at Iteration @ 5826 is 2.255511522293091\n",
      "Loss at Iteration @ 5827 is 2.0973548889160156\n",
      "Evaluation Loss at Iteration @ 5827 is 2.261000871658325\n",
      "Loss at Iteration @ 5828 is 1.9862682819366455\n",
      "Evaluation Loss at Iteration @ 5828 is 2.2930259704589844\n",
      "Loss at Iteration @ 5829 is 2.219733953475952\n",
      "Evaluation Loss at Iteration @ 5829 is 2.2430639266967773\n",
      "Loss at Iteration @ 5830 is 2.6042518615722656\n",
      "Evaluation Loss at Iteration @ 5830 is 2.244039297103882\n",
      "Loss at Iteration @ 5831 is 2.115495204925537\n",
      "Evaluation Loss at Iteration @ 5831 is 2.3010308742523193\n",
      "Loss at Iteration @ 5832 is 2.365605115890503\n",
      "Evaluation Loss at Iteration @ 5832 is 2.240666389465332\n",
      "Loss at Iteration @ 5833 is 1.9276206493377686\n",
      "Evaluation Loss at Iteration @ 5833 is 2.2655837535858154\n",
      "Loss at Iteration @ 5834 is 2.1889426708221436\n",
      "Evaluation Loss at Iteration @ 5834 is 2.233020544052124\n",
      "Loss at Iteration @ 5835 is 2.3399159908294678\n",
      "Evaluation Loss at Iteration @ 5835 is 2.244063377380371\n",
      "Loss at Iteration @ 5836 is 2.494704484939575\n",
      "Evaluation Loss at Iteration @ 5836 is 2.263374090194702\n",
      "Loss at Iteration @ 5837 is 2.4498486518859863\n",
      "Evaluation Loss at Iteration @ 5837 is 2.2391278743743896\n",
      "Loss at Iteration @ 5838 is 2.528000831604004\n",
      "Evaluation Loss at Iteration @ 5838 is 2.2369697093963623\n",
      "Loss at Iteration @ 5839 is 2.0803067684173584\n",
      "Evaluation Loss at Iteration @ 5839 is 2.3057944774627686\n",
      "Loss at Iteration @ 5840 is 2.122943878173828\n",
      "Evaluation Loss at Iteration @ 5840 is 2.2337687015533447\n",
      "Loss at Iteration @ 5841 is 2.1989314556121826\n",
      "Evaluation Loss at Iteration @ 5841 is 2.2581257820129395\n",
      "Loss at Iteration @ 5842 is 2.151850938796997\n",
      "Evaluation Loss at Iteration @ 5842 is 2.251570463180542\n",
      "Loss at Iteration @ 5843 is 2.2718100547790527\n",
      "Evaluation Loss at Iteration @ 5843 is 2.2718026638031006\n",
      "Loss at Iteration @ 5844 is 2.690406560897827\n",
      "Evaluation Loss at Iteration @ 5844 is 2.2709579467773438\n",
      "Loss at Iteration @ 5845 is 2.3810155391693115\n",
      "Evaluation Loss at Iteration @ 5845 is 2.2327113151550293\n",
      "Loss at Iteration @ 5846 is 1.977765679359436\n",
      "Evaluation Loss at Iteration @ 5846 is 2.256326675415039\n",
      "Loss at Iteration @ 5847 is 2.358539342880249\n",
      "Evaluation Loss at Iteration @ 5847 is 2.2028300762176514\n",
      "Loss at Iteration @ 5848 is 2.2084145545959473\n",
      "Evaluation Loss at Iteration @ 5848 is 2.2555272579193115\n",
      "Loss at Iteration @ 5849 is 2.4981844425201416\n",
      "Evaluation Loss at Iteration @ 5849 is 2.2610714435577393\n",
      "Loss at Iteration @ 5850 is 2.0101499557495117\n",
      "Evaluation Loss at Iteration @ 5850 is 2.2602882385253906\n",
      "Loss at Iteration @ 5851 is 2.209409475326538\n",
      "Evaluation Loss at Iteration @ 5851 is 2.2740864753723145\n",
      "Loss at Iteration @ 5852 is 2.2940006256103516\n",
      "Evaluation Loss at Iteration @ 5852 is 2.2410266399383545\n",
      "Loss at Iteration @ 5853 is 2.098703384399414\n",
      "Evaluation Loss at Iteration @ 5853 is 2.282921075820923\n",
      "Loss at Iteration @ 5854 is 2.4237959384918213\n",
      "Evaluation Loss at Iteration @ 5854 is 2.240281820297241\n",
      "Loss at Iteration @ 5855 is 2.527085304260254\n",
      "Evaluation Loss at Iteration @ 5855 is 2.2672781944274902\n",
      "Loss at Iteration @ 5856 is 2.2478649616241455\n",
      "Evaluation Loss at Iteration @ 5856 is 2.202664852142334\n",
      "Loss at Iteration @ 5857 is 2.6236507892608643\n",
      "Evaluation Loss at Iteration @ 5857 is 2.2132036685943604\n",
      "Loss at Iteration @ 5858 is 2.18125581741333\n",
      "Evaluation Loss at Iteration @ 5858 is 2.2760367393493652\n",
      "Loss at Iteration @ 5859 is 2.262021780014038\n",
      "Evaluation Loss at Iteration @ 5859 is 2.215378999710083\n",
      "Loss at Iteration @ 5860 is 2.15838885307312\n",
      "Evaluation Loss at Iteration @ 5860 is 2.198732614517212\n",
      "Loss at Iteration @ 5861 is 2.1954290866851807\n",
      "Evaluation Loss at Iteration @ 5861 is 2.2095580101013184\n",
      "Loss at Iteration @ 5862 is 2.23530912399292\n",
      "Evaluation Loss at Iteration @ 5862 is 2.2084221839904785\n",
      "Loss at Iteration @ 5863 is 2.2382972240448\n",
      "Evaluation Loss at Iteration @ 5863 is 2.277794599533081\n",
      "Loss at Iteration @ 5864 is 1.8693797588348389\n",
      "Evaluation Loss at Iteration @ 5864 is 2.2262775897979736\n",
      "Loss at Iteration @ 5865 is 2.0492172241210938\n",
      "Evaluation Loss at Iteration @ 5865 is 2.2037131786346436\n",
      "Loss at Iteration @ 5866 is 2.182047128677368\n",
      "Evaluation Loss at Iteration @ 5866 is 2.23154354095459\n",
      "Loss at Iteration @ 5867 is 1.9386870861053467\n",
      "Evaluation Loss at Iteration @ 5867 is 2.272264242172241\n",
      "Loss at Iteration @ 5868 is 2.039376974105835\n",
      "Evaluation Loss at Iteration @ 5868 is 2.2724318504333496\n",
      "Loss at Iteration @ 5869 is 2.198021173477173\n",
      "Evaluation Loss at Iteration @ 5869 is 2.278334379196167\n",
      "Loss at Iteration @ 5870 is 2.386064291000366\n",
      "Evaluation Loss at Iteration @ 5870 is 2.2791600227355957\n",
      "Loss at Iteration @ 5871 is 2.4901745319366455\n",
      "Evaluation Loss at Iteration @ 5871 is 2.252119302749634\n",
      "Loss at Iteration @ 5872 is 2.3259055614471436\n",
      "Evaluation Loss at Iteration @ 5872 is 2.229825258255005\n",
      "Loss at Iteration @ 5873 is 2.2500922679901123\n",
      "Evaluation Loss at Iteration @ 5873 is 2.201204776763916\n",
      "Loss at Iteration @ 5874 is 2.1175882816314697\n",
      "Evaluation Loss at Iteration @ 5874 is 2.2691962718963623\n",
      "Loss at Iteration @ 5875 is 2.235581159591675\n",
      "Evaluation Loss at Iteration @ 5875 is 2.2255234718322754\n",
      "Loss at Iteration @ 5876 is 2.270918607711792\n",
      "Evaluation Loss at Iteration @ 5876 is 2.216017007827759\n",
      "Loss at Iteration @ 5877 is 2.2485907077789307\n",
      "Evaluation Loss at Iteration @ 5877 is 2.2796192169189453\n",
      "Loss at Iteration @ 5878 is 2.118910312652588\n",
      "Evaluation Loss at Iteration @ 5878 is 2.273942470550537\n",
      "Loss at Iteration @ 5879 is 2.2000787258148193\n",
      "Evaluation Loss at Iteration @ 5879 is 2.2921836376190186\n",
      "Loss at Iteration @ 5880 is 2.4282126426696777\n",
      "Evaluation Loss at Iteration @ 5880 is 2.2524607181549072\n",
      "Loss at Iteration @ 5881 is 2.280252695083618\n",
      "Evaluation Loss at Iteration @ 5881 is 2.2642815113067627\n",
      "Loss at Iteration @ 5882 is 2.277022123336792\n",
      "Evaluation Loss at Iteration @ 5882 is 2.2679765224456787\n",
      "Loss at Iteration @ 5883 is 2.2108213901519775\n",
      "Evaluation Loss at Iteration @ 5883 is 2.2546865940093994\n",
      "Loss at Iteration @ 5884 is 2.286099433898926\n",
      "Evaluation Loss at Iteration @ 5884 is 2.2722976207733154\n",
      "Loss at Iteration @ 5885 is 2.4883694648742676\n",
      "Evaluation Loss at Iteration @ 5885 is 2.28330135345459\n",
      "Loss at Iteration @ 5886 is 2.049875020980835\n",
      "Evaluation Loss at Iteration @ 5886 is 2.2494733333587646\n",
      "Loss at Iteration @ 5887 is 2.2344610691070557\n",
      "Evaluation Loss at Iteration @ 5887 is 2.218254566192627\n",
      "Loss at Iteration @ 5888 is 2.3973710536956787\n",
      "Evaluation Loss at Iteration @ 5888 is 2.2474863529205322\n",
      "Loss at Iteration @ 5889 is 2.0298614501953125\n",
      "Evaluation Loss at Iteration @ 5889 is 2.1971030235290527\n",
      "Loss at Iteration @ 5890 is 2.1744062900543213\n",
      "Evaluation Loss at Iteration @ 5890 is 2.22575044631958\n",
      "Loss at Iteration @ 5891 is 2.5459401607513428\n",
      "Evaluation Loss at Iteration @ 5891 is 2.276573419570923\n",
      "Loss at Iteration @ 5892 is 2.2247538566589355\n",
      "Evaluation Loss at Iteration @ 5892 is 2.2007362842559814\n",
      "Loss at Iteration @ 5893 is 2.3272483348846436\n",
      "Evaluation Loss at Iteration @ 5893 is 2.2460460662841797\n",
      "Loss at Iteration @ 5894 is 2.1868410110473633\n",
      "Evaluation Loss at Iteration @ 5894 is 2.260221004486084\n",
      "Loss at Iteration @ 5895 is 2.187124013900757\n",
      "Evaluation Loss at Iteration @ 5895 is 2.2347185611724854\n",
      "Loss at Iteration @ 5896 is 2.0821123123168945\n",
      "Evaluation Loss at Iteration @ 5896 is 2.229342222213745\n",
      "Loss at Iteration @ 5897 is 2.3844797611236572\n",
      "Evaluation Loss at Iteration @ 5897 is 2.324869394302368\n",
      "Loss at Iteration @ 5898 is 2.0982818603515625\n",
      "Evaluation Loss at Iteration @ 5898 is 2.1845223903656006\n",
      "Loss at Iteration @ 5899 is 2.2298460006713867\n",
      "Evaluation Loss at Iteration @ 5899 is 2.2637276649475098\n",
      "Loss at Iteration @ 5900 is 2.125657081604004\n",
      "Evaluation Loss at Iteration @ 5900 is 2.2213551998138428\n",
      "Loss at Iteration @ 5901 is 2.2751364707946777\n",
      "Evaluation Loss at Iteration @ 5901 is 2.282148838043213\n",
      "Loss at Iteration @ 5902 is 2.0143399238586426\n",
      "Evaluation Loss at Iteration @ 5902 is 2.234707832336426\n",
      "Loss at Iteration @ 5903 is 2.4640798568725586\n",
      "Evaluation Loss at Iteration @ 5903 is 2.2502496242523193\n",
      "Loss at Iteration @ 5904 is 2.0860886573791504\n",
      "Evaluation Loss at Iteration @ 5904 is 2.279306650161743\n",
      "Loss at Iteration @ 5905 is 2.2221672534942627\n",
      "Evaluation Loss at Iteration @ 5905 is 2.253887176513672\n",
      "Loss at Iteration @ 5906 is 2.281759738922119\n",
      "Evaluation Loss at Iteration @ 5906 is 2.2546026706695557\n",
      "Loss at Iteration @ 5907 is 2.2541778087615967\n",
      "Evaluation Loss at Iteration @ 5907 is 2.215686082839966\n",
      "Loss at Iteration @ 5908 is 2.2892813682556152\n",
      "Evaluation Loss at Iteration @ 5908 is 2.2769229412078857\n",
      "Loss at Iteration @ 5909 is 2.0643820762634277\n",
      "Evaluation Loss at Iteration @ 5909 is 2.2484335899353027\n",
      "Loss at Iteration @ 5910 is 2.0080032348632812\n",
      "Evaluation Loss at Iteration @ 5910 is 2.1928696632385254\n",
      "Loss at Iteration @ 5911 is 2.38667893409729\n",
      "Evaluation Loss at Iteration @ 5911 is 2.2528975009918213\n",
      "Loss at Iteration @ 5912 is 2.2594046592712402\n",
      "Evaluation Loss at Iteration @ 5912 is 2.252082109451294\n",
      "Loss at Iteration @ 5913 is 2.2414441108703613\n",
      "Evaluation Loss at Iteration @ 5913 is 2.2553460597991943\n",
      "Loss at Iteration @ 5914 is 1.818070650100708\n",
      "Evaluation Loss at Iteration @ 5914 is 2.2299423217773438\n",
      "Loss at Iteration @ 5915 is 2.2281246185302734\n",
      "Evaluation Loss at Iteration @ 5915 is 2.1943960189819336\n",
      "Loss at Iteration @ 5916 is 2.4673912525177\n",
      "Evaluation Loss at Iteration @ 5916 is 2.202101469039917\n",
      "Loss at Iteration @ 5917 is 1.9765769243240356\n",
      "Evaluation Loss at Iteration @ 5917 is 2.224992036819458\n",
      "Loss at Iteration @ 5918 is 2.156858444213867\n",
      "Evaluation Loss at Iteration @ 5918 is 2.2669811248779297\n",
      "Loss at Iteration @ 5919 is 2.3480637073516846\n",
      "Evaluation Loss at Iteration @ 5919 is 2.263113021850586\n",
      "Loss at Iteration @ 5920 is 1.8599750995635986\n",
      "Evaluation Loss at Iteration @ 5920 is 2.234100580215454\n",
      "Loss at Iteration @ 5921 is 2.0609610080718994\n",
      "Evaluation Loss at Iteration @ 5921 is 2.269577741622925\n",
      "Loss at Iteration @ 5922 is 2.0426173210144043\n",
      "Evaluation Loss at Iteration @ 5922 is 2.246293306350708\n",
      "Loss at Iteration @ 5923 is 2.18100643157959\n",
      "Evaluation Loss at Iteration @ 5923 is 2.2542240619659424\n",
      "Loss at Iteration @ 5924 is 2.18678879737854\n",
      "Evaluation Loss at Iteration @ 5924 is 2.2754523754119873\n",
      "Loss at Iteration @ 5925 is 2.297023296356201\n",
      "Evaluation Loss at Iteration @ 5925 is 2.2286453247070312\n",
      "Loss at Iteration @ 5926 is 2.354471206665039\n",
      "Evaluation Loss at Iteration @ 5926 is 2.3082692623138428\n",
      "Loss at Iteration @ 5927 is 2.2322096824645996\n",
      "Evaluation Loss at Iteration @ 5927 is 2.2382395267486572\n",
      "Loss at Iteration @ 5928 is 1.9673106670379639\n",
      "Evaluation Loss at Iteration @ 5928 is 2.221339225769043\n",
      "Loss at Iteration @ 5929 is 1.949447751045227\n",
      "Evaluation Loss at Iteration @ 5929 is 2.250973701477051\n",
      "Loss at Iteration @ 5930 is 2.103405714035034\n",
      "Evaluation Loss at Iteration @ 5930 is 2.205460548400879\n",
      "Loss at Iteration @ 5931 is 2.1556954383850098\n",
      "Evaluation Loss at Iteration @ 5931 is 2.2462122440338135\n",
      "Loss at Iteration @ 5932 is 2.458014488220215\n",
      "Evaluation Loss at Iteration @ 5932 is 2.2879137992858887\n",
      "Loss at Iteration @ 5933 is 2.5424997806549072\n",
      "Evaluation Loss at Iteration @ 5933 is 2.2296900749206543\n",
      "Loss at Iteration @ 5934 is 2.4003429412841797\n",
      "Evaluation Loss at Iteration @ 5934 is 2.2572989463806152\n",
      "Loss at Iteration @ 5935 is 2.3434243202209473\n",
      "Evaluation Loss at Iteration @ 5935 is 2.2622408866882324\n",
      "Loss at Iteration @ 5936 is 2.3248653411865234\n",
      "Evaluation Loss at Iteration @ 5936 is 2.295236587524414\n",
      "Loss at Iteration @ 5937 is 2.2239043712615967\n",
      "Evaluation Loss at Iteration @ 5937 is 2.2411439418792725\n",
      "Loss at Iteration @ 5938 is 2.159458875656128\n",
      "Evaluation Loss at Iteration @ 5938 is 2.2183361053466797\n",
      "Loss at Iteration @ 5939 is 2.261415481567383\n",
      "Evaluation Loss at Iteration @ 5939 is 2.2581090927124023\n",
      "Loss at Iteration @ 5940 is 2.2283153533935547\n",
      "Evaluation Loss at Iteration @ 5940 is 2.257612943649292\n",
      "Loss at Iteration @ 5941 is 2.2183358669281006\n",
      "Evaluation Loss at Iteration @ 5941 is 2.23759388923645\n",
      "Loss at Iteration @ 5942 is 2.0239288806915283\n",
      "Evaluation Loss at Iteration @ 5942 is 2.2763004302978516\n",
      "Loss at Iteration @ 5943 is 2.020071268081665\n",
      "Evaluation Loss at Iteration @ 5943 is 2.262765645980835\n",
      "Loss at Iteration @ 5944 is 2.162947177886963\n",
      "Evaluation Loss at Iteration @ 5944 is 2.255526304244995\n",
      "Loss at Iteration @ 5945 is 2.1650795936584473\n",
      "Evaluation Loss at Iteration @ 5945 is 2.2359673976898193\n",
      "Loss at Iteration @ 5946 is 2.259627342224121\n",
      "Evaluation Loss at Iteration @ 5946 is 2.278116464614868\n",
      "Loss at Iteration @ 5947 is 2.300812005996704\n",
      "Evaluation Loss at Iteration @ 5947 is 2.2405598163604736\n",
      "Loss at Iteration @ 5948 is 2.283243417739868\n",
      "Evaluation Loss at Iteration @ 5948 is 2.2277581691741943\n",
      "Loss at Iteration @ 5949 is 2.166611909866333\n",
      "Evaluation Loss at Iteration @ 5949 is 2.269946336746216\n",
      "Loss at Iteration @ 5950 is 2.2706475257873535\n",
      "Evaluation Loss at Iteration @ 5950 is 2.2524962425231934\n",
      "Loss at Iteration @ 5951 is 2.1330626010894775\n",
      "Evaluation Loss at Iteration @ 5951 is 2.2726824283599854\n",
      "Loss at Iteration @ 5952 is 2.2615013122558594\n",
      "Evaluation Loss at Iteration @ 5952 is 2.24004864692688\n",
      "Loss at Iteration @ 5953 is 2.2379255294799805\n",
      "Evaluation Loss at Iteration @ 5953 is 2.287025213241577\n",
      "Loss at Iteration @ 5954 is 1.9955123662948608\n",
      "Evaluation Loss at Iteration @ 5954 is 2.280592441558838\n",
      "Loss at Iteration @ 5955 is 2.380317211151123\n",
      "Evaluation Loss at Iteration @ 5955 is 2.2235560417175293\n",
      "Loss at Iteration @ 5956 is 2.2516183853149414\n",
      "Evaluation Loss at Iteration @ 5956 is 2.283876895904541\n",
      "Loss at Iteration @ 5957 is 2.4590771198272705\n",
      "Evaluation Loss at Iteration @ 5957 is 2.2681660652160645\n",
      "Loss at Iteration @ 5958 is 2.364778757095337\n",
      "Evaluation Loss at Iteration @ 5958 is 2.2380001544952393\n",
      "Loss at Iteration @ 5959 is 2.144347667694092\n",
      "Evaluation Loss at Iteration @ 5959 is 2.2638461589813232\n",
      "Loss at Iteration @ 5960 is 2.161792755126953\n",
      "Evaluation Loss at Iteration @ 5960 is 2.272479295730591\n",
      "Loss at Iteration @ 5961 is 2.2428903579711914\n",
      "Evaluation Loss at Iteration @ 5961 is 2.224137783050537\n",
      "Loss at Iteration @ 5962 is 2.279165267944336\n",
      "Evaluation Loss at Iteration @ 5962 is 2.2370388507843018\n",
      "Loss at Iteration @ 5963 is 2.20060396194458\n",
      "Evaluation Loss at Iteration @ 5963 is 2.2081546783447266\n",
      "Loss at Iteration @ 5964 is 2.0851426124572754\n",
      "Evaluation Loss at Iteration @ 5964 is 2.2106854915618896\n",
      "Loss at Iteration @ 5965 is 2.2837061882019043\n",
      "Evaluation Loss at Iteration @ 5965 is 2.2416396141052246\n",
      "Loss at Iteration @ 5966 is 2.32633113861084\n",
      "Evaluation Loss at Iteration @ 5966 is 2.2187612056732178\n",
      "Loss at Iteration @ 5967 is 2.039036989212036\n",
      "Evaluation Loss at Iteration @ 5967 is 2.241312026977539\n",
      "Loss at Iteration @ 5968 is 2.3252131938934326\n",
      "Evaluation Loss at Iteration @ 5968 is 2.2684342861175537\n",
      "Loss at Iteration @ 5969 is 2.4907188415527344\n",
      "Evaluation Loss at Iteration @ 5969 is 2.304377317428589\n",
      "Loss at Iteration @ 5970 is 2.304841995239258\n",
      "Evaluation Loss at Iteration @ 5970 is 2.2457118034362793\n",
      "Loss at Iteration @ 5971 is 2.389976978302002\n",
      "Evaluation Loss at Iteration @ 5971 is 2.2843728065490723\n",
      "Loss at Iteration @ 5972 is 2.4124033451080322\n",
      "Evaluation Loss at Iteration @ 5972 is 2.2490453720092773\n",
      "Loss at Iteration @ 5973 is 2.171909809112549\n",
      "Evaluation Loss at Iteration @ 5973 is 2.1958084106445312\n",
      "Loss at Iteration @ 5974 is 2.2102389335632324\n",
      "Evaluation Loss at Iteration @ 5974 is 2.252141237258911\n",
      "Loss at Iteration @ 5975 is 2.213606119155884\n",
      "Evaluation Loss at Iteration @ 5975 is 2.262063503265381\n",
      "Loss at Iteration @ 5976 is 2.4928386211395264\n",
      "Evaluation Loss at Iteration @ 5976 is 2.292170763015747\n",
      "Loss at Iteration @ 5977 is 2.2502548694610596\n",
      "Evaluation Loss at Iteration @ 5977 is 2.2258453369140625\n",
      "Loss at Iteration @ 5978 is 2.182394027709961\n",
      "Evaluation Loss at Iteration @ 5978 is 2.2466206550598145\n",
      "Loss at Iteration @ 5979 is 2.2516987323760986\n",
      "Evaluation Loss at Iteration @ 5979 is 2.2610106468200684\n",
      "Loss at Iteration @ 5980 is 2.405195474624634\n",
      "Evaluation Loss at Iteration @ 5980 is 2.2336502075195312\n",
      "Loss at Iteration @ 5981 is 2.214418411254883\n",
      "Evaluation Loss at Iteration @ 5981 is 2.272202491760254\n",
      "Loss at Iteration @ 5982 is 2.23142671585083\n",
      "Evaluation Loss at Iteration @ 5982 is 2.3034908771514893\n",
      "Loss at Iteration @ 5983 is 2.209416151046753\n",
      "Evaluation Loss at Iteration @ 5983 is 2.2166154384613037\n",
      "Loss at Iteration @ 5984 is 2.469430923461914\n",
      "Evaluation Loss at Iteration @ 5984 is 2.2371294498443604\n",
      "Loss at Iteration @ 5985 is 2.1225314140319824\n",
      "Evaluation Loss at Iteration @ 5985 is 2.2993438243865967\n",
      "Loss at Iteration @ 5986 is 2.1838245391845703\n",
      "Evaluation Loss at Iteration @ 5986 is 2.2635252475738525\n",
      "Loss at Iteration @ 5987 is 2.299703359603882\n",
      "Evaluation Loss at Iteration @ 5987 is 2.270693302154541\n",
      "Loss at Iteration @ 5988 is 2.1013174057006836\n",
      "Evaluation Loss at Iteration @ 5988 is 2.2857840061187744\n",
      "Loss at Iteration @ 5989 is 2.1489458084106445\n",
      "Evaluation Loss at Iteration @ 5989 is 2.2713735103607178\n",
      "Loss at Iteration @ 5990 is 2.2835092544555664\n",
      "Evaluation Loss at Iteration @ 5990 is 2.2383124828338623\n",
      "Loss at Iteration @ 5991 is 2.3354721069335938\n",
      "Evaluation Loss at Iteration @ 5991 is 2.2637858390808105\n",
      "Loss at Iteration @ 5992 is 2.079169273376465\n",
      "Evaluation Loss at Iteration @ 5992 is 2.259801149368286\n",
      "Loss at Iteration @ 5993 is 2.332341194152832\n",
      "Evaluation Loss at Iteration @ 5993 is 2.2557523250579834\n",
      "Loss at Iteration @ 5994 is 1.9812482595443726\n",
      "Evaluation Loss at Iteration @ 5994 is 2.239724636077881\n",
      "Loss at Iteration @ 5995 is 2.3606932163238525\n",
      "Evaluation Loss at Iteration @ 5995 is 2.266737699508667\n",
      "Loss at Iteration @ 5996 is 2.130749464035034\n",
      "Evaluation Loss at Iteration @ 5996 is 2.231532335281372\n",
      "Loss at Iteration @ 5997 is 2.159400224685669\n",
      "Evaluation Loss at Iteration @ 5997 is 2.2458817958831787\n",
      "Loss at Iteration @ 5998 is 2.281693935394287\n",
      "Evaluation Loss at Iteration @ 5998 is 2.2759339809417725\n",
      "Loss at Iteration @ 5999 is 2.377746343612671\n",
      "Evaluation Loss at Iteration @ 5999 is 2.226363182067871\n",
      "Loss at Iteration @ 6000 is 2.506192684173584\n",
      "Evaluation Loss at Iteration @ 6000 is 2.2478466033935547\n",
      "Loss at Iteration @ 6001 is 1.937048316001892\n",
      "Evaluation Loss at Iteration @ 6001 is 2.257086992263794\n",
      "Loss at Iteration @ 6002 is 2.3568520545959473\n",
      "Evaluation Loss at Iteration @ 6002 is 2.246946334838867\n",
      "Loss at Iteration @ 6003 is 2.41583251953125\n",
      "Evaluation Loss at Iteration @ 6003 is 2.2607619762420654\n",
      "Loss at Iteration @ 6004 is 2.4677162170410156\n",
      "Evaluation Loss at Iteration @ 6004 is 2.243551254272461\n",
      "Loss at Iteration @ 6005 is 2.589301824569702\n",
      "Evaluation Loss at Iteration @ 6005 is 2.25331711769104\n",
      "Loss at Iteration @ 6006 is 2.510174036026001\n",
      "Evaluation Loss at Iteration @ 6006 is 2.3069677352905273\n",
      "Loss at Iteration @ 6007 is 2.136791229248047\n",
      "Evaluation Loss at Iteration @ 6007 is 2.2088735103607178\n",
      "Loss at Iteration @ 6008 is 2.713697910308838\n",
      "Evaluation Loss at Iteration @ 6008 is 2.2590606212615967\n",
      "Loss at Iteration @ 6009 is 2.307356834411621\n",
      "Evaluation Loss at Iteration @ 6009 is 2.26080322265625\n",
      "Loss at Iteration @ 6010 is 2.2500884532928467\n",
      "Evaluation Loss at Iteration @ 6010 is 2.239170789718628\n",
      "Loss at Iteration @ 6011 is 2.256281614303589\n",
      "Evaluation Loss at Iteration @ 6011 is 2.236762523651123\n",
      "Loss at Iteration @ 6012 is 2.299539089202881\n",
      "Evaluation Loss at Iteration @ 6012 is 2.2289531230926514\n",
      "Loss at Iteration @ 6013 is 2.248821258544922\n",
      "Evaluation Loss at Iteration @ 6013 is 2.229788303375244\n",
      "Loss at Iteration @ 6014 is 2.1861958503723145\n",
      "Evaluation Loss at Iteration @ 6014 is 2.2334887981414795\n",
      "Loss at Iteration @ 6015 is 2.0711207389831543\n",
      "Evaluation Loss at Iteration @ 6015 is 2.273097515106201\n",
      "Loss at Iteration @ 6016 is 2.184459686279297\n",
      "Evaluation Loss at Iteration @ 6016 is 2.287954568862915\n",
      "Loss at Iteration @ 6017 is 2.1443533897399902\n",
      "Evaluation Loss at Iteration @ 6017 is 2.2436585426330566\n",
      "Loss at Iteration @ 6018 is 2.282907485961914\n",
      "Evaluation Loss at Iteration @ 6018 is 2.249610185623169\n",
      "Loss at Iteration @ 6019 is 2.3706228733062744\n",
      "Evaluation Loss at Iteration @ 6019 is 2.271585702896118\n",
      "Loss at Iteration @ 6020 is 2.1046676635742188\n",
      "Evaluation Loss at Iteration @ 6020 is 2.285496234893799\n",
      "Loss at Iteration @ 6021 is 2.471331834793091\n",
      "Evaluation Loss at Iteration @ 6021 is 2.2087457180023193\n",
      "Loss at Iteration @ 6022 is 2.0831170082092285\n",
      "Evaluation Loss at Iteration @ 6022 is 2.231659173965454\n",
      "Loss at Iteration @ 6023 is 2.1219677925109863\n",
      "Evaluation Loss at Iteration @ 6023 is 2.2261993885040283\n",
      "Loss at Iteration @ 6024 is 2.2336132526397705\n",
      "Evaluation Loss at Iteration @ 6024 is 2.234586238861084\n",
      "Loss at Iteration @ 6025 is 2.0425212383270264\n",
      "Evaluation Loss at Iteration @ 6025 is 2.235848903656006\n",
      "Loss at Iteration @ 6026 is 2.306114673614502\n",
      "Evaluation Loss at Iteration @ 6026 is 2.1962616443634033\n",
      "Loss at Iteration @ 6027 is 2.1892683506011963\n",
      "Evaluation Loss at Iteration @ 6027 is 2.2197928428649902\n",
      "Loss at Iteration @ 6028 is 2.2776637077331543\n",
      "Evaluation Loss at Iteration @ 6028 is 2.257866859436035\n",
      "Loss at Iteration @ 6029 is 2.3212087154388428\n",
      "Evaluation Loss at Iteration @ 6029 is 2.234670400619507\n",
      "Loss at Iteration @ 6030 is 2.1526267528533936\n",
      "Evaluation Loss at Iteration @ 6030 is 2.26495361328125\n",
      "Loss at Iteration @ 6031 is 2.3672759532928467\n",
      "Evaluation Loss at Iteration @ 6031 is 2.223170280456543\n",
      "Loss at Iteration @ 6032 is 2.0559370517730713\n",
      "Evaluation Loss at Iteration @ 6032 is 2.3278825283050537\n",
      "Loss at Iteration @ 6033 is 2.0343973636627197\n",
      "Evaluation Loss at Iteration @ 6033 is 2.2725272178649902\n",
      "Loss at Iteration @ 6034 is 2.0687921047210693\n",
      "Evaluation Loss at Iteration @ 6034 is 2.2306501865386963\n",
      "Loss at Iteration @ 6035 is 2.400294303894043\n",
      "Evaluation Loss at Iteration @ 6035 is 2.2631659507751465\n",
      "Loss at Iteration @ 6036 is 2.359966278076172\n",
      "Evaluation Loss at Iteration @ 6036 is 2.1918137073516846\n",
      "Loss at Iteration @ 6037 is 2.1257107257843018\n",
      "Evaluation Loss at Iteration @ 6037 is 2.2062950134277344\n",
      "Loss at Iteration @ 6038 is 2.236743927001953\n",
      "Evaluation Loss at Iteration @ 6038 is 2.2518229484558105\n",
      "Loss at Iteration @ 6039 is 1.9214805364608765\n",
      "Evaluation Loss at Iteration @ 6039 is 2.2887043952941895\n",
      "Loss at Iteration @ 6040 is 2.190589427947998\n",
      "Evaluation Loss at Iteration @ 6040 is 2.2815423011779785\n",
      "Loss at Iteration @ 6041 is 2.129068613052368\n",
      "Evaluation Loss at Iteration @ 6041 is 2.2228567600250244\n",
      "Loss at Iteration @ 6042 is 2.153029680252075\n",
      "Evaluation Loss at Iteration @ 6042 is 2.215256452560425\n",
      "Loss at Iteration @ 6043 is 2.59792423248291\n",
      "Evaluation Loss at Iteration @ 6043 is 2.213409423828125\n",
      "Loss at Iteration @ 6044 is 2.2869713306427\n",
      "Evaluation Loss at Iteration @ 6044 is 2.2541604042053223\n",
      "Loss at Iteration @ 6045 is 2.198373794555664\n",
      "Evaluation Loss at Iteration @ 6045 is 2.276170015335083\n",
      "Loss at Iteration @ 6046 is 2.3062562942504883\n",
      "Evaluation Loss at Iteration @ 6046 is 2.2603886127471924\n",
      "Loss at Iteration @ 6047 is 2.4818074703216553\n",
      "Evaluation Loss at Iteration @ 6047 is 2.282536506652832\n",
      "Loss at Iteration @ 6048 is 2.3739731311798096\n",
      "Evaluation Loss at Iteration @ 6048 is 2.2460403442382812\n",
      "Loss at Iteration @ 6049 is 2.1540398597717285\n",
      "Evaluation Loss at Iteration @ 6049 is 2.228024959564209\n",
      "Loss at Iteration @ 6050 is 2.3080084323883057\n",
      "Evaluation Loss at Iteration @ 6050 is 2.2206568717956543\n",
      "Loss at Iteration @ 6051 is 2.0334908962249756\n",
      "Evaluation Loss at Iteration @ 6051 is 2.237730026245117\n",
      "Loss at Iteration @ 6052 is 2.322626829147339\n",
      "Evaluation Loss at Iteration @ 6052 is 2.2597153186798096\n",
      "Loss at Iteration @ 6053 is 2.2904651165008545\n",
      "Evaluation Loss at Iteration @ 6053 is 2.271759033203125\n",
      "Loss at Iteration @ 6054 is 2.2836785316467285\n",
      "Evaluation Loss at Iteration @ 6054 is 2.2441563606262207\n",
      "Loss at Iteration @ 6055 is 2.3479785919189453\n",
      "Evaluation Loss at Iteration @ 6055 is 2.2097537517547607\n",
      "Loss at Iteration @ 6056 is 2.38970947265625\n",
      "Evaluation Loss at Iteration @ 6056 is 2.297621965408325\n",
      "Loss at Iteration @ 6057 is 2.049572467803955\n",
      "Evaluation Loss at Iteration @ 6057 is 2.266880512237549\n",
      "Loss at Iteration @ 6058 is 2.1302525997161865\n",
      "Evaluation Loss at Iteration @ 6058 is 2.2703404426574707\n",
      "Loss at Iteration @ 6059 is 2.248894453048706\n",
      "Evaluation Loss at Iteration @ 6059 is 2.2695329189300537\n",
      "Loss at Iteration @ 6060 is 2.2660019397735596\n",
      "Evaluation Loss at Iteration @ 6060 is 2.242253303527832\n",
      "Loss at Iteration @ 6061 is 2.4480605125427246\n",
      "Evaluation Loss at Iteration @ 6061 is 2.2842276096343994\n",
      "Loss at Iteration @ 6062 is 2.3579318523406982\n",
      "Evaluation Loss at Iteration @ 6062 is 2.2691848278045654\n",
      "Loss at Iteration @ 6063 is 2.5434625148773193\n",
      "Evaluation Loss at Iteration @ 6063 is 2.254969596862793\n",
      "Loss at Iteration @ 6064 is 2.3947641849517822\n",
      "Evaluation Loss at Iteration @ 6064 is 2.244293451309204\n",
      "Loss at Iteration @ 6065 is 2.282119035720825\n",
      "Evaluation Loss at Iteration @ 6065 is 2.27785587310791\n",
      "Loss at Iteration @ 6066 is 2.2206685543060303\n",
      "Evaluation Loss at Iteration @ 6066 is 2.2353432178497314\n",
      "Loss at Iteration @ 6067 is 2.3617148399353027\n",
      "Evaluation Loss at Iteration @ 6067 is 2.238013505935669\n",
      "Loss at Iteration @ 6068 is 2.19364857673645\n",
      "Evaluation Loss at Iteration @ 6068 is 2.2702014446258545\n",
      "Loss at Iteration @ 6069 is 2.2927603721618652\n",
      "Evaluation Loss at Iteration @ 6069 is 2.225109815597534\n",
      "Loss at Iteration @ 6070 is 2.2642667293548584\n",
      "Evaluation Loss at Iteration @ 6070 is 2.245854616165161\n",
      "Loss at Iteration @ 6071 is 2.2822303771972656\n",
      "Evaluation Loss at Iteration @ 6071 is 2.230299711227417\n",
      "Loss at Iteration @ 6072 is 2.650508403778076\n",
      "Evaluation Loss at Iteration @ 6072 is 2.2509517669677734\n",
      "Loss at Iteration @ 6073 is 2.36924409866333\n",
      "Evaluation Loss at Iteration @ 6073 is 2.2474968433380127\n",
      "Loss at Iteration @ 6074 is 2.307776927947998\n",
      "Evaluation Loss at Iteration @ 6074 is 2.28315806388855\n",
      "Loss at Iteration @ 6075 is 2.4874298572540283\n",
      "Evaluation Loss at Iteration @ 6075 is 2.242543935775757\n",
      "Loss at Iteration @ 6076 is 2.4078073501586914\n",
      "Evaluation Loss at Iteration @ 6076 is 2.2544331550598145\n",
      "Loss at Iteration @ 6077 is 2.392019033432007\n",
      "Evaluation Loss at Iteration @ 6077 is 2.22810697555542\n",
      "Loss at Iteration @ 6078 is 2.3725082874298096\n",
      "Evaluation Loss at Iteration @ 6078 is 2.233445882797241\n",
      "Loss at Iteration @ 6079 is 2.4076828956604004\n",
      "Evaluation Loss at Iteration @ 6079 is 2.294257640838623\n",
      "Loss at Iteration @ 6080 is 2.1185944080352783\n",
      "Evaluation Loss at Iteration @ 6080 is 2.2204606533050537\n",
      "Loss at Iteration @ 6081 is 2.3292720317840576\n",
      "Evaluation Loss at Iteration @ 6081 is 2.2352635860443115\n",
      "Loss at Iteration @ 6082 is 2.4024555683135986\n",
      "Evaluation Loss at Iteration @ 6082 is 2.2968101501464844\n",
      "Loss at Iteration @ 6083 is 2.1610219478607178\n",
      "Evaluation Loss at Iteration @ 6083 is 2.2176198959350586\n",
      "Loss at Iteration @ 6084 is 2.6476385593414307\n",
      "Evaluation Loss at Iteration @ 6084 is 2.2705671787261963\n",
      "Loss at Iteration @ 6085 is 2.3687174320220947\n",
      "Evaluation Loss at Iteration @ 6085 is 2.2900514602661133\n",
      "Loss at Iteration @ 6086 is 2.1811039447784424\n",
      "Evaluation Loss at Iteration @ 6086 is 2.2005715370178223\n",
      "Loss at Iteration @ 6087 is 2.2734148502349854\n",
      "Evaluation Loss at Iteration @ 6087 is 2.239071846008301\n",
      "Loss at Iteration @ 6088 is 2.2506558895111084\n",
      "Evaluation Loss at Iteration @ 6088 is 2.234501600265503\n",
      "Loss at Iteration @ 6089 is 2.454638957977295\n",
      "Evaluation Loss at Iteration @ 6089 is 2.251206398010254\n",
      "Loss at Iteration @ 6090 is 2.254021406173706\n",
      "Evaluation Loss at Iteration @ 6090 is 2.2378969192504883\n",
      "Loss at Iteration @ 6091 is 2.26261043548584\n",
      "Evaluation Loss at Iteration @ 6091 is 2.2576653957366943\n",
      "Loss at Iteration @ 6092 is 2.1619880199432373\n",
      "Evaluation Loss at Iteration @ 6092 is 2.2375943660736084\n",
      "Loss at Iteration @ 6093 is 2.1356070041656494\n",
      "Evaluation Loss at Iteration @ 6093 is 2.2579503059387207\n",
      "Loss at Iteration @ 6094 is 2.188883066177368\n",
      "Evaluation Loss at Iteration @ 6094 is 2.2370834350585938\n",
      "Loss at Iteration @ 6095 is 2.44655704498291\n",
      "Evaluation Loss at Iteration @ 6095 is 2.2965314388275146\n",
      "Loss at Iteration @ 6096 is 2.316174268722534\n",
      "Evaluation Loss at Iteration @ 6096 is 2.2665016651153564\n",
      "Loss at Iteration @ 6097 is 2.2300848960876465\n",
      "Evaluation Loss at Iteration @ 6097 is 2.2850661277770996\n",
      "Loss at Iteration @ 6098 is 2.0724709033966064\n",
      "Evaluation Loss at Iteration @ 6098 is 2.2533328533172607\n",
      "Loss at Iteration @ 6099 is 1.897913932800293\n",
      "Evaluation Loss at Iteration @ 6099 is 2.2351269721984863\n",
      "Loss at Iteration @ 6100 is 2.2813920974731445\n",
      "Evaluation Loss at Iteration @ 6100 is 2.220804452896118\n",
      "Loss at Iteration @ 6101 is 2.2443273067474365\n",
      "Evaluation Loss at Iteration @ 6101 is 2.247911214828491\n",
      "Loss at Iteration @ 6102 is 2.1626334190368652\n",
      "Evaluation Loss at Iteration @ 6102 is 2.2491118907928467\n",
      "Loss at Iteration @ 6103 is 2.582001209259033\n",
      "Evaluation Loss at Iteration @ 6103 is 2.2322566509246826\n",
      "Loss at Iteration @ 6104 is 2.488917350769043\n",
      "Evaluation Loss at Iteration @ 6104 is 2.247448205947876\n",
      "Loss at Iteration @ 6105 is 2.1512584686279297\n",
      "Evaluation Loss at Iteration @ 6105 is 2.2578654289245605\n",
      "Loss at Iteration @ 6106 is 2.159669876098633\n",
      "Evaluation Loss at Iteration @ 6106 is 2.256953239440918\n",
      "Loss at Iteration @ 6107 is 2.2238078117370605\n",
      "Evaluation Loss at Iteration @ 6107 is 2.197702646255493\n",
      "Loss at Iteration @ 6108 is 2.1965839862823486\n",
      "Evaluation Loss at Iteration @ 6108 is 2.2698934078216553\n",
      "Loss at Iteration @ 6109 is 2.177907705307007\n",
      "Evaluation Loss at Iteration @ 6109 is 2.220907211303711\n",
      "Loss at Iteration @ 6110 is 2.682004451751709\n",
      "Evaluation Loss at Iteration @ 6110 is 2.219865322113037\n",
      "Loss at Iteration @ 6111 is 2.161738634109497\n",
      "Evaluation Loss at Iteration @ 6111 is 2.2619500160217285\n",
      "Loss at Iteration @ 6112 is 2.3363356590270996\n",
      "Evaluation Loss at Iteration @ 6112 is 2.282440185546875\n",
      "Loss at Iteration @ 6113 is 2.059885025024414\n",
      "Evaluation Loss at Iteration @ 6113 is 2.253594160079956\n",
      "Loss at Iteration @ 6114 is 2.2366862297058105\n",
      "Evaluation Loss at Iteration @ 6114 is 2.2560393810272217\n",
      "Loss at Iteration @ 6115 is 2.2192301750183105\n",
      "Evaluation Loss at Iteration @ 6115 is 2.2641711235046387\n",
      "Loss at Iteration @ 6116 is 2.1792285442352295\n",
      "Evaluation Loss at Iteration @ 6116 is 2.2842559814453125\n",
      "Loss at Iteration @ 6117 is 2.2152867317199707\n",
      "Evaluation Loss at Iteration @ 6117 is 2.239635944366455\n",
      "Loss at Iteration @ 6118 is 2.2663490772247314\n",
      "Evaluation Loss at Iteration @ 6118 is 2.231144905090332\n",
      "Loss at Iteration @ 6119 is 2.3741824626922607\n",
      "Evaluation Loss at Iteration @ 6119 is 2.2643768787384033\n",
      "Loss at Iteration @ 6120 is 2.3644773960113525\n",
      "Evaluation Loss at Iteration @ 6120 is 2.2251760959625244\n",
      "Loss at Iteration @ 6121 is 2.099841833114624\n",
      "Evaluation Loss at Iteration @ 6121 is 2.242276191711426\n",
      "Loss at Iteration @ 6122 is 2.3776540756225586\n",
      "Evaluation Loss at Iteration @ 6122 is 2.228440761566162\n",
      "Loss at Iteration @ 6123 is 2.20982027053833\n",
      "Evaluation Loss at Iteration @ 6123 is 2.1833178997039795\n",
      "Loss at Iteration @ 6124 is 2.5372986793518066\n",
      "Evaluation Loss at Iteration @ 6124 is 2.2355988025665283\n",
      "Loss at Iteration @ 6125 is 2.2943499088287354\n",
      "Evaluation Loss at Iteration @ 6125 is 2.2658846378326416\n",
      "Loss at Iteration @ 6126 is 1.9695502519607544\n",
      "Evaluation Loss at Iteration @ 6126 is 2.24959397315979\n",
      "Loss at Iteration @ 6127 is 2.133608818054199\n",
      "Evaluation Loss at Iteration @ 6127 is 2.292912721633911\n",
      "Loss at Iteration @ 6128 is 2.240403890609741\n",
      "Evaluation Loss at Iteration @ 6128 is 2.2182559967041016\n",
      "Loss at Iteration @ 6129 is 2.0964417457580566\n",
      "Evaluation Loss at Iteration @ 6129 is 2.2647249698638916\n",
      "Loss at Iteration @ 6130 is 2.096193313598633\n",
      "Evaluation Loss at Iteration @ 6130 is 2.211136817932129\n",
      "Loss at Iteration @ 6131 is 2.313844919204712\n",
      "Evaluation Loss at Iteration @ 6131 is 2.251589775085449\n",
      "Loss at Iteration @ 6132 is 2.25292706489563\n",
      "Evaluation Loss at Iteration @ 6132 is 2.255235195159912\n",
      "Loss at Iteration @ 6133 is 2.42952036857605\n",
      "Evaluation Loss at Iteration @ 6133 is 2.2941019535064697\n",
      "Loss at Iteration @ 6134 is 2.204965829849243\n",
      "Evaluation Loss at Iteration @ 6134 is 2.272867202758789\n",
      "Loss at Iteration @ 6135 is 2.2047934532165527\n",
      "Evaluation Loss at Iteration @ 6135 is 2.2607977390289307\n",
      "Loss at Iteration @ 6136 is 2.1132256984710693\n",
      "Evaluation Loss at Iteration @ 6136 is 2.253201961517334\n",
      "Loss at Iteration @ 6137 is 2.3969180583953857\n",
      "Evaluation Loss at Iteration @ 6137 is 2.28422474861145\n",
      "Loss at Iteration @ 6138 is 2.287475824356079\n",
      "Evaluation Loss at Iteration @ 6138 is 2.2735037803649902\n",
      "Loss at Iteration @ 6139 is 2.174529552459717\n",
      "Evaluation Loss at Iteration @ 6139 is 2.2901875972747803\n",
      "Loss at Iteration @ 6140 is 2.2619996070861816\n",
      "Evaluation Loss at Iteration @ 6140 is 2.2515225410461426\n",
      "Loss at Iteration @ 6141 is 2.20137882232666\n",
      "Evaluation Loss at Iteration @ 6141 is 2.2356271743774414\n",
      "Loss at Iteration @ 6142 is 2.1689372062683105\n",
      "Evaluation Loss at Iteration @ 6142 is 2.230424165725708\n",
      "Loss at Iteration @ 6143 is 2.189764976501465\n",
      "Evaluation Loss at Iteration @ 6143 is 2.2316009998321533\n",
      "Loss at Iteration @ 6144 is 2.1373984813690186\n",
      "Evaluation Loss at Iteration @ 6144 is 2.206254482269287\n",
      "Loss at Iteration @ 6145 is 2.117147445678711\n",
      "Evaluation Loss at Iteration @ 6145 is 2.2697970867156982\n",
      "Loss at Iteration @ 6146 is 2.3774020671844482\n",
      "Evaluation Loss at Iteration @ 6146 is 2.2724480628967285\n",
      "Loss at Iteration @ 6147 is 2.5605978965759277\n",
      "Evaluation Loss at Iteration @ 6147 is 2.2542779445648193\n",
      "Loss at Iteration @ 6148 is 2.2818174362182617\n",
      "Evaluation Loss at Iteration @ 6148 is 2.281001567840576\n",
      "Loss at Iteration @ 6149 is 2.5171010494232178\n",
      "Evaluation Loss at Iteration @ 6149 is 2.246356964111328\n",
      "Loss at Iteration @ 6150 is 2.321298837661743\n",
      "Evaluation Loss at Iteration @ 6150 is 2.26235294342041\n",
      "Loss at Iteration @ 6151 is 2.301835775375366\n",
      "Evaluation Loss at Iteration @ 6151 is 2.2641241550445557\n",
      "Loss at Iteration @ 6152 is 2.044485092163086\n",
      "Evaluation Loss at Iteration @ 6152 is 2.242821455001831\n",
      "Loss at Iteration @ 6153 is 1.9555518627166748\n",
      "Evaluation Loss at Iteration @ 6153 is 2.3243582248687744\n",
      "Loss at Iteration @ 6154 is 2.3137457370758057\n",
      "Evaluation Loss at Iteration @ 6154 is 2.25108003616333\n",
      "Loss at Iteration @ 6155 is 2.347431182861328\n",
      "Evaluation Loss at Iteration @ 6155 is 2.2514214515686035\n",
      "Loss at Iteration @ 6156 is 2.143869161605835\n",
      "Evaluation Loss at Iteration @ 6156 is 2.274257183074951\n",
      "Loss at Iteration @ 6157 is 2.342806577682495\n",
      "Evaluation Loss at Iteration @ 6157 is 2.2329812049865723\n",
      "Loss at Iteration @ 6158 is 2.314910411834717\n",
      "Evaluation Loss at Iteration @ 6158 is 2.2661054134368896\n",
      "Loss at Iteration @ 6159 is 1.976492166519165\n",
      "Evaluation Loss at Iteration @ 6159 is 2.2521140575408936\n",
      "Loss at Iteration @ 6160 is 2.12663197517395\n",
      "Evaluation Loss at Iteration @ 6160 is 2.238384485244751\n",
      "Loss at Iteration @ 6161 is 2.147580623626709\n",
      "Evaluation Loss at Iteration @ 6161 is 2.2461512088775635\n",
      "Loss at Iteration @ 6162 is 2.3611855506896973\n",
      "Evaluation Loss at Iteration @ 6162 is 2.28200626373291\n",
      "Loss at Iteration @ 6163 is 2.1113438606262207\n",
      "Evaluation Loss at Iteration @ 6163 is 2.258671522140503\n",
      "Loss at Iteration @ 6164 is 2.132180690765381\n",
      "Evaluation Loss at Iteration @ 6164 is 2.2400572299957275\n",
      "Loss at Iteration @ 6165 is 2.0218210220336914\n",
      "Evaluation Loss at Iteration @ 6165 is 2.281855583190918\n",
      "Loss at Iteration @ 6166 is 2.211263656616211\n",
      "Evaluation Loss at Iteration @ 6166 is 2.2584948539733887\n",
      "Loss at Iteration @ 6167 is 2.200357437133789\n",
      "Evaluation Loss at Iteration @ 6167 is 2.227971315383911\n",
      "Loss at Iteration @ 6168 is 2.2636375427246094\n",
      "Evaluation Loss at Iteration @ 6168 is 2.301574468612671\n",
      "Loss at Iteration @ 6169 is 2.1774117946624756\n",
      "Evaluation Loss at Iteration @ 6169 is 2.243971109390259\n",
      "Loss at Iteration @ 6170 is 2.590954303741455\n",
      "Evaluation Loss at Iteration @ 6170 is 2.2728445529937744\n",
      "Loss at Iteration @ 6171 is 1.95857834815979\n",
      "Evaluation Loss at Iteration @ 6171 is 2.2428300380706787\n",
      "Loss at Iteration @ 6172 is 2.3932809829711914\n",
      "Evaluation Loss at Iteration @ 6172 is 2.2461018562316895\n",
      "Loss at Iteration @ 6173 is 2.2290825843811035\n",
      "Evaluation Loss at Iteration @ 6173 is 2.2436363697052\n",
      "Loss at Iteration @ 6174 is 2.3819961547851562\n",
      "Evaluation Loss at Iteration @ 6174 is 2.2511987686157227\n",
      "Loss at Iteration @ 6175 is 2.14341402053833\n",
      "Evaluation Loss at Iteration @ 6175 is 2.2256908416748047\n",
      "Loss at Iteration @ 6176 is 2.1586976051330566\n",
      "Evaluation Loss at Iteration @ 6176 is 2.2395081520080566\n",
      "Loss at Iteration @ 6177 is 2.185224771499634\n",
      "Evaluation Loss at Iteration @ 6177 is 2.2738685607910156\n",
      "Loss at Iteration @ 6178 is 2.2967424392700195\n",
      "Evaluation Loss at Iteration @ 6178 is 2.2308943271636963\n",
      "Loss at Iteration @ 6179 is 2.3231899738311768\n",
      "Evaluation Loss at Iteration @ 6179 is 2.273916006088257\n",
      "Loss at Iteration @ 6180 is 2.229649782180786\n",
      "Evaluation Loss at Iteration @ 6180 is 2.270048141479492\n",
      "Loss at Iteration @ 6181 is 2.149543523788452\n",
      "Evaluation Loss at Iteration @ 6181 is 2.227104902267456\n",
      "Loss at Iteration @ 6182 is 2.3261592388153076\n",
      "Evaluation Loss at Iteration @ 6182 is 2.255352735519409\n",
      "Loss at Iteration @ 6183 is 2.176131010055542\n",
      "Evaluation Loss at Iteration @ 6183 is 2.2321548461914062\n",
      "Loss at Iteration @ 6184 is 2.355318784713745\n",
      "Evaluation Loss at Iteration @ 6184 is 2.3030054569244385\n",
      "Loss at Iteration @ 6185 is 2.210937023162842\n",
      "Evaluation Loss at Iteration @ 6185 is 2.237938642501831\n",
      "Loss at Iteration @ 6186 is 2.472245454788208\n",
      "Evaluation Loss at Iteration @ 6186 is 2.2767224311828613\n",
      "Loss at Iteration @ 6187 is 2.19598388671875\n",
      "Evaluation Loss at Iteration @ 6187 is 2.2563276290893555\n",
      "Loss at Iteration @ 6188 is 2.0206122398376465\n",
      "Evaluation Loss at Iteration @ 6188 is 2.2524147033691406\n",
      "Loss at Iteration @ 6189 is 2.369479179382324\n",
      "Evaluation Loss at Iteration @ 6189 is 2.213373899459839\n",
      "Loss at Iteration @ 6190 is 2.2357704639434814\n",
      "Evaluation Loss at Iteration @ 6190 is 2.2442033290863037\n",
      "Loss at Iteration @ 6191 is 2.2727673053741455\n",
      "Evaluation Loss at Iteration @ 6191 is 2.1897828578948975\n",
      "Loss at Iteration @ 6192 is 2.0332703590393066\n",
      "Evaluation Loss at Iteration @ 6192 is 2.2452731132507324\n",
      "Loss at Iteration @ 6193 is 2.231903076171875\n",
      "Evaluation Loss at Iteration @ 6193 is 2.265092134475708\n",
      "Loss at Iteration @ 6194 is 2.170050859451294\n",
      "Evaluation Loss at Iteration @ 6194 is 2.225762367248535\n",
      "Loss at Iteration @ 6195 is 2.105532169342041\n",
      "Evaluation Loss at Iteration @ 6195 is 2.2633473873138428\n",
      "Loss at Iteration @ 6196 is 2.3421809673309326\n",
      "Evaluation Loss at Iteration @ 6196 is 2.2556731700897217\n",
      "Loss at Iteration @ 6197 is 2.3423240184783936\n",
      "Evaluation Loss at Iteration @ 6197 is 2.2475714683532715\n",
      "Loss at Iteration @ 6198 is 2.08797550201416\n",
      "Evaluation Loss at Iteration @ 6198 is 2.2486178874969482\n",
      "Loss at Iteration @ 6199 is 2.2887470722198486\n",
      "Evaluation Loss at Iteration @ 6199 is 2.2500712871551514\n",
      "Loss at Iteration @ 6200 is 2.446838140487671\n",
      "Evaluation Loss at Iteration @ 6200 is 2.2495670318603516\n",
      "Loss at Iteration @ 6201 is 2.2392115592956543\n",
      "Evaluation Loss at Iteration @ 6201 is 2.2494382858276367\n",
      "Loss at Iteration @ 6202 is 2.0382261276245117\n",
      "Evaluation Loss at Iteration @ 6202 is 2.2524726390838623\n",
      "Loss at Iteration @ 6203 is 2.3384716510772705\n",
      "Evaluation Loss at Iteration @ 6203 is 2.2693140506744385\n",
      "Loss at Iteration @ 6204 is 2.217952013015747\n",
      "Evaluation Loss at Iteration @ 6204 is 2.2729337215423584\n",
      "Loss at Iteration @ 6205 is 2.4265382289886475\n",
      "Evaluation Loss at Iteration @ 6205 is 2.284177541732788\n",
      "Loss at Iteration @ 6206 is 2.0400280952453613\n",
      "Evaluation Loss at Iteration @ 6206 is 2.2381742000579834\n",
      "Loss at Iteration @ 6207 is 2.5612633228302\n",
      "Evaluation Loss at Iteration @ 6207 is 2.2976410388946533\n",
      "Loss at Iteration @ 6208 is 2.1519081592559814\n",
      "Evaluation Loss at Iteration @ 6208 is 2.2366175651550293\n",
      "Loss at Iteration @ 6209 is 2.068366765975952\n",
      "Evaluation Loss at Iteration @ 6209 is 2.2922563552856445\n",
      "Loss at Iteration @ 6210 is 2.4679312705993652\n",
      "Evaluation Loss at Iteration @ 6210 is 2.2837345600128174\n",
      "Loss at Iteration @ 6211 is 2.0311026573181152\n",
      "Evaluation Loss at Iteration @ 6211 is 2.2901127338409424\n",
      "Loss at Iteration @ 6212 is 2.176884889602661\n",
      "Evaluation Loss at Iteration @ 6212 is 2.274871826171875\n",
      "Loss at Iteration @ 6213 is 2.437669515609741\n",
      "Evaluation Loss at Iteration @ 6213 is 2.23966383934021\n",
      "Loss at Iteration @ 6214 is 1.9427459239959717\n",
      "Evaluation Loss at Iteration @ 6214 is 2.2923922538757324\n",
      "Loss at Iteration @ 6215 is 2.1208701133728027\n",
      "Evaluation Loss at Iteration @ 6215 is 2.271230459213257\n",
      "Loss at Iteration @ 6216 is 2.1182920932769775\n",
      "Evaluation Loss at Iteration @ 6216 is 2.2627792358398438\n",
      "Loss at Iteration @ 6217 is 2.2273972034454346\n",
      "Evaluation Loss at Iteration @ 6217 is 2.2955291271209717\n",
      "Loss at Iteration @ 6218 is 2.250856876373291\n",
      "Evaluation Loss at Iteration @ 6218 is 2.2296762466430664\n",
      "Loss at Iteration @ 6219 is 2.2337570190429688\n",
      "Evaluation Loss at Iteration @ 6219 is 2.209763288497925\n",
      "Loss at Iteration @ 6220 is 1.9679290056228638\n",
      "Evaluation Loss at Iteration @ 6220 is 2.2717247009277344\n",
      "Loss at Iteration @ 6221 is 1.873484492301941\n",
      "Evaluation Loss at Iteration @ 6221 is 2.2494688034057617\n",
      "Loss at Iteration @ 6222 is 2.1866581439971924\n",
      "Evaluation Loss at Iteration @ 6222 is 2.22648286819458\n",
      "Loss at Iteration @ 6223 is 2.1470680236816406\n",
      "Evaluation Loss at Iteration @ 6223 is 2.271000385284424\n",
      "Loss at Iteration @ 6224 is 2.293811559677124\n",
      "Evaluation Loss at Iteration @ 6224 is 2.2391185760498047\n",
      "Loss at Iteration @ 6225 is 2.344007968902588\n",
      "Evaluation Loss at Iteration @ 6225 is 2.2095491886138916\n",
      "Loss at Iteration @ 6226 is 2.084648370742798\n",
      "Evaluation Loss at Iteration @ 6226 is 2.2538869380950928\n",
      "Loss at Iteration @ 6227 is 2.2817776203155518\n",
      "Evaluation Loss at Iteration @ 6227 is 2.2707858085632324\n",
      "Loss at Iteration @ 6228 is 2.295187473297119\n",
      "Evaluation Loss at Iteration @ 6228 is 2.215567111968994\n",
      "Loss at Iteration @ 6229 is 2.396109104156494\n",
      "Evaluation Loss at Iteration @ 6229 is 2.2526965141296387\n",
      "Loss at Iteration @ 6230 is 2.082685708999634\n",
      "Evaluation Loss at Iteration @ 6230 is 2.2826194763183594\n",
      "Loss at Iteration @ 6231 is 2.244267225265503\n",
      "Evaluation Loss at Iteration @ 6231 is 2.26896333694458\n",
      "Loss at Iteration @ 6232 is 2.0697789192199707\n",
      "Evaluation Loss at Iteration @ 6232 is 2.2530581951141357\n",
      "Loss at Iteration @ 6233 is 2.2123589515686035\n",
      "Evaluation Loss at Iteration @ 6233 is 2.2095963954925537\n",
      "Loss at Iteration @ 6234 is 2.256767511367798\n",
      "Evaluation Loss at Iteration @ 6234 is 2.2060351371765137\n",
      "Loss at Iteration @ 6235 is 2.4507334232330322\n",
      "Evaluation Loss at Iteration @ 6235 is 2.193535327911377\n",
      "Loss at Iteration @ 6236 is 2.1608340740203857\n",
      "Evaluation Loss at Iteration @ 6236 is 2.2414982318878174\n",
      "Loss at Iteration @ 6237 is 2.1028826236724854\n",
      "Evaluation Loss at Iteration @ 6237 is 2.2202749252319336\n",
      "Loss at Iteration @ 6238 is 2.1022870540618896\n",
      "Evaluation Loss at Iteration @ 6238 is 2.2874972820281982\n",
      "Loss at Iteration @ 6239 is 2.2244443893432617\n",
      "Evaluation Loss at Iteration @ 6239 is 2.2538177967071533\n",
      "Loss at Iteration @ 6240 is 2.608793258666992\n",
      "Evaluation Loss at Iteration @ 6240 is 2.3000214099884033\n",
      "Loss at Iteration @ 6241 is 2.257668972015381\n",
      "Evaluation Loss at Iteration @ 6241 is 2.2636027336120605\n",
      "Loss at Iteration @ 6242 is 2.208801746368408\n",
      "Evaluation Loss at Iteration @ 6242 is 2.256342887878418\n",
      "Loss at Iteration @ 6243 is 2.4155092239379883\n",
      "Evaluation Loss at Iteration @ 6243 is 2.2122271060943604\n",
      "Loss at Iteration @ 6244 is 2.174644708633423\n",
      "Evaluation Loss at Iteration @ 6244 is 2.257373332977295\n",
      "Loss at Iteration @ 6245 is 2.3357083797454834\n",
      "Evaluation Loss at Iteration @ 6245 is 2.2704639434814453\n",
      "Loss at Iteration @ 6246 is 2.2470362186431885\n",
      "Evaluation Loss at Iteration @ 6246 is 2.2498953342437744\n",
      "Loss at Iteration @ 6247 is 2.4121975898742676\n",
      "Evaluation Loss at Iteration @ 6247 is 2.2816271781921387\n",
      "Loss at Iteration @ 6248 is 2.501959800720215\n",
      "Evaluation Loss at Iteration @ 6248 is 2.2234652042388916\n",
      "Loss at Iteration @ 6249 is 2.207920551300049\n",
      "Evaluation Loss at Iteration @ 6249 is 2.229586601257324\n",
      "Loss at Iteration @ 6250 is 2.2509589195251465\n",
      "Evaluation Loss at Iteration @ 6250 is 2.2764768600463867\n",
      "Loss at Iteration @ 6251 is 2.1101088523864746\n",
      "Evaluation Loss at Iteration @ 6251 is 2.226717472076416\n",
      "Loss at Iteration @ 6252 is 2.3926358222961426\n",
      "Evaluation Loss at Iteration @ 6252 is 2.2075440883636475\n",
      "Loss at Iteration @ 6253 is 1.9591915607452393\n",
      "Evaluation Loss at Iteration @ 6253 is 2.275676965713501\n",
      "Loss at Iteration @ 6254 is 2.389709711074829\n",
      "Evaluation Loss at Iteration @ 6254 is 2.296504020690918\n",
      "Loss at Iteration @ 6255 is 2.416860818862915\n",
      "Evaluation Loss at Iteration @ 6255 is 2.211331844329834\n",
      "Loss at Iteration @ 6256 is 1.8914605379104614\n",
      "Evaluation Loss at Iteration @ 6256 is 2.2884087562561035\n",
      "Loss at Iteration @ 6257 is 2.264725923538208\n",
      "Evaluation Loss at Iteration @ 6257 is 2.251668930053711\n",
      "Loss at Iteration @ 6258 is 2.014052629470825\n",
      "Evaluation Loss at Iteration @ 6258 is 2.247083902359009\n",
      "Loss at Iteration @ 6259 is 2.3847310543060303\n",
      "Evaluation Loss at Iteration @ 6259 is 2.2462148666381836\n",
      "Loss at Iteration @ 6260 is 1.9376691579818726\n",
      "Evaluation Loss at Iteration @ 6260 is 2.2801449298858643\n",
      "Loss at Iteration @ 6261 is 2.2117507457733154\n",
      "Evaluation Loss at Iteration @ 6261 is 2.2406535148620605\n",
      "Loss at Iteration @ 6262 is 2.2596044540405273\n",
      "Evaluation Loss at Iteration @ 6262 is 2.25426983833313\n",
      "Loss at Iteration @ 6263 is 2.2364203929901123\n",
      "Evaluation Loss at Iteration @ 6263 is 2.2671918869018555\n",
      "Loss at Iteration @ 6264 is 2.063580274581909\n",
      "Evaluation Loss at Iteration @ 6264 is 2.2389421463012695\n",
      "Loss at Iteration @ 6265 is 1.979371428489685\n",
      "Evaluation Loss at Iteration @ 6265 is 2.1963205337524414\n",
      "Loss at Iteration @ 6266 is 2.4501399993896484\n",
      "Evaluation Loss at Iteration @ 6266 is 2.232961654663086\n",
      "Loss at Iteration @ 6267 is 2.205493450164795\n",
      "Evaluation Loss at Iteration @ 6267 is 2.188347816467285\n",
      "Loss at Iteration @ 6268 is 2.074594497680664\n",
      "Evaluation Loss at Iteration @ 6268 is 2.2301292419433594\n",
      "Loss at Iteration @ 6269 is 2.494504928588867\n",
      "Evaluation Loss at Iteration @ 6269 is 2.2154147624969482\n",
      "Loss at Iteration @ 6270 is 2.2331736087799072\n",
      "Evaluation Loss at Iteration @ 6270 is 2.2899444103240967\n",
      "Loss at Iteration @ 6271 is 2.035799264907837\n",
      "Evaluation Loss at Iteration @ 6271 is 2.2354674339294434\n",
      "Loss at Iteration @ 6272 is 2.226461410522461\n",
      "Evaluation Loss at Iteration @ 6272 is 2.2891552448272705\n",
      "Loss at Iteration @ 6273 is 2.2361788749694824\n",
      "Evaluation Loss at Iteration @ 6273 is 2.263486385345459\n",
      "Loss at Iteration @ 6274 is 2.3923206329345703\n",
      "Evaluation Loss at Iteration @ 6274 is 2.232095718383789\n",
      "Loss at Iteration @ 6275 is 2.1144721508026123\n",
      "Evaluation Loss at Iteration @ 6275 is 2.266493558883667\n",
      "Loss at Iteration @ 6276 is 2.064633846282959\n",
      "Evaluation Loss at Iteration @ 6276 is 2.288517951965332\n",
      "Loss at Iteration @ 6277 is 2.3004672527313232\n",
      "Evaluation Loss at Iteration @ 6277 is 2.245143175125122\n",
      "Loss at Iteration @ 6278 is 2.07324481010437\n",
      "Evaluation Loss at Iteration @ 6278 is 2.2922329902648926\n",
      "Loss at Iteration @ 6279 is 2.371373414993286\n",
      "Evaluation Loss at Iteration @ 6279 is 2.291996717453003\n",
      "Loss at Iteration @ 6280 is 2.0365939140319824\n",
      "Evaluation Loss at Iteration @ 6280 is 2.2187187671661377\n",
      "Loss at Iteration @ 6281 is 2.2585954666137695\n",
      "Evaluation Loss at Iteration @ 6281 is 2.2319915294647217\n",
      "Loss at Iteration @ 6282 is 2.4008302688598633\n",
      "Evaluation Loss at Iteration @ 6282 is 2.224132776260376\n",
      "Loss at Iteration @ 6283 is 2.1130971908569336\n",
      "Evaluation Loss at Iteration @ 6283 is 2.25931715965271\n",
      "Loss at Iteration @ 6284 is 2.2278802394866943\n",
      "Evaluation Loss at Iteration @ 6284 is 2.298356294631958\n",
      "Loss at Iteration @ 6285 is 2.5061049461364746\n",
      "Evaluation Loss at Iteration @ 6285 is 2.263251304626465\n",
      "Loss at Iteration @ 6286 is 2.138838052749634\n",
      "Evaluation Loss at Iteration @ 6286 is 2.2484922409057617\n",
      "Loss at Iteration @ 6287 is 2.2907445430755615\n",
      "Evaluation Loss at Iteration @ 6287 is 2.237093448638916\n",
      "Loss at Iteration @ 6288 is 2.35854434967041\n",
      "Evaluation Loss at Iteration @ 6288 is 2.2381513118743896\n",
      "Loss at Iteration @ 6289 is 2.1537387371063232\n",
      "Evaluation Loss at Iteration @ 6289 is 2.2246432304382324\n",
      "Loss at Iteration @ 6290 is 2.0434892177581787\n",
      "Evaluation Loss at Iteration @ 6290 is 2.2627017498016357\n",
      "Loss at Iteration @ 6291 is 2.309818744659424\n",
      "Evaluation Loss at Iteration @ 6291 is 2.210883617401123\n",
      "Loss at Iteration @ 6292 is 2.185427188873291\n",
      "Evaluation Loss at Iteration @ 6292 is 2.2752604484558105\n",
      "Loss at Iteration @ 6293 is 1.9667810201644897\n",
      "Evaluation Loss at Iteration @ 6293 is 2.255486011505127\n",
      "Loss at Iteration @ 6294 is 2.2952656745910645\n",
      "Evaluation Loss at Iteration @ 6294 is 2.23917818069458\n",
      "Loss at Iteration @ 6295 is 2.2388503551483154\n",
      "Evaluation Loss at Iteration @ 6295 is 2.236171245574951\n",
      "Loss at Iteration @ 6296 is 2.193138360977173\n",
      "Evaluation Loss at Iteration @ 6296 is 2.286742687225342\n",
      "Loss at Iteration @ 6297 is 2.171372175216675\n",
      "Evaluation Loss at Iteration @ 6297 is 2.2856557369232178\n",
      "Loss at Iteration @ 6298 is 2.455127000808716\n",
      "Evaluation Loss at Iteration @ 6298 is 2.2726519107818604\n",
      "Loss at Iteration @ 6299 is 2.0904481410980225\n",
      "Evaluation Loss at Iteration @ 6299 is 2.2625675201416016\n",
      "Loss at Iteration @ 6300 is 2.323636293411255\n",
      "Evaluation Loss at Iteration @ 6300 is 2.2985997200012207\n",
      "Loss at Iteration @ 6301 is 2.614891290664673\n",
      "Evaluation Loss at Iteration @ 6301 is 2.234363555908203\n",
      "Loss at Iteration @ 6302 is 2.1671810150146484\n",
      "Evaluation Loss at Iteration @ 6302 is 2.257741689682007\n",
      "Loss at Iteration @ 6303 is 2.3108785152435303\n",
      "Evaluation Loss at Iteration @ 6303 is 2.248674154281616\n",
      "Loss at Iteration @ 6304 is 2.1067235469818115\n",
      "Evaluation Loss at Iteration @ 6304 is 2.2404568195343018\n",
      "Loss at Iteration @ 6305 is 1.8362641334533691\n",
      "Evaluation Loss at Iteration @ 6305 is 2.205077648162842\n",
      "Loss at Iteration @ 6306 is 2.2133896350860596\n",
      "Evaluation Loss at Iteration @ 6306 is 2.2089385986328125\n",
      "Loss at Iteration @ 6307 is 2.407616138458252\n",
      "Evaluation Loss at Iteration @ 6307 is 2.2377946376800537\n",
      "Loss at Iteration @ 6308 is 2.3687009811401367\n",
      "Evaluation Loss at Iteration @ 6308 is 2.230525255203247\n",
      "Loss at Iteration @ 6309 is 2.1425704956054688\n",
      "Evaluation Loss at Iteration @ 6309 is 2.2150039672851562\n",
      "Loss at Iteration @ 6310 is 2.108227491378784\n",
      "Evaluation Loss at Iteration @ 6310 is 2.2562530040740967\n",
      "Loss at Iteration @ 6311 is 2.284377336502075\n",
      "Evaluation Loss at Iteration @ 6311 is 2.2574079036712646\n",
      "Loss at Iteration @ 6312 is 2.3579821586608887\n",
      "Evaluation Loss at Iteration @ 6312 is 2.255572557449341\n",
      "Loss at Iteration @ 6313 is 2.2081754207611084\n",
      "Evaluation Loss at Iteration @ 6313 is 2.196157932281494\n",
      "Loss at Iteration @ 6314 is 2.2092342376708984\n",
      "Evaluation Loss at Iteration @ 6314 is 2.2299509048461914\n",
      "Loss at Iteration @ 6315 is 1.908059000968933\n",
      "Evaluation Loss at Iteration @ 6315 is 2.2678096294403076\n",
      "Loss at Iteration @ 6316 is 2.2724788188934326\n",
      "Evaluation Loss at Iteration @ 6316 is 2.2251105308532715\n",
      "Loss at Iteration @ 6317 is 2.291944980621338\n",
      "Evaluation Loss at Iteration @ 6317 is 2.239564895629883\n",
      "Loss at Iteration @ 6318 is 2.3127870559692383\n",
      "Evaluation Loss at Iteration @ 6318 is 2.2634530067443848\n",
      "Loss at Iteration @ 6319 is 2.041590690612793\n",
      "Evaluation Loss at Iteration @ 6319 is 2.2708635330200195\n",
      "Loss at Iteration @ 6320 is 2.2905619144439697\n",
      "Evaluation Loss at Iteration @ 6320 is 2.2632925510406494\n",
      "Loss at Iteration @ 6321 is 2.2800183296203613\n",
      "Evaluation Loss at Iteration @ 6321 is 2.2590322494506836\n",
      "Loss at Iteration @ 6322 is 2.2934443950653076\n",
      "Evaluation Loss at Iteration @ 6322 is 2.2402279376983643\n",
      "Loss at Iteration @ 6323 is 2.37608003616333\n",
      "Evaluation Loss at Iteration @ 6323 is 2.285526990890503\n",
      "Loss at Iteration @ 6324 is 2.2036356925964355\n",
      "Evaluation Loss at Iteration @ 6324 is 2.2081589698791504\n",
      "Loss at Iteration @ 6325 is 2.2874233722686768\n",
      "Evaluation Loss at Iteration @ 6325 is 2.230290412902832\n",
      "Loss at Iteration @ 6326 is 2.4420886039733887\n",
      "Evaluation Loss at Iteration @ 6326 is 2.26786470413208\n",
      "Loss at Iteration @ 6327 is 2.4402272701263428\n",
      "Evaluation Loss at Iteration @ 6327 is 2.25097918510437\n",
      "Loss at Iteration @ 6328 is 2.384582996368408\n",
      "Evaluation Loss at Iteration @ 6328 is 2.227588653564453\n",
      "Loss at Iteration @ 6329 is 2.4668333530426025\n",
      "Evaluation Loss at Iteration @ 6329 is 2.2674736976623535\n",
      "Loss at Iteration @ 6330 is 2.144939422607422\n",
      "Evaluation Loss at Iteration @ 6330 is 2.2671844959259033\n",
      "Loss at Iteration @ 6331 is 2.289782762527466\n",
      "Evaluation Loss at Iteration @ 6331 is 2.2377073764801025\n",
      "Loss at Iteration @ 6332 is 2.126814842224121\n",
      "Evaluation Loss at Iteration @ 6332 is 2.3357248306274414\n",
      "Loss at Iteration @ 6333 is 2.613823652267456\n",
      "Evaluation Loss at Iteration @ 6333 is 2.241609573364258\n",
      "Loss at Iteration @ 6334 is 2.1506118774414062\n",
      "Evaluation Loss at Iteration @ 6334 is 2.256281852722168\n",
      "Loss at Iteration @ 6335 is 2.2691025733947754\n",
      "Evaluation Loss at Iteration @ 6335 is 2.243100166320801\n",
      "Loss at Iteration @ 6336 is 2.2605552673339844\n",
      "Evaluation Loss at Iteration @ 6336 is 2.264761209487915\n",
      "Loss at Iteration @ 6337 is 2.19295597076416\n",
      "Evaluation Loss at Iteration @ 6337 is 2.2463581562042236\n",
      "Loss at Iteration @ 6338 is 2.119406223297119\n",
      "Evaluation Loss at Iteration @ 6338 is 2.2588188648223877\n",
      "Loss at Iteration @ 6339 is 2.1438958644866943\n",
      "Evaluation Loss at Iteration @ 6339 is 2.283759355545044\n",
      "Loss at Iteration @ 6340 is 2.175628423690796\n",
      "Evaluation Loss at Iteration @ 6340 is 2.246734380722046\n",
      "Loss at Iteration @ 6341 is 2.325889825820923\n",
      "Evaluation Loss at Iteration @ 6341 is 2.244345188140869\n",
      "Loss at Iteration @ 6342 is 2.07507061958313\n",
      "Evaluation Loss at Iteration @ 6342 is 2.3032314777374268\n",
      "Loss at Iteration @ 6343 is 2.425436496734619\n",
      "Evaluation Loss at Iteration @ 6343 is 2.2546472549438477\n",
      "Loss at Iteration @ 6344 is 2.213574171066284\n",
      "Evaluation Loss at Iteration @ 6344 is 2.282043218612671\n",
      "Loss at Iteration @ 6345 is 2.2897865772247314\n",
      "Evaluation Loss at Iteration @ 6345 is 2.284748077392578\n",
      "Loss at Iteration @ 6346 is 2.006810188293457\n",
      "Evaluation Loss at Iteration @ 6346 is 2.238097906112671\n",
      "Loss at Iteration @ 6347 is 2.1790261268615723\n",
      "Evaluation Loss at Iteration @ 6347 is 2.281538248062134\n",
      "Loss at Iteration @ 6348 is 2.064647674560547\n",
      "Evaluation Loss at Iteration @ 6348 is 2.2417523860931396\n",
      "Loss at Iteration @ 6349 is 1.9076118469238281\n",
      "Evaluation Loss at Iteration @ 6349 is 2.253483295440674\n",
      "Loss at Iteration @ 6350 is 2.3263211250305176\n",
      "Evaluation Loss at Iteration @ 6350 is 2.2738893032073975\n",
      "Loss at Iteration @ 6351 is 2.2482478618621826\n",
      "Evaluation Loss at Iteration @ 6351 is 2.2776072025299072\n",
      "Loss at Iteration @ 6352 is 2.3286020755767822\n",
      "Evaluation Loss at Iteration @ 6352 is 2.2024178504943848\n",
      "Loss at Iteration @ 6353 is 2.5107545852661133\n",
      "Evaluation Loss at Iteration @ 6353 is 2.2400166988372803\n",
      "Loss at Iteration @ 6354 is 2.332911252975464\n",
      "Evaluation Loss at Iteration @ 6354 is 2.2501556873321533\n",
      "Loss at Iteration @ 6355 is 1.9011722803115845\n",
      "Evaluation Loss at Iteration @ 6355 is 2.17094349861145\n",
      "Loss at Iteration @ 6356 is 2.1857810020446777\n",
      "Evaluation Loss at Iteration @ 6356 is 2.261086940765381\n",
      "Loss at Iteration @ 6357 is 2.179196357727051\n",
      "Evaluation Loss at Iteration @ 6357 is 2.2652595043182373\n",
      "Loss at Iteration @ 6358 is 2.4826877117156982\n",
      "Evaluation Loss at Iteration @ 6358 is 2.232891321182251\n",
      "Loss at Iteration @ 6359 is 2.0867903232574463\n",
      "Evaluation Loss at Iteration @ 6359 is 2.2697646617889404\n",
      "Loss at Iteration @ 6360 is 2.090604305267334\n",
      "Evaluation Loss at Iteration @ 6360 is 2.290064811706543\n",
      "Loss at Iteration @ 6361 is 2.053765058517456\n",
      "Evaluation Loss at Iteration @ 6361 is 2.2917940616607666\n",
      "Loss at Iteration @ 6362 is 2.194483757019043\n",
      "Evaluation Loss at Iteration @ 6362 is 2.2452900409698486\n",
      "Loss at Iteration @ 6363 is 2.0285303592681885\n",
      "Evaluation Loss at Iteration @ 6363 is 2.2474591732025146\n",
      "Loss at Iteration @ 6364 is 2.0496058464050293\n",
      "Evaluation Loss at Iteration @ 6364 is 2.244154691696167\n",
      "Loss at Iteration @ 6365 is 2.2434091567993164\n",
      "Evaluation Loss at Iteration @ 6365 is 2.2184784412384033\n",
      "Loss at Iteration @ 6366 is 2.007362127304077\n",
      "Evaluation Loss at Iteration @ 6366 is 2.3041954040527344\n",
      "Loss at Iteration @ 6367 is 2.2922329902648926\n",
      "Evaluation Loss at Iteration @ 6367 is 2.2365527153015137\n",
      "Loss at Iteration @ 6368 is 2.3897769451141357\n",
      "Evaluation Loss at Iteration @ 6368 is 2.2897708415985107\n",
      "Loss at Iteration @ 6369 is 2.1718809604644775\n",
      "Evaluation Loss at Iteration @ 6369 is 2.2786362171173096\n",
      "Loss at Iteration @ 6370 is 2.5222935676574707\n",
      "Evaluation Loss at Iteration @ 6370 is 2.2566802501678467\n",
      "Loss at Iteration @ 6371 is 2.1605188846588135\n",
      "Evaluation Loss at Iteration @ 6371 is 2.2787883281707764\n",
      "Loss at Iteration @ 6372 is 2.434943199157715\n",
      "Evaluation Loss at Iteration @ 6372 is 2.2223284244537354\n",
      "Loss at Iteration @ 6373 is 2.284271478652954\n",
      "Evaluation Loss at Iteration @ 6373 is 2.2463619709014893\n",
      "Loss at Iteration @ 6374 is 2.0173943042755127\n",
      "Evaluation Loss at Iteration @ 6374 is 2.245152711868286\n",
      "Loss at Iteration @ 6375 is 2.2879271507263184\n",
      "Evaluation Loss at Iteration @ 6375 is 2.257756471633911\n",
      "Loss at Iteration @ 6376 is 2.269015073776245\n",
      "Evaluation Loss at Iteration @ 6376 is 2.2608189582824707\n",
      "Loss at Iteration @ 6377 is 1.9254703521728516\n",
      "Evaluation Loss at Iteration @ 6377 is 2.225822687149048\n",
      "Loss at Iteration @ 6378 is 2.142923593521118\n",
      "Evaluation Loss at Iteration @ 6378 is 2.2574691772460938\n",
      "Loss at Iteration @ 6379 is 2.3196990489959717\n",
      "Evaluation Loss at Iteration @ 6379 is 2.248746633529663\n",
      "Loss at Iteration @ 6380 is 2.5162153244018555\n",
      "Evaluation Loss at Iteration @ 6380 is 2.242285966873169\n",
      "Loss at Iteration @ 6381 is 2.0880510807037354\n",
      "Evaluation Loss at Iteration @ 6381 is 2.2404544353485107\n",
      "Loss at Iteration @ 6382 is 2.4500863552093506\n",
      "Evaluation Loss at Iteration @ 6382 is 2.2719688415527344\n",
      "Loss at Iteration @ 6383 is 2.393442392349243\n",
      "Evaluation Loss at Iteration @ 6383 is 2.2774617671966553\n",
      "Loss at Iteration @ 6384 is 2.267603874206543\n",
      "Evaluation Loss at Iteration @ 6384 is 2.2345902919769287\n",
      "Loss at Iteration @ 6385 is 2.1914074420928955\n",
      "Evaluation Loss at Iteration @ 6385 is 2.2115182876586914\n",
      "Loss at Iteration @ 6386 is 2.231132745742798\n",
      "Evaluation Loss at Iteration @ 6386 is 2.2567830085754395\n",
      "Loss at Iteration @ 6387 is 2.3639895915985107\n",
      "Evaluation Loss at Iteration @ 6387 is 2.232875108718872\n",
      "Loss at Iteration @ 6388 is 2.247080087661743\n",
      "Evaluation Loss at Iteration @ 6388 is 2.2758114337921143\n",
      "Loss at Iteration @ 6389 is 2.2713022232055664\n",
      "Evaluation Loss at Iteration @ 6389 is 2.251227855682373\n",
      "Loss at Iteration @ 6390 is 2.2286739349365234\n",
      "Evaluation Loss at Iteration @ 6390 is 2.2597544193267822\n",
      "Loss at Iteration @ 6391 is 2.6050894260406494\n",
      "Evaluation Loss at Iteration @ 6391 is 2.232942581176758\n",
      "Loss at Iteration @ 6392 is 2.418112277984619\n",
      "Evaluation Loss at Iteration @ 6392 is 2.279897689819336\n",
      "Loss at Iteration @ 6393 is 2.180922031402588\n",
      "Evaluation Loss at Iteration @ 6393 is 2.271657943725586\n",
      "Loss at Iteration @ 6394 is 2.166733741760254\n",
      "Evaluation Loss at Iteration @ 6394 is 2.232461929321289\n",
      "Loss at Iteration @ 6395 is 2.201200485229492\n",
      "Evaluation Loss at Iteration @ 6395 is 2.260411500930786\n",
      "Loss at Iteration @ 6396 is 2.1296792030334473\n",
      "Evaluation Loss at Iteration @ 6396 is 2.2899668216705322\n",
      "Loss at Iteration @ 6397 is 2.137937307357788\n",
      "Evaluation Loss at Iteration @ 6397 is 2.2304227352142334\n",
      "Loss at Iteration @ 6398 is 2.2441394329071045\n",
      "Evaluation Loss at Iteration @ 6398 is 2.2714521884918213\n",
      "Loss at Iteration @ 6399 is 2.4232118129730225\n",
      "Evaluation Loss at Iteration @ 6399 is 2.2531251907348633\n",
      "Loss at Iteration @ 6400 is 2.071045160293579\n",
      "Evaluation Loss at Iteration @ 6400 is 2.259061813354492\n",
      "Loss at Iteration @ 6401 is 2.0934343338012695\n",
      "Evaluation Loss at Iteration @ 6401 is 2.2648098468780518\n",
      "Loss at Iteration @ 6402 is 2.3921003341674805\n",
      "Evaluation Loss at Iteration @ 6402 is 2.2844314575195312\n",
      "Loss at Iteration @ 6403 is 2.127387046813965\n",
      "Evaluation Loss at Iteration @ 6403 is 2.23476243019104\n",
      "Loss at Iteration @ 6404 is 1.9174989461898804\n",
      "Evaluation Loss at Iteration @ 6404 is 2.2726869583129883\n",
      "Loss at Iteration @ 6405 is 2.4451966285705566\n",
      "Evaluation Loss at Iteration @ 6405 is 2.251563549041748\n",
      "Loss at Iteration @ 6406 is 2.3407037258148193\n",
      "Evaluation Loss at Iteration @ 6406 is 2.2375104427337646\n",
      "Loss at Iteration @ 6407 is 2.4637391567230225\n",
      "Evaluation Loss at Iteration @ 6407 is 2.280942440032959\n",
      "Loss at Iteration @ 6408 is 2.2829432487487793\n",
      "Evaluation Loss at Iteration @ 6408 is 2.2890706062316895\n",
      "Loss at Iteration @ 6409 is 2.125927209854126\n",
      "Evaluation Loss at Iteration @ 6409 is 2.2512166500091553\n",
      "Loss at Iteration @ 6410 is 2.261823892593384\n",
      "Evaluation Loss at Iteration @ 6410 is 2.2735838890075684\n",
      "Loss at Iteration @ 6411 is 2.335355281829834\n",
      "Evaluation Loss at Iteration @ 6411 is 2.266359567642212\n",
      "Loss at Iteration @ 6412 is 2.269465684890747\n",
      "Evaluation Loss at Iteration @ 6412 is 2.2592837810516357\n",
      "Loss at Iteration @ 6413 is 2.2161242961883545\n",
      "Evaluation Loss at Iteration @ 6413 is 2.2536733150482178\n",
      "Loss at Iteration @ 6414 is 2.1937806606292725\n",
      "Evaluation Loss at Iteration @ 6414 is 2.216486930847168\n",
      "Loss at Iteration @ 6415 is 2.0112788677215576\n",
      "Evaluation Loss at Iteration @ 6415 is 2.282930374145508\n",
      "Loss at Iteration @ 6416 is 2.095886468887329\n",
      "Evaluation Loss at Iteration @ 6416 is 2.32466983795166\n",
      "Loss at Iteration @ 6417 is 2.1938819885253906\n",
      "Evaluation Loss at Iteration @ 6417 is 2.2250232696533203\n",
      "Loss at Iteration @ 6418 is 2.442840099334717\n",
      "Evaluation Loss at Iteration @ 6418 is 2.2756736278533936\n",
      "Loss at Iteration @ 6419 is 2.170597553253174\n",
      "Evaluation Loss at Iteration @ 6419 is 2.237955093383789\n",
      "Loss at Iteration @ 6420 is 2.209019660949707\n",
      "Evaluation Loss at Iteration @ 6420 is 2.241795301437378\n",
      "Loss at Iteration @ 6421 is 2.003512382507324\n",
      "Evaluation Loss at Iteration @ 6421 is 2.244473457336426\n",
      "Loss at Iteration @ 6422 is 2.326585292816162\n",
      "Evaluation Loss at Iteration @ 6422 is 2.2656781673431396\n",
      "Loss at Iteration @ 6423 is 2.202423334121704\n",
      "Evaluation Loss at Iteration @ 6423 is 2.266902208328247\n",
      "Loss at Iteration @ 6424 is 2.0930707454681396\n",
      "Evaluation Loss at Iteration @ 6424 is 2.2651195526123047\n",
      "Loss at Iteration @ 6425 is 2.2624151706695557\n",
      "Evaluation Loss at Iteration @ 6425 is 2.2177627086639404\n",
      "Loss at Iteration @ 6426 is 2.203942060470581\n",
      "Evaluation Loss at Iteration @ 6426 is 2.2488322257995605\n",
      "Loss at Iteration @ 6427 is 2.142620801925659\n",
      "Evaluation Loss at Iteration @ 6427 is 2.2970316410064697\n",
      "Loss at Iteration @ 6428 is 2.156639575958252\n",
      "Evaluation Loss at Iteration @ 6428 is 2.242295265197754\n",
      "Loss at Iteration @ 6429 is 2.247312068939209\n",
      "Evaluation Loss at Iteration @ 6429 is 2.236095428466797\n",
      "Loss at Iteration @ 6430 is 2.0013694763183594\n",
      "Evaluation Loss at Iteration @ 6430 is 2.3070871829986572\n",
      "Loss at Iteration @ 6431 is 2.1941938400268555\n",
      "Evaluation Loss at Iteration @ 6431 is 2.196898937225342\n",
      "Loss at Iteration @ 6432 is 2.4991798400878906\n",
      "Evaluation Loss at Iteration @ 6432 is 2.2535581588745117\n",
      "Loss at Iteration @ 6433 is 2.100752353668213\n",
      "Evaluation Loss at Iteration @ 6433 is 2.1952030658721924\n",
      "Loss at Iteration @ 6434 is 2.226242780685425\n",
      "Evaluation Loss at Iteration @ 6434 is 2.234814167022705\n",
      "Loss at Iteration @ 6435 is 2.1486966609954834\n",
      "Evaluation Loss at Iteration @ 6435 is 2.2720353603363037\n",
      "Loss at Iteration @ 6436 is 2.271552562713623\n",
      "Evaluation Loss at Iteration @ 6436 is 2.2565722465515137\n",
      "Loss at Iteration @ 6437 is 2.2959792613983154\n",
      "Evaluation Loss at Iteration @ 6437 is 2.2402749061584473\n",
      "Loss at Iteration @ 6438 is 2.023197889328003\n",
      "Evaluation Loss at Iteration @ 6438 is 2.2525827884674072\n",
      "Loss at Iteration @ 6439 is 2.0791428089141846\n",
      "Evaluation Loss at Iteration @ 6439 is 2.2608895301818848\n",
      "Loss at Iteration @ 6440 is 2.0638978481292725\n",
      "Evaluation Loss at Iteration @ 6440 is 2.2231173515319824\n",
      "Loss at Iteration @ 6441 is 2.3336899280548096\n",
      "Evaluation Loss at Iteration @ 6441 is 2.2287099361419678\n",
      "Loss at Iteration @ 6442 is 2.133608341217041\n",
      "Evaluation Loss at Iteration @ 6442 is 2.259218692779541\n",
      "Loss at Iteration @ 6443 is 2.013357639312744\n",
      "Evaluation Loss at Iteration @ 6443 is 2.273345947265625\n",
      "Loss at Iteration @ 6444 is 2.100388765335083\n",
      "Evaluation Loss at Iteration @ 6444 is 2.2519099712371826\n",
      "Loss at Iteration @ 6445 is 2.070558786392212\n",
      "Evaluation Loss at Iteration @ 6445 is 2.2265255451202393\n",
      "Loss at Iteration @ 6446 is 2.2594614028930664\n",
      "Evaluation Loss at Iteration @ 6446 is 2.290067672729492\n",
      "Loss at Iteration @ 6447 is 2.2341389656066895\n",
      "Evaluation Loss at Iteration @ 6447 is 2.2385737895965576\n",
      "Loss at Iteration @ 6448 is 2.2603981494903564\n",
      "Evaluation Loss at Iteration @ 6448 is 2.2766523361206055\n",
      "Loss at Iteration @ 6449 is 2.322953701019287\n",
      "Evaluation Loss at Iteration @ 6449 is 2.2425155639648438\n",
      "Loss at Iteration @ 6450 is 2.5089545249938965\n",
      "Evaluation Loss at Iteration @ 6450 is 2.222669839859009\n",
      "Loss at Iteration @ 6451 is 2.192361831665039\n",
      "Evaluation Loss at Iteration @ 6451 is 2.284217357635498\n",
      "Loss at Iteration @ 6452 is 2.1338019371032715\n",
      "Evaluation Loss at Iteration @ 6452 is 2.2638208866119385\n",
      "Loss at Iteration @ 6453 is 2.0951168537139893\n",
      "Evaluation Loss at Iteration @ 6453 is 2.2235937118530273\n",
      "Loss at Iteration @ 6454 is 2.1900851726531982\n",
      "Evaluation Loss at Iteration @ 6454 is 2.280846357345581\n",
      "Loss at Iteration @ 6455 is 2.2261600494384766\n",
      "Evaluation Loss at Iteration @ 6455 is 2.3072397708892822\n",
      "Loss at Iteration @ 6456 is 2.3173866271972656\n",
      "Evaluation Loss at Iteration @ 6456 is 2.247803211212158\n",
      "Loss at Iteration @ 6457 is 2.0938022136688232\n",
      "Evaluation Loss at Iteration @ 6457 is 2.2724850177764893\n",
      "Loss at Iteration @ 6458 is 2.156790018081665\n",
      "Evaluation Loss at Iteration @ 6458 is 2.255652904510498\n",
      "Loss at Iteration @ 6459 is 2.0588040351867676\n",
      "Evaluation Loss at Iteration @ 6459 is 2.241163969039917\n",
      "Loss at Iteration @ 6460 is 1.9905285835266113\n",
      "Evaluation Loss at Iteration @ 6460 is 2.248671293258667\n",
      "Loss at Iteration @ 6461 is 2.5964126586914062\n",
      "Evaluation Loss at Iteration @ 6461 is 2.192765712738037\n",
      "Loss at Iteration @ 6462 is 2.089935779571533\n",
      "Evaluation Loss at Iteration @ 6462 is 2.266204833984375\n",
      "Loss at Iteration @ 6463 is 2.287139654159546\n",
      "Evaluation Loss at Iteration @ 6463 is 2.2256715297698975\n",
      "Loss at Iteration @ 6464 is 2.050633430480957\n",
      "Evaluation Loss at Iteration @ 6464 is 2.2725019454956055\n",
      "Loss at Iteration @ 6465 is 2.467604875564575\n",
      "Evaluation Loss at Iteration @ 6465 is 2.2517926692962646\n",
      "Loss at Iteration @ 6466 is 2.304126739501953\n",
      "Evaluation Loss at Iteration @ 6466 is 2.3046281337738037\n",
      "Loss at Iteration @ 6467 is 2.2616007328033447\n",
      "Evaluation Loss at Iteration @ 6467 is 2.28786039352417\n",
      "Loss at Iteration @ 6468 is 1.9993162155151367\n",
      "Evaluation Loss at Iteration @ 6468 is 2.242811441421509\n",
      "Loss at Iteration @ 6469 is 2.2701101303100586\n",
      "Evaluation Loss at Iteration @ 6469 is 2.233139753341675\n",
      "Loss at Iteration @ 6470 is 2.617398738861084\n",
      "Evaluation Loss at Iteration @ 6470 is 2.2385284900665283\n",
      "Loss at Iteration @ 6471 is 2.2052347660064697\n",
      "Evaluation Loss at Iteration @ 6471 is 2.3051557540893555\n",
      "Loss at Iteration @ 6472 is 2.156480550765991\n",
      "Evaluation Loss at Iteration @ 6472 is 2.2069027423858643\n",
      "Loss at Iteration @ 6473 is 2.0821115970611572\n",
      "Evaluation Loss at Iteration @ 6473 is 2.2840421199798584\n",
      "Loss at Iteration @ 6474 is 2.2676143646240234\n",
      "Evaluation Loss at Iteration @ 6474 is 2.2606000900268555\n",
      "Loss at Iteration @ 6475 is 2.343662977218628\n",
      "Evaluation Loss at Iteration @ 6475 is 2.272237539291382\n",
      "Loss at Iteration @ 6476 is 2.2070088386535645\n",
      "Evaluation Loss at Iteration @ 6476 is 2.243117094039917\n",
      "Loss at Iteration @ 6477 is 2.1431405544281006\n",
      "Evaluation Loss at Iteration @ 6477 is 2.294616937637329\n",
      "Loss at Iteration @ 6478 is 1.879585862159729\n",
      "Evaluation Loss at Iteration @ 6478 is 2.270648717880249\n",
      "Loss at Iteration @ 6479 is 2.3111684322357178\n",
      "Evaluation Loss at Iteration @ 6479 is 2.3067290782928467\n",
      "Loss at Iteration @ 6480 is 2.075342893600464\n",
      "Evaluation Loss at Iteration @ 6480 is 2.2347757816314697\n",
      "Loss at Iteration @ 6481 is 2.1867127418518066\n",
      "Evaluation Loss at Iteration @ 6481 is 2.266005754470825\n",
      "Loss at Iteration @ 6482 is 2.1350018978118896\n",
      "Evaluation Loss at Iteration @ 6482 is 2.3455681800842285\n",
      "Loss at Iteration @ 6483 is 2.1989476680755615\n",
      "Evaluation Loss at Iteration @ 6483 is 2.2905564308166504\n",
      "Loss at Iteration @ 6484 is 2.320441246032715\n",
      "Evaluation Loss at Iteration @ 6484 is 2.235844612121582\n",
      "Loss at Iteration @ 6485 is 2.3980371952056885\n",
      "Evaluation Loss at Iteration @ 6485 is 2.2605745792388916\n",
      "Loss at Iteration @ 6486 is 2.2420833110809326\n",
      "Evaluation Loss at Iteration @ 6486 is 2.287900447845459\n",
      "Loss at Iteration @ 6487 is 2.5295963287353516\n",
      "Evaluation Loss at Iteration @ 6487 is 2.252009391784668\n",
      "Loss at Iteration @ 6488 is 2.4711244106292725\n",
      "Evaluation Loss at Iteration @ 6488 is 2.2692341804504395\n",
      "Loss at Iteration @ 6489 is 2.1581685543060303\n",
      "Evaluation Loss at Iteration @ 6489 is 2.2525811195373535\n",
      "Loss at Iteration @ 6490 is 2.3752310276031494\n",
      "Evaluation Loss at Iteration @ 6490 is 2.2264790534973145\n",
      "Loss at Iteration @ 6491 is 2.1519970893859863\n",
      "Evaluation Loss at Iteration @ 6491 is 2.2649002075195312\n",
      "Loss at Iteration @ 6492 is 2.1859846115112305\n",
      "Evaluation Loss at Iteration @ 6492 is 2.246960401535034\n",
      "Loss at Iteration @ 6493 is 2.092484712600708\n",
      "Evaluation Loss at Iteration @ 6493 is 2.254025936126709\n",
      "Loss at Iteration @ 6494 is 2.0045342445373535\n",
      "Evaluation Loss at Iteration @ 6494 is 2.2506346702575684\n",
      "Loss at Iteration @ 6495 is 2.074779510498047\n",
      "Evaluation Loss at Iteration @ 6495 is 2.2020320892333984\n",
      "Loss at Iteration @ 6496 is 2.345564126968384\n",
      "Evaluation Loss at Iteration @ 6496 is 2.255870819091797\n",
      "Loss at Iteration @ 6497 is 2.419999361038208\n",
      "Evaluation Loss at Iteration @ 6497 is 2.2325947284698486\n",
      "Loss at Iteration @ 6498 is 2.1176953315734863\n",
      "Evaluation Loss at Iteration @ 6498 is 2.2500858306884766\n",
      "Loss at Iteration @ 6499 is 2.2555177211761475\n",
      "Evaluation Loss at Iteration @ 6499 is 2.2498505115509033\n",
      "Loss at Iteration @ 6500 is 2.4024579524993896\n",
      "Evaluation Loss at Iteration @ 6500 is 2.212312936782837\n",
      "Loss at Iteration @ 6501 is 2.3048360347747803\n",
      "Evaluation Loss at Iteration @ 6501 is 2.2855594158172607\n",
      "Loss at Iteration @ 6502 is 2.014054775238037\n",
      "Evaluation Loss at Iteration @ 6502 is 2.208719491958618\n",
      "Loss at Iteration @ 6503 is 2.227499485015869\n",
      "Evaluation Loss at Iteration @ 6503 is 2.277035713195801\n",
      "Loss at Iteration @ 6504 is 2.1055917739868164\n",
      "Evaluation Loss at Iteration @ 6504 is 2.252992868423462\n",
      "Loss at Iteration @ 6505 is 2.2554876804351807\n",
      "Evaluation Loss at Iteration @ 6505 is 2.2691237926483154\n",
      "Loss at Iteration @ 6506 is 2.0315206050872803\n",
      "Evaluation Loss at Iteration @ 6506 is 2.236793041229248\n",
      "Loss at Iteration @ 6507 is 2.351435899734497\n",
      "Evaluation Loss at Iteration @ 6507 is 2.2335681915283203\n",
      "Loss at Iteration @ 6508 is 2.209411382675171\n",
      "Evaluation Loss at Iteration @ 6508 is 2.245968818664551\n",
      "Loss at Iteration @ 6509 is 2.3526113033294678\n",
      "Evaluation Loss at Iteration @ 6509 is 2.251127243041992\n",
      "Loss at Iteration @ 6510 is 2.0469443798065186\n",
      "Evaluation Loss at Iteration @ 6510 is 2.20904541015625\n",
      "Loss at Iteration @ 6511 is 2.014788866043091\n",
      "Evaluation Loss at Iteration @ 6511 is 2.262726068496704\n",
      "Loss at Iteration @ 6512 is 2.3033347129821777\n",
      "Evaluation Loss at Iteration @ 6512 is 2.19903302192688\n",
      "Loss at Iteration @ 6513 is 2.3437488079071045\n",
      "Evaluation Loss at Iteration @ 6513 is 2.2560930252075195\n",
      "Loss at Iteration @ 6514 is 2.4594812393188477\n",
      "Evaluation Loss at Iteration @ 6514 is 2.3141891956329346\n",
      "Loss at Iteration @ 6515 is 1.9274500608444214\n",
      "Evaluation Loss at Iteration @ 6515 is 2.2423810958862305\n",
      "Loss at Iteration @ 6516 is 2.1492815017700195\n",
      "Evaluation Loss at Iteration @ 6516 is 2.25907301902771\n",
      "Loss at Iteration @ 6517 is 2.0029520988464355\n",
      "Evaluation Loss at Iteration @ 6517 is 2.2288286685943604\n",
      "Loss at Iteration @ 6518 is 2.1288113594055176\n",
      "Evaluation Loss at Iteration @ 6518 is 2.2434539794921875\n",
      "Loss at Iteration @ 6519 is 2.4319658279418945\n",
      "Evaluation Loss at Iteration @ 6519 is 2.274608612060547\n",
      "Loss at Iteration @ 6520 is 2.4282660484313965\n",
      "Evaluation Loss at Iteration @ 6520 is 2.23697829246521\n",
      "Loss at Iteration @ 6521 is 2.269092082977295\n",
      "Evaluation Loss at Iteration @ 6521 is 2.2786953449249268\n",
      "Loss at Iteration @ 6522 is 2.231778383255005\n",
      "Evaluation Loss at Iteration @ 6522 is 2.2381958961486816\n",
      "Loss at Iteration @ 6523 is 2.301560878753662\n",
      "Evaluation Loss at Iteration @ 6523 is 2.2715651988983154\n",
      "Loss at Iteration @ 6524 is 2.3049113750457764\n",
      "Evaluation Loss at Iteration @ 6524 is 2.2606303691864014\n",
      "Loss at Iteration @ 6525 is 2.530832529067993\n",
      "Evaluation Loss at Iteration @ 6525 is 2.208775520324707\n",
      "Loss at Iteration @ 6526 is 2.1299378871917725\n",
      "Evaluation Loss at Iteration @ 6526 is 2.2952795028686523\n",
      "Loss at Iteration @ 6527 is 2.511263608932495\n",
      "Evaluation Loss at Iteration @ 6527 is 2.2306876182556152\n",
      "Loss at Iteration @ 6528 is 2.3872079849243164\n",
      "Evaluation Loss at Iteration @ 6528 is 2.2753219604492188\n",
      "Loss at Iteration @ 6529 is 2.1363255977630615\n",
      "Evaluation Loss at Iteration @ 6529 is 2.2526073455810547\n",
      "Loss at Iteration @ 6530 is 2.1984148025512695\n",
      "Evaluation Loss at Iteration @ 6530 is 2.2405407428741455\n",
      "Loss at Iteration @ 6531 is 2.184274435043335\n",
      "Evaluation Loss at Iteration @ 6531 is 2.2651684284210205\n",
      "Loss at Iteration @ 6532 is 2.423907995223999\n",
      "Evaluation Loss at Iteration @ 6532 is 2.2401251792907715\n",
      "Loss at Iteration @ 6533 is 2.2929577827453613\n",
      "Evaluation Loss at Iteration @ 6533 is 2.2817111015319824\n",
      "Loss at Iteration @ 6534 is 2.1880409717559814\n",
      "Evaluation Loss at Iteration @ 6534 is 2.3144917488098145\n",
      "Loss at Iteration @ 6535 is 2.190537691116333\n",
      "Evaluation Loss at Iteration @ 6535 is 2.2756259441375732\n",
      "Loss at Iteration @ 6536 is 2.464031457901001\n",
      "Evaluation Loss at Iteration @ 6536 is 2.2482750415802\n",
      "Loss at Iteration @ 6537 is 2.2205214500427246\n",
      "Evaluation Loss at Iteration @ 6537 is 2.267294406890869\n",
      "Loss at Iteration @ 6538 is 2.197218656539917\n",
      "Evaluation Loss at Iteration @ 6538 is 2.1993722915649414\n",
      "Loss at Iteration @ 6539 is 2.2938554286956787\n",
      "Evaluation Loss at Iteration @ 6539 is 2.252687454223633\n",
      "Loss at Iteration @ 6540 is 2.2203972339630127\n",
      "Evaluation Loss at Iteration @ 6540 is 2.2617688179016113\n",
      "Loss at Iteration @ 6541 is 2.1127796173095703\n",
      "Evaluation Loss at Iteration @ 6541 is 2.2046658992767334\n",
      "Loss at Iteration @ 6542 is 2.0894272327423096\n",
      "Evaluation Loss at Iteration @ 6542 is 2.278252601623535\n",
      "Loss at Iteration @ 6543 is 2.542371988296509\n",
      "Evaluation Loss at Iteration @ 6543 is 2.246400833129883\n",
      "Loss at Iteration @ 6544 is 1.9086618423461914\n",
      "Evaluation Loss at Iteration @ 6544 is 2.3024399280548096\n",
      "Loss at Iteration @ 6545 is 2.6232612133026123\n",
      "Evaluation Loss at Iteration @ 6545 is 2.274803400039673\n",
      "Loss at Iteration @ 6546 is 2.2393078804016113\n",
      "Evaluation Loss at Iteration @ 6546 is 2.2565834522247314\n",
      "Loss at Iteration @ 6547 is 2.348059892654419\n",
      "Evaluation Loss at Iteration @ 6547 is 2.252664089202881\n",
      "Loss at Iteration @ 6548 is 2.1264383792877197\n",
      "Evaluation Loss at Iteration @ 6548 is 2.295576572418213\n",
      "Loss at Iteration @ 6549 is 2.3382554054260254\n",
      "Evaluation Loss at Iteration @ 6549 is 2.281812906265259\n",
      "Loss at Iteration @ 6550 is 2.3100969791412354\n",
      "Evaluation Loss at Iteration @ 6550 is 2.2717642784118652\n",
      "Loss at Iteration @ 6551 is 2.273987293243408\n",
      "Evaluation Loss at Iteration @ 6551 is 2.2182891368865967\n",
      "Loss at Iteration @ 6552 is 2.5836734771728516\n",
      "Evaluation Loss at Iteration @ 6552 is 2.2953903675079346\n",
      "Loss at Iteration @ 6553 is 2.3441858291625977\n",
      "Evaluation Loss at Iteration @ 6553 is 2.2554328441619873\n",
      "Loss at Iteration @ 6554 is 2.08662748336792\n",
      "Evaluation Loss at Iteration @ 6554 is 2.300902843475342\n",
      "Loss at Iteration @ 6555 is 2.2562460899353027\n",
      "Evaluation Loss at Iteration @ 6555 is 2.2561867237091064\n",
      "Loss at Iteration @ 6556 is 2.1542258262634277\n",
      "Evaluation Loss at Iteration @ 6556 is 2.2755634784698486\n",
      "Loss at Iteration @ 6557 is 2.214095115661621\n",
      "Evaluation Loss at Iteration @ 6557 is 2.2553186416625977\n",
      "Loss at Iteration @ 6558 is 2.375567674636841\n",
      "Evaluation Loss at Iteration @ 6558 is 2.261669158935547\n",
      "Loss at Iteration @ 6559 is 2.4384071826934814\n",
      "Evaluation Loss at Iteration @ 6559 is 2.244049072265625\n",
      "Loss at Iteration @ 6560 is 2.386542558670044\n",
      "Evaluation Loss at Iteration @ 6560 is 2.2657532691955566\n",
      "Loss at Iteration @ 6561 is 2.540771722793579\n",
      "Evaluation Loss at Iteration @ 6561 is 2.2756969928741455\n",
      "Loss at Iteration @ 6562 is 2.4589898586273193\n",
      "Evaluation Loss at Iteration @ 6562 is 2.199848175048828\n",
      "Loss at Iteration @ 6563 is 2.197563648223877\n",
      "Evaluation Loss at Iteration @ 6563 is 2.2442121505737305\n",
      "Loss at Iteration @ 6564 is 2.053607225418091\n",
      "Evaluation Loss at Iteration @ 6564 is 2.267652988433838\n",
      "Loss at Iteration @ 6565 is 2.468329906463623\n",
      "Evaluation Loss at Iteration @ 6565 is 2.2396233081817627\n",
      "Loss at Iteration @ 6566 is 2.1465296745300293\n",
      "Evaluation Loss at Iteration @ 6566 is 2.217615842819214\n",
      "Loss at Iteration @ 6567 is 2.01473331451416\n",
      "Evaluation Loss at Iteration @ 6567 is 2.275207757949829\n",
      "Loss at Iteration @ 6568 is 2.1943159103393555\n",
      "Evaluation Loss at Iteration @ 6568 is 2.2923777103424072\n",
      "Loss at Iteration @ 6569 is 2.209796905517578\n",
      "Evaluation Loss at Iteration @ 6569 is 2.194204330444336\n",
      "Loss at Iteration @ 6570 is 2.413956642150879\n",
      "Evaluation Loss at Iteration @ 6570 is 2.2503371238708496\n",
      "Loss at Iteration @ 6571 is 2.192105293273926\n",
      "Evaluation Loss at Iteration @ 6571 is 2.218717336654663\n",
      "Loss at Iteration @ 6572 is 2.24015736579895\n",
      "Evaluation Loss at Iteration @ 6572 is 2.2803871631622314\n",
      "Loss at Iteration @ 6573 is 2.298384666442871\n",
      "Evaluation Loss at Iteration @ 6573 is 2.237135171890259\n",
      "Loss at Iteration @ 6574 is 2.447216033935547\n",
      "Evaluation Loss at Iteration @ 6574 is 2.2508533000946045\n",
      "Loss at Iteration @ 6575 is 2.2829253673553467\n",
      "Evaluation Loss at Iteration @ 6575 is 2.2839772701263428\n",
      "Loss at Iteration @ 6576 is 1.9646209478378296\n",
      "Evaluation Loss at Iteration @ 6576 is 2.248164653778076\n",
      "Loss at Iteration @ 6577 is 2.278851270675659\n",
      "Evaluation Loss at Iteration @ 6577 is 2.279536247253418\n",
      "Loss at Iteration @ 6578 is 2.22871732711792\n",
      "Evaluation Loss at Iteration @ 6578 is 2.272696018218994\n",
      "Loss at Iteration @ 6579 is 2.117135763168335\n",
      "Evaluation Loss at Iteration @ 6579 is 2.2570536136627197\n",
      "Loss at Iteration @ 6580 is 2.1330225467681885\n",
      "Evaluation Loss at Iteration @ 6580 is 2.310901165008545\n",
      "Loss at Iteration @ 6581 is 2.302800416946411\n",
      "Evaluation Loss at Iteration @ 6581 is 2.2639827728271484\n",
      "Loss at Iteration @ 6582 is 2.2786595821380615\n",
      "Evaluation Loss at Iteration @ 6582 is 2.2676100730895996\n",
      "Loss at Iteration @ 6583 is 2.1496546268463135\n",
      "Evaluation Loss at Iteration @ 6583 is 2.2610111236572266\n",
      "Loss at Iteration @ 6584 is 2.1399965286254883\n",
      "Evaluation Loss at Iteration @ 6584 is 2.237445116043091\n",
      "Loss at Iteration @ 6585 is 2.0889017581939697\n",
      "Evaluation Loss at Iteration @ 6585 is 2.292266607284546\n",
      "Loss at Iteration @ 6586 is 2.404221534729004\n",
      "Evaluation Loss at Iteration @ 6586 is 2.265624761581421\n",
      "Loss at Iteration @ 6587 is 2.320110321044922\n",
      "Evaluation Loss at Iteration @ 6587 is 2.279339551925659\n",
      "Loss at Iteration @ 6588 is 2.2349696159362793\n",
      "Evaluation Loss at Iteration @ 6588 is 2.2915079593658447\n",
      "Loss at Iteration @ 6589 is 2.3300278186798096\n",
      "Evaluation Loss at Iteration @ 6589 is 2.2764437198638916\n",
      "Loss at Iteration @ 6590 is 2.311241865158081\n",
      "Evaluation Loss at Iteration @ 6590 is 2.2711873054504395\n",
      "Loss at Iteration @ 6591 is 1.9147518873214722\n",
      "Evaluation Loss at Iteration @ 6591 is 2.2066879272460938\n",
      "Loss at Iteration @ 6592 is 2.154015064239502\n",
      "Evaluation Loss at Iteration @ 6592 is 2.261540412902832\n",
      "Loss at Iteration @ 6593 is 2.0866971015930176\n",
      "Evaluation Loss at Iteration @ 6593 is 2.2810890674591064\n",
      "Loss at Iteration @ 6594 is 2.301572561264038\n",
      "Evaluation Loss at Iteration @ 6594 is 2.2746710777282715\n",
      "Loss at Iteration @ 6595 is 2.3508200645446777\n",
      "Evaluation Loss at Iteration @ 6595 is 2.2429676055908203\n",
      "Loss at Iteration @ 6596 is 2.386176586151123\n",
      "Evaluation Loss at Iteration @ 6596 is 2.2783002853393555\n",
      "Loss at Iteration @ 6597 is 2.1782913208007812\n",
      "Evaluation Loss at Iteration @ 6597 is 2.2547178268432617\n",
      "Loss at Iteration @ 6598 is 2.3286116123199463\n",
      "Evaluation Loss at Iteration @ 6598 is 2.2389848232269287\n",
      "Loss at Iteration @ 6599 is 2.248443603515625\n",
      "Evaluation Loss at Iteration @ 6599 is 2.2440006732940674\n",
      "Loss at Iteration @ 6600 is 2.4467179775238037\n",
      "Evaluation Loss at Iteration @ 6600 is 2.2283060550689697\n",
      "Loss at Iteration @ 6601 is 2.2612953186035156\n",
      "Evaluation Loss at Iteration @ 6601 is 2.270535469055176\n",
      "Loss at Iteration @ 6602 is 2.026827335357666\n",
      "Evaluation Loss at Iteration @ 6602 is 2.2489821910858154\n",
      "Loss at Iteration @ 6603 is 2.1827149391174316\n",
      "Evaluation Loss at Iteration @ 6603 is 2.2127182483673096\n",
      "Loss at Iteration @ 6604 is 2.3155529499053955\n",
      "Evaluation Loss at Iteration @ 6604 is 2.288621425628662\n",
      "Loss at Iteration @ 6605 is 2.3060784339904785\n",
      "Evaluation Loss at Iteration @ 6605 is 2.2888286113739014\n",
      "Loss at Iteration @ 6606 is 2.3022634983062744\n",
      "Evaluation Loss at Iteration @ 6606 is 2.244488477706909\n",
      "Loss at Iteration @ 6607 is 2.4552628993988037\n",
      "Evaluation Loss at Iteration @ 6607 is 2.211775302886963\n",
      "Loss at Iteration @ 6608 is 2.174271583557129\n",
      "Evaluation Loss at Iteration @ 6608 is 2.2430977821350098\n",
      "Loss at Iteration @ 6609 is 2.18100905418396\n",
      "Evaluation Loss at Iteration @ 6609 is 2.2082056999206543\n",
      "Loss at Iteration @ 6610 is 2.306333303451538\n",
      "Evaluation Loss at Iteration @ 6610 is 2.216068744659424\n",
      "Loss at Iteration @ 6611 is 2.049403429031372\n",
      "Evaluation Loss at Iteration @ 6611 is 2.261139154434204\n",
      "Loss at Iteration @ 6612 is 2.3169870376586914\n",
      "Evaluation Loss at Iteration @ 6612 is 2.2494759559631348\n",
      "Loss at Iteration @ 6613 is 2.311116933822632\n",
      "Evaluation Loss at Iteration @ 6613 is 2.2391281127929688\n",
      "Loss at Iteration @ 6614 is 2.3266305923461914\n",
      "Evaluation Loss at Iteration @ 6614 is 2.2275187969207764\n",
      "Loss at Iteration @ 6615 is 2.025188684463501\n",
      "Evaluation Loss at Iteration @ 6615 is 2.2325832843780518\n",
      "Loss at Iteration @ 6616 is 2.1151559352874756\n",
      "Evaluation Loss at Iteration @ 6616 is 2.297822952270508\n",
      "Loss at Iteration @ 6617 is 2.331824779510498\n",
      "Evaluation Loss at Iteration @ 6617 is 2.2129297256469727\n",
      "Loss at Iteration @ 6618 is 2.138887882232666\n",
      "Evaluation Loss at Iteration @ 6618 is 2.254577875137329\n",
      "Loss at Iteration @ 6619 is 2.1676156520843506\n",
      "Evaluation Loss at Iteration @ 6619 is 2.2806646823883057\n",
      "Loss at Iteration @ 6620 is 2.0739595890045166\n",
      "Evaluation Loss at Iteration @ 6620 is 2.2296884059906006\n",
      "Loss at Iteration @ 6621 is 2.3325796127319336\n",
      "Evaluation Loss at Iteration @ 6621 is 2.263526678085327\n",
      "Loss at Iteration @ 6622 is 2.271030902862549\n",
      "Evaluation Loss at Iteration @ 6622 is 2.26113224029541\n",
      "Loss at Iteration @ 6623 is 2.000330686569214\n",
      "Evaluation Loss at Iteration @ 6623 is 2.306140184402466\n",
      "Loss at Iteration @ 6624 is 2.0189359188079834\n",
      "Evaluation Loss at Iteration @ 6624 is 2.1869006156921387\n",
      "Loss at Iteration @ 6625 is 2.3264260292053223\n",
      "Evaluation Loss at Iteration @ 6625 is 2.2480084896087646\n",
      "Loss at Iteration @ 6626 is 2.210892915725708\n",
      "Evaluation Loss at Iteration @ 6626 is 2.3040354251861572\n",
      "Loss at Iteration @ 6627 is 2.267413377761841\n",
      "Evaluation Loss at Iteration @ 6627 is 2.2306296825408936\n",
      "Loss at Iteration @ 6628 is 2.4667279720306396\n",
      "Evaluation Loss at Iteration @ 6628 is 2.2762351036071777\n",
      "Loss at Iteration @ 6629 is 1.9865018129348755\n",
      "Evaluation Loss at Iteration @ 6629 is 2.2175052165985107\n",
      "Loss at Iteration @ 6630 is 2.205087900161743\n",
      "Evaluation Loss at Iteration @ 6630 is 2.2262749671936035\n",
      "Loss at Iteration @ 6631 is 2.153775453567505\n",
      "Evaluation Loss at Iteration @ 6631 is 2.252709150314331\n",
      "Loss at Iteration @ 6632 is 2.1964638233184814\n",
      "Evaluation Loss at Iteration @ 6632 is 2.251020908355713\n",
      "Loss at Iteration @ 6633 is 2.386350154876709\n",
      "Evaluation Loss at Iteration @ 6633 is 2.2800962924957275\n",
      "Loss at Iteration @ 6634 is 2.1730589866638184\n",
      "Evaluation Loss at Iteration @ 6634 is 2.252119541168213\n",
      "Loss at Iteration @ 6635 is 2.2724101543426514\n",
      "Evaluation Loss at Iteration @ 6635 is 2.2349328994750977\n",
      "Loss at Iteration @ 6636 is 1.9889881610870361\n",
      "Evaluation Loss at Iteration @ 6636 is 2.265565872192383\n",
      "Loss at Iteration @ 6637 is 2.1134250164031982\n",
      "Evaluation Loss at Iteration @ 6637 is 2.233027219772339\n",
      "Loss at Iteration @ 6638 is 2.430715799331665\n",
      "Evaluation Loss at Iteration @ 6638 is 2.2471816539764404\n",
      "Loss at Iteration @ 6639 is 2.4083635807037354\n",
      "Evaluation Loss at Iteration @ 6639 is 2.270484685897827\n",
      "Loss at Iteration @ 6640 is 2.095780611038208\n",
      "Evaluation Loss at Iteration @ 6640 is 2.242006778717041\n",
      "Loss at Iteration @ 6641 is 2.2162275314331055\n",
      "Evaluation Loss at Iteration @ 6641 is 2.231210947036743\n",
      "Loss at Iteration @ 6642 is 2.0030012130737305\n",
      "Evaluation Loss at Iteration @ 6642 is 2.2598485946655273\n",
      "Loss at Iteration @ 6643 is 2.2463860511779785\n",
      "Evaluation Loss at Iteration @ 6643 is 2.278635263442993\n",
      "Loss at Iteration @ 6644 is 1.9515451192855835\n",
      "Evaluation Loss at Iteration @ 6644 is 2.26088809967041\n",
      "Loss at Iteration @ 6645 is 2.302490472793579\n",
      "Evaluation Loss at Iteration @ 6645 is 2.26214861869812\n",
      "Loss at Iteration @ 6646 is 2.307790517807007\n",
      "Evaluation Loss at Iteration @ 6646 is 2.296245574951172\n",
      "Loss at Iteration @ 6647 is 2.146650791168213\n",
      "Evaluation Loss at Iteration @ 6647 is 2.270484685897827\n",
      "Loss at Iteration @ 6648 is 2.0660758018493652\n",
      "Evaluation Loss at Iteration @ 6648 is 2.267094612121582\n",
      "Loss at Iteration @ 6649 is 1.9635041952133179\n",
      "Evaluation Loss at Iteration @ 6649 is 2.227649688720703\n",
      "Loss at Iteration @ 6650 is 2.0658118724823\n",
      "Evaluation Loss at Iteration @ 6650 is 2.2322797775268555\n",
      "Loss at Iteration @ 6651 is 2.361208438873291\n",
      "Evaluation Loss at Iteration @ 6651 is 2.2284677028656006\n",
      "Loss at Iteration @ 6652 is 2.2842371463775635\n",
      "Evaluation Loss at Iteration @ 6652 is 2.222914218902588\n",
      "Loss at Iteration @ 6653 is 2.1456384658813477\n",
      "Evaluation Loss at Iteration @ 6653 is 2.2100296020507812\n",
      "Loss at Iteration @ 6654 is 2.4964523315429688\n",
      "Evaluation Loss at Iteration @ 6654 is 2.245157241821289\n",
      "Loss at Iteration @ 6655 is 2.321462392807007\n",
      "Evaluation Loss at Iteration @ 6655 is 2.2601571083068848\n",
      "Loss at Iteration @ 6656 is 2.4614341259002686\n",
      "Evaluation Loss at Iteration @ 6656 is 2.259580612182617\n",
      "Loss at Iteration @ 6657 is 2.076327085494995\n",
      "Evaluation Loss at Iteration @ 6657 is 2.2796738147735596\n",
      "Loss at Iteration @ 6658 is 2.445298194885254\n",
      "Evaluation Loss at Iteration @ 6658 is 2.293574333190918\n",
      "Loss at Iteration @ 6659 is 2.385573148727417\n",
      "Evaluation Loss at Iteration @ 6659 is 2.296969413757324\n",
      "Loss at Iteration @ 6660 is 2.1738386154174805\n",
      "Evaluation Loss at Iteration @ 6660 is 2.277956485748291\n",
      "Loss at Iteration @ 6661 is 2.2228338718414307\n",
      "Evaluation Loss at Iteration @ 6661 is 2.248483657836914\n",
      "Loss at Iteration @ 6662 is 2.1036062240600586\n",
      "Evaluation Loss at Iteration @ 6662 is 2.2291383743286133\n",
      "Loss at Iteration @ 6663 is 2.0834176540374756\n",
      "Evaluation Loss at Iteration @ 6663 is 2.217637777328491\n",
      "Loss at Iteration @ 6664 is 2.361345052719116\n",
      "Evaluation Loss at Iteration @ 6664 is 2.217216968536377\n",
      "Loss at Iteration @ 6665 is 2.204768657684326\n",
      "Evaluation Loss at Iteration @ 6665 is 2.2516815662384033\n",
      "Loss at Iteration @ 6666 is 2.367525815963745\n",
      "Evaluation Loss at Iteration @ 6666 is 2.219693660736084\n",
      "Loss at Iteration @ 6667 is 2.2915291786193848\n",
      "Evaluation Loss at Iteration @ 6667 is 2.255011558532715\n",
      "Loss at Iteration @ 6668 is 2.18178129196167\n",
      "Evaluation Loss at Iteration @ 6668 is 2.2616851329803467\n",
      "Loss at Iteration @ 6669 is 2.4887099266052246\n",
      "Evaluation Loss at Iteration @ 6669 is 2.232743263244629\n",
      "Loss at Iteration @ 6670 is 2.207617998123169\n",
      "Evaluation Loss at Iteration @ 6670 is 2.2035326957702637\n",
      "Loss at Iteration @ 6671 is 2.160349130630493\n",
      "Evaluation Loss at Iteration @ 6671 is 2.295447826385498\n",
      "Loss at Iteration @ 6672 is 2.2142770290374756\n",
      "Evaluation Loss at Iteration @ 6672 is 2.292613983154297\n",
      "Loss at Iteration @ 6673 is 2.078784465789795\n",
      "Evaluation Loss at Iteration @ 6673 is 2.2154014110565186\n",
      "Loss at Iteration @ 6674 is 2.507516384124756\n",
      "Evaluation Loss at Iteration @ 6674 is 2.238983392715454\n",
      "Loss at Iteration @ 6675 is 2.2286365032196045\n",
      "Evaluation Loss at Iteration @ 6675 is 2.2469053268432617\n",
      "Loss at Iteration @ 6676 is 2.0792596340179443\n",
      "Evaluation Loss at Iteration @ 6676 is 2.2265262603759766\n",
      "Loss at Iteration @ 6677 is 2.2976105213165283\n",
      "Evaluation Loss at Iteration @ 6677 is 2.249688148498535\n",
      "Loss at Iteration @ 6678 is 2.274405002593994\n",
      "Evaluation Loss at Iteration @ 6678 is 2.244908571243286\n",
      "Loss at Iteration @ 6679 is 2.2028415203094482\n",
      "Evaluation Loss at Iteration @ 6679 is 2.2154362201690674\n",
      "Loss at Iteration @ 6680 is 2.115690231323242\n",
      "Evaluation Loss at Iteration @ 6680 is 2.222381830215454\n",
      "Loss at Iteration @ 6681 is 2.1470866203308105\n",
      "Evaluation Loss at Iteration @ 6681 is 2.2898638248443604\n",
      "Loss at Iteration @ 6682 is 2.27390718460083\n",
      "Evaluation Loss at Iteration @ 6682 is 2.2696855068206787\n",
      "Loss at Iteration @ 6683 is 2.3532180786132812\n",
      "Evaluation Loss at Iteration @ 6683 is 2.286684036254883\n",
      "Loss at Iteration @ 6684 is 2.1631362438201904\n",
      "Evaluation Loss at Iteration @ 6684 is 2.242465019226074\n",
      "Loss at Iteration @ 6685 is 2.406078815460205\n",
      "Evaluation Loss at Iteration @ 6685 is 2.2524068355560303\n",
      "Loss at Iteration @ 6686 is 2.414547920227051\n",
      "Evaluation Loss at Iteration @ 6686 is 2.2583224773406982\n",
      "Loss at Iteration @ 6687 is 2.2726340293884277\n",
      "Evaluation Loss at Iteration @ 6687 is 2.2764806747436523\n",
      "Loss at Iteration @ 6688 is 2.154967784881592\n",
      "Evaluation Loss at Iteration @ 6688 is 2.255406379699707\n",
      "Loss at Iteration @ 6689 is 2.524815320968628\n",
      "Evaluation Loss at Iteration @ 6689 is 2.255675792694092\n",
      "Loss at Iteration @ 6690 is 2.254960536956787\n",
      "Evaluation Loss at Iteration @ 6690 is 2.23811411857605\n",
      "Loss at Iteration @ 6691 is 2.045705795288086\n",
      "Evaluation Loss at Iteration @ 6691 is 2.270852565765381\n",
      "Loss at Iteration @ 6692 is 2.0424201488494873\n",
      "Evaluation Loss at Iteration @ 6692 is 2.220057725906372\n",
      "Loss at Iteration @ 6693 is 2.2162184715270996\n",
      "Evaluation Loss at Iteration @ 6693 is 2.254589080810547\n",
      "Loss at Iteration @ 6694 is 2.2773358821868896\n",
      "Evaluation Loss at Iteration @ 6694 is 2.329815626144409\n",
      "Loss at Iteration @ 6695 is 2.281712770462036\n",
      "Evaluation Loss at Iteration @ 6695 is 2.2458932399749756\n",
      "Loss at Iteration @ 6696 is 2.1785919666290283\n",
      "Evaluation Loss at Iteration @ 6696 is 2.261467695236206\n",
      "Loss at Iteration @ 6697 is 2.1532835960388184\n",
      "Evaluation Loss at Iteration @ 6697 is 2.227104425430298\n",
      "Loss at Iteration @ 6698 is 2.1750545501708984\n",
      "Evaluation Loss at Iteration @ 6698 is 2.2019059658050537\n",
      "Loss at Iteration @ 6699 is 2.501985788345337\n",
      "Evaluation Loss at Iteration @ 6699 is 2.231259346008301\n",
      "Loss at Iteration @ 6700 is 2.2654175758361816\n",
      "Evaluation Loss at Iteration @ 6700 is 2.2497434616088867\n",
      "Loss at Iteration @ 6701 is 2.097954034805298\n",
      "Evaluation Loss at Iteration @ 6701 is 2.247434616088867\n",
      "Loss at Iteration @ 6702 is 2.165120840072632\n",
      "Evaluation Loss at Iteration @ 6702 is 2.24294376373291\n",
      "Loss at Iteration @ 6703 is 2.112483501434326\n",
      "Evaluation Loss at Iteration @ 6703 is 2.254018545150757\n",
      "Loss at Iteration @ 6704 is 2.332472801208496\n",
      "Evaluation Loss at Iteration @ 6704 is 2.230396270751953\n",
      "Loss at Iteration @ 6705 is 2.369586944580078\n",
      "Evaluation Loss at Iteration @ 6705 is 2.230503797531128\n",
      "Loss at Iteration @ 6706 is 2.232801914215088\n",
      "Evaluation Loss at Iteration @ 6706 is 2.2687785625457764\n",
      "Loss at Iteration @ 6707 is 2.1814048290252686\n",
      "Evaluation Loss at Iteration @ 6707 is 2.2151377201080322\n",
      "Loss at Iteration @ 6708 is 2.3023264408111572\n",
      "Evaluation Loss at Iteration @ 6708 is 2.243833303451538\n",
      "Loss at Iteration @ 6709 is 2.100680112838745\n",
      "Evaluation Loss at Iteration @ 6709 is 2.2539031505584717\n",
      "Loss at Iteration @ 6710 is 2.1038341522216797\n",
      "Evaluation Loss at Iteration @ 6710 is 2.249894380569458\n",
      "Loss at Iteration @ 6711 is 2.080132007598877\n",
      "Evaluation Loss at Iteration @ 6711 is 2.2276322841644287\n",
      "Loss at Iteration @ 6712 is 2.3698647022247314\n",
      "Evaluation Loss at Iteration @ 6712 is 2.2896974086761475\n",
      "Loss at Iteration @ 6713 is 2.6025311946868896\n",
      "Evaluation Loss at Iteration @ 6713 is 2.2208080291748047\n",
      "Loss at Iteration @ 6714 is 2.3781723976135254\n",
      "Evaluation Loss at Iteration @ 6714 is 2.259366750717163\n",
      "Loss at Iteration @ 6715 is 2.296116590499878\n",
      "Evaluation Loss at Iteration @ 6715 is 2.2707602977752686\n",
      "Loss at Iteration @ 6716 is 2.1967015266418457\n",
      "Evaluation Loss at Iteration @ 6716 is 2.2635247707366943\n",
      "Loss at Iteration @ 6717 is 2.2125792503356934\n",
      "Evaluation Loss at Iteration @ 6717 is 2.2460341453552246\n",
      "Loss at Iteration @ 6718 is 2.0565178394317627\n",
      "Evaluation Loss at Iteration @ 6718 is 2.214081287384033\n",
      "Loss at Iteration @ 6719 is 2.278806447982788\n",
      "Evaluation Loss at Iteration @ 6719 is 2.2840325832366943\n",
      "Loss at Iteration @ 6720 is 2.5192084312438965\n",
      "Evaluation Loss at Iteration @ 6720 is 2.23469877243042\n",
      "Loss at Iteration @ 6721 is 2.443866729736328\n",
      "Evaluation Loss at Iteration @ 6721 is 2.2935521602630615\n",
      "Loss at Iteration @ 6722 is 1.894951343536377\n",
      "Evaluation Loss at Iteration @ 6722 is 2.2626802921295166\n",
      "Loss at Iteration @ 6723 is 2.3268821239471436\n",
      "Evaluation Loss at Iteration @ 6723 is 2.283344030380249\n",
      "Loss at Iteration @ 6724 is 2.1630160808563232\n",
      "Evaluation Loss at Iteration @ 6724 is 2.2568747997283936\n",
      "Loss at Iteration @ 6725 is 2.337268352508545\n",
      "Evaluation Loss at Iteration @ 6725 is 2.2227694988250732\n",
      "Loss at Iteration @ 6726 is 2.299798011779785\n",
      "Evaluation Loss at Iteration @ 6726 is 2.2547104358673096\n",
      "Loss at Iteration @ 6727 is 2.132690668106079\n",
      "Evaluation Loss at Iteration @ 6727 is 2.2712299823760986\n",
      "Loss at Iteration @ 6728 is 1.995707392692566\n",
      "Evaluation Loss at Iteration @ 6728 is 2.2842612266540527\n",
      "Loss at Iteration @ 6729 is 2.2430408000946045\n",
      "Evaluation Loss at Iteration @ 6729 is 2.2808210849761963\n",
      "Loss at Iteration @ 6730 is 2.319248676300049\n",
      "Evaluation Loss at Iteration @ 6730 is 2.249413013458252\n",
      "Loss at Iteration @ 6731 is 2.199064254760742\n",
      "Evaluation Loss at Iteration @ 6731 is 2.2592179775238037\n",
      "Loss at Iteration @ 6732 is 1.9808000326156616\n",
      "Evaluation Loss at Iteration @ 6732 is 2.241621971130371\n",
      "Loss at Iteration @ 6733 is 2.0373635292053223\n",
      "Evaluation Loss at Iteration @ 6733 is 2.2192986011505127\n",
      "Loss at Iteration @ 6734 is 2.3325281143188477\n",
      "Evaluation Loss at Iteration @ 6734 is 2.284489154815674\n",
      "Loss at Iteration @ 6735 is 2.3270974159240723\n",
      "Evaluation Loss at Iteration @ 6735 is 2.265089988708496\n",
      "Loss at Iteration @ 6736 is 2.209564447402954\n",
      "Evaluation Loss at Iteration @ 6736 is 2.22602915763855\n",
      "Loss at Iteration @ 6737 is 1.9309674501419067\n",
      "Evaluation Loss at Iteration @ 6737 is 2.252393960952759\n",
      "Loss at Iteration @ 6738 is 2.362680673599243\n",
      "Evaluation Loss at Iteration @ 6738 is 2.2407615184783936\n",
      "Loss at Iteration @ 6739 is 2.3546624183654785\n",
      "Evaluation Loss at Iteration @ 6739 is 2.2874178886413574\n",
      "Loss at Iteration @ 6740 is 2.382913112640381\n",
      "Evaluation Loss at Iteration @ 6740 is 2.263503074645996\n",
      "Loss at Iteration @ 6741 is 2.55314302444458\n",
      "Evaluation Loss at Iteration @ 6741 is 2.221277952194214\n",
      "Loss at Iteration @ 6742 is 2.121380090713501\n",
      "Evaluation Loss at Iteration @ 6742 is 2.2494983673095703\n",
      "Loss at Iteration @ 6743 is 2.3100240230560303\n",
      "Evaluation Loss at Iteration @ 6743 is 2.2217307090759277\n",
      "Loss at Iteration @ 6744 is 2.43218994140625\n",
      "Evaluation Loss at Iteration @ 6744 is 2.221858263015747\n",
      "Loss at Iteration @ 6745 is 2.1563034057617188\n",
      "Evaluation Loss at Iteration @ 6745 is 2.294981002807617\n",
      "Loss at Iteration @ 6746 is 2.246361017227173\n",
      "Evaluation Loss at Iteration @ 6746 is 2.261604070663452\n",
      "Loss at Iteration @ 6747 is 2.3082947731018066\n",
      "Evaluation Loss at Iteration @ 6747 is 2.2313942909240723\n",
      "Loss at Iteration @ 6748 is 2.2686665058135986\n",
      "Evaluation Loss at Iteration @ 6748 is 2.254669666290283\n",
      "Loss at Iteration @ 6749 is 2.526789426803589\n",
      "Evaluation Loss at Iteration @ 6749 is 2.2735419273376465\n",
      "Loss at Iteration @ 6750 is 2.256415605545044\n",
      "Evaluation Loss at Iteration @ 6750 is 2.2738711833953857\n",
      "Loss at Iteration @ 6751 is 2.150075674057007\n",
      "Evaluation Loss at Iteration @ 6751 is 2.2345855236053467\n",
      "Loss at Iteration @ 6752 is 2.066727876663208\n",
      "Evaluation Loss at Iteration @ 6752 is 2.250579833984375\n",
      "Loss at Iteration @ 6753 is 2.4737231731414795\n",
      "Evaluation Loss at Iteration @ 6753 is 2.2858455181121826\n",
      "Loss at Iteration @ 6754 is 2.360325574874878\n",
      "Evaluation Loss at Iteration @ 6754 is 2.227478504180908\n",
      "Loss at Iteration @ 6755 is 2.022394895553589\n",
      "Evaluation Loss at Iteration @ 6755 is 2.2654635906219482\n",
      "Loss at Iteration @ 6756 is 2.2923340797424316\n",
      "Evaluation Loss at Iteration @ 6756 is 2.2630889415740967\n",
      "Loss at Iteration @ 6757 is 2.303391218185425\n",
      "Evaluation Loss at Iteration @ 6757 is 2.217414617538452\n",
      "Loss at Iteration @ 6758 is 2.126552104949951\n",
      "Evaluation Loss at Iteration @ 6758 is 2.2141714096069336\n",
      "Loss at Iteration @ 6759 is 2.4163033962249756\n",
      "Evaluation Loss at Iteration @ 6759 is 2.21247935295105\n",
      "Loss at Iteration @ 6760 is 2.0303800106048584\n",
      "Evaluation Loss at Iteration @ 6760 is 2.195404052734375\n",
      "Loss at Iteration @ 6761 is 2.094987154006958\n",
      "Evaluation Loss at Iteration @ 6761 is 2.230137586593628\n",
      "Loss at Iteration @ 6762 is 2.3470816612243652\n",
      "Evaluation Loss at Iteration @ 6762 is 2.235933303833008\n",
      "Loss at Iteration @ 6763 is 1.893743634223938\n",
      "Evaluation Loss at Iteration @ 6763 is 2.2239508628845215\n",
      "Loss at Iteration @ 6764 is 2.4214556217193604\n",
      "Evaluation Loss at Iteration @ 6764 is 2.255039691925049\n",
      "Loss at Iteration @ 6765 is 2.38379168510437\n",
      "Evaluation Loss at Iteration @ 6765 is 2.2727651596069336\n",
      "Loss at Iteration @ 6766 is 2.3698225021362305\n",
      "Evaluation Loss at Iteration @ 6766 is 2.2547237873077393\n",
      "Loss at Iteration @ 6767 is 2.230361223220825\n",
      "Evaluation Loss at Iteration @ 6767 is 2.2651448249816895\n",
      "Loss at Iteration @ 6768 is 2.5274767875671387\n",
      "Evaluation Loss at Iteration @ 6768 is 2.2875466346740723\n",
      "Loss at Iteration @ 6769 is 2.195859909057617\n",
      "Evaluation Loss at Iteration @ 6769 is 2.261591672897339\n",
      "Loss at Iteration @ 6770 is 2.205721616744995\n",
      "Evaluation Loss at Iteration @ 6770 is 2.2610249519348145\n",
      "Loss at Iteration @ 6771 is 2.3016228675842285\n",
      "Evaluation Loss at Iteration @ 6771 is 2.269129514694214\n",
      "Loss at Iteration @ 6772 is 2.3889482021331787\n",
      "Evaluation Loss at Iteration @ 6772 is 2.250209331512451\n",
      "Loss at Iteration @ 6773 is 2.164581537246704\n",
      "Evaluation Loss at Iteration @ 6773 is 2.2387313842773438\n",
      "Loss at Iteration @ 6774 is 2.2472355365753174\n",
      "Evaluation Loss at Iteration @ 6774 is 2.2534561157226562\n",
      "Loss at Iteration @ 6775 is 2.229487895965576\n",
      "Evaluation Loss at Iteration @ 6775 is 2.190765857696533\n",
      "Loss at Iteration @ 6776 is 2.2372963428497314\n",
      "Evaluation Loss at Iteration @ 6776 is 2.243441104888916\n",
      "Loss at Iteration @ 6777 is 2.1385457515716553\n",
      "Evaluation Loss at Iteration @ 6777 is 2.2775604724884033\n",
      "Loss at Iteration @ 6778 is 1.8833630084991455\n",
      "Evaluation Loss at Iteration @ 6778 is 2.2195138931274414\n",
      "Loss at Iteration @ 6779 is 2.1194939613342285\n",
      "Evaluation Loss at Iteration @ 6779 is 2.249964714050293\n",
      "Loss at Iteration @ 6780 is 2.2901899814605713\n",
      "Evaluation Loss at Iteration @ 6780 is 2.2324540615081787\n",
      "Loss at Iteration @ 6781 is 2.1648447513580322\n",
      "Evaluation Loss at Iteration @ 6781 is 2.2409515380859375\n",
      "Loss at Iteration @ 6782 is 1.9572018384933472\n",
      "Evaluation Loss at Iteration @ 6782 is 2.2975857257843018\n",
      "Loss at Iteration @ 6783 is 2.1069064140319824\n",
      "Evaluation Loss at Iteration @ 6783 is 2.2744970321655273\n",
      "Loss at Iteration @ 6784 is 2.178697347640991\n",
      "Evaluation Loss at Iteration @ 6784 is 2.212299346923828\n",
      "Loss at Iteration @ 6785 is 2.4250333309173584\n",
      "Evaluation Loss at Iteration @ 6785 is 2.2536580562591553\n",
      "Loss at Iteration @ 6786 is 2.065786123275757\n",
      "Evaluation Loss at Iteration @ 6786 is 2.2266886234283447\n",
      "Loss at Iteration @ 6787 is 2.223402261734009\n",
      "Evaluation Loss at Iteration @ 6787 is 2.264626979827881\n",
      "Loss at Iteration @ 6788 is 2.584658145904541\n",
      "Evaluation Loss at Iteration @ 6788 is 2.246565103530884\n",
      "Loss at Iteration @ 6789 is 2.462200164794922\n",
      "Evaluation Loss at Iteration @ 6789 is 2.2470929622650146\n",
      "Loss at Iteration @ 6790 is 2.3278794288635254\n",
      "Evaluation Loss at Iteration @ 6790 is 2.260843276977539\n",
      "Loss at Iteration @ 6791 is 2.3815758228302\n",
      "Evaluation Loss at Iteration @ 6791 is 2.252143621444702\n",
      "Loss at Iteration @ 6792 is 1.9301403760910034\n",
      "Evaluation Loss at Iteration @ 6792 is 2.2246947288513184\n",
      "Loss at Iteration @ 6793 is 2.3387491703033447\n",
      "Evaluation Loss at Iteration @ 6793 is 2.2366859912872314\n",
      "Loss at Iteration @ 6794 is 2.3741958141326904\n",
      "Evaluation Loss at Iteration @ 6794 is 2.2348034381866455\n",
      "Loss at Iteration @ 6795 is 2.3188700675964355\n",
      "Evaluation Loss at Iteration @ 6795 is 2.218724489212036\n",
      "Loss at Iteration @ 6796 is 2.510324001312256\n",
      "Evaluation Loss at Iteration @ 6796 is 2.2495903968811035\n",
      "Loss at Iteration @ 6797 is 1.9930012226104736\n",
      "Evaluation Loss at Iteration @ 6797 is 2.2276947498321533\n",
      "Loss at Iteration @ 6798 is 2.227102756500244\n",
      "Evaluation Loss at Iteration @ 6798 is 2.2397515773773193\n",
      "Loss at Iteration @ 6799 is 2.2147552967071533\n",
      "Evaluation Loss at Iteration @ 6799 is 2.1972315311431885\n",
      "Loss at Iteration @ 6800 is 2.0516562461853027\n",
      "Evaluation Loss at Iteration @ 6800 is 2.26589035987854\n",
      "Loss at Iteration @ 6801 is 2.080260753631592\n",
      "Evaluation Loss at Iteration @ 6801 is 2.260962724685669\n",
      "Loss at Iteration @ 6802 is 2.1773667335510254\n",
      "Evaluation Loss at Iteration @ 6802 is 2.2268285751342773\n",
      "Loss at Iteration @ 6803 is 2.0953500270843506\n",
      "Evaluation Loss at Iteration @ 6803 is 2.269310712814331\n",
      "Loss at Iteration @ 6804 is 1.9749817848205566\n",
      "Evaluation Loss at Iteration @ 6804 is 2.2282767295837402\n",
      "Loss at Iteration @ 6805 is 1.9619090557098389\n",
      "Evaluation Loss at Iteration @ 6805 is 2.250955581665039\n",
      "Loss at Iteration @ 6806 is 2.3063740730285645\n",
      "Evaluation Loss at Iteration @ 6806 is 2.221945285797119\n",
      "Loss at Iteration @ 6807 is 2.1310818195343018\n",
      "Evaluation Loss at Iteration @ 6807 is 2.24690318107605\n",
      "Loss at Iteration @ 6808 is 2.273146867752075\n",
      "Evaluation Loss at Iteration @ 6808 is 2.266031265258789\n",
      "Loss at Iteration @ 6809 is 2.223806142807007\n",
      "Evaluation Loss at Iteration @ 6809 is 2.3041107654571533\n",
      "Loss at Iteration @ 6810 is 2.1398825645446777\n",
      "Evaluation Loss at Iteration @ 6810 is 2.218161106109619\n",
      "Loss at Iteration @ 6811 is 2.360443592071533\n",
      "Evaluation Loss at Iteration @ 6811 is 2.257906675338745\n",
      "Loss at Iteration @ 6812 is 2.173504114151001\n",
      "Evaluation Loss at Iteration @ 6812 is 2.236257791519165\n",
      "Loss at Iteration @ 6813 is 2.2375636100769043\n",
      "Evaluation Loss at Iteration @ 6813 is 2.24703311920166\n",
      "Loss at Iteration @ 6814 is 2.3098912239074707\n",
      "Evaluation Loss at Iteration @ 6814 is 2.2539076805114746\n",
      "Loss at Iteration @ 6815 is 2.387221336364746\n",
      "Evaluation Loss at Iteration @ 6815 is 2.2831408977508545\n",
      "Loss at Iteration @ 6816 is 2.2998883724212646\n",
      "Evaluation Loss at Iteration @ 6816 is 2.2479805946350098\n",
      "Loss at Iteration @ 6817 is 1.8342416286468506\n",
      "Evaluation Loss at Iteration @ 6817 is 2.2152199745178223\n",
      "Loss at Iteration @ 6818 is 2.2576112747192383\n",
      "Evaluation Loss at Iteration @ 6818 is 2.2713119983673096\n",
      "Loss at Iteration @ 6819 is 2.1699259281158447\n",
      "Evaluation Loss at Iteration @ 6819 is 2.2720794677734375\n",
      "Loss at Iteration @ 6820 is 2.266711473464966\n",
      "Evaluation Loss at Iteration @ 6820 is 2.266319751739502\n",
      "Loss at Iteration @ 6821 is 2.172680616378784\n",
      "Evaluation Loss at Iteration @ 6821 is 2.1989781856536865\n",
      "Loss at Iteration @ 6822 is 2.297650098800659\n",
      "Evaluation Loss at Iteration @ 6822 is 2.228571891784668\n",
      "Loss at Iteration @ 6823 is 2.138537883758545\n",
      "Evaluation Loss at Iteration @ 6823 is 2.2638707160949707\n",
      "Loss at Iteration @ 6824 is 2.2364509105682373\n",
      "Evaluation Loss at Iteration @ 6824 is 2.2051422595977783\n",
      "Loss at Iteration @ 6825 is 2.0342204570770264\n",
      "Evaluation Loss at Iteration @ 6825 is 2.220050573348999\n",
      "Loss at Iteration @ 6826 is 2.2579212188720703\n",
      "Evaluation Loss at Iteration @ 6826 is 2.234894037246704\n",
      "Loss at Iteration @ 6827 is 2.033447742462158\n",
      "Evaluation Loss at Iteration @ 6827 is 2.2738418579101562\n",
      "Loss at Iteration @ 6828 is 2.2649636268615723\n",
      "Evaluation Loss at Iteration @ 6828 is 2.231273651123047\n",
      "Loss at Iteration @ 6829 is 2.344137668609619\n",
      "Evaluation Loss at Iteration @ 6829 is 2.228567361831665\n",
      "Loss at Iteration @ 6830 is 2.1200318336486816\n",
      "Evaluation Loss at Iteration @ 6830 is 2.2790298461914062\n",
      "Loss at Iteration @ 6831 is 2.0988516807556152\n",
      "Evaluation Loss at Iteration @ 6831 is 2.2397546768188477\n",
      "Loss at Iteration @ 6832 is 2.0234363079071045\n",
      "Evaluation Loss at Iteration @ 6832 is 2.280702829360962\n",
      "Loss at Iteration @ 6833 is 2.3431990146636963\n",
      "Evaluation Loss at Iteration @ 6833 is 2.2721633911132812\n",
      "Loss at Iteration @ 6834 is 2.347656011581421\n",
      "Evaluation Loss at Iteration @ 6834 is 2.2040205001831055\n",
      "Loss at Iteration @ 6835 is 2.184309959411621\n",
      "Evaluation Loss at Iteration @ 6835 is 2.2292897701263428\n",
      "Loss at Iteration @ 6836 is 2.2358648777008057\n",
      "Evaluation Loss at Iteration @ 6836 is 2.2572343349456787\n",
      "Loss at Iteration @ 6837 is 2.3304007053375244\n",
      "Evaluation Loss at Iteration @ 6837 is 2.239058256149292\n",
      "Loss at Iteration @ 6838 is 1.9479552507400513\n",
      "Evaluation Loss at Iteration @ 6838 is 2.2194912433624268\n",
      "Loss at Iteration @ 6839 is 1.7811099290847778\n",
      "Evaluation Loss at Iteration @ 6839 is 2.259749412536621\n",
      "Loss at Iteration @ 6840 is 2.103935718536377\n",
      "Evaluation Loss at Iteration @ 6840 is 2.2222251892089844\n",
      "Loss at Iteration @ 6841 is 1.9886884689331055\n",
      "Evaluation Loss at Iteration @ 6841 is 2.3093578815460205\n",
      "Loss at Iteration @ 6842 is 2.290008068084717\n",
      "Evaluation Loss at Iteration @ 6842 is 2.252983331680298\n",
      "Loss at Iteration @ 6843 is 2.3878679275512695\n",
      "Evaluation Loss at Iteration @ 6843 is 2.2421326637268066\n",
      "Loss at Iteration @ 6844 is 2.3648841381073\n",
      "Evaluation Loss at Iteration @ 6844 is 2.266321897506714\n",
      "Loss at Iteration @ 6845 is 2.0464541912078857\n",
      "Evaluation Loss at Iteration @ 6845 is 2.2387561798095703\n",
      "Loss at Iteration @ 6846 is 2.544160842895508\n",
      "Evaluation Loss at Iteration @ 6846 is 2.2590417861938477\n",
      "Loss at Iteration @ 6847 is 2.2019145488739014\n",
      "Evaluation Loss at Iteration @ 6847 is 2.186450481414795\n",
      "Loss at Iteration @ 6848 is 2.2827231884002686\n",
      "Evaluation Loss at Iteration @ 6848 is 2.2370965480804443\n",
      "Loss at Iteration @ 6849 is 2.449890375137329\n",
      "Evaluation Loss at Iteration @ 6849 is 2.273460865020752\n",
      "Loss at Iteration @ 6850 is 1.8561878204345703\n",
      "Evaluation Loss at Iteration @ 6850 is 2.253683090209961\n",
      "Loss at Iteration @ 6851 is 2.241633415222168\n",
      "Evaluation Loss at Iteration @ 6851 is 2.2591238021850586\n",
      "Loss at Iteration @ 6852 is 2.0621821880340576\n",
      "Evaluation Loss at Iteration @ 6852 is 2.2581939697265625\n",
      "Loss at Iteration @ 6853 is 2.2932162284851074\n",
      "Evaluation Loss at Iteration @ 6853 is 2.2274410724639893\n",
      "Loss at Iteration @ 6854 is 2.2567410469055176\n",
      "Evaluation Loss at Iteration @ 6854 is 2.256392002105713\n",
      "Loss at Iteration @ 6855 is 2.4475483894348145\n",
      "Evaluation Loss at Iteration @ 6855 is 2.3068034648895264\n",
      "Loss at Iteration @ 6856 is 2.190195083618164\n",
      "Evaluation Loss at Iteration @ 6856 is 2.2270610332489014\n",
      "Loss at Iteration @ 6857 is 2.766021966934204\n",
      "Evaluation Loss at Iteration @ 6857 is 2.2015397548675537\n",
      "Loss at Iteration @ 6858 is 2.1131327152252197\n",
      "Evaluation Loss at Iteration @ 6858 is 2.212693214416504\n",
      "Loss at Iteration @ 6859 is 1.8724658489227295\n",
      "Evaluation Loss at Iteration @ 6859 is 2.225616931915283\n",
      "Loss at Iteration @ 6860 is 2.101315498352051\n",
      "Evaluation Loss at Iteration @ 6860 is 2.2456750869750977\n",
      "Loss at Iteration @ 6861 is 2.4868414402008057\n",
      "Evaluation Loss at Iteration @ 6861 is 2.288482666015625\n",
      "Loss at Iteration @ 6862 is 2.404973268508911\n",
      "Evaluation Loss at Iteration @ 6862 is 2.2847936153411865\n",
      "Loss at Iteration @ 6863 is 2.4568190574645996\n",
      "Evaluation Loss at Iteration @ 6863 is 2.2553629875183105\n",
      "Loss at Iteration @ 6864 is 2.1322720050811768\n",
      "Evaluation Loss at Iteration @ 6864 is 2.247997999191284\n",
      "Loss at Iteration @ 6865 is 2.378096580505371\n",
      "Evaluation Loss at Iteration @ 6865 is 2.247678756713867\n",
      "Loss at Iteration @ 6866 is 2.227863073348999\n",
      "Evaluation Loss at Iteration @ 6866 is 2.22133731842041\n",
      "Loss at Iteration @ 6867 is 2.360107898712158\n",
      "Evaluation Loss at Iteration @ 6867 is 2.273344039916992\n",
      "Loss at Iteration @ 6868 is 2.1145195960998535\n",
      "Evaluation Loss at Iteration @ 6868 is 2.2645695209503174\n",
      "Loss at Iteration @ 6869 is 1.9629467725753784\n",
      "Evaluation Loss at Iteration @ 6869 is 2.2072677612304688\n",
      "Loss at Iteration @ 6870 is 2.0017967224121094\n",
      "Evaluation Loss at Iteration @ 6870 is 2.247072219848633\n",
      "Loss at Iteration @ 6871 is 2.031480550765991\n",
      "Evaluation Loss at Iteration @ 6871 is 2.2829771041870117\n",
      "Loss at Iteration @ 6872 is 2.067958354949951\n",
      "Evaluation Loss at Iteration @ 6872 is 2.234537363052368\n",
      "Loss at Iteration @ 6873 is 2.250910997390747\n",
      "Evaluation Loss at Iteration @ 6873 is 2.2346601486206055\n",
      "Loss at Iteration @ 6874 is 2.2724390029907227\n",
      "Evaluation Loss at Iteration @ 6874 is 2.197688102722168\n",
      "Loss at Iteration @ 6875 is 2.062690496444702\n",
      "Evaluation Loss at Iteration @ 6875 is 2.2258424758911133\n",
      "Loss at Iteration @ 6876 is 2.432135820388794\n",
      "Evaluation Loss at Iteration @ 6876 is 2.2230207920074463\n",
      "Loss at Iteration @ 6877 is 2.3703794479370117\n",
      "Evaluation Loss at Iteration @ 6877 is 2.196143627166748\n",
      "Loss at Iteration @ 6878 is 2.1919498443603516\n",
      "Evaluation Loss at Iteration @ 6878 is 2.266063928604126\n",
      "Loss at Iteration @ 6879 is 2.5141334533691406\n",
      "Evaluation Loss at Iteration @ 6879 is 2.2547414302825928\n",
      "Loss at Iteration @ 6880 is 2.104466438293457\n",
      "Evaluation Loss at Iteration @ 6880 is 2.2620644569396973\n",
      "Loss at Iteration @ 6881 is 2.401895046234131\n",
      "Evaluation Loss at Iteration @ 6881 is 2.19291615486145\n",
      "Loss at Iteration @ 6882 is 2.367957830429077\n",
      "Evaluation Loss at Iteration @ 6882 is 2.276021957397461\n",
      "Loss at Iteration @ 6883 is 2.242537021636963\n",
      "Evaluation Loss at Iteration @ 6883 is 2.2999157905578613\n",
      "Loss at Iteration @ 6884 is 2.019979953765869\n",
      "Evaluation Loss at Iteration @ 6884 is 2.2611517906188965\n",
      "Loss at Iteration @ 6885 is 2.289013147354126\n",
      "Evaluation Loss at Iteration @ 6885 is 2.308462619781494\n",
      "Loss at Iteration @ 6886 is 2.0607962608337402\n",
      "Evaluation Loss at Iteration @ 6886 is 2.272400379180908\n",
      "Loss at Iteration @ 6887 is 2.091207504272461\n",
      "Evaluation Loss at Iteration @ 6887 is 2.211458206176758\n",
      "Loss at Iteration @ 6888 is 2.2877960205078125\n",
      "Evaluation Loss at Iteration @ 6888 is 2.2726736068725586\n",
      "Loss at Iteration @ 6889 is 2.1466734409332275\n",
      "Evaluation Loss at Iteration @ 6889 is 2.220571279525757\n",
      "Loss at Iteration @ 6890 is 1.9693663120269775\n",
      "Evaluation Loss at Iteration @ 6890 is 2.237475633621216\n",
      "Loss at Iteration @ 6891 is 2.331111192703247\n",
      "Evaluation Loss at Iteration @ 6891 is 2.2335734367370605\n",
      "Loss at Iteration @ 6892 is 2.675203561782837\n",
      "Evaluation Loss at Iteration @ 6892 is 2.2234888076782227\n",
      "Loss at Iteration @ 6893 is 2.290386438369751\n",
      "Evaluation Loss at Iteration @ 6893 is 2.223994255065918\n",
      "Loss at Iteration @ 6894 is 2.3121933937072754\n",
      "Evaluation Loss at Iteration @ 6894 is 2.238037347793579\n",
      "Loss at Iteration @ 6895 is 2.547999620437622\n",
      "Evaluation Loss at Iteration @ 6895 is 2.2492809295654297\n",
      "Loss at Iteration @ 6896 is 1.7355003356933594\n",
      "Evaluation Loss at Iteration @ 6896 is 2.2872703075408936\n",
      "Loss at Iteration @ 6897 is 2.0667834281921387\n",
      "Evaluation Loss at Iteration @ 6897 is 2.1972451210021973\n",
      "Loss at Iteration @ 6898 is 2.3487160205841064\n",
      "Evaluation Loss at Iteration @ 6898 is 2.22400164604187\n",
      "Loss at Iteration @ 6899 is 2.036487340927124\n",
      "Evaluation Loss at Iteration @ 6899 is 2.261518955230713\n",
      "Loss at Iteration @ 6900 is 2.212209701538086\n",
      "Evaluation Loss at Iteration @ 6900 is 2.2723915576934814\n",
      "Loss at Iteration @ 6901 is 2.317648410797119\n",
      "Evaluation Loss at Iteration @ 6901 is 2.223531723022461\n",
      "Loss at Iteration @ 6902 is 2.2339107990264893\n",
      "Evaluation Loss at Iteration @ 6902 is 2.2802815437316895\n",
      "Loss at Iteration @ 6903 is 2.096439838409424\n",
      "Evaluation Loss at Iteration @ 6903 is 2.27275013923645\n",
      "Loss at Iteration @ 6904 is 2.1519272327423096\n",
      "Evaluation Loss at Iteration @ 6904 is 2.2399301528930664\n",
      "Loss at Iteration @ 6905 is 1.8567659854888916\n",
      "Evaluation Loss at Iteration @ 6905 is 2.2517030239105225\n",
      "Loss at Iteration @ 6906 is 2.323826551437378\n",
      "Evaluation Loss at Iteration @ 6906 is 2.215306282043457\n",
      "Loss at Iteration @ 6907 is 2.0850870609283447\n",
      "Evaluation Loss at Iteration @ 6907 is 2.2258591651916504\n",
      "Loss at Iteration @ 6908 is 2.6572482585906982\n",
      "Evaluation Loss at Iteration @ 6908 is 2.2453036308288574\n",
      "Loss at Iteration @ 6909 is 2.1075360774993896\n",
      "Evaluation Loss at Iteration @ 6909 is 2.2529337406158447\n",
      "Loss at Iteration @ 6910 is 2.3610615730285645\n",
      "Evaluation Loss at Iteration @ 6910 is 2.263148784637451\n",
      "Loss at Iteration @ 6911 is 2.041311025619507\n",
      "Evaluation Loss at Iteration @ 6911 is 2.2442245483398438\n",
      "Loss at Iteration @ 6912 is 2.2387444972991943\n",
      "Evaluation Loss at Iteration @ 6912 is 2.2617292404174805\n",
      "Loss at Iteration @ 6913 is 2.1241676807403564\n",
      "Evaluation Loss at Iteration @ 6913 is 2.2638466358184814\n",
      "Loss at Iteration @ 6914 is 2.40605092048645\n",
      "Evaluation Loss at Iteration @ 6914 is 2.2998321056365967\n",
      "Loss at Iteration @ 6915 is 2.4121525287628174\n",
      "Evaluation Loss at Iteration @ 6915 is 2.2415716648101807\n",
      "Loss at Iteration @ 6916 is 1.8827180862426758\n",
      "Evaluation Loss at Iteration @ 6916 is 2.2282774448394775\n",
      "Loss at Iteration @ 6917 is 2.0880653858184814\n",
      "Evaluation Loss at Iteration @ 6917 is 2.2378740310668945\n",
      "Loss at Iteration @ 6918 is 2.196422815322876\n",
      "Evaluation Loss at Iteration @ 6918 is 2.2617998123168945\n",
      "Loss at Iteration @ 6919 is 2.4242746829986572\n",
      "Evaluation Loss at Iteration @ 6919 is 2.254112958908081\n",
      "Loss at Iteration @ 6920 is 2.2602968215942383\n",
      "Evaluation Loss at Iteration @ 6920 is 2.2514443397521973\n",
      "Loss at Iteration @ 6921 is 2.2233901023864746\n",
      "Evaluation Loss at Iteration @ 6921 is 2.190464973449707\n",
      "Loss at Iteration @ 6922 is 2.1901440620422363\n",
      "Evaluation Loss at Iteration @ 6922 is 2.2963409423828125\n",
      "Loss at Iteration @ 6923 is 2.2653627395629883\n",
      "Evaluation Loss at Iteration @ 6923 is 2.241069793701172\n",
      "Loss at Iteration @ 6924 is 2.444305419921875\n",
      "Evaluation Loss at Iteration @ 6924 is 2.290314197540283\n",
      "Loss at Iteration @ 6925 is 2.3644216060638428\n",
      "Evaluation Loss at Iteration @ 6925 is 2.260991096496582\n",
      "Loss at Iteration @ 6926 is 1.937710165977478\n",
      "Evaluation Loss at Iteration @ 6926 is 2.248051643371582\n",
      "Loss at Iteration @ 6927 is 2.347055673599243\n",
      "Evaluation Loss at Iteration @ 6927 is 2.2599287033081055\n",
      "Loss at Iteration @ 6928 is 2.3220245838165283\n",
      "Evaluation Loss at Iteration @ 6928 is 2.2607920169830322\n",
      "Loss at Iteration @ 6929 is 2.3223979473114014\n",
      "Evaluation Loss at Iteration @ 6929 is 2.233821153640747\n",
      "Loss at Iteration @ 6930 is 2.325662851333618\n",
      "Evaluation Loss at Iteration @ 6930 is 2.2220847606658936\n",
      "Loss at Iteration @ 6931 is 2.164872407913208\n",
      "Evaluation Loss at Iteration @ 6931 is 2.2634735107421875\n",
      "Loss at Iteration @ 6932 is 2.323127031326294\n",
      "Evaluation Loss at Iteration @ 6932 is 2.2845726013183594\n",
      "Loss at Iteration @ 6933 is 2.3679325580596924\n",
      "Evaluation Loss at Iteration @ 6933 is 2.2198386192321777\n",
      "Loss at Iteration @ 6934 is 2.2909746170043945\n",
      "Evaluation Loss at Iteration @ 6934 is 2.254059314727783\n",
      "Loss at Iteration @ 6935 is 2.33402681350708\n",
      "Evaluation Loss at Iteration @ 6935 is 2.241729736328125\n",
      "Loss at Iteration @ 6936 is 2.3937602043151855\n",
      "Evaluation Loss at Iteration @ 6936 is 2.212663173675537\n",
      "Loss at Iteration @ 6937 is 2.0979535579681396\n",
      "Evaluation Loss at Iteration @ 6937 is 2.2871358394622803\n",
      "Loss at Iteration @ 6938 is 2.1000537872314453\n",
      "Evaluation Loss at Iteration @ 6938 is 2.2325305938720703\n",
      "Loss at Iteration @ 6939 is 2.0509393215179443\n",
      "Evaluation Loss at Iteration @ 6939 is 2.2611563205718994\n",
      "Loss at Iteration @ 6940 is 2.226867437362671\n",
      "Evaluation Loss at Iteration @ 6940 is 2.230743646621704\n",
      "Loss at Iteration @ 6941 is 2.095944881439209\n",
      "Evaluation Loss at Iteration @ 6941 is 2.263371467590332\n",
      "Loss at Iteration @ 6942 is 2.0666351318359375\n",
      "Evaluation Loss at Iteration @ 6942 is 2.2814130783081055\n",
      "Loss at Iteration @ 6943 is 2.216041088104248\n",
      "Evaluation Loss at Iteration @ 6943 is 2.2198562622070312\n",
      "Loss at Iteration @ 6944 is 2.13836407661438\n",
      "Evaluation Loss at Iteration @ 6944 is 2.2740731239318848\n",
      "Loss at Iteration @ 6945 is 2.1645193099975586\n",
      "Evaluation Loss at Iteration @ 6945 is 2.1826157569885254\n",
      "Loss at Iteration @ 6946 is 1.938583493232727\n",
      "Evaluation Loss at Iteration @ 6946 is 2.2751691341400146\n",
      "Loss at Iteration @ 6947 is 2.156456470489502\n",
      "Evaluation Loss at Iteration @ 6947 is 2.212568998336792\n",
      "Loss at Iteration @ 6948 is 2.2848355770111084\n",
      "Evaluation Loss at Iteration @ 6948 is 2.27131724357605\n",
      "Loss at Iteration @ 6949 is 2.1077613830566406\n",
      "Evaluation Loss at Iteration @ 6949 is 2.271721839904785\n",
      "Loss at Iteration @ 6950 is 2.3036868572235107\n",
      "Evaluation Loss at Iteration @ 6950 is 2.238131046295166\n",
      "Loss at Iteration @ 6951 is 2.20510196685791\n",
      "Evaluation Loss at Iteration @ 6951 is 2.214088201522827\n",
      "Loss at Iteration @ 6952 is 2.25146746635437\n",
      "Evaluation Loss at Iteration @ 6952 is 2.2837319374084473\n",
      "Loss at Iteration @ 6953 is 2.3685708045959473\n",
      "Evaluation Loss at Iteration @ 6953 is 2.2246837615966797\n",
      "Loss at Iteration @ 6954 is 2.4552009105682373\n",
      "Evaluation Loss at Iteration @ 6954 is 2.213639259338379\n",
      "Loss at Iteration @ 6955 is 1.9173743724822998\n",
      "Evaluation Loss at Iteration @ 6955 is 2.234595537185669\n",
      "Loss at Iteration @ 6956 is 2.262474298477173\n",
      "Evaluation Loss at Iteration @ 6956 is 2.264732599258423\n",
      "Loss at Iteration @ 6957 is 2.221550226211548\n",
      "Evaluation Loss at Iteration @ 6957 is 2.217970609664917\n",
      "Loss at Iteration @ 6958 is 2.1698412895202637\n",
      "Evaluation Loss at Iteration @ 6958 is 2.2248549461364746\n",
      "Loss at Iteration @ 6959 is 2.0084407329559326\n",
      "Evaluation Loss at Iteration @ 6959 is 2.3230481147766113\n",
      "Loss at Iteration @ 6960 is 2.4995298385620117\n",
      "Evaluation Loss at Iteration @ 6960 is 2.2840077877044678\n",
      "Loss at Iteration @ 6961 is 2.2547147274017334\n",
      "Evaluation Loss at Iteration @ 6961 is 2.220254421234131\n",
      "Loss at Iteration @ 6962 is 1.9901570081710815\n",
      "Evaluation Loss at Iteration @ 6962 is 2.277845859527588\n",
      "Loss at Iteration @ 6963 is 2.404705762863159\n",
      "Evaluation Loss at Iteration @ 6963 is 2.2614991664886475\n",
      "Loss at Iteration @ 6964 is 2.003082036972046\n",
      "Evaluation Loss at Iteration @ 6964 is 2.2485830783843994\n",
      "Loss at Iteration @ 6965 is 1.994681477546692\n",
      "Evaluation Loss at Iteration @ 6965 is 2.2566030025482178\n",
      "Loss at Iteration @ 6966 is 2.2403268814086914\n",
      "Evaluation Loss at Iteration @ 6966 is 2.256256103515625\n",
      "Loss at Iteration @ 6967 is 2.3677191734313965\n",
      "Evaluation Loss at Iteration @ 6967 is 2.262819290161133\n",
      "Loss at Iteration @ 6968 is 2.071040391921997\n",
      "Evaluation Loss at Iteration @ 6968 is 2.2847414016723633\n",
      "Loss at Iteration @ 6969 is 2.4823365211486816\n",
      "Evaluation Loss at Iteration @ 6969 is 2.2642533779144287\n",
      "Loss at Iteration @ 6970 is 2.4483931064605713\n",
      "Evaluation Loss at Iteration @ 6970 is 2.2780232429504395\n",
      "Loss at Iteration @ 6971 is 2.3805630207061768\n",
      "Evaluation Loss at Iteration @ 6971 is 2.221595525741577\n",
      "Loss at Iteration @ 6972 is 2.3397700786590576\n",
      "Evaluation Loss at Iteration @ 6972 is 2.2406890392303467\n",
      "Loss at Iteration @ 6973 is 1.9324686527252197\n",
      "Evaluation Loss at Iteration @ 6973 is 2.2263479232788086\n",
      "Loss at Iteration @ 6974 is 2.198990821838379\n",
      "Evaluation Loss at Iteration @ 6974 is 2.248049736022949\n",
      "Loss at Iteration @ 6975 is 2.263219118118286\n",
      "Evaluation Loss at Iteration @ 6975 is 2.206221580505371\n",
      "Loss at Iteration @ 6976 is 2.428647756576538\n",
      "Evaluation Loss at Iteration @ 6976 is 2.249234676361084\n",
      "Loss at Iteration @ 6977 is 2.3306832313537598\n",
      "Evaluation Loss at Iteration @ 6977 is 2.2211356163024902\n",
      "Loss at Iteration @ 6978 is 2.2771613597869873\n",
      "Evaluation Loss at Iteration @ 6978 is 2.2585484981536865\n",
      "Loss at Iteration @ 6979 is 2.332486867904663\n",
      "Evaluation Loss at Iteration @ 6979 is 2.1943113803863525\n",
      "Loss at Iteration @ 6980 is 2.294426441192627\n",
      "Evaluation Loss at Iteration @ 6980 is 2.2675893306732178\n",
      "Loss at Iteration @ 6981 is 2.246619462966919\n",
      "Evaluation Loss at Iteration @ 6981 is 2.2144393920898438\n",
      "Loss at Iteration @ 6982 is 2.190783977508545\n",
      "Evaluation Loss at Iteration @ 6982 is 2.283597946166992\n",
      "Loss at Iteration @ 6983 is 2.1411235332489014\n",
      "Evaluation Loss at Iteration @ 6983 is 2.1588432788848877\n",
      "Loss at Iteration @ 6984 is 2.273730754852295\n",
      "Evaluation Loss at Iteration @ 6984 is 2.2509572505950928\n",
      "Loss at Iteration @ 6985 is 2.2043251991271973\n",
      "Evaluation Loss at Iteration @ 6985 is 2.277426242828369\n",
      "Loss at Iteration @ 6986 is 2.3676342964172363\n",
      "Evaluation Loss at Iteration @ 6986 is 2.2679717540740967\n",
      "Loss at Iteration @ 6987 is 2.3044064044952393\n",
      "Evaluation Loss at Iteration @ 6987 is 2.2898685932159424\n",
      "Loss at Iteration @ 6988 is 1.9773035049438477\n",
      "Evaluation Loss at Iteration @ 6988 is 2.2544004917144775\n",
      "Loss at Iteration @ 6989 is 2.383068084716797\n",
      "Evaluation Loss at Iteration @ 6989 is 2.3078863620758057\n",
      "Loss at Iteration @ 6990 is 2.220067262649536\n",
      "Evaluation Loss at Iteration @ 6990 is 2.2478933334350586\n",
      "Loss at Iteration @ 6991 is 2.4803688526153564\n",
      "Evaluation Loss at Iteration @ 6991 is 2.2450125217437744\n",
      "Loss at Iteration @ 6992 is 2.629749298095703\n",
      "Evaluation Loss at Iteration @ 6992 is 2.225066900253296\n",
      "Loss at Iteration @ 6993 is 2.216259241104126\n",
      "Evaluation Loss at Iteration @ 6993 is 2.257260322570801\n",
      "Loss at Iteration @ 6994 is 2.2221856117248535\n",
      "Evaluation Loss at Iteration @ 6994 is 2.2461273670196533\n",
      "Loss at Iteration @ 6995 is 2.1472442150115967\n",
      "Evaluation Loss at Iteration @ 6995 is 2.2605814933776855\n",
      "Loss at Iteration @ 6996 is 2.1867763996124268\n",
      "Evaluation Loss at Iteration @ 6996 is 2.255382776260376\n",
      "Loss at Iteration @ 6997 is 2.344252347946167\n",
      "Evaluation Loss at Iteration @ 6997 is 2.2327446937561035\n",
      "Loss at Iteration @ 6998 is 2.1629295349121094\n",
      "Evaluation Loss at Iteration @ 6998 is 2.2794437408447266\n",
      "Loss at Iteration @ 6999 is 2.462029218673706\n",
      "Evaluation Loss at Iteration @ 6999 is 2.2227623462677\n",
      "Loss at Iteration @ 7000 is 2.4067485332489014\n",
      "Evaluation Loss at Iteration @ 7000 is 2.242246150970459\n",
      "Loss at Iteration @ 7001 is 2.1639630794525146\n",
      "Evaluation Loss at Iteration @ 7001 is 2.2319834232330322\n",
      "Loss at Iteration @ 7002 is 2.2497053146362305\n",
      "Evaluation Loss at Iteration @ 7002 is 2.2565135955810547\n",
      "Loss at Iteration @ 7003 is 2.095726728439331\n",
      "Evaluation Loss at Iteration @ 7003 is 2.204134464263916\n",
      "Loss at Iteration @ 7004 is 2.2603676319122314\n",
      "Evaluation Loss at Iteration @ 7004 is 2.2481603622436523\n",
      "Loss at Iteration @ 7005 is 2.2671074867248535\n",
      "Evaluation Loss at Iteration @ 7005 is 2.250440835952759\n",
      "Loss at Iteration @ 7006 is 1.9646713733673096\n",
      "Evaluation Loss at Iteration @ 7006 is 2.241868257522583\n",
      "Loss at Iteration @ 7007 is 2.3179078102111816\n",
      "Evaluation Loss at Iteration @ 7007 is 2.2634546756744385\n",
      "Loss at Iteration @ 7008 is 2.152344226837158\n",
      "Evaluation Loss at Iteration @ 7008 is 2.2531981468200684\n",
      "Loss at Iteration @ 7009 is 2.2693042755126953\n",
      "Evaluation Loss at Iteration @ 7009 is 2.1995632648468018\n",
      "Loss at Iteration @ 7010 is 2.4491007328033447\n",
      "Evaluation Loss at Iteration @ 7010 is 2.2736198902130127\n",
      "Loss at Iteration @ 7011 is 2.130495071411133\n",
      "Evaluation Loss at Iteration @ 7011 is 2.233659029006958\n",
      "Loss at Iteration @ 7012 is 2.199584484100342\n",
      "Evaluation Loss at Iteration @ 7012 is 2.256596326828003\n",
      "Loss at Iteration @ 7013 is 2.2122278213500977\n",
      "Evaluation Loss at Iteration @ 7013 is 2.274395227432251\n",
      "Loss at Iteration @ 7014 is 2.151259422302246\n",
      "Evaluation Loss at Iteration @ 7014 is 2.2658138275146484\n",
      "Loss at Iteration @ 7015 is 2.3986148834228516\n",
      "Evaluation Loss at Iteration @ 7015 is 2.295102596282959\n",
      "Loss at Iteration @ 7016 is 2.2865240573883057\n",
      "Evaluation Loss at Iteration @ 7016 is 2.2564289569854736\n",
      "Loss at Iteration @ 7017 is 2.354879379272461\n",
      "Evaluation Loss at Iteration @ 7017 is 2.267686605453491\n",
      "Loss at Iteration @ 7018 is 2.3418567180633545\n",
      "Evaluation Loss at Iteration @ 7018 is 2.2575180530548096\n",
      "Loss at Iteration @ 7019 is 2.0026378631591797\n",
      "Evaluation Loss at Iteration @ 7019 is 2.189988374710083\n",
      "Loss at Iteration @ 7020 is 2.288665533065796\n",
      "Evaluation Loss at Iteration @ 7020 is 2.2459938526153564\n",
      "Loss at Iteration @ 7021 is 2.1843841075897217\n",
      "Evaluation Loss at Iteration @ 7021 is 2.2744712829589844\n",
      "Loss at Iteration @ 7022 is 2.202674627304077\n",
      "Evaluation Loss at Iteration @ 7022 is 2.261319637298584\n",
      "Loss at Iteration @ 7023 is 2.293854236602783\n",
      "Evaluation Loss at Iteration @ 7023 is 2.1544783115386963\n",
      "Loss at Iteration @ 7024 is 2.2167766094207764\n",
      "Evaluation Loss at Iteration @ 7024 is 2.278524398803711\n",
      "Loss at Iteration @ 7025 is 2.276153564453125\n",
      "Evaluation Loss at Iteration @ 7025 is 2.247023820877075\n",
      "Loss at Iteration @ 7026 is 2.148197889328003\n",
      "Evaluation Loss at Iteration @ 7026 is 2.2555770874023438\n",
      "Loss at Iteration @ 7027 is 2.207822322845459\n",
      "Evaluation Loss at Iteration @ 7027 is 2.2697529792785645\n",
      "Loss at Iteration @ 7028 is 2.2060890197753906\n",
      "Evaluation Loss at Iteration @ 7028 is 2.217776298522949\n",
      "Loss at Iteration @ 7029 is 2.2512264251708984\n",
      "Evaluation Loss at Iteration @ 7029 is 2.205753803253174\n",
      "Loss at Iteration @ 7030 is 2.2618393898010254\n",
      "Evaluation Loss at Iteration @ 7030 is 2.216623306274414\n",
      "Loss at Iteration @ 7031 is 2.3585667610168457\n",
      "Evaluation Loss at Iteration @ 7031 is 2.262986183166504\n",
      "Loss at Iteration @ 7032 is 2.463674306869507\n",
      "Evaluation Loss at Iteration @ 7032 is 2.2151618003845215\n",
      "Loss at Iteration @ 7033 is 2.415322780609131\n",
      "Evaluation Loss at Iteration @ 7033 is 2.234640121459961\n",
      "Loss at Iteration @ 7034 is 2.1196084022521973\n",
      "Evaluation Loss at Iteration @ 7034 is 2.289348602294922\n",
      "Loss at Iteration @ 7035 is 2.309562921524048\n",
      "Evaluation Loss at Iteration @ 7035 is 2.2284982204437256\n",
      "Loss at Iteration @ 7036 is 2.376422166824341\n",
      "Evaluation Loss at Iteration @ 7036 is 2.294166088104248\n",
      "Loss at Iteration @ 7037 is 2.3768599033355713\n",
      "Evaluation Loss at Iteration @ 7037 is 2.22855806350708\n",
      "Loss at Iteration @ 7038 is 2.1994433403015137\n",
      "Evaluation Loss at Iteration @ 7038 is 2.236978769302368\n",
      "Loss at Iteration @ 7039 is 2.3243234157562256\n",
      "Evaluation Loss at Iteration @ 7039 is 2.260145664215088\n",
      "Loss at Iteration @ 7040 is 2.4466521739959717\n",
      "Evaluation Loss at Iteration @ 7040 is 2.243103265762329\n",
      "Loss at Iteration @ 7041 is 2.1650757789611816\n",
      "Evaluation Loss at Iteration @ 7041 is 2.2525768280029297\n",
      "Loss at Iteration @ 7042 is 2.10543155670166\n",
      "Evaluation Loss at Iteration @ 7042 is 2.288177251815796\n",
      "Loss at Iteration @ 7043 is 2.2049009799957275\n",
      "Evaluation Loss at Iteration @ 7043 is 2.2137420177459717\n",
      "Loss at Iteration @ 7044 is 2.123540163040161\n",
      "Evaluation Loss at Iteration @ 7044 is 2.257704496383667\n",
      "Loss at Iteration @ 7045 is 2.1007261276245117\n",
      "Evaluation Loss at Iteration @ 7045 is 2.2298684120178223\n",
      "Loss at Iteration @ 7046 is 2.222027540206909\n",
      "Evaluation Loss at Iteration @ 7046 is 2.2477335929870605\n",
      "Loss at Iteration @ 7047 is 2.5264647006988525\n",
      "Evaluation Loss at Iteration @ 7047 is 2.278543472290039\n",
      "Loss at Iteration @ 7048 is 1.993194818496704\n",
      "Evaluation Loss at Iteration @ 7048 is 2.2075655460357666\n",
      "Loss at Iteration @ 7049 is 2.005852222442627\n",
      "Evaluation Loss at Iteration @ 7049 is 2.2273013591766357\n",
      "Loss at Iteration @ 7050 is 2.1165435314178467\n",
      "Evaluation Loss at Iteration @ 7050 is 2.281855583190918\n",
      "Loss at Iteration @ 7051 is 2.401888132095337\n",
      "Evaluation Loss at Iteration @ 7051 is 2.2372026443481445\n",
      "Loss at Iteration @ 7052 is 2.2886648178100586\n",
      "Evaluation Loss at Iteration @ 7052 is 2.245605230331421\n",
      "Loss at Iteration @ 7053 is 2.199439287185669\n",
      "Evaluation Loss at Iteration @ 7053 is 2.2530500888824463\n",
      "Loss at Iteration @ 7054 is 2.3530242443084717\n",
      "Evaluation Loss at Iteration @ 7054 is 2.2621092796325684\n",
      "Loss at Iteration @ 7055 is 2.499570846557617\n",
      "Evaluation Loss at Iteration @ 7055 is 2.241456985473633\n",
      "Loss at Iteration @ 7056 is 2.196641683578491\n",
      "Evaluation Loss at Iteration @ 7056 is 2.2619564533233643\n",
      "Loss at Iteration @ 7057 is 2.3972837924957275\n",
      "Evaluation Loss at Iteration @ 7057 is 2.22309947013855\n",
      "Loss at Iteration @ 7058 is 2.087751626968384\n",
      "Evaluation Loss at Iteration @ 7058 is 2.2627639770507812\n",
      "Loss at Iteration @ 7059 is 2.481273651123047\n",
      "Evaluation Loss at Iteration @ 7059 is 2.2494163513183594\n",
      "Loss at Iteration @ 7060 is 2.1306722164154053\n",
      "Evaluation Loss at Iteration @ 7060 is 2.3019797801971436\n",
      "Loss at Iteration @ 7061 is 2.4335906505584717\n",
      "Evaluation Loss at Iteration @ 7061 is 2.2583389282226562\n",
      "Loss at Iteration @ 7062 is 2.2598206996917725\n",
      "Evaluation Loss at Iteration @ 7062 is 2.2447028160095215\n",
      "Loss at Iteration @ 7063 is 2.1541619300842285\n",
      "Evaluation Loss at Iteration @ 7063 is 2.2324516773223877\n",
      "Loss at Iteration @ 7064 is 2.0154526233673096\n",
      "Evaluation Loss at Iteration @ 7064 is 2.2005245685577393\n",
      "Loss at Iteration @ 7065 is 2.268024444580078\n",
      "Evaluation Loss at Iteration @ 7065 is 2.279289484024048\n",
      "Loss at Iteration @ 7066 is 2.0614514350891113\n",
      "Evaluation Loss at Iteration @ 7066 is 2.2210373878479004\n",
      "Loss at Iteration @ 7067 is 2.200666666030884\n",
      "Evaluation Loss at Iteration @ 7067 is 2.2407174110412598\n",
      "Loss at Iteration @ 7068 is 2.341968536376953\n",
      "Evaluation Loss at Iteration @ 7068 is 2.273592472076416\n",
      "Loss at Iteration @ 7069 is 2.3313775062561035\n",
      "Evaluation Loss at Iteration @ 7069 is 2.238560199737549\n",
      "Loss at Iteration @ 7070 is 1.809456467628479\n",
      "Evaluation Loss at Iteration @ 7070 is 2.2527546882629395\n",
      "Loss at Iteration @ 7071 is 2.1187171936035156\n",
      "Evaluation Loss at Iteration @ 7071 is 2.2508139610290527\n",
      "Loss at Iteration @ 7072 is 1.9532946348190308\n",
      "Evaluation Loss at Iteration @ 7072 is 2.285452127456665\n",
      "Loss at Iteration @ 7073 is 2.1599910259246826\n",
      "Evaluation Loss at Iteration @ 7073 is 2.222278356552124\n",
      "Loss at Iteration @ 7074 is 2.2925450801849365\n",
      "Evaluation Loss at Iteration @ 7074 is 2.2168164253234863\n",
      "Loss at Iteration @ 7075 is 2.197338581085205\n",
      "Evaluation Loss at Iteration @ 7075 is 2.2219676971435547\n",
      "Loss at Iteration @ 7076 is 2.2921640872955322\n",
      "Evaluation Loss at Iteration @ 7076 is 2.278228282928467\n",
      "Loss at Iteration @ 7077 is 2.3921287059783936\n",
      "Evaluation Loss at Iteration @ 7077 is 2.237708568572998\n",
      "Loss at Iteration @ 7078 is 2.2282676696777344\n",
      "Evaluation Loss at Iteration @ 7078 is 2.2675223350524902\n",
      "Loss at Iteration @ 7079 is 2.4814887046813965\n",
      "Evaluation Loss at Iteration @ 7079 is 2.2239267826080322\n",
      "Loss at Iteration @ 7080 is 1.919464111328125\n",
      "Evaluation Loss at Iteration @ 7080 is 2.239219903945923\n",
      "Loss at Iteration @ 7081 is 2.229753255844116\n",
      "Evaluation Loss at Iteration @ 7081 is 2.2283473014831543\n",
      "Loss at Iteration @ 7082 is 2.078482151031494\n",
      "Evaluation Loss at Iteration @ 7082 is 2.3201045989990234\n",
      "Loss at Iteration @ 7083 is 2.2300970554351807\n",
      "Evaluation Loss at Iteration @ 7083 is 2.230029344558716\n",
      "Loss at Iteration @ 7084 is 2.1718387603759766\n",
      "Evaluation Loss at Iteration @ 7084 is 2.2576351165771484\n",
      "Loss at Iteration @ 7085 is 2.1272165775299072\n",
      "Evaluation Loss at Iteration @ 7085 is 2.2734551429748535\n",
      "Loss at Iteration @ 7086 is 2.534438133239746\n",
      "Evaluation Loss at Iteration @ 7086 is 2.253002166748047\n",
      "Loss at Iteration @ 7087 is 2.427980422973633\n",
      "Evaluation Loss at Iteration @ 7087 is 2.279233932495117\n",
      "Loss at Iteration @ 7088 is 2.157118082046509\n",
      "Evaluation Loss at Iteration @ 7088 is 2.2570011615753174\n",
      "Loss at Iteration @ 7089 is 2.271209478378296\n",
      "Evaluation Loss at Iteration @ 7089 is 2.257096529006958\n",
      "Loss at Iteration @ 7090 is 2.363168478012085\n",
      "Evaluation Loss at Iteration @ 7090 is 2.2634031772613525\n",
      "Loss at Iteration @ 7091 is 2.350094795227051\n",
      "Evaluation Loss at Iteration @ 7091 is 2.2519850730895996\n",
      "Loss at Iteration @ 7092 is 2.256162405014038\n",
      "Evaluation Loss at Iteration @ 7092 is 2.2510225772857666\n",
      "Loss at Iteration @ 7093 is 2.3637871742248535\n",
      "Evaluation Loss at Iteration @ 7093 is 2.2485547065734863\n",
      "Loss at Iteration @ 7094 is 2.2373199462890625\n",
      "Evaluation Loss at Iteration @ 7094 is 2.3041493892669678\n",
      "Loss at Iteration @ 7095 is 2.2680840492248535\n",
      "Evaluation Loss at Iteration @ 7095 is 2.277529001235962\n",
      "Loss at Iteration @ 7096 is 2.6331253051757812\n",
      "Evaluation Loss at Iteration @ 7096 is 2.297351598739624\n",
      "Loss at Iteration @ 7097 is 2.2945244312286377\n",
      "Evaluation Loss at Iteration @ 7097 is 2.2516403198242188\n",
      "Loss at Iteration @ 7098 is 2.272348403930664\n",
      "Evaluation Loss at Iteration @ 7098 is 2.2820417881011963\n",
      "Loss at Iteration @ 7099 is 2.3718860149383545\n",
      "Evaluation Loss at Iteration @ 7099 is 2.2497363090515137\n",
      "Loss at Iteration @ 7100 is 2.079012870788574\n",
      "Evaluation Loss at Iteration @ 7100 is 2.264632225036621\n",
      "Loss at Iteration @ 7101 is 1.9439483880996704\n",
      "Evaluation Loss at Iteration @ 7101 is 2.262432813644409\n",
      "Loss at Iteration @ 7102 is 1.9983612298965454\n",
      "Evaluation Loss at Iteration @ 7102 is 2.2034833431243896\n",
      "Loss at Iteration @ 7103 is 2.2101423740386963\n",
      "Evaluation Loss at Iteration @ 7103 is 2.241209030151367\n",
      "Loss at Iteration @ 7104 is 2.0348188877105713\n",
      "Evaluation Loss at Iteration @ 7104 is 2.259958028793335\n",
      "Loss at Iteration @ 7105 is 2.2064297199249268\n",
      "Evaluation Loss at Iteration @ 7105 is 2.2628068923950195\n",
      "Loss at Iteration @ 7106 is 2.485121965408325\n",
      "Evaluation Loss at Iteration @ 7106 is 2.23225998878479\n",
      "Loss at Iteration @ 7107 is 2.2259533405303955\n",
      "Evaluation Loss at Iteration @ 7107 is 2.262474536895752\n",
      "Loss at Iteration @ 7108 is 2.2805023193359375\n",
      "Evaluation Loss at Iteration @ 7108 is 2.284381866455078\n",
      "Loss at Iteration @ 7109 is 1.9672209024429321\n",
      "Evaluation Loss at Iteration @ 7109 is 2.28836989402771\n",
      "Loss at Iteration @ 7110 is 2.2584924697875977\n",
      "Evaluation Loss at Iteration @ 7110 is 2.273989677429199\n",
      "Loss at Iteration @ 7111 is 2.3242082595825195\n",
      "Evaluation Loss at Iteration @ 7111 is 2.257014751434326\n",
      "Loss at Iteration @ 7112 is 1.9616649150848389\n",
      "Evaluation Loss at Iteration @ 7112 is 2.2268142700195312\n",
      "Loss at Iteration @ 7113 is 2.2261767387390137\n",
      "Evaluation Loss at Iteration @ 7113 is 2.220986843109131\n",
      "Loss at Iteration @ 7114 is 2.156379222869873\n",
      "Evaluation Loss at Iteration @ 7114 is 2.2535417079925537\n",
      "Loss at Iteration @ 7115 is 2.3123278617858887\n",
      "Evaluation Loss at Iteration @ 7115 is 2.2194175720214844\n",
      "Loss at Iteration @ 7116 is 2.193232297897339\n",
      "Evaluation Loss at Iteration @ 7116 is 2.272249221801758\n",
      "Loss at Iteration @ 7117 is 1.9748860597610474\n",
      "Evaluation Loss at Iteration @ 7117 is 2.256057024002075\n",
      "Loss at Iteration @ 7118 is 2.2354533672332764\n",
      "Evaluation Loss at Iteration @ 7118 is 2.2232351303100586\n",
      "Loss at Iteration @ 7119 is 2.1963582038879395\n",
      "Evaluation Loss at Iteration @ 7119 is 2.2149460315704346\n",
      "Loss at Iteration @ 7120 is 2.1437301635742188\n",
      "Evaluation Loss at Iteration @ 7120 is 2.2354936599731445\n",
      "Loss at Iteration @ 7121 is 2.3614394664764404\n",
      "Evaluation Loss at Iteration @ 7121 is 2.250326156616211\n",
      "Loss at Iteration @ 7122 is 2.2686100006103516\n",
      "Evaluation Loss at Iteration @ 7122 is 2.2274768352508545\n",
      "Loss at Iteration @ 7123 is 2.4436066150665283\n",
      "Evaluation Loss at Iteration @ 7123 is 2.194389581680298\n",
      "Loss at Iteration @ 7124 is 2.189962148666382\n",
      "Evaluation Loss at Iteration @ 7124 is 2.2483386993408203\n",
      "Loss at Iteration @ 7125 is 2.4824209213256836\n",
      "Evaluation Loss at Iteration @ 7125 is 2.2092554569244385\n",
      "Loss at Iteration @ 7126 is 1.9528594017028809\n",
      "Evaluation Loss at Iteration @ 7126 is 2.3201985359191895\n",
      "Loss at Iteration @ 7127 is 2.337200880050659\n",
      "Evaluation Loss at Iteration @ 7127 is 2.219360113143921\n",
      "Loss at Iteration @ 7128 is 2.1274914741516113\n",
      "Evaluation Loss at Iteration @ 7128 is 2.2190372943878174\n",
      "Loss at Iteration @ 7129 is 2.1140239238739014\n",
      "Evaluation Loss at Iteration @ 7129 is 2.258474826812744\n",
      "Loss at Iteration @ 7130 is 2.2020983695983887\n",
      "Evaluation Loss at Iteration @ 7130 is 2.2537879943847656\n",
      "Loss at Iteration @ 7131 is 1.954901933670044\n",
      "Evaluation Loss at Iteration @ 7131 is 2.255448579788208\n",
      "Loss at Iteration @ 7132 is 2.076796054840088\n",
      "Evaluation Loss at Iteration @ 7132 is 2.2496557235717773\n",
      "Loss at Iteration @ 7133 is 2.3501932621002197\n",
      "Evaluation Loss at Iteration @ 7133 is 2.256747007369995\n",
      "Loss at Iteration @ 7134 is 2.3919296264648438\n",
      "Evaluation Loss at Iteration @ 7134 is 2.228421449661255\n",
      "Loss at Iteration @ 7135 is 2.513871908187866\n",
      "Evaluation Loss at Iteration @ 7135 is 2.262768507003784\n",
      "Loss at Iteration @ 7136 is 2.240830421447754\n",
      "Evaluation Loss at Iteration @ 7136 is 2.2846462726593018\n",
      "Loss at Iteration @ 7137 is 2.3547303676605225\n",
      "Evaluation Loss at Iteration @ 7137 is 2.257780075073242\n",
      "Loss at Iteration @ 7138 is 2.4469587802886963\n",
      "Evaluation Loss at Iteration @ 7138 is 2.2953948974609375\n",
      "Loss at Iteration @ 7139 is 2.258962869644165\n",
      "Evaluation Loss at Iteration @ 7139 is 2.2270243167877197\n",
      "Loss at Iteration @ 7140 is 2.1920087337493896\n",
      "Evaluation Loss at Iteration @ 7140 is 2.2865686416625977\n",
      "Loss at Iteration @ 7141 is 2.3617336750030518\n",
      "Evaluation Loss at Iteration @ 7141 is 2.2524263858795166\n",
      "Loss at Iteration @ 7142 is 2.480942726135254\n",
      "Evaluation Loss at Iteration @ 7142 is 2.2240653038024902\n",
      "Loss at Iteration @ 7143 is 2.237924814224243\n",
      "Evaluation Loss at Iteration @ 7143 is 2.2171456813812256\n",
      "Loss at Iteration @ 7144 is 2.173779010772705\n",
      "Evaluation Loss at Iteration @ 7144 is 2.236727714538574\n",
      "Loss at Iteration @ 7145 is 2.065727949142456\n",
      "Evaluation Loss at Iteration @ 7145 is 2.236175298690796\n",
      "Loss at Iteration @ 7146 is 2.0430307388305664\n",
      "Evaluation Loss at Iteration @ 7146 is 2.2883119583129883\n",
      "Loss at Iteration @ 7147 is 1.9865418672561646\n",
      "Evaluation Loss at Iteration @ 7147 is 2.246767520904541\n",
      "Loss at Iteration @ 7148 is 2.411442279815674\n",
      "Evaluation Loss at Iteration @ 7148 is 2.2457292079925537\n",
      "Loss at Iteration @ 7149 is 2.299039125442505\n",
      "Evaluation Loss at Iteration @ 7149 is 2.284745931625366\n",
      "Loss at Iteration @ 7150 is 2.335237741470337\n",
      "Evaluation Loss at Iteration @ 7150 is 2.2707691192626953\n",
      "Loss at Iteration @ 7151 is 2.6220743656158447\n",
      "Evaluation Loss at Iteration @ 7151 is 2.2500741481781006\n",
      "Loss at Iteration @ 7152 is 1.9599175453186035\n",
      "Evaluation Loss at Iteration @ 7152 is 2.2474045753479004\n",
      "Loss at Iteration @ 7153 is 2.0996651649475098\n",
      "Evaluation Loss at Iteration @ 7153 is 2.2583348751068115\n",
      "Loss at Iteration @ 7154 is 2.230271100997925\n",
      "Evaluation Loss at Iteration @ 7154 is 2.245980978012085\n",
      "Loss at Iteration @ 7155 is 2.4626288414001465\n",
      "Evaluation Loss at Iteration @ 7155 is 2.2694811820983887\n",
      "Loss at Iteration @ 7156 is 2.460181713104248\n",
      "Evaluation Loss at Iteration @ 7156 is 2.2203667163848877\n",
      "Loss at Iteration @ 7157 is 2.271754741668701\n",
      "Evaluation Loss at Iteration @ 7157 is 2.279297113418579\n",
      "Loss at Iteration @ 7158 is 2.204606056213379\n",
      "Evaluation Loss at Iteration @ 7158 is 2.1991348266601562\n",
      "Loss at Iteration @ 7159 is 2.2879648208618164\n",
      "Evaluation Loss at Iteration @ 7159 is 2.23286509513855\n",
      "Loss at Iteration @ 7160 is 2.6623613834381104\n",
      "Evaluation Loss at Iteration @ 7160 is 2.2657840251922607\n",
      "Loss at Iteration @ 7161 is 2.136897325515747\n",
      "Evaluation Loss at Iteration @ 7161 is 2.1959855556488037\n",
      "Loss at Iteration @ 7162 is 2.2279109954833984\n",
      "Evaluation Loss at Iteration @ 7162 is 2.2534422874450684\n",
      "Loss at Iteration @ 7163 is 2.3629379272460938\n",
      "Evaluation Loss at Iteration @ 7163 is 2.2606124877929688\n",
      "Loss at Iteration @ 7164 is 2.2181711196899414\n",
      "Evaluation Loss at Iteration @ 7164 is 2.218045949935913\n",
      "Loss at Iteration @ 7165 is 2.168020486831665\n",
      "Evaluation Loss at Iteration @ 7165 is 2.2382283210754395\n",
      "Loss at Iteration @ 7166 is 2.5529026985168457\n",
      "Evaluation Loss at Iteration @ 7166 is 2.2089755535125732\n",
      "Loss at Iteration @ 7167 is 2.3412246704101562\n",
      "Evaluation Loss at Iteration @ 7167 is 2.2563977241516113\n",
      "Loss at Iteration @ 7168 is 2.004088878631592\n",
      "Evaluation Loss at Iteration @ 7168 is 2.289921760559082\n",
      "Loss at Iteration @ 7169 is 2.209108829498291\n",
      "Evaluation Loss at Iteration @ 7169 is 2.1974964141845703\n",
      "Loss at Iteration @ 7170 is 2.0454397201538086\n",
      "Evaluation Loss at Iteration @ 7170 is 2.245197296142578\n",
      "Loss at Iteration @ 7171 is 2.122598648071289\n",
      "Evaluation Loss at Iteration @ 7171 is 2.2674944400787354\n",
      "Loss at Iteration @ 7172 is 2.299379825592041\n",
      "Evaluation Loss at Iteration @ 7172 is 2.2143337726593018\n",
      "Loss at Iteration @ 7173 is 2.0505595207214355\n",
      "Evaluation Loss at Iteration @ 7173 is 2.2263472080230713\n",
      "Loss at Iteration @ 7174 is 1.7366515398025513\n",
      "Evaluation Loss at Iteration @ 7174 is 2.2372047901153564\n",
      "Loss at Iteration @ 7175 is 2.183748722076416\n",
      "Evaluation Loss at Iteration @ 7175 is 2.2236568927764893\n",
      "Loss at Iteration @ 7176 is 2.404414415359497\n",
      "Evaluation Loss at Iteration @ 7176 is 2.2069783210754395\n",
      "Loss at Iteration @ 7177 is 2.159832715988159\n",
      "Evaluation Loss at Iteration @ 7177 is 2.253631830215454\n",
      "Loss at Iteration @ 7178 is 2.468268871307373\n",
      "Evaluation Loss at Iteration @ 7178 is 2.2213134765625\n",
      "Loss at Iteration @ 7179 is 2.463067054748535\n",
      "Evaluation Loss at Iteration @ 7179 is 2.2273447513580322\n",
      "Loss at Iteration @ 7180 is 2.406184673309326\n",
      "Evaluation Loss at Iteration @ 7180 is 2.251119613647461\n",
      "Loss at Iteration @ 7181 is 2.1158578395843506\n",
      "Evaluation Loss at Iteration @ 7181 is 2.2268946170806885\n",
      "Loss at Iteration @ 7182 is 2.440673589706421\n",
      "Evaluation Loss at Iteration @ 7182 is 2.270508289337158\n",
      "Loss at Iteration @ 7183 is 2.198267698287964\n",
      "Evaluation Loss at Iteration @ 7183 is 2.274078369140625\n",
      "Loss at Iteration @ 7184 is 2.141322612762451\n",
      "Evaluation Loss at Iteration @ 7184 is 2.294057607650757\n",
      "Loss at Iteration @ 7185 is 2.166149139404297\n",
      "Evaluation Loss at Iteration @ 7185 is 2.2239937782287598\n",
      "Loss at Iteration @ 7186 is 2.427560567855835\n",
      "Evaluation Loss at Iteration @ 7186 is 2.2424635887145996\n",
      "Loss at Iteration @ 7187 is 2.5126452445983887\n",
      "Evaluation Loss at Iteration @ 7187 is 2.2184019088745117\n",
      "Loss at Iteration @ 7188 is 2.1479904651641846\n",
      "Evaluation Loss at Iteration @ 7188 is 2.223379611968994\n",
      "Loss at Iteration @ 7189 is 2.2043800354003906\n",
      "Evaluation Loss at Iteration @ 7189 is 2.2576797008514404\n",
      "Loss at Iteration @ 7190 is 2.302502393722534\n",
      "Evaluation Loss at Iteration @ 7190 is 2.2776119709014893\n",
      "Loss at Iteration @ 7191 is 2.166818857192993\n",
      "Evaluation Loss at Iteration @ 7191 is 2.241839647293091\n",
      "Loss at Iteration @ 7192 is 2.4163694381713867\n",
      "Evaluation Loss at Iteration @ 7192 is 2.243466377258301\n",
      "Loss at Iteration @ 7193 is 2.2481672763824463\n",
      "Evaluation Loss at Iteration @ 7193 is 2.267758846282959\n",
      "Loss at Iteration @ 7194 is 2.3288028240203857\n",
      "Evaluation Loss at Iteration @ 7194 is 2.2280614376068115\n",
      "Loss at Iteration @ 7195 is 2.4548513889312744\n",
      "Evaluation Loss at Iteration @ 7195 is 2.259838342666626\n",
      "Loss at Iteration @ 7196 is 2.621304988861084\n",
      "Evaluation Loss at Iteration @ 7196 is 2.261129140853882\n",
      "Loss at Iteration @ 7197 is 2.1674201488494873\n",
      "Evaluation Loss at Iteration @ 7197 is 2.1969075202941895\n",
      "Loss at Iteration @ 7198 is 2.1477208137512207\n",
      "Evaluation Loss at Iteration @ 7198 is 2.2505154609680176\n",
      "Loss at Iteration @ 7199 is 2.083282470703125\n",
      "Evaluation Loss at Iteration @ 7199 is 2.243502616882324\n",
      "Loss at Iteration @ 7200 is 2.342109203338623\n",
      "Evaluation Loss at Iteration @ 7200 is 2.224560022354126\n",
      "Loss at Iteration @ 7201 is 2.4197885990142822\n",
      "Evaluation Loss at Iteration @ 7201 is 2.2534332275390625\n",
      "Loss at Iteration @ 7202 is 2.3223507404327393\n",
      "Evaluation Loss at Iteration @ 7202 is 2.27372407913208\n",
      "Loss at Iteration @ 7203 is 2.137725353240967\n",
      "Evaluation Loss at Iteration @ 7203 is 2.2315800189971924\n",
      "Loss at Iteration @ 7204 is 2.469291925430298\n",
      "Evaluation Loss at Iteration @ 7204 is 2.2489705085754395\n",
      "Loss at Iteration @ 7205 is 2.1138620376586914\n",
      "Evaluation Loss at Iteration @ 7205 is 2.271071672439575\n",
      "Loss at Iteration @ 7206 is 2.331881523132324\n",
      "Evaluation Loss at Iteration @ 7206 is 2.247314691543579\n",
      "Loss at Iteration @ 7207 is 2.3283116817474365\n",
      "Evaluation Loss at Iteration @ 7207 is 2.273001194000244\n",
      "Loss at Iteration @ 7208 is 2.5030484199523926\n",
      "Evaluation Loss at Iteration @ 7208 is 2.300426483154297\n",
      "Loss at Iteration @ 7209 is 2.1945831775665283\n",
      "Evaluation Loss at Iteration @ 7209 is 2.263613700866699\n",
      "Loss at Iteration @ 7210 is 1.8785828351974487\n",
      "Evaluation Loss at Iteration @ 7210 is 2.273345708847046\n",
      "Loss at Iteration @ 7211 is 2.0571539402008057\n",
      "Evaluation Loss at Iteration @ 7211 is 2.2402467727661133\n",
      "Loss at Iteration @ 7212 is 2.1883530616760254\n",
      "Evaluation Loss at Iteration @ 7212 is 2.261812925338745\n",
      "Loss at Iteration @ 7213 is 2.300276279449463\n",
      "Evaluation Loss at Iteration @ 7213 is 2.2705671787261963\n",
      "Loss at Iteration @ 7214 is 2.3616788387298584\n",
      "Evaluation Loss at Iteration @ 7214 is 2.251699209213257\n",
      "Loss at Iteration @ 7215 is 2.1620566844940186\n",
      "Evaluation Loss at Iteration @ 7215 is 2.221397876739502\n",
      "Loss at Iteration @ 7216 is 2.115445613861084\n",
      "Evaluation Loss at Iteration @ 7216 is 2.25362229347229\n",
      "Loss at Iteration @ 7217 is 2.255183219909668\n",
      "Evaluation Loss at Iteration @ 7217 is 2.250258684158325\n",
      "Loss at Iteration @ 7218 is 2.093121290206909\n",
      "Evaluation Loss at Iteration @ 7218 is 2.242976188659668\n",
      "Loss at Iteration @ 7219 is 2.1140336990356445\n",
      "Evaluation Loss at Iteration @ 7219 is 2.282158613204956\n",
      "Loss at Iteration @ 7220 is 2.2238917350769043\n",
      "Evaluation Loss at Iteration @ 7220 is 2.2497823238372803\n",
      "Loss at Iteration @ 7221 is 2.2694754600524902\n",
      "Evaluation Loss at Iteration @ 7221 is 2.24006986618042\n",
      "Loss at Iteration @ 7222 is 2.3890762329101562\n",
      "Evaluation Loss at Iteration @ 7222 is 2.2387404441833496\n",
      "Loss at Iteration @ 7223 is 2.3111135959625244\n",
      "Evaluation Loss at Iteration @ 7223 is 2.2785792350769043\n",
      "Loss at Iteration @ 7224 is 2.2070374488830566\n",
      "Evaluation Loss at Iteration @ 7224 is 2.276672840118408\n",
      "Loss at Iteration @ 7225 is 2.243483066558838\n",
      "Evaluation Loss at Iteration @ 7225 is 2.271070718765259\n",
      "Loss at Iteration @ 7226 is 2.2185306549072266\n",
      "Evaluation Loss at Iteration @ 7226 is 2.2577109336853027\n",
      "Loss at Iteration @ 7227 is 2.0216755867004395\n",
      "Evaluation Loss at Iteration @ 7227 is 2.1959526538848877\n",
      "Loss at Iteration @ 7228 is 2.3006410598754883\n",
      "Evaluation Loss at Iteration @ 7228 is 2.3036930561065674\n",
      "Loss at Iteration @ 7229 is 2.1605639457702637\n",
      "Evaluation Loss at Iteration @ 7229 is 2.2612619400024414\n",
      "Loss at Iteration @ 7230 is 2.1916449069976807\n",
      "Evaluation Loss at Iteration @ 7230 is 2.2495834827423096\n",
      "Loss at Iteration @ 7231 is 2.0892927646636963\n",
      "Evaluation Loss at Iteration @ 7231 is 2.2409842014312744\n",
      "Loss at Iteration @ 7232 is 2.431842088699341\n",
      "Evaluation Loss at Iteration @ 7232 is 2.2646162509918213\n",
      "Loss at Iteration @ 7233 is 2.3815526962280273\n",
      "Evaluation Loss at Iteration @ 7233 is 2.2401742935180664\n",
      "Loss at Iteration @ 7234 is 2.059519052505493\n",
      "Evaluation Loss at Iteration @ 7234 is 2.242840051651001\n",
      "Loss at Iteration @ 7235 is 2.191070079803467\n",
      "Evaluation Loss at Iteration @ 7235 is 2.2546606063842773\n",
      "Loss at Iteration @ 7236 is 2.102201461791992\n",
      "Evaluation Loss at Iteration @ 7236 is 2.2200682163238525\n",
      "Loss at Iteration @ 7237 is 2.0976643562316895\n",
      "Evaluation Loss at Iteration @ 7237 is 2.300027847290039\n",
      "Loss at Iteration @ 7238 is 2.3334388732910156\n",
      "Evaluation Loss at Iteration @ 7238 is 2.2150425910949707\n",
      "Loss at Iteration @ 7239 is 2.1468701362609863\n",
      "Evaluation Loss at Iteration @ 7239 is 2.241588592529297\n",
      "Loss at Iteration @ 7240 is 2.117788314819336\n",
      "Evaluation Loss at Iteration @ 7240 is 2.191249132156372\n",
      "Loss at Iteration @ 7241 is 2.3689398765563965\n",
      "Evaluation Loss at Iteration @ 7241 is 2.2502410411834717\n",
      "Loss at Iteration @ 7242 is 2.022662878036499\n",
      "Evaluation Loss at Iteration @ 7242 is 2.2660951614379883\n",
      "Loss at Iteration @ 7243 is 2.3164775371551514\n",
      "Evaluation Loss at Iteration @ 7243 is 2.3078458309173584\n",
      "Loss at Iteration @ 7244 is 2.192725658416748\n",
      "Evaluation Loss at Iteration @ 7244 is 2.248018741607666\n",
      "Loss at Iteration @ 7245 is 2.4449660778045654\n",
      "Evaluation Loss at Iteration @ 7245 is 2.2304816246032715\n",
      "Loss at Iteration @ 7246 is 2.3536431789398193\n",
      "Evaluation Loss at Iteration @ 7246 is 2.2869060039520264\n",
      "Loss at Iteration @ 7247 is 2.1771562099456787\n",
      "Evaluation Loss at Iteration @ 7247 is 2.267157554626465\n",
      "Loss at Iteration @ 7248 is 2.11940598487854\n",
      "Evaluation Loss at Iteration @ 7248 is 2.2408299446105957\n",
      "Loss at Iteration @ 7249 is 2.53118634223938\n",
      "Evaluation Loss at Iteration @ 7249 is 2.276978015899658\n",
      "Loss at Iteration @ 7250 is 2.2381467819213867\n",
      "Evaluation Loss at Iteration @ 7250 is 2.276245594024658\n",
      "Loss at Iteration @ 7251 is 2.1980342864990234\n",
      "Evaluation Loss at Iteration @ 7251 is 2.2501847743988037\n",
      "Loss at Iteration @ 7252 is 2.3284595012664795\n",
      "Evaluation Loss at Iteration @ 7252 is 2.220547676086426\n",
      "Loss at Iteration @ 7253 is 2.167870283126831\n",
      "Evaluation Loss at Iteration @ 7253 is 2.2617416381835938\n",
      "Loss at Iteration @ 7254 is 2.2640347480773926\n",
      "Evaluation Loss at Iteration @ 7254 is 2.2791547775268555\n",
      "Loss at Iteration @ 7255 is 2.1538867950439453\n",
      "Evaluation Loss at Iteration @ 7255 is 2.2545433044433594\n",
      "Loss at Iteration @ 7256 is 2.300097703933716\n",
      "Evaluation Loss at Iteration @ 7256 is 2.3131604194641113\n",
      "Loss at Iteration @ 7257 is 2.3213682174682617\n",
      "Evaluation Loss at Iteration @ 7257 is 2.2657530307769775\n",
      "Loss at Iteration @ 7258 is 2.2261292934417725\n",
      "Evaluation Loss at Iteration @ 7258 is 2.2530038356781006\n",
      "Loss at Iteration @ 7259 is 2.3183276653289795\n",
      "Evaluation Loss at Iteration @ 7259 is 2.265793800354004\n",
      "Loss at Iteration @ 7260 is 2.0695557594299316\n",
      "Evaluation Loss at Iteration @ 7260 is 2.2819712162017822\n",
      "Loss at Iteration @ 7261 is 2.339057683944702\n",
      "Evaluation Loss at Iteration @ 7261 is 2.216808557510376\n",
      "Loss at Iteration @ 7262 is 2.2022287845611572\n",
      "Evaluation Loss at Iteration @ 7262 is 2.2311220169067383\n",
      "Loss at Iteration @ 7263 is 2.0309247970581055\n",
      "Evaluation Loss at Iteration @ 7263 is 2.28212571144104\n",
      "Loss at Iteration @ 7264 is 2.337778091430664\n",
      "Evaluation Loss at Iteration @ 7264 is 2.2226309776306152\n",
      "Loss at Iteration @ 7265 is 2.238400936126709\n",
      "Evaluation Loss at Iteration @ 7265 is 2.284788131713867\n",
      "Loss at Iteration @ 7266 is 2.0926246643066406\n",
      "Evaluation Loss at Iteration @ 7266 is 2.2324235439300537\n",
      "Loss at Iteration @ 7267 is 2.3280224800109863\n",
      "Evaluation Loss at Iteration @ 7267 is 2.277067184448242\n",
      "Loss at Iteration @ 7268 is 2.2243261337280273\n",
      "Evaluation Loss at Iteration @ 7268 is 2.2447140216827393\n",
      "Loss at Iteration @ 7269 is 2.4174420833587646\n",
      "Evaluation Loss at Iteration @ 7269 is 2.232161045074463\n",
      "Loss at Iteration @ 7270 is 2.325432300567627\n",
      "Evaluation Loss at Iteration @ 7270 is 2.251084089279175\n",
      "Loss at Iteration @ 7271 is 2.39247989654541\n",
      "Evaluation Loss at Iteration @ 7271 is 2.2658257484436035\n",
      "Loss at Iteration @ 7272 is 2.3168084621429443\n",
      "Evaluation Loss at Iteration @ 7272 is 2.2403504848480225\n",
      "Loss at Iteration @ 7273 is 2.407956123352051\n",
      "Evaluation Loss at Iteration @ 7273 is 2.2759857177734375\n",
      "Loss at Iteration @ 7274 is 2.1083528995513916\n",
      "Evaluation Loss at Iteration @ 7274 is 2.284109354019165\n",
      "Loss at Iteration @ 7275 is 1.9049668312072754\n",
      "Evaluation Loss at Iteration @ 7275 is 2.2368052005767822\n",
      "Loss at Iteration @ 7276 is 2.4309606552124023\n",
      "Evaluation Loss at Iteration @ 7276 is 2.286770820617676\n",
      "Loss at Iteration @ 7277 is 2.2176759243011475\n",
      "Evaluation Loss at Iteration @ 7277 is 2.240525484085083\n",
      "Loss at Iteration @ 7278 is 2.205800771713257\n",
      "Evaluation Loss at Iteration @ 7278 is 2.258121967315674\n",
      "Loss at Iteration @ 7279 is 2.082836627960205\n",
      "Evaluation Loss at Iteration @ 7279 is 2.2678189277648926\n",
      "Loss at Iteration @ 7280 is 2.2562525272369385\n",
      "Evaluation Loss at Iteration @ 7280 is 2.2479257583618164\n",
      "Loss at Iteration @ 7281 is 2.317889928817749\n",
      "Evaluation Loss at Iteration @ 7281 is 2.2487266063690186\n",
      "Loss at Iteration @ 7282 is 2.293740749359131\n",
      "Evaluation Loss at Iteration @ 7282 is 2.240687608718872\n",
      "Loss at Iteration @ 7283 is 2.0932810306549072\n",
      "Evaluation Loss at Iteration @ 7283 is 2.279869556427002\n",
      "Loss at Iteration @ 7284 is 2.0159308910369873\n",
      "Evaluation Loss at Iteration @ 7284 is 2.2362143993377686\n",
      "Loss at Iteration @ 7285 is 2.2837979793548584\n",
      "Evaluation Loss at Iteration @ 7285 is 2.245957136154175\n",
      "Loss at Iteration @ 7286 is 2.0800695419311523\n",
      "Evaluation Loss at Iteration @ 7286 is 2.2312605381011963\n",
      "Loss at Iteration @ 7287 is 2.2391936779022217\n",
      "Evaluation Loss at Iteration @ 7287 is 2.2527592182159424\n",
      "Loss at Iteration @ 7288 is 2.1820311546325684\n",
      "Evaluation Loss at Iteration @ 7288 is 2.2461798191070557\n",
      "Loss at Iteration @ 7289 is 2.3942596912384033\n",
      "Evaluation Loss at Iteration @ 7289 is 2.297255516052246\n",
      "Loss at Iteration @ 7290 is 2.392545461654663\n",
      "Evaluation Loss at Iteration @ 7290 is 2.2643609046936035\n",
      "Loss at Iteration @ 7291 is 1.9669606685638428\n",
      "Evaluation Loss at Iteration @ 7291 is 2.2901175022125244\n",
      "Loss at Iteration @ 7292 is 2.16202974319458\n",
      "Evaluation Loss at Iteration @ 7292 is 2.241485357284546\n",
      "Loss at Iteration @ 7293 is 2.2318994998931885\n",
      "Evaluation Loss at Iteration @ 7293 is 2.247013807296753\n",
      "Loss at Iteration @ 7294 is 2.4655864238739014\n",
      "Evaluation Loss at Iteration @ 7294 is 2.230227470397949\n",
      "Loss at Iteration @ 7295 is 2.190457582473755\n",
      "Evaluation Loss at Iteration @ 7295 is 2.285538911819458\n",
      "Loss at Iteration @ 7296 is 2.211474657058716\n",
      "Evaluation Loss at Iteration @ 7296 is 2.2563364505767822\n",
      "Loss at Iteration @ 7297 is 2.3539345264434814\n",
      "Evaluation Loss at Iteration @ 7297 is 2.2571940422058105\n",
      "Loss at Iteration @ 7298 is 2.0816762447357178\n",
      "Evaluation Loss at Iteration @ 7298 is 2.2484068870544434\n",
      "Loss at Iteration @ 7299 is 2.1304893493652344\n",
      "Evaluation Loss at Iteration @ 7299 is 2.241774797439575\n",
      "Loss at Iteration @ 7300 is 2.083672046661377\n",
      "Evaluation Loss at Iteration @ 7300 is 2.2735254764556885\n",
      "Loss at Iteration @ 7301 is 2.2552640438079834\n",
      "Evaluation Loss at Iteration @ 7301 is 2.2343690395355225\n",
      "Loss at Iteration @ 7302 is 2.4378066062927246\n",
      "Evaluation Loss at Iteration @ 7302 is 2.274411201477051\n",
      "Loss at Iteration @ 7303 is 2.144745349884033\n",
      "Evaluation Loss at Iteration @ 7303 is 2.2229721546173096\n",
      "Loss at Iteration @ 7304 is 2.183638095855713\n",
      "Evaluation Loss at Iteration @ 7304 is 2.233250379562378\n",
      "Loss at Iteration @ 7305 is 2.2592175006866455\n",
      "Evaluation Loss at Iteration @ 7305 is 2.232703924179077\n",
      "Loss at Iteration @ 7306 is 2.227748155593872\n",
      "Evaluation Loss at Iteration @ 7306 is 2.257354736328125\n",
      "Loss at Iteration @ 7307 is 2.620251178741455\n",
      "Evaluation Loss at Iteration @ 7307 is 2.2146847248077393\n",
      "Loss at Iteration @ 7308 is 2.2100229263305664\n",
      "Evaluation Loss at Iteration @ 7308 is 2.252361297607422\n",
      "Loss at Iteration @ 7309 is 2.1391735076904297\n",
      "Evaluation Loss at Iteration @ 7309 is 2.2464637756347656\n",
      "Loss at Iteration @ 7310 is 2.267824172973633\n",
      "Evaluation Loss at Iteration @ 7310 is 2.240787982940674\n",
      "Loss at Iteration @ 7311 is 2.062042236328125\n",
      "Evaluation Loss at Iteration @ 7311 is 2.223952293395996\n",
      "Loss at Iteration @ 7312 is 2.1289188861846924\n",
      "Evaluation Loss at Iteration @ 7312 is 2.243989944458008\n",
      "Loss at Iteration @ 7313 is 2.1875996589660645\n",
      "Evaluation Loss at Iteration @ 7313 is 2.221872091293335\n",
      "Loss at Iteration @ 7314 is 2.378659725189209\n",
      "Evaluation Loss at Iteration @ 7314 is 2.295858860015869\n",
      "Loss at Iteration @ 7315 is 2.204012155532837\n",
      "Evaluation Loss at Iteration @ 7315 is 2.2429487705230713\n",
      "Loss at Iteration @ 7316 is 2.4599742889404297\n",
      "Evaluation Loss at Iteration @ 7316 is 2.2741708755493164\n",
      "Loss at Iteration @ 7317 is 2.330543041229248\n",
      "Evaluation Loss at Iteration @ 7317 is 2.2060201168060303\n",
      "Loss at Iteration @ 7318 is 2.343700408935547\n",
      "Evaluation Loss at Iteration @ 7318 is 2.237492322921753\n",
      "Loss at Iteration @ 7319 is 2.091329574584961\n",
      "Evaluation Loss at Iteration @ 7319 is 2.243349552154541\n",
      "Loss at Iteration @ 7320 is 2.1418163776397705\n",
      "Evaluation Loss at Iteration @ 7320 is 2.2354812622070312\n",
      "Loss at Iteration @ 7321 is 2.2359044551849365\n",
      "Evaluation Loss at Iteration @ 7321 is 2.298386812210083\n",
      "Loss at Iteration @ 7322 is 2.052523612976074\n",
      "Evaluation Loss at Iteration @ 7322 is 2.267336130142212\n",
      "Loss at Iteration @ 7323 is 2.488734722137451\n",
      "Evaluation Loss at Iteration @ 7323 is 2.3040688037872314\n",
      "Loss at Iteration @ 7324 is 2.095886707305908\n",
      "Evaluation Loss at Iteration @ 7324 is 2.2252981662750244\n",
      "Loss at Iteration @ 7325 is 2.0184736251831055\n",
      "Evaluation Loss at Iteration @ 7325 is 2.248217821121216\n",
      "Loss at Iteration @ 7326 is 2.172598123550415\n",
      "Evaluation Loss at Iteration @ 7326 is 2.256042957305908\n",
      "Loss at Iteration @ 7327 is 2.0539908409118652\n",
      "Evaluation Loss at Iteration @ 7327 is 2.2085771560668945\n",
      "Loss at Iteration @ 7328 is 2.1734225749969482\n",
      "Evaluation Loss at Iteration @ 7328 is 2.249831199645996\n",
      "Loss at Iteration @ 7329 is 2.129204273223877\n",
      "Evaluation Loss at Iteration @ 7329 is 2.2236835956573486\n",
      "Loss at Iteration @ 7330 is 2.2792723178863525\n",
      "Evaluation Loss at Iteration @ 7330 is 2.2103822231292725\n",
      "Loss at Iteration @ 7331 is 2.2432472705841064\n",
      "Evaluation Loss at Iteration @ 7331 is 2.2672691345214844\n",
      "Loss at Iteration @ 7332 is 2.1460142135620117\n",
      "Evaluation Loss at Iteration @ 7332 is 2.2298567295074463\n",
      "Loss at Iteration @ 7333 is 2.6009788513183594\n",
      "Evaluation Loss at Iteration @ 7333 is 2.2209761142730713\n",
      "Loss at Iteration @ 7334 is 2.2656731605529785\n",
      "Evaluation Loss at Iteration @ 7334 is 2.216895818710327\n",
      "Loss at Iteration @ 7335 is 1.940822720527649\n",
      "Evaluation Loss at Iteration @ 7335 is 2.2446720600128174\n",
      "Loss at Iteration @ 7336 is 2.476322889328003\n",
      "Evaluation Loss at Iteration @ 7336 is 2.2606022357940674\n",
      "Loss at Iteration @ 7337 is 2.179291009902954\n",
      "Evaluation Loss at Iteration @ 7337 is 2.2860631942749023\n",
      "Loss at Iteration @ 7338 is 2.2555091381073\n",
      "Evaluation Loss at Iteration @ 7338 is 2.2805185317993164\n",
      "Loss at Iteration @ 7339 is 2.121880054473877\n",
      "Evaluation Loss at Iteration @ 7339 is 2.279515504837036\n",
      "Loss at Iteration @ 7340 is 2.2224225997924805\n",
      "Evaluation Loss at Iteration @ 7340 is 2.3023502826690674\n",
      "Loss at Iteration @ 7341 is 2.3612136840820312\n",
      "Evaluation Loss at Iteration @ 7341 is 2.246628999710083\n",
      "Loss at Iteration @ 7342 is 2.355989694595337\n",
      "Evaluation Loss at Iteration @ 7342 is 2.235743284225464\n",
      "Loss at Iteration @ 7343 is 2.3659579753875732\n",
      "Evaluation Loss at Iteration @ 7343 is 2.28698468208313\n",
      "Loss at Iteration @ 7344 is 2.0661184787750244\n",
      "Evaluation Loss at Iteration @ 7344 is 2.275914192199707\n",
      "Loss at Iteration @ 7345 is 1.995673418045044\n",
      "Evaluation Loss at Iteration @ 7345 is 2.2781901359558105\n",
      "Loss at Iteration @ 7346 is 2.119140148162842\n",
      "Evaluation Loss at Iteration @ 7346 is 2.244283676147461\n",
      "Loss at Iteration @ 7347 is 2.10288667678833\n",
      "Evaluation Loss at Iteration @ 7347 is 2.279006242752075\n",
      "Loss at Iteration @ 7348 is 2.1429641246795654\n",
      "Evaluation Loss at Iteration @ 7348 is 2.280116081237793\n",
      "Loss at Iteration @ 7349 is 2.5031139850616455\n",
      "Evaluation Loss at Iteration @ 7349 is 2.2096426486968994\n",
      "Loss at Iteration @ 7350 is 2.339451789855957\n",
      "Evaluation Loss at Iteration @ 7350 is 2.237757682800293\n",
      "Loss at Iteration @ 7351 is 2.50805926322937\n",
      "Evaluation Loss at Iteration @ 7351 is 2.284029722213745\n",
      "Loss at Iteration @ 7352 is 2.151914358139038\n",
      "Evaluation Loss at Iteration @ 7352 is 2.2302074432373047\n",
      "Loss at Iteration @ 7353 is 2.368459701538086\n",
      "Evaluation Loss at Iteration @ 7353 is 2.251049518585205\n",
      "Loss at Iteration @ 7354 is 2.2143454551696777\n",
      "Evaluation Loss at Iteration @ 7354 is 2.2306554317474365\n",
      "Loss at Iteration @ 7355 is 2.0756914615631104\n",
      "Evaluation Loss at Iteration @ 7355 is 2.2525274753570557\n",
      "Loss at Iteration @ 7356 is 2.2043631076812744\n",
      "Evaluation Loss at Iteration @ 7356 is 2.2545857429504395\n",
      "Loss at Iteration @ 7357 is 2.1701440811157227\n",
      "Evaluation Loss at Iteration @ 7357 is 2.216477632522583\n",
      "Loss at Iteration @ 7358 is 2.181081771850586\n",
      "Evaluation Loss at Iteration @ 7358 is 2.278377056121826\n",
      "Loss at Iteration @ 7359 is 2.229220151901245\n",
      "Evaluation Loss at Iteration @ 7359 is 2.263742685317993\n",
      "Loss at Iteration @ 7360 is 2.3199281692504883\n",
      "Evaluation Loss at Iteration @ 7360 is 2.195186138153076\n",
      "Loss at Iteration @ 7361 is 2.304919958114624\n",
      "Evaluation Loss at Iteration @ 7361 is 2.265087842941284\n",
      "Loss at Iteration @ 7362 is 2.221449136734009\n",
      "Evaluation Loss at Iteration @ 7362 is 2.2422988414764404\n",
      "Loss at Iteration @ 7363 is 2.0730412006378174\n",
      "Evaluation Loss at Iteration @ 7363 is 2.297647476196289\n",
      "Loss at Iteration @ 7364 is 2.0607359409332275\n",
      "Evaluation Loss at Iteration @ 7364 is 2.2476143836975098\n",
      "Loss at Iteration @ 7365 is 1.9546672105789185\n",
      "Evaluation Loss at Iteration @ 7365 is 2.244107246398926\n",
      "Loss at Iteration @ 7366 is 2.129330635070801\n",
      "Evaluation Loss at Iteration @ 7366 is 2.2596805095672607\n",
      "Loss at Iteration @ 7367 is 2.4977433681488037\n",
      "Evaluation Loss at Iteration @ 7367 is 2.218881368637085\n",
      "Loss at Iteration @ 7368 is 2.3810617923736572\n",
      "Evaluation Loss at Iteration @ 7368 is 2.253018856048584\n",
      "Loss at Iteration @ 7369 is 2.305821657180786\n",
      "Evaluation Loss at Iteration @ 7369 is 2.245770215988159\n",
      "Loss at Iteration @ 7370 is 2.358633041381836\n",
      "Evaluation Loss at Iteration @ 7370 is 2.269045114517212\n",
      "Loss at Iteration @ 7371 is 2.283803939819336\n",
      "Evaluation Loss at Iteration @ 7371 is 2.28987193107605\n",
      "Loss at Iteration @ 7372 is 2.323782444000244\n",
      "Evaluation Loss at Iteration @ 7372 is 2.2311959266662598\n",
      "Loss at Iteration @ 7373 is 2.376023054122925\n",
      "Evaluation Loss at Iteration @ 7373 is 2.2917256355285645\n",
      "Loss at Iteration @ 7374 is 2.1614151000976562\n",
      "Evaluation Loss at Iteration @ 7374 is 2.316807270050049\n",
      "Loss at Iteration @ 7375 is 2.3398208618164062\n",
      "Evaluation Loss at Iteration @ 7375 is 2.2326807975769043\n",
      "Loss at Iteration @ 7376 is 2.357297658920288\n",
      "Evaluation Loss at Iteration @ 7376 is 2.246793508529663\n",
      "Loss at Iteration @ 7377 is 2.064742088317871\n",
      "Evaluation Loss at Iteration @ 7377 is 2.2665703296661377\n",
      "Loss at Iteration @ 7378 is 2.2945945262908936\n",
      "Evaluation Loss at Iteration @ 7378 is 2.2516586780548096\n",
      "Loss at Iteration @ 7379 is 2.0521082878112793\n",
      "Evaluation Loss at Iteration @ 7379 is 2.2294862270355225\n",
      "Loss at Iteration @ 7380 is 2.460024356842041\n",
      "Evaluation Loss at Iteration @ 7380 is 2.2638704776763916\n",
      "Loss at Iteration @ 7381 is 2.1561806201934814\n",
      "Evaluation Loss at Iteration @ 7381 is 2.2522494792938232\n",
      "Loss at Iteration @ 7382 is 2.427619218826294\n",
      "Evaluation Loss at Iteration @ 7382 is 2.2277708053588867\n",
      "Loss at Iteration @ 7383 is 2.224472761154175\n",
      "Evaluation Loss at Iteration @ 7383 is 2.211678981781006\n",
      "Loss at Iteration @ 7384 is 2.2047834396362305\n",
      "Evaluation Loss at Iteration @ 7384 is 2.2294840812683105\n",
      "Loss at Iteration @ 7385 is 2.330554246902466\n",
      "Evaluation Loss at Iteration @ 7385 is 2.276026725769043\n",
      "Loss at Iteration @ 7386 is 2.2143301963806152\n",
      "Evaluation Loss at Iteration @ 7386 is 2.2654595375061035\n",
      "Loss at Iteration @ 7387 is 2.213158369064331\n",
      "Evaluation Loss at Iteration @ 7387 is 2.3023977279663086\n",
      "Loss at Iteration @ 7388 is 2.2738616466522217\n",
      "Evaluation Loss at Iteration @ 7388 is 2.2608306407928467\n",
      "Loss at Iteration @ 7389 is 2.240739583969116\n",
      "Evaluation Loss at Iteration @ 7389 is 2.26125168800354\n",
      "Loss at Iteration @ 7390 is 2.4697296619415283\n",
      "Evaluation Loss at Iteration @ 7390 is 2.2438600063323975\n",
      "Loss at Iteration @ 7391 is 2.379899501800537\n",
      "Evaluation Loss at Iteration @ 7391 is 2.257155656814575\n",
      "Loss at Iteration @ 7392 is 2.2494568824768066\n",
      "Evaluation Loss at Iteration @ 7392 is 2.3055503368377686\n",
      "Loss at Iteration @ 7393 is 2.2277839183807373\n",
      "Evaluation Loss at Iteration @ 7393 is 2.248593807220459\n",
      "Loss at Iteration @ 7394 is 2.413907289505005\n",
      "Evaluation Loss at Iteration @ 7394 is 2.2352139949798584\n",
      "Loss at Iteration @ 7395 is 2.04502010345459\n",
      "Evaluation Loss at Iteration @ 7395 is 2.2566583156585693\n",
      "Loss at Iteration @ 7396 is 2.381560802459717\n",
      "Evaluation Loss at Iteration @ 7396 is 2.2731127738952637\n",
      "Loss at Iteration @ 7397 is 2.3039534091949463\n",
      "Evaluation Loss at Iteration @ 7397 is 2.1966776847839355\n",
      "Loss at Iteration @ 7398 is 2.1218669414520264\n",
      "Evaluation Loss at Iteration @ 7398 is 2.206221342086792\n",
      "Loss at Iteration @ 7399 is 2.4153928756713867\n",
      "Evaluation Loss at Iteration @ 7399 is 2.2744076251983643\n",
      "Loss at Iteration @ 7400 is 2.260669231414795\n",
      "Evaluation Loss at Iteration @ 7400 is 2.230490207672119\n",
      "Loss at Iteration @ 7401 is 2.34846830368042\n",
      "Evaluation Loss at Iteration @ 7401 is 2.2192444801330566\n",
      "Loss at Iteration @ 7402 is 2.3141207695007324\n",
      "Evaluation Loss at Iteration @ 7402 is 2.237907648086548\n",
      "Loss at Iteration @ 7403 is 2.3427915573120117\n",
      "Evaluation Loss at Iteration @ 7403 is 2.3029637336730957\n",
      "Loss at Iteration @ 7404 is 2.400705337524414\n",
      "Evaluation Loss at Iteration @ 7404 is 2.2846131324768066\n",
      "Loss at Iteration @ 7405 is 2.2189927101135254\n",
      "Evaluation Loss at Iteration @ 7405 is 2.284717321395874\n",
      "Loss at Iteration @ 7406 is 2.380620241165161\n",
      "Evaluation Loss at Iteration @ 7406 is 2.2476346492767334\n",
      "Loss at Iteration @ 7407 is 2.1712210178375244\n",
      "Evaluation Loss at Iteration @ 7407 is 2.2550506591796875\n",
      "Loss at Iteration @ 7408 is 2.319713592529297\n",
      "Evaluation Loss at Iteration @ 7408 is 2.289167881011963\n",
      "Loss at Iteration @ 7409 is 2.1525158882141113\n",
      "Evaluation Loss at Iteration @ 7409 is 2.202486276626587\n",
      "Loss at Iteration @ 7410 is 2.1951098442077637\n",
      "Evaluation Loss at Iteration @ 7410 is 2.246448040008545\n",
      "Loss at Iteration @ 7411 is 2.241154670715332\n",
      "Evaluation Loss at Iteration @ 7411 is 2.2317473888397217\n",
      "Loss at Iteration @ 7412 is 2.1660377979278564\n",
      "Evaluation Loss at Iteration @ 7412 is 2.2305541038513184\n",
      "Loss at Iteration @ 7413 is 2.1116182804107666\n",
      "Evaluation Loss at Iteration @ 7413 is 2.197880744934082\n",
      "Loss at Iteration @ 7414 is 2.3333709239959717\n",
      "Evaluation Loss at Iteration @ 7414 is 2.2085821628570557\n",
      "Loss at Iteration @ 7415 is 2.457195281982422\n",
      "Evaluation Loss at Iteration @ 7415 is 2.246689558029175\n",
      "Loss at Iteration @ 7416 is 2.1509742736816406\n",
      "Evaluation Loss at Iteration @ 7416 is 2.277329683303833\n",
      "Loss at Iteration @ 7417 is 2.519071578979492\n",
      "Evaluation Loss at Iteration @ 7417 is 2.2311031818389893\n",
      "Loss at Iteration @ 7418 is 2.605860948562622\n",
      "Evaluation Loss at Iteration @ 7418 is 2.2413439750671387\n",
      "Loss at Iteration @ 7419 is 1.9119882583618164\n",
      "Evaluation Loss at Iteration @ 7419 is 2.258875846862793\n",
      "Loss at Iteration @ 7420 is 2.18312668800354\n",
      "Evaluation Loss at Iteration @ 7420 is 2.2216899394989014\n",
      "Loss at Iteration @ 7421 is 2.408646583557129\n",
      "Evaluation Loss at Iteration @ 7421 is 2.2612476348876953\n",
      "Loss at Iteration @ 7422 is 2.2649357318878174\n",
      "Evaluation Loss at Iteration @ 7422 is 2.2490293979644775\n",
      "Loss at Iteration @ 7423 is 2.087144136428833\n",
      "Evaluation Loss at Iteration @ 7423 is 2.269439458847046\n",
      "Loss at Iteration @ 7424 is 2.4754040241241455\n",
      "Evaluation Loss at Iteration @ 7424 is 2.2850778102874756\n",
      "Loss at Iteration @ 7425 is 2.1188838481903076\n",
      "Evaluation Loss at Iteration @ 7425 is 2.2377748489379883\n",
      "Loss at Iteration @ 7426 is 2.061549425125122\n",
      "Evaluation Loss at Iteration @ 7426 is 2.2372496128082275\n",
      "Loss at Iteration @ 7427 is 2.4749956130981445\n",
      "Evaluation Loss at Iteration @ 7427 is 2.24868106842041\n",
      "Loss at Iteration @ 7428 is 2.3195574283599854\n",
      "Evaluation Loss at Iteration @ 7428 is 2.252366065979004\n",
      "Loss at Iteration @ 7429 is 2.202866315841675\n",
      "Evaluation Loss at Iteration @ 7429 is 2.2606451511383057\n",
      "Loss at Iteration @ 7430 is 2.102280616760254\n",
      "Evaluation Loss at Iteration @ 7430 is 2.2584340572357178\n",
      "Loss at Iteration @ 7431 is 2.2596302032470703\n",
      "Evaluation Loss at Iteration @ 7431 is 2.277353048324585\n",
      "Loss at Iteration @ 7432 is 2.0980350971221924\n",
      "Evaluation Loss at Iteration @ 7432 is 2.2973456382751465\n",
      "Loss at Iteration @ 7433 is 2.2401394844055176\n",
      "Evaluation Loss at Iteration @ 7433 is 2.2306394577026367\n",
      "Loss at Iteration @ 7434 is 2.2861926555633545\n",
      "Evaluation Loss at Iteration @ 7434 is 2.2585830688476562\n",
      "Loss at Iteration @ 7435 is 2.5034406185150146\n",
      "Evaluation Loss at Iteration @ 7435 is 2.2926812171936035\n",
      "Loss at Iteration @ 7436 is 2.1569812297821045\n",
      "Evaluation Loss at Iteration @ 7436 is 2.3103532791137695\n",
      "Loss at Iteration @ 7437 is 2.223609209060669\n",
      "Evaluation Loss at Iteration @ 7437 is 2.2878966331481934\n",
      "Loss at Iteration @ 7438 is 2.3369662761688232\n",
      "Evaluation Loss at Iteration @ 7438 is 2.235652208328247\n",
      "Loss at Iteration @ 7439 is 2.2757911682128906\n",
      "Evaluation Loss at Iteration @ 7439 is 2.2413082122802734\n",
      "Loss at Iteration @ 7440 is 2.2052035331726074\n",
      "Evaluation Loss at Iteration @ 7440 is 2.2733101844787598\n",
      "Loss at Iteration @ 7441 is 2.036231517791748\n",
      "Evaluation Loss at Iteration @ 7441 is 2.1999902725219727\n",
      "Loss at Iteration @ 7442 is 2.3191051483154297\n",
      "Evaluation Loss at Iteration @ 7442 is 2.2269532680511475\n",
      "Loss at Iteration @ 7443 is 2.506439447402954\n",
      "Evaluation Loss at Iteration @ 7443 is 2.265829563140869\n",
      "Loss at Iteration @ 7444 is 2.311753034591675\n",
      "Evaluation Loss at Iteration @ 7444 is 2.1897330284118652\n",
      "Loss at Iteration @ 7445 is 2.18410325050354\n",
      "Evaluation Loss at Iteration @ 7445 is 2.2135097980499268\n",
      "Loss at Iteration @ 7446 is 2.3378329277038574\n",
      "Evaluation Loss at Iteration @ 7446 is 2.215597629547119\n",
      "Loss at Iteration @ 7447 is 2.374253511428833\n",
      "Evaluation Loss at Iteration @ 7447 is 2.26065731048584\n",
      "Loss at Iteration @ 7448 is 2.325451612472534\n",
      "Evaluation Loss at Iteration @ 7448 is 2.2717690467834473\n",
      "Loss at Iteration @ 7449 is 2.4026715755462646\n",
      "Evaluation Loss at Iteration @ 7449 is 2.298091411590576\n",
      "Loss at Iteration @ 7450 is 2.0298564434051514\n",
      "Evaluation Loss at Iteration @ 7450 is 2.2542355060577393\n",
      "Loss at Iteration @ 7451 is 2.036557912826538\n",
      "Evaluation Loss at Iteration @ 7451 is 2.227062463760376\n",
      "Loss at Iteration @ 7452 is 2.1091928482055664\n",
      "Evaluation Loss at Iteration @ 7452 is 2.250549554824829\n",
      "Loss at Iteration @ 7453 is 1.8558317422866821\n",
      "Evaluation Loss at Iteration @ 7453 is 2.255361318588257\n",
      "Loss at Iteration @ 7454 is 1.911924123764038\n",
      "Evaluation Loss at Iteration @ 7454 is 2.2999751567840576\n",
      "Loss at Iteration @ 7455 is 2.3029110431671143\n",
      "Evaluation Loss at Iteration @ 7455 is 2.2128524780273438\n",
      "Loss at Iteration @ 7456 is 2.6594491004943848\n",
      "Evaluation Loss at Iteration @ 7456 is 2.271381378173828\n",
      "Loss at Iteration @ 7457 is 2.1147708892822266\n",
      "Evaluation Loss at Iteration @ 7457 is 2.2195353507995605\n",
      "Loss at Iteration @ 7458 is 2.4777400493621826\n",
      "Evaluation Loss at Iteration @ 7458 is 2.2666451930999756\n",
      "Loss at Iteration @ 7459 is 2.4706945419311523\n",
      "Evaluation Loss at Iteration @ 7459 is 2.242356777191162\n",
      "Loss at Iteration @ 7460 is 2.223680019378662\n",
      "Evaluation Loss at Iteration @ 7460 is 2.262789011001587\n",
      "Loss at Iteration @ 7461 is 2.205700635910034\n",
      "Evaluation Loss at Iteration @ 7461 is 2.2973690032958984\n",
      "Loss at Iteration @ 7462 is 2.093487024307251\n",
      "Evaluation Loss at Iteration @ 7462 is 2.208712339401245\n",
      "Loss at Iteration @ 7463 is 2.387036085128784\n",
      "Evaluation Loss at Iteration @ 7463 is 2.222877025604248\n",
      "Loss at Iteration @ 7464 is 2.434225082397461\n",
      "Evaluation Loss at Iteration @ 7464 is 2.2602181434631348\n",
      "Loss at Iteration @ 7465 is 2.5130317211151123\n",
      "Evaluation Loss at Iteration @ 7465 is 2.2280542850494385\n",
      "Loss at Iteration @ 7466 is 2.223280668258667\n",
      "Evaluation Loss at Iteration @ 7466 is 2.2252321243286133\n",
      "Loss at Iteration @ 7467 is 2.555192232131958\n",
      "Evaluation Loss at Iteration @ 7467 is 2.2646853923797607\n",
      "Loss at Iteration @ 7468 is 2.2850987911224365\n",
      "Evaluation Loss at Iteration @ 7468 is 2.2469124794006348\n",
      "Loss at Iteration @ 7469 is 2.337318181991577\n",
      "Evaluation Loss at Iteration @ 7469 is 2.2818925380706787\n",
      "Loss at Iteration @ 7470 is 2.1403234004974365\n",
      "Evaluation Loss at Iteration @ 7470 is 2.2310268878936768\n",
      "Loss at Iteration @ 7471 is 2.372682571411133\n",
      "Evaluation Loss at Iteration @ 7471 is 2.282808780670166\n",
      "Loss at Iteration @ 7472 is 2.033942699432373\n",
      "Evaluation Loss at Iteration @ 7472 is 2.2750415802001953\n",
      "Loss at Iteration @ 7473 is 2.318730592727661\n",
      "Evaluation Loss at Iteration @ 7473 is 2.203781843185425\n",
      "Loss at Iteration @ 7474 is 2.214735507965088\n",
      "Evaluation Loss at Iteration @ 7474 is 2.2610576152801514\n",
      "Loss at Iteration @ 7475 is 2.2056641578674316\n",
      "Evaluation Loss at Iteration @ 7475 is 2.2316086292266846\n",
      "Loss at Iteration @ 7476 is 2.136889934539795\n",
      "Evaluation Loss at Iteration @ 7476 is 2.264150381088257\n",
      "Loss at Iteration @ 7477 is 2.3553006649017334\n",
      "Evaluation Loss at Iteration @ 7477 is 2.2438082695007324\n",
      "Loss at Iteration @ 7478 is 2.2646679878234863\n",
      "Evaluation Loss at Iteration @ 7478 is 2.261817693710327\n",
      "Loss at Iteration @ 7479 is 2.426499366760254\n",
      "Evaluation Loss at Iteration @ 7479 is 2.200791120529175\n",
      "Loss at Iteration @ 7480 is 2.016124963760376\n",
      "Evaluation Loss at Iteration @ 7480 is 2.227630138397217\n",
      "Loss at Iteration @ 7481 is 2.319084882736206\n",
      "Evaluation Loss at Iteration @ 7481 is 2.2701354026794434\n",
      "Loss at Iteration @ 7482 is 2.276411294937134\n",
      "Evaluation Loss at Iteration @ 7482 is 2.244060754776001\n",
      "Loss at Iteration @ 7483 is 2.217663288116455\n",
      "Evaluation Loss at Iteration @ 7483 is 2.2491674423217773\n",
      "Loss at Iteration @ 7484 is 2.078634262084961\n",
      "Evaluation Loss at Iteration @ 7484 is 2.1920158863067627\n",
      "Loss at Iteration @ 7485 is 2.2811429500579834\n",
      "Evaluation Loss at Iteration @ 7485 is 2.269035577774048\n",
      "Loss at Iteration @ 7486 is 2.127067804336548\n",
      "Evaluation Loss at Iteration @ 7486 is 2.2212090492248535\n",
      "Loss at Iteration @ 7487 is 2.5362274646759033\n",
      "Evaluation Loss at Iteration @ 7487 is 2.214777946472168\n",
      "Loss at Iteration @ 7488 is 2.1288070678710938\n",
      "Evaluation Loss at Iteration @ 7488 is 2.251244306564331\n",
      "Loss at Iteration @ 7489 is 2.1793158054351807\n",
      "Evaluation Loss at Iteration @ 7489 is 2.237942934036255\n",
      "Loss at Iteration @ 7490 is 2.1329917907714844\n",
      "Evaluation Loss at Iteration @ 7490 is 2.1966211795806885\n",
      "Loss at Iteration @ 7491 is 2.515148401260376\n",
      "Evaluation Loss at Iteration @ 7491 is 2.275186777114868\n",
      "Loss at Iteration @ 7492 is 2.227644920349121\n",
      "Evaluation Loss at Iteration @ 7492 is 2.2461183071136475\n",
      "Loss at Iteration @ 7493 is 2.290705680847168\n",
      "Evaluation Loss at Iteration @ 7493 is 2.2788782119750977\n",
      "Loss at Iteration @ 7494 is 2.2819721698760986\n",
      "Evaluation Loss at Iteration @ 7494 is 2.2521636486053467\n",
      "Loss at Iteration @ 7495 is 1.978432059288025\n",
      "Evaluation Loss at Iteration @ 7495 is 2.244163990020752\n",
      "Loss at Iteration @ 7496 is 2.0897064208984375\n",
      "Evaluation Loss at Iteration @ 7496 is 2.232128858566284\n",
      "Loss at Iteration @ 7497 is 2.2956008911132812\n",
      "Evaluation Loss at Iteration @ 7497 is 2.290764093399048\n",
      "Loss at Iteration @ 7498 is 2.120748281478882\n",
      "Evaluation Loss at Iteration @ 7498 is 2.2763895988464355\n",
      "Loss at Iteration @ 7499 is 2.0693576335906982\n",
      "Evaluation Loss at Iteration @ 7499 is 2.264692544937134\n",
      "Loss at Iteration @ 7500 is 2.321735382080078\n",
      "Evaluation Loss at Iteration @ 7500 is 2.2137300968170166\n",
      "Loss at Iteration @ 7501 is 2.157594919204712\n",
      "Evaluation Loss at Iteration @ 7501 is 2.2705929279327393\n",
      "Loss at Iteration @ 7502 is 2.2730205059051514\n",
      "Evaluation Loss at Iteration @ 7502 is 2.2345597743988037\n",
      "Loss at Iteration @ 7503 is 2.4413907527923584\n",
      "Evaluation Loss at Iteration @ 7503 is 2.3243486881256104\n",
      "Loss at Iteration @ 7504 is 2.265674114227295\n",
      "Evaluation Loss at Iteration @ 7504 is 2.284001350402832\n",
      "Loss at Iteration @ 7505 is 2.522080421447754\n",
      "Evaluation Loss at Iteration @ 7505 is 2.2438602447509766\n",
      "Loss at Iteration @ 7506 is 2.3533899784088135\n",
      "Evaluation Loss at Iteration @ 7506 is 2.272095203399658\n",
      "Loss at Iteration @ 7507 is 2.3582050800323486\n",
      "Evaluation Loss at Iteration @ 7507 is 2.2316224575042725\n",
      "Loss at Iteration @ 7508 is 2.1701040267944336\n",
      "Evaluation Loss at Iteration @ 7508 is 2.2870590686798096\n",
      "Loss at Iteration @ 7509 is 2.129568338394165\n",
      "Evaluation Loss at Iteration @ 7509 is 2.264298677444458\n",
      "Loss at Iteration @ 7510 is 2.241980791091919\n",
      "Evaluation Loss at Iteration @ 7510 is 2.2558815479278564\n",
      "Loss at Iteration @ 7511 is 2.1044719219207764\n",
      "Evaluation Loss at Iteration @ 7511 is 2.301642656326294\n",
      "Loss at Iteration @ 7512 is 2.4330484867095947\n",
      "Evaluation Loss at Iteration @ 7512 is 2.250436305999756\n",
      "Loss at Iteration @ 7513 is 2.2437617778778076\n",
      "Evaluation Loss at Iteration @ 7513 is 2.3017003536224365\n",
      "Loss at Iteration @ 7514 is 2.240037202835083\n",
      "Evaluation Loss at Iteration @ 7514 is 2.2359442710876465\n",
      "Loss at Iteration @ 7515 is 2.3977787494659424\n",
      "Evaluation Loss at Iteration @ 7515 is 2.254579782485962\n",
      "Loss at Iteration @ 7516 is 2.28096866607666\n",
      "Evaluation Loss at Iteration @ 7516 is 2.232905864715576\n",
      "Loss at Iteration @ 7517 is 2.0972788333892822\n",
      "Evaluation Loss at Iteration @ 7517 is 2.3218846321105957\n",
      "Loss at Iteration @ 7518 is 2.0626485347747803\n",
      "Evaluation Loss at Iteration @ 7518 is 2.228484869003296\n",
      "Loss at Iteration @ 7519 is 2.334563732147217\n",
      "Evaluation Loss at Iteration @ 7519 is 2.264730453491211\n",
      "Loss at Iteration @ 7520 is 1.9881705045700073\n",
      "Evaluation Loss at Iteration @ 7520 is 2.2445027828216553\n",
      "Loss at Iteration @ 7521 is 2.189302921295166\n",
      "Evaluation Loss at Iteration @ 7521 is 2.2717909812927246\n",
      "Loss at Iteration @ 7522 is 2.2220170497894287\n",
      "Evaluation Loss at Iteration @ 7522 is 2.2459323406219482\n",
      "Loss at Iteration @ 7523 is 2.0985798835754395\n",
      "Evaluation Loss at Iteration @ 7523 is 2.2086551189422607\n",
      "Loss at Iteration @ 7524 is 1.9420418739318848\n",
      "Evaluation Loss at Iteration @ 7524 is 2.251474618911743\n",
      "Loss at Iteration @ 7525 is 2.177438735961914\n",
      "Evaluation Loss at Iteration @ 7525 is 2.233987808227539\n",
      "Loss at Iteration @ 7526 is 1.8798121213912964\n",
      "Evaluation Loss at Iteration @ 7526 is 2.219498634338379\n",
      "Loss at Iteration @ 7527 is 2.0330348014831543\n",
      "Evaluation Loss at Iteration @ 7527 is 2.238757848739624\n",
      "Loss at Iteration @ 7528 is 2.306147336959839\n",
      "Evaluation Loss at Iteration @ 7528 is 2.2888786792755127\n",
      "Loss at Iteration @ 7529 is 1.944858431816101\n",
      "Evaluation Loss at Iteration @ 7529 is 2.2162673473358154\n",
      "Loss at Iteration @ 7530 is 2.173922061920166\n",
      "Evaluation Loss at Iteration @ 7530 is 2.248964309692383\n",
      "Loss at Iteration @ 7531 is 2.227160692214966\n",
      "Evaluation Loss at Iteration @ 7531 is 2.268134117126465\n",
      "Loss at Iteration @ 7532 is 2.3408186435699463\n",
      "Evaluation Loss at Iteration @ 7532 is 2.2757723331451416\n",
      "Loss at Iteration @ 7533 is 2.3759584426879883\n",
      "Evaluation Loss at Iteration @ 7533 is 2.2342920303344727\n",
      "Loss at Iteration @ 7534 is 2.3010213375091553\n",
      "Evaluation Loss at Iteration @ 7534 is 2.2413675785064697\n",
      "Loss at Iteration @ 7535 is 2.414409637451172\n",
      "Evaluation Loss at Iteration @ 7535 is 2.314222812652588\n",
      "Loss at Iteration @ 7536 is 2.100905418395996\n",
      "Evaluation Loss at Iteration @ 7536 is 2.2459795475006104\n",
      "Loss at Iteration @ 7537 is 2.378035545349121\n",
      "Evaluation Loss at Iteration @ 7537 is 2.2433390617370605\n",
      "Loss at Iteration @ 7538 is 2.2026994228363037\n",
      "Evaluation Loss at Iteration @ 7538 is 2.2376980781555176\n",
      "Loss at Iteration @ 7539 is 1.9549576044082642\n",
      "Evaluation Loss at Iteration @ 7539 is 2.262007713317871\n",
      "Loss at Iteration @ 7540 is 2.36630916595459\n",
      "Evaluation Loss at Iteration @ 7540 is 2.2650744915008545\n",
      "Loss at Iteration @ 7541 is 2.216758966445923\n",
      "Evaluation Loss at Iteration @ 7541 is 2.23867130279541\n",
      "Loss at Iteration @ 7542 is 2.6075549125671387\n",
      "Evaluation Loss at Iteration @ 7542 is 2.259549140930176\n",
      "Loss at Iteration @ 7543 is 2.015876293182373\n",
      "Evaluation Loss at Iteration @ 7543 is 2.1832385063171387\n",
      "Loss at Iteration @ 7544 is 2.313030958175659\n",
      "Evaluation Loss at Iteration @ 7544 is 2.2638933658599854\n",
      "Loss at Iteration @ 7545 is 2.29948353767395\n",
      "Evaluation Loss at Iteration @ 7545 is 2.3047285079956055\n",
      "Loss at Iteration @ 7546 is 2.3936846256256104\n",
      "Evaluation Loss at Iteration @ 7546 is 2.2690846920013428\n",
      "Loss at Iteration @ 7547 is 2.1203255653381348\n",
      "Evaluation Loss at Iteration @ 7547 is 2.2320713996887207\n",
      "Loss at Iteration @ 7548 is 2.173539638519287\n",
      "Evaluation Loss at Iteration @ 7548 is 2.234290361404419\n",
      "Loss at Iteration @ 7549 is 2.4676427841186523\n",
      "Evaluation Loss at Iteration @ 7549 is 2.211233377456665\n",
      "Loss at Iteration @ 7550 is 2.234398603439331\n",
      "Evaluation Loss at Iteration @ 7550 is 2.2187321186065674\n",
      "Loss at Iteration @ 7551 is 2.2948546409606934\n",
      "Evaluation Loss at Iteration @ 7551 is 2.261202096939087\n",
      "Loss at Iteration @ 7552 is 2.2717502117156982\n",
      "Evaluation Loss at Iteration @ 7552 is 2.2875165939331055\n",
      "Loss at Iteration @ 7553 is 2.1953213214874268\n",
      "Evaluation Loss at Iteration @ 7553 is 2.2482571601867676\n",
      "Loss at Iteration @ 7554 is 1.9696446657180786\n",
      "Evaluation Loss at Iteration @ 7554 is 2.215562343597412\n",
      "Loss at Iteration @ 7555 is 2.251694679260254\n",
      "Evaluation Loss at Iteration @ 7555 is 2.2611019611358643\n",
      "Loss at Iteration @ 7556 is 2.456212282180786\n",
      "Evaluation Loss at Iteration @ 7556 is 2.265970230102539\n",
      "Loss at Iteration @ 7557 is 2.571505308151245\n",
      "Evaluation Loss at Iteration @ 7557 is 2.2368483543395996\n",
      "Loss at Iteration @ 7558 is 2.1941816806793213\n",
      "Evaluation Loss at Iteration @ 7558 is 2.215217113494873\n",
      "Loss at Iteration @ 7559 is 2.273130178451538\n",
      "Evaluation Loss at Iteration @ 7559 is 2.278613328933716\n",
      "Loss at Iteration @ 7560 is 2.2979390621185303\n",
      "Evaluation Loss at Iteration @ 7560 is 2.2500240802764893\n",
      "Loss at Iteration @ 7561 is 2.212144374847412\n",
      "Evaluation Loss at Iteration @ 7561 is 2.2597780227661133\n",
      "Loss at Iteration @ 7562 is 1.9579659700393677\n",
      "Evaluation Loss at Iteration @ 7562 is 2.2417662143707275\n",
      "Loss at Iteration @ 7563 is 2.4181361198425293\n",
      "Evaluation Loss at Iteration @ 7563 is 2.283256769180298\n",
      "Loss at Iteration @ 7564 is 2.269155979156494\n",
      "Evaluation Loss at Iteration @ 7564 is 2.2064836025238037\n",
      "Loss at Iteration @ 7565 is 2.3260374069213867\n",
      "Evaluation Loss at Iteration @ 7565 is 2.260521650314331\n",
      "Loss at Iteration @ 7566 is 2.2763826847076416\n",
      "Evaluation Loss at Iteration @ 7566 is 2.290764093399048\n",
      "Loss at Iteration @ 7567 is 2.1758346557617188\n",
      "Evaluation Loss at Iteration @ 7567 is 2.258535623550415\n",
      "Loss at Iteration @ 7568 is 2.2267513275146484\n",
      "Evaluation Loss at Iteration @ 7568 is 2.172865152359009\n",
      "Loss at Iteration @ 7569 is 2.287168502807617\n",
      "Evaluation Loss at Iteration @ 7569 is 2.217191219329834\n",
      "Loss at Iteration @ 7570 is 2.1691641807556152\n",
      "Evaluation Loss at Iteration @ 7570 is 2.219191074371338\n",
      "Loss at Iteration @ 7571 is 2.1988472938537598\n",
      "Evaluation Loss at Iteration @ 7571 is 2.2459828853607178\n",
      "Loss at Iteration @ 7572 is 2.231675863265991\n",
      "Evaluation Loss at Iteration @ 7572 is 2.2930150032043457\n",
      "Loss at Iteration @ 7573 is 2.1744227409362793\n",
      "Evaluation Loss at Iteration @ 7573 is 2.1782708168029785\n",
      "Loss at Iteration @ 7574 is 2.4770755767822266\n",
      "Evaluation Loss at Iteration @ 7574 is 2.184356212615967\n",
      "Loss at Iteration @ 7575 is 2.3706018924713135\n",
      "Evaluation Loss at Iteration @ 7575 is 2.2411298751831055\n",
      "Loss at Iteration @ 7576 is 2.2156004905700684\n",
      "Evaluation Loss at Iteration @ 7576 is 2.2749948501586914\n",
      "Loss at Iteration @ 7577 is 2.1501080989837646\n",
      "Evaluation Loss at Iteration @ 7577 is 2.278562068939209\n",
      "Loss at Iteration @ 7578 is 2.2783777713775635\n",
      "Evaluation Loss at Iteration @ 7578 is 2.2511234283447266\n",
      "Loss at Iteration @ 7579 is 2.5846052169799805\n",
      "Evaluation Loss at Iteration @ 7579 is 2.272003173828125\n",
      "Loss at Iteration @ 7580 is 2.0756499767303467\n",
      "Evaluation Loss at Iteration @ 7580 is 2.2364206314086914\n",
      "Loss at Iteration @ 7581 is 2.2275774478912354\n",
      "Evaluation Loss at Iteration @ 7581 is 2.2789032459259033\n",
      "Loss at Iteration @ 7582 is 2.531834840774536\n",
      "Evaluation Loss at Iteration @ 7582 is 2.2614176273345947\n",
      "Loss at Iteration @ 7583 is 2.529834747314453\n",
      "Evaluation Loss at Iteration @ 7583 is 2.271094560623169\n",
      "Loss at Iteration @ 7584 is 2.200312376022339\n",
      "Evaluation Loss at Iteration @ 7584 is 2.2221662998199463\n",
      "Loss at Iteration @ 7585 is 2.537679672241211\n",
      "Evaluation Loss at Iteration @ 7585 is 2.2966699600219727\n",
      "Loss at Iteration @ 7586 is 2.342784881591797\n",
      "Evaluation Loss at Iteration @ 7586 is 2.2392303943634033\n",
      "Loss at Iteration @ 7587 is 2.0822064876556396\n",
      "Evaluation Loss at Iteration @ 7587 is 2.2801780700683594\n",
      "Loss at Iteration @ 7588 is 2.5475776195526123\n",
      "Evaluation Loss at Iteration @ 7588 is 2.256829023361206\n",
      "Loss at Iteration @ 7589 is 2.330618143081665\n",
      "Evaluation Loss at Iteration @ 7589 is 2.232297658920288\n",
      "Loss at Iteration @ 7590 is 2.2482097148895264\n",
      "Evaluation Loss at Iteration @ 7590 is 2.2924580574035645\n",
      "Loss at Iteration @ 7591 is 2.479489326477051\n",
      "Evaluation Loss at Iteration @ 7591 is 2.241093397140503\n",
      "Loss at Iteration @ 7592 is 2.1390151977539062\n",
      "Evaluation Loss at Iteration @ 7592 is 2.2845728397369385\n",
      "Loss at Iteration @ 7593 is 2.298520565032959\n",
      "Evaluation Loss at Iteration @ 7593 is 2.271538496017456\n",
      "Loss at Iteration @ 7594 is 1.9872820377349854\n",
      "Evaluation Loss at Iteration @ 7594 is 2.2294187545776367\n",
      "Loss at Iteration @ 7595 is 2.0322320461273193\n",
      "Evaluation Loss at Iteration @ 7595 is 2.2311065196990967\n",
      "Loss at Iteration @ 7596 is 2.2829434871673584\n",
      "Evaluation Loss at Iteration @ 7596 is 2.2416064739227295\n",
      "Loss at Iteration @ 7597 is 2.289677619934082\n",
      "Evaluation Loss at Iteration @ 7597 is 2.211503028869629\n",
      "Loss at Iteration @ 7598 is 2.051100730895996\n",
      "Evaluation Loss at Iteration @ 7598 is 2.27405047416687\n",
      "Loss at Iteration @ 7599 is 2.138162851333618\n",
      "Evaluation Loss at Iteration @ 7599 is 2.2432587146759033\n",
      "Loss at Iteration @ 7600 is 2.373507022857666\n",
      "Evaluation Loss at Iteration @ 7600 is 2.2620275020599365\n",
      "Loss at Iteration @ 7601 is 2.19042706489563\n",
      "Evaluation Loss at Iteration @ 7601 is 2.2187604904174805\n",
      "Loss at Iteration @ 7602 is 2.161998748779297\n",
      "Evaluation Loss at Iteration @ 7602 is 2.2351346015930176\n",
      "Loss at Iteration @ 7603 is 2.2874348163604736\n",
      "Evaluation Loss at Iteration @ 7603 is 2.2036209106445312\n",
      "Loss at Iteration @ 7604 is 2.6111862659454346\n",
      "Evaluation Loss at Iteration @ 7604 is 2.2270543575286865\n",
      "Loss at Iteration @ 7605 is 2.401639223098755\n",
      "Evaluation Loss at Iteration @ 7605 is 2.272083044052124\n",
      "Loss at Iteration @ 7606 is 2.2714641094207764\n",
      "Evaluation Loss at Iteration @ 7606 is 2.2446401119232178\n",
      "Loss at Iteration @ 7607 is 2.053004503250122\n",
      "Evaluation Loss at Iteration @ 7607 is 2.231529474258423\n",
      "Loss at Iteration @ 7608 is 2.122685432434082\n",
      "Evaluation Loss at Iteration @ 7608 is 2.283726930618286\n",
      "Loss at Iteration @ 7609 is 2.316890239715576\n",
      "Evaluation Loss at Iteration @ 7609 is 2.25532603263855\n",
      "Loss at Iteration @ 7610 is 2.4516422748565674\n",
      "Evaluation Loss at Iteration @ 7610 is 2.2719948291778564\n",
      "Loss at Iteration @ 7611 is 2.040713310241699\n",
      "Evaluation Loss at Iteration @ 7611 is 2.2406771183013916\n",
      "Loss at Iteration @ 7612 is 2.0987489223480225\n",
      "Evaluation Loss at Iteration @ 7612 is 2.210282564163208\n",
      "Loss at Iteration @ 7613 is 2.0138063430786133\n",
      "Evaluation Loss at Iteration @ 7613 is 2.206982374191284\n",
      "Loss at Iteration @ 7614 is 2.4446730613708496\n",
      "Evaluation Loss at Iteration @ 7614 is 2.2770633697509766\n",
      "Loss at Iteration @ 7615 is 2.150351047515869\n",
      "Evaluation Loss at Iteration @ 7615 is 2.236238956451416\n",
      "Loss at Iteration @ 7616 is 2.1445443630218506\n",
      "Evaluation Loss at Iteration @ 7616 is 2.215095281600952\n",
      "Loss at Iteration @ 7617 is 2.278273582458496\n",
      "Evaluation Loss at Iteration @ 7617 is 2.2729990482330322\n",
      "Loss at Iteration @ 7618 is 1.896459937095642\n",
      "Evaluation Loss at Iteration @ 7618 is 2.2716588973999023\n",
      "Loss at Iteration @ 7619 is 2.19857120513916\n",
      "Evaluation Loss at Iteration @ 7619 is 2.2842869758605957\n",
      "Loss at Iteration @ 7620 is 1.9668300151824951\n",
      "Evaluation Loss at Iteration @ 7620 is 2.2369863986968994\n",
      "Loss at Iteration @ 7621 is 2.249211549758911\n",
      "Evaluation Loss at Iteration @ 7621 is 2.280177354812622\n",
      "Loss at Iteration @ 7622 is 2.4073238372802734\n",
      "Evaluation Loss at Iteration @ 7622 is 2.239145278930664\n",
      "Loss at Iteration @ 7623 is 2.092665672302246\n",
      "Evaluation Loss at Iteration @ 7623 is 2.2968602180480957\n",
      "Loss at Iteration @ 7624 is 2.081083297729492\n",
      "Evaluation Loss at Iteration @ 7624 is 2.281576156616211\n",
      "Loss at Iteration @ 7625 is 2.222295045852661\n",
      "Evaluation Loss at Iteration @ 7625 is 2.227356195449829\n",
      "Loss at Iteration @ 7626 is 2.2446374893188477\n",
      "Evaluation Loss at Iteration @ 7626 is 2.2340691089630127\n",
      "Loss at Iteration @ 7627 is 2.319859504699707\n",
      "Evaluation Loss at Iteration @ 7627 is 2.276244878768921\n",
      "Loss at Iteration @ 7628 is 2.336897134780884\n",
      "Evaluation Loss at Iteration @ 7628 is 2.2321135997772217\n",
      "Loss at Iteration @ 7629 is 2.129909038543701\n",
      "Evaluation Loss at Iteration @ 7629 is 2.180931806564331\n",
      "Loss at Iteration @ 7630 is 2.0593910217285156\n",
      "Evaluation Loss at Iteration @ 7630 is 2.272066593170166\n",
      "Loss at Iteration @ 7631 is 2.2396631240844727\n",
      "Evaluation Loss at Iteration @ 7631 is 2.259699583053589\n",
      "Loss at Iteration @ 7632 is 2.3241000175476074\n",
      "Evaluation Loss at Iteration @ 7632 is 2.3128693103790283\n",
      "Loss at Iteration @ 7633 is 2.2089500427246094\n",
      "Evaluation Loss at Iteration @ 7633 is 2.285430431365967\n",
      "Loss at Iteration @ 7634 is 2.0868639945983887\n",
      "Evaluation Loss at Iteration @ 7634 is 2.262101650238037\n",
      "Loss at Iteration @ 7635 is 2.4150242805480957\n",
      "Evaluation Loss at Iteration @ 7635 is 2.2570533752441406\n",
      "Loss at Iteration @ 7636 is 2.2570462226867676\n",
      "Evaluation Loss at Iteration @ 7636 is 2.1987149715423584\n",
      "Loss at Iteration @ 7637 is 2.242384910583496\n",
      "Evaluation Loss at Iteration @ 7637 is 2.269305944442749\n",
      "Loss at Iteration @ 7638 is 2.206684112548828\n",
      "Evaluation Loss at Iteration @ 7638 is 2.253614902496338\n",
      "Loss at Iteration @ 7639 is 2.2103219032287598\n",
      "Evaluation Loss at Iteration @ 7639 is 2.264726161956787\n",
      "Loss at Iteration @ 7640 is 2.337294101715088\n",
      "Evaluation Loss at Iteration @ 7640 is 2.223093032836914\n",
      "Loss at Iteration @ 7641 is 2.3479714393615723\n",
      "Evaluation Loss at Iteration @ 7641 is 2.2608797550201416\n",
      "Loss at Iteration @ 7642 is 2.295546531677246\n",
      "Evaluation Loss at Iteration @ 7642 is 2.290065050125122\n",
      "Loss at Iteration @ 7643 is 2.137688636779785\n",
      "Evaluation Loss at Iteration @ 7643 is 2.2551865577697754\n",
      "Loss at Iteration @ 7644 is 1.9932141304016113\n",
      "Evaluation Loss at Iteration @ 7644 is 2.2804336547851562\n",
      "Loss at Iteration @ 7645 is 2.0371692180633545\n",
      "Evaluation Loss at Iteration @ 7645 is 2.235318422317505\n",
      "Loss at Iteration @ 7646 is 2.1580255031585693\n",
      "Evaluation Loss at Iteration @ 7646 is 2.286205291748047\n",
      "Loss at Iteration @ 7647 is 2.1046676635742188\n",
      "Evaluation Loss at Iteration @ 7647 is 2.238905429840088\n",
      "Loss at Iteration @ 7648 is 2.2746269702911377\n",
      "Evaluation Loss at Iteration @ 7648 is 2.324115037918091\n",
      "Loss at Iteration @ 7649 is 2.0005390644073486\n",
      "Evaluation Loss at Iteration @ 7649 is 2.300276756286621\n",
      "Loss at Iteration @ 7650 is 2.230567216873169\n",
      "Evaluation Loss at Iteration @ 7650 is 2.275085210800171\n",
      "Loss at Iteration @ 7651 is 2.3433990478515625\n",
      "Evaluation Loss at Iteration @ 7651 is 2.290057420730591\n",
      "Loss at Iteration @ 7652 is 2.0493898391723633\n",
      "Evaluation Loss at Iteration @ 7652 is 2.225597381591797\n",
      "Loss at Iteration @ 7653 is 2.1929385662078857\n",
      "Evaluation Loss at Iteration @ 7653 is 2.256455183029175\n",
      "Loss at Iteration @ 7654 is 2.299827814102173\n",
      "Evaluation Loss at Iteration @ 7654 is 2.274435043334961\n",
      "Loss at Iteration @ 7655 is 2.175936698913574\n",
      "Evaluation Loss at Iteration @ 7655 is 2.229605197906494\n",
      "Loss at Iteration @ 7656 is 2.1550958156585693\n",
      "Evaluation Loss at Iteration @ 7656 is 2.2500128746032715\n",
      "Loss at Iteration @ 7657 is 2.21794056892395\n",
      "Evaluation Loss at Iteration @ 7657 is 2.2555930614471436\n",
      "Loss at Iteration @ 7658 is 2.3359975814819336\n",
      "Evaluation Loss at Iteration @ 7658 is 2.1976583003997803\n",
      "Loss at Iteration @ 7659 is 2.2745561599731445\n",
      "Evaluation Loss at Iteration @ 7659 is 2.267606735229492\n",
      "Loss at Iteration @ 7660 is 2.193542242050171\n",
      "Evaluation Loss at Iteration @ 7660 is 2.2264981269836426\n",
      "Loss at Iteration @ 7661 is 2.392056465148926\n",
      "Evaluation Loss at Iteration @ 7661 is 2.2340307235717773\n",
      "Loss at Iteration @ 7662 is 2.6896698474884033\n",
      "Evaluation Loss at Iteration @ 7662 is 2.248779058456421\n",
      "Loss at Iteration @ 7663 is 2.256194829940796\n",
      "Evaluation Loss at Iteration @ 7663 is 2.2328414916992188\n",
      "Loss at Iteration @ 7664 is 2.2066376209259033\n",
      "Evaluation Loss at Iteration @ 7664 is 2.218351364135742\n",
      "Loss at Iteration @ 7665 is 1.960793375968933\n",
      "Evaluation Loss at Iteration @ 7665 is 2.2865188121795654\n",
      "Loss at Iteration @ 7666 is 2.1353561878204346\n",
      "Evaluation Loss at Iteration @ 7666 is 2.2908453941345215\n",
      "Loss at Iteration @ 7667 is 2.1269378662109375\n",
      "Evaluation Loss at Iteration @ 7667 is 2.264570474624634\n",
      "Loss at Iteration @ 7668 is 2.2303009033203125\n",
      "Evaluation Loss at Iteration @ 7668 is 2.23244309425354\n",
      "Loss at Iteration @ 7669 is 2.117204427719116\n",
      "Evaluation Loss at Iteration @ 7669 is 2.232940673828125\n",
      "Loss at Iteration @ 7670 is 2.4422037601470947\n",
      "Evaluation Loss at Iteration @ 7670 is 2.23866868019104\n",
      "Loss at Iteration @ 7671 is 2.3045804500579834\n",
      "Evaluation Loss at Iteration @ 7671 is 2.2427520751953125\n",
      "Loss at Iteration @ 7672 is 2.5595648288726807\n",
      "Evaluation Loss at Iteration @ 7672 is 2.226395845413208\n",
      "Loss at Iteration @ 7673 is 1.9888235330581665\n",
      "Evaluation Loss at Iteration @ 7673 is 2.241384983062744\n",
      "Loss at Iteration @ 7674 is 1.9816598892211914\n",
      "Evaluation Loss at Iteration @ 7674 is 2.2644217014312744\n",
      "Loss at Iteration @ 7675 is 2.400456190109253\n",
      "Evaluation Loss at Iteration @ 7675 is 2.2416040897369385\n",
      "Loss at Iteration @ 7676 is 2.0363693237304688\n",
      "Evaluation Loss at Iteration @ 7676 is 2.2522881031036377\n",
      "Loss at Iteration @ 7677 is 2.2563958168029785\n",
      "Evaluation Loss at Iteration @ 7677 is 2.217446804046631\n",
      "Loss at Iteration @ 7678 is 1.9292690753936768\n",
      "Evaluation Loss at Iteration @ 7678 is 2.234844923019409\n",
      "Loss at Iteration @ 7679 is 2.2549586296081543\n",
      "Evaluation Loss at Iteration @ 7679 is 2.2214818000793457\n",
      "Loss at Iteration @ 7680 is 2.2502973079681396\n",
      "Evaluation Loss at Iteration @ 7680 is 2.2829067707061768\n",
      "Loss at Iteration @ 7681 is 2.2894654273986816\n",
      "Evaluation Loss at Iteration @ 7681 is 2.2694664001464844\n",
      "Loss at Iteration @ 7682 is 2.576941967010498\n",
      "Evaluation Loss at Iteration @ 7682 is 2.2676753997802734\n",
      "Loss at Iteration @ 7683 is 2.179025173187256\n",
      "Evaluation Loss at Iteration @ 7683 is 2.2406606674194336\n",
      "Loss at Iteration @ 7684 is 2.3498778343200684\n",
      "Evaluation Loss at Iteration @ 7684 is 2.2680583000183105\n",
      "Loss at Iteration @ 7685 is 2.369419813156128\n",
      "Evaluation Loss at Iteration @ 7685 is 2.202011823654175\n",
      "Loss at Iteration @ 7686 is 2.101173162460327\n",
      "Evaluation Loss at Iteration @ 7686 is 2.2247257232666016\n",
      "Loss at Iteration @ 7687 is 2.1822690963745117\n",
      "Evaluation Loss at Iteration @ 7687 is 2.244365930557251\n",
      "Loss at Iteration @ 7688 is 2.2927186489105225\n",
      "Evaluation Loss at Iteration @ 7688 is 2.2597594261169434\n",
      "Loss at Iteration @ 7689 is 2.2421727180480957\n",
      "Evaluation Loss at Iteration @ 7689 is 2.224714994430542\n",
      "Loss at Iteration @ 7690 is 2.178403377532959\n",
      "Evaluation Loss at Iteration @ 7690 is 2.2709853649139404\n",
      "Loss at Iteration @ 7691 is 2.2958526611328125\n",
      "Evaluation Loss at Iteration @ 7691 is 2.198845148086548\n",
      "Loss at Iteration @ 7692 is 2.3440802097320557\n",
      "Evaluation Loss at Iteration @ 7692 is 2.2291622161865234\n",
      "Loss at Iteration @ 7693 is 2.299837589263916\n",
      "Evaluation Loss at Iteration @ 7693 is 2.226126194000244\n",
      "Loss at Iteration @ 7694 is 2.4166879653930664\n",
      "Evaluation Loss at Iteration @ 7694 is 2.274292230606079\n",
      "Loss at Iteration @ 7695 is 1.9793612957000732\n",
      "Evaluation Loss at Iteration @ 7695 is 2.2619073390960693\n",
      "Loss at Iteration @ 7696 is 2.1725833415985107\n",
      "Evaluation Loss at Iteration @ 7696 is 2.276883840560913\n",
      "Loss at Iteration @ 7697 is 2.146928548812866\n",
      "Evaluation Loss at Iteration @ 7697 is 2.2883968353271484\n",
      "Loss at Iteration @ 7698 is 2.5940849781036377\n",
      "Evaluation Loss at Iteration @ 7698 is 2.3064656257629395\n",
      "Loss at Iteration @ 7699 is 2.1082372665405273\n",
      "Evaluation Loss at Iteration @ 7699 is 2.246786117553711\n",
      "Loss at Iteration @ 7700 is 2.160017967224121\n",
      "Evaluation Loss at Iteration @ 7700 is 2.269852876663208\n",
      "Loss at Iteration @ 7701 is 2.191114902496338\n",
      "Evaluation Loss at Iteration @ 7701 is 2.232170820236206\n",
      "Loss at Iteration @ 7702 is 2.1072425842285156\n",
      "Evaluation Loss at Iteration @ 7702 is 2.2870078086853027\n",
      "Loss at Iteration @ 7703 is 1.8940393924713135\n",
      "Evaluation Loss at Iteration @ 7703 is 2.2750065326690674\n",
      "Loss at Iteration @ 7704 is 2.3285000324249268\n",
      "Evaluation Loss at Iteration @ 7704 is 2.2614386081695557\n",
      "Loss at Iteration @ 7705 is 2.1905128955841064\n",
      "Evaluation Loss at Iteration @ 7705 is 2.270798444747925\n",
      "Loss at Iteration @ 7706 is 2.1580400466918945\n",
      "Evaluation Loss at Iteration @ 7706 is 2.2776198387145996\n",
      "Loss at Iteration @ 7707 is 2.062800407409668\n",
      "Evaluation Loss at Iteration @ 7707 is 2.2772586345672607\n",
      "Loss at Iteration @ 7708 is 2.196202516555786\n",
      "Evaluation Loss at Iteration @ 7708 is 2.213965654373169\n",
      "Loss at Iteration @ 7709 is 2.438938617706299\n",
      "Evaluation Loss at Iteration @ 7709 is 2.2522659301757812\n",
      "Loss at Iteration @ 7710 is 2.238895893096924\n",
      "Evaluation Loss at Iteration @ 7710 is 2.2426838874816895\n",
      "Loss at Iteration @ 7711 is 2.3407092094421387\n",
      "Evaluation Loss at Iteration @ 7711 is 2.247055768966675\n",
      "Loss at Iteration @ 7712 is 2.505950689315796\n",
      "Evaluation Loss at Iteration @ 7712 is 2.243187427520752\n",
      "Loss at Iteration @ 7713 is 2.0680251121520996\n",
      "Evaluation Loss at Iteration @ 7713 is 2.274209976196289\n",
      "Loss at Iteration @ 7714 is 2.1393983364105225\n",
      "Evaluation Loss at Iteration @ 7714 is 2.2586042881011963\n",
      "Loss at Iteration @ 7715 is 2.026926279067993\n",
      "Evaluation Loss at Iteration @ 7715 is 2.2491118907928467\n",
      "Loss at Iteration @ 7716 is 2.2841951847076416\n",
      "Evaluation Loss at Iteration @ 7716 is 2.220115900039673\n",
      "Loss at Iteration @ 7717 is 2.478611946105957\n",
      "Evaluation Loss at Iteration @ 7717 is 2.25164794921875\n",
      "Loss at Iteration @ 7718 is 2.116272211074829\n",
      "Evaluation Loss at Iteration @ 7718 is 2.245389223098755\n",
      "Loss at Iteration @ 7719 is 2.223637342453003\n",
      "Evaluation Loss at Iteration @ 7719 is 2.1901261806488037\n",
      "Loss at Iteration @ 7720 is 2.186521530151367\n",
      "Evaluation Loss at Iteration @ 7720 is 2.2152326107025146\n",
      "Loss at Iteration @ 7721 is 2.2505991458892822\n",
      "Evaluation Loss at Iteration @ 7721 is 2.2082102298736572\n",
      "Loss at Iteration @ 7722 is 2.139681577682495\n",
      "Evaluation Loss at Iteration @ 7722 is 2.2222559452056885\n",
      "Loss at Iteration @ 7723 is 2.3729846477508545\n",
      "Evaluation Loss at Iteration @ 7723 is 2.294501304626465\n",
      "Loss at Iteration @ 7724 is 2.2890915870666504\n",
      "Evaluation Loss at Iteration @ 7724 is 2.2598650455474854\n",
      "Loss at Iteration @ 7725 is 2.256829023361206\n",
      "Evaluation Loss at Iteration @ 7725 is 2.2358107566833496\n",
      "Loss at Iteration @ 7726 is 2.43253755569458\n",
      "Evaluation Loss at Iteration @ 7726 is 2.248663902282715\n",
      "Loss at Iteration @ 7727 is 2.012390375137329\n",
      "Evaluation Loss at Iteration @ 7727 is 2.2850911617279053\n",
      "Loss at Iteration @ 7728 is 2.2831783294677734\n",
      "Evaluation Loss at Iteration @ 7728 is 2.2860007286071777\n",
      "Loss at Iteration @ 7729 is 2.140517473220825\n",
      "Evaluation Loss at Iteration @ 7729 is 2.243197441101074\n",
      "Loss at Iteration @ 7730 is 2.3079042434692383\n",
      "Evaluation Loss at Iteration @ 7730 is 2.255335807800293\n",
      "Loss at Iteration @ 7731 is 2.2041573524475098\n",
      "Evaluation Loss at Iteration @ 7731 is 2.2705793380737305\n",
      "Loss at Iteration @ 7732 is 1.991265892982483\n",
      "Evaluation Loss at Iteration @ 7732 is 2.2693405151367188\n",
      "Loss at Iteration @ 7733 is 2.112741231918335\n",
      "Evaluation Loss at Iteration @ 7733 is 2.2765376567840576\n",
      "Loss at Iteration @ 7734 is 2.238165855407715\n",
      "Evaluation Loss at Iteration @ 7734 is 2.2343757152557373\n",
      "Loss at Iteration @ 7735 is 2.3919458389282227\n",
      "Evaluation Loss at Iteration @ 7735 is 2.2082040309906006\n",
      "Loss at Iteration @ 7736 is 2.0182552337646484\n",
      "Evaluation Loss at Iteration @ 7736 is 2.2107553482055664\n",
      "Loss at Iteration @ 7737 is 1.9967726469039917\n",
      "Evaluation Loss at Iteration @ 7737 is 2.257333755493164\n",
      "Loss at Iteration @ 7738 is 2.3785319328308105\n",
      "Evaluation Loss at Iteration @ 7738 is 2.2623181343078613\n",
      "Loss at Iteration @ 7739 is 2.3292887210845947\n",
      "Evaluation Loss at Iteration @ 7739 is 2.2632980346679688\n",
      "Loss at Iteration @ 7740 is 2.2823410034179688\n",
      "Evaluation Loss at Iteration @ 7740 is 2.2538022994995117\n",
      "Loss at Iteration @ 7741 is 2.1997153759002686\n",
      "Evaluation Loss at Iteration @ 7741 is 2.2520124912261963\n",
      "Loss at Iteration @ 7742 is 2.1261181831359863\n",
      "Evaluation Loss at Iteration @ 7742 is 2.2458677291870117\n",
      "Loss at Iteration @ 7743 is 2.1611478328704834\n",
      "Evaluation Loss at Iteration @ 7743 is 2.2149670124053955\n",
      "Loss at Iteration @ 7744 is 2.218614339828491\n",
      "Evaluation Loss at Iteration @ 7744 is 2.2629733085632324\n",
      "Loss at Iteration @ 7745 is 2.369591236114502\n",
      "Evaluation Loss at Iteration @ 7745 is 2.1805858612060547\n",
      "Loss at Iteration @ 7746 is 2.2793519496917725\n",
      "Evaluation Loss at Iteration @ 7746 is 2.255324363708496\n",
      "Loss at Iteration @ 7747 is 2.1402268409729004\n",
      "Evaluation Loss at Iteration @ 7747 is 2.228444814682007\n",
      "Loss at Iteration @ 7748 is 2.011406898498535\n",
      "Evaluation Loss at Iteration @ 7748 is 2.2558603286743164\n",
      "Loss at Iteration @ 7749 is 2.0807201862335205\n",
      "Evaluation Loss at Iteration @ 7749 is 2.2011122703552246\n",
      "Loss at Iteration @ 7750 is 2.425006866455078\n",
      "Evaluation Loss at Iteration @ 7750 is 2.239077568054199\n",
      "Loss at Iteration @ 7751 is 2.2293894290924072\n",
      "Evaluation Loss at Iteration @ 7751 is 2.243251323699951\n",
      "Loss at Iteration @ 7752 is 2.0426435470581055\n",
      "Evaluation Loss at Iteration @ 7752 is 2.2384111881256104\n",
      "Loss at Iteration @ 7753 is 2.0138251781463623\n",
      "Evaluation Loss at Iteration @ 7753 is 2.2184910774230957\n",
      "Loss at Iteration @ 7754 is 2.0580077171325684\n",
      "Evaluation Loss at Iteration @ 7754 is 2.236255168914795\n",
      "Loss at Iteration @ 7755 is 2.371264934539795\n",
      "Evaluation Loss at Iteration @ 7755 is 2.246090888977051\n",
      "Loss at Iteration @ 7756 is 2.28580641746521\n",
      "Evaluation Loss at Iteration @ 7756 is 2.2733209133148193\n",
      "Loss at Iteration @ 7757 is 2.214142322540283\n",
      "Evaluation Loss at Iteration @ 7757 is 2.298760414123535\n",
      "Loss at Iteration @ 7758 is 2.2815334796905518\n",
      "Evaluation Loss at Iteration @ 7758 is 2.2366435527801514\n",
      "Loss at Iteration @ 7759 is 2.324983596801758\n",
      "Evaluation Loss at Iteration @ 7759 is 2.276583433151245\n",
      "Loss at Iteration @ 7760 is 2.2764296531677246\n",
      "Evaluation Loss at Iteration @ 7760 is 2.2211339473724365\n",
      "Loss at Iteration @ 7761 is 2.0924460887908936\n",
      "Evaluation Loss at Iteration @ 7761 is 2.2223880290985107\n",
      "Loss at Iteration @ 7762 is 2.1110568046569824\n",
      "Evaluation Loss at Iteration @ 7762 is 2.2420148849487305\n",
      "Loss at Iteration @ 7763 is 2.369133949279785\n",
      "Evaluation Loss at Iteration @ 7763 is 2.2247748374938965\n",
      "Loss at Iteration @ 7764 is 2.275851249694824\n",
      "Evaluation Loss at Iteration @ 7764 is 2.2228217124938965\n",
      "Loss at Iteration @ 7765 is 2.2461602687835693\n",
      "Evaluation Loss at Iteration @ 7765 is 2.2748095989227295\n",
      "Loss at Iteration @ 7766 is 2.2542200088500977\n",
      "Evaluation Loss at Iteration @ 7766 is 2.2228024005889893\n",
      "Loss at Iteration @ 7767 is 2.1529853343963623\n",
      "Evaluation Loss at Iteration @ 7767 is 2.251000165939331\n",
      "Loss at Iteration @ 7768 is 2.6510138511657715\n",
      "Evaluation Loss at Iteration @ 7768 is 2.2494611740112305\n",
      "Loss at Iteration @ 7769 is 2.241227149963379\n",
      "Evaluation Loss at Iteration @ 7769 is 2.231688976287842\n",
      "Loss at Iteration @ 7770 is 2.5771656036376953\n",
      "Evaluation Loss at Iteration @ 7770 is 2.250380277633667\n",
      "Loss at Iteration @ 7771 is 2.2936675548553467\n",
      "Evaluation Loss at Iteration @ 7771 is 2.2820589542388916\n",
      "Loss at Iteration @ 7772 is 2.238752603530884\n",
      "Evaluation Loss at Iteration @ 7772 is 2.258190631866455\n",
      "Loss at Iteration @ 7773 is 2.0013957023620605\n",
      "Evaluation Loss at Iteration @ 7773 is 2.2841763496398926\n",
      "Loss at Iteration @ 7774 is 2.375009536743164\n",
      "Evaluation Loss at Iteration @ 7774 is 2.281881093978882\n",
      "Loss at Iteration @ 7775 is 2.044020414352417\n",
      "Evaluation Loss at Iteration @ 7775 is 2.242417812347412\n",
      "Loss at Iteration @ 7776 is 2.2965452671051025\n",
      "Evaluation Loss at Iteration @ 7776 is 2.230736494064331\n",
      "Loss at Iteration @ 7777 is 2.1807503700256348\n",
      "Evaluation Loss at Iteration @ 7777 is 2.2963433265686035\n",
      "Loss at Iteration @ 7778 is 2.3460853099823\n",
      "Evaluation Loss at Iteration @ 7778 is 2.2176756858825684\n",
      "Loss at Iteration @ 7779 is 2.2053842544555664\n",
      "Evaluation Loss at Iteration @ 7779 is 2.260058641433716\n",
      "Loss at Iteration @ 7780 is 2.061978578567505\n",
      "Evaluation Loss at Iteration @ 7780 is 2.2687501907348633\n",
      "Loss at Iteration @ 7781 is 2.2142245769500732\n",
      "Evaluation Loss at Iteration @ 7781 is 2.2380008697509766\n",
      "Loss at Iteration @ 7782 is 2.193711757659912\n",
      "Evaluation Loss at Iteration @ 7782 is 2.283036470413208\n",
      "Loss at Iteration @ 7783 is 2.425415277481079\n",
      "Evaluation Loss at Iteration @ 7783 is 2.2664971351623535\n",
      "Loss at Iteration @ 7784 is 1.9276593923568726\n",
      "Evaluation Loss at Iteration @ 7784 is 2.2667179107666016\n",
      "Loss at Iteration @ 7785 is 2.2375686168670654\n",
      "Evaluation Loss at Iteration @ 7785 is 2.2515785694122314\n",
      "Loss at Iteration @ 7786 is 2.002652645111084\n",
      "Evaluation Loss at Iteration @ 7786 is 2.2406387329101562\n",
      "Loss at Iteration @ 7787 is 2.151771068572998\n",
      "Evaluation Loss at Iteration @ 7787 is 2.283022880554199\n",
      "Loss at Iteration @ 7788 is 2.40293025970459\n",
      "Evaluation Loss at Iteration @ 7788 is 2.2789418697357178\n",
      "Loss at Iteration @ 7789 is 2.735273599624634\n",
      "Evaluation Loss at Iteration @ 7789 is 2.268059253692627\n",
      "Loss at Iteration @ 7790 is 2.214116096496582\n",
      "Evaluation Loss at Iteration @ 7790 is 2.2281618118286133\n",
      "Loss at Iteration @ 7791 is 2.3145296573638916\n",
      "Evaluation Loss at Iteration @ 7791 is 2.2154595851898193\n",
      "Loss at Iteration @ 7792 is 2.270590305328369\n",
      "Evaluation Loss at Iteration @ 7792 is 2.262920379638672\n",
      "Loss at Iteration @ 7793 is 1.9970632791519165\n",
      "Evaluation Loss at Iteration @ 7793 is 2.3018360137939453\n",
      "Loss at Iteration @ 7794 is 2.4531118869781494\n",
      "Evaluation Loss at Iteration @ 7794 is 2.296069622039795\n",
      "Loss at Iteration @ 7795 is 2.1121950149536133\n",
      "Evaluation Loss at Iteration @ 7795 is 2.2597415447235107\n",
      "Loss at Iteration @ 7796 is 2.2629013061523438\n",
      "Evaluation Loss at Iteration @ 7796 is 2.2352406978607178\n",
      "Loss at Iteration @ 7797 is 2.652669668197632\n",
      "Evaluation Loss at Iteration @ 7797 is 2.257512331008911\n",
      "Loss at Iteration @ 7798 is 2.246403932571411\n",
      "Evaluation Loss at Iteration @ 7798 is 2.269157648086548\n",
      "Loss at Iteration @ 7799 is 2.4370639324188232\n",
      "Evaluation Loss at Iteration @ 7799 is 2.250774621963501\n",
      "Loss at Iteration @ 7800 is 2.0337395668029785\n",
      "Evaluation Loss at Iteration @ 7800 is 2.216524839401245\n",
      "Loss at Iteration @ 7801 is 2.061523675918579\n",
      "Evaluation Loss at Iteration @ 7801 is 2.192002773284912\n",
      "Loss at Iteration @ 7802 is 2.1281871795654297\n",
      "Evaluation Loss at Iteration @ 7802 is 2.2595221996307373\n",
      "Loss at Iteration @ 7803 is 2.1428141593933105\n",
      "Evaluation Loss at Iteration @ 7803 is 2.242279052734375\n",
      "Loss at Iteration @ 7804 is 2.235133171081543\n",
      "Evaluation Loss at Iteration @ 7804 is 2.225743293762207\n",
      "Loss at Iteration @ 7805 is 2.2689313888549805\n",
      "Evaluation Loss at Iteration @ 7805 is 2.2625505924224854\n",
      "Loss at Iteration @ 7806 is 2.46321177482605\n",
      "Evaluation Loss at Iteration @ 7806 is 2.2186977863311768\n",
      "Loss at Iteration @ 7807 is 2.1413021087646484\n",
      "Evaluation Loss at Iteration @ 7807 is 2.2968523502349854\n",
      "Loss at Iteration @ 7808 is 1.9762663841247559\n",
      "Evaluation Loss at Iteration @ 7808 is 2.2656633853912354\n",
      "Loss at Iteration @ 7809 is 2.2884767055511475\n",
      "Evaluation Loss at Iteration @ 7809 is 2.2434916496276855\n",
      "Loss at Iteration @ 7810 is 2.168537139892578\n",
      "Evaluation Loss at Iteration @ 7810 is 2.2434215545654297\n",
      "Loss at Iteration @ 7811 is 2.3370938301086426\n",
      "Evaluation Loss at Iteration @ 7811 is 2.2615699768066406\n",
      "Loss at Iteration @ 7812 is 2.1133296489715576\n",
      "Evaluation Loss at Iteration @ 7812 is 2.311246871948242\n",
      "Loss at Iteration @ 7813 is 2.2477948665618896\n",
      "Evaluation Loss at Iteration @ 7813 is 2.2076916694641113\n",
      "Loss at Iteration @ 7814 is 2.3758020401000977\n",
      "Evaluation Loss at Iteration @ 7814 is 2.2445590496063232\n",
      "Loss at Iteration @ 7815 is 2.450305938720703\n",
      "Evaluation Loss at Iteration @ 7815 is 2.2403481006622314\n",
      "Loss at Iteration @ 7816 is 2.2703490257263184\n",
      "Evaluation Loss at Iteration @ 7816 is 2.2681283950805664\n",
      "Loss at Iteration @ 7817 is 2.207036256790161\n",
      "Evaluation Loss at Iteration @ 7817 is 2.2546911239624023\n",
      "Loss at Iteration @ 7818 is 2.225956916809082\n",
      "Evaluation Loss at Iteration @ 7818 is 2.2602481842041016\n",
      "Loss at Iteration @ 7819 is 2.076608896255493\n",
      "Evaluation Loss at Iteration @ 7819 is 2.297138214111328\n",
      "Loss at Iteration @ 7820 is 2.366020679473877\n",
      "Evaluation Loss at Iteration @ 7820 is 2.3468575477600098\n",
      "Loss at Iteration @ 7821 is 2.709944009780884\n",
      "Evaluation Loss at Iteration @ 7821 is 2.2302138805389404\n",
      "Loss at Iteration @ 7822 is 2.396369457244873\n",
      "Evaluation Loss at Iteration @ 7822 is 2.2500617504119873\n",
      "Loss at Iteration @ 7823 is 2.507523775100708\n",
      "Evaluation Loss at Iteration @ 7823 is 2.2152621746063232\n",
      "Loss at Iteration @ 7824 is 2.1491148471832275\n",
      "Evaluation Loss at Iteration @ 7824 is 2.237900495529175\n",
      "Loss at Iteration @ 7825 is 2.2157742977142334\n",
      "Evaluation Loss at Iteration @ 7825 is 2.1999411582946777\n",
      "Loss at Iteration @ 7826 is 1.9881259202957153\n",
      "Evaluation Loss at Iteration @ 7826 is 2.2797746658325195\n",
      "Loss at Iteration @ 7827 is 2.151625394821167\n",
      "Evaluation Loss at Iteration @ 7827 is 2.232428550720215\n",
      "Loss at Iteration @ 7828 is 2.32562255859375\n",
      "Evaluation Loss at Iteration @ 7828 is 2.270371675491333\n",
      "Loss at Iteration @ 7829 is 1.9935334920883179\n",
      "Evaluation Loss at Iteration @ 7829 is 2.2689833641052246\n",
      "Loss at Iteration @ 7830 is 2.3266520500183105\n",
      "Evaluation Loss at Iteration @ 7830 is 2.287292718887329\n",
      "Loss at Iteration @ 7831 is 2.078491449356079\n",
      "Evaluation Loss at Iteration @ 7831 is 2.247657060623169\n",
      "Loss at Iteration @ 7832 is 1.893836259841919\n",
      "Evaluation Loss at Iteration @ 7832 is 2.2240653038024902\n",
      "Loss at Iteration @ 7833 is 2.3279638290405273\n",
      "Evaluation Loss at Iteration @ 7833 is 2.2877938747406006\n",
      "Loss at Iteration @ 7834 is 2.3789174556732178\n",
      "Evaluation Loss at Iteration @ 7834 is 2.2518231868743896\n",
      "Loss at Iteration @ 7835 is 2.479356288909912\n",
      "Evaluation Loss at Iteration @ 7835 is 2.247330904006958\n",
      "Loss at Iteration @ 7836 is 2.2978179454803467\n",
      "Evaluation Loss at Iteration @ 7836 is 2.2616209983825684\n",
      "Loss at Iteration @ 7837 is 2.4863839149475098\n",
      "Evaluation Loss at Iteration @ 7837 is 2.213388442993164\n",
      "Loss at Iteration @ 7838 is 2.4586403369903564\n",
      "Evaluation Loss at Iteration @ 7838 is 2.2603063583374023\n",
      "Loss at Iteration @ 7839 is 2.1548328399658203\n",
      "Evaluation Loss at Iteration @ 7839 is 2.263202667236328\n",
      "Loss at Iteration @ 7840 is 2.10282039642334\n",
      "Evaluation Loss at Iteration @ 7840 is 2.2957968711853027\n",
      "Loss at Iteration @ 7841 is 2.035313367843628\n",
      "Evaluation Loss at Iteration @ 7841 is 2.294323205947876\n",
      "Loss at Iteration @ 7842 is 2.047689199447632\n",
      "Evaluation Loss at Iteration @ 7842 is 2.2320685386657715\n",
      "Loss at Iteration @ 7843 is 2.2077178955078125\n",
      "Evaluation Loss at Iteration @ 7843 is 2.234302043914795\n",
      "Loss at Iteration @ 7844 is 2.351346492767334\n",
      "Evaluation Loss at Iteration @ 7844 is 2.2511842250823975\n",
      "Loss at Iteration @ 7845 is 2.252920389175415\n",
      "Evaluation Loss at Iteration @ 7845 is 2.307313919067383\n",
      "Loss at Iteration @ 7846 is 2.5079238414764404\n",
      "Evaluation Loss at Iteration @ 7846 is 2.250497579574585\n",
      "Loss at Iteration @ 7847 is 1.992746114730835\n",
      "Evaluation Loss at Iteration @ 7847 is 2.2756073474884033\n",
      "Loss at Iteration @ 7848 is 2.0199368000030518\n",
      "Evaluation Loss at Iteration @ 7848 is 2.253117561340332\n",
      "Loss at Iteration @ 7849 is 2.016784906387329\n",
      "Evaluation Loss at Iteration @ 7849 is 2.257251739501953\n",
      "Loss at Iteration @ 7850 is 2.654710531234741\n",
      "Evaluation Loss at Iteration @ 7850 is 2.218846082687378\n",
      "Loss at Iteration @ 7851 is 2.045053720474243\n",
      "Evaluation Loss at Iteration @ 7851 is 2.213447093963623\n",
      "Loss at Iteration @ 7852 is 1.9341650009155273\n",
      "Evaluation Loss at Iteration @ 7852 is 2.2341389656066895\n",
      "Loss at Iteration @ 7853 is 2.318890333175659\n",
      "Evaluation Loss at Iteration @ 7853 is 2.2115349769592285\n",
      "Loss at Iteration @ 7854 is 2.0700883865356445\n",
      "Evaluation Loss at Iteration @ 7854 is 2.255650758743286\n",
      "Loss at Iteration @ 7855 is 2.2009871006011963\n",
      "Evaluation Loss at Iteration @ 7855 is 2.281372308731079\n",
      "Loss at Iteration @ 7856 is 1.9307092428207397\n",
      "Evaluation Loss at Iteration @ 7856 is 2.2114593982696533\n",
      "Loss at Iteration @ 7857 is 2.349623680114746\n",
      "Evaluation Loss at Iteration @ 7857 is 2.258709192276001\n",
      "Loss at Iteration @ 7858 is 2.283761501312256\n",
      "Evaluation Loss at Iteration @ 7858 is 2.248279571533203\n",
      "Loss at Iteration @ 7859 is 1.845214605331421\n",
      "Evaluation Loss at Iteration @ 7859 is 2.2740304470062256\n",
      "Loss at Iteration @ 7860 is 2.3897881507873535\n",
      "Evaluation Loss at Iteration @ 7860 is 2.220400094985962\n",
      "Loss at Iteration @ 7861 is 2.2411017417907715\n",
      "Evaluation Loss at Iteration @ 7861 is 2.2857704162597656\n",
      "Loss at Iteration @ 7862 is 2.106027364730835\n",
      "Evaluation Loss at Iteration @ 7862 is 2.2061562538146973\n",
      "Loss at Iteration @ 7863 is 2.247624635696411\n",
      "Evaluation Loss at Iteration @ 7863 is 2.23278546333313\n",
      "Loss at Iteration @ 7864 is 2.098426580429077\n",
      "Evaluation Loss at Iteration @ 7864 is 2.2504003047943115\n",
      "Loss at Iteration @ 7865 is 2.2256438732147217\n",
      "Evaluation Loss at Iteration @ 7865 is 2.24678111076355\n",
      "Loss at Iteration @ 7866 is 2.268321990966797\n",
      "Evaluation Loss at Iteration @ 7866 is 2.2594285011291504\n",
      "Loss at Iteration @ 7867 is 2.119713068008423\n",
      "Evaluation Loss at Iteration @ 7867 is 2.212635040283203\n",
      "Loss at Iteration @ 7868 is 2.210383653640747\n",
      "Evaluation Loss at Iteration @ 7868 is 2.2769455909729004\n",
      "Loss at Iteration @ 7869 is 2.5334079265594482\n",
      "Evaluation Loss at Iteration @ 7869 is 2.2093231678009033\n",
      "Loss at Iteration @ 7870 is 2.181692361831665\n",
      "Evaluation Loss at Iteration @ 7870 is 2.241098403930664\n",
      "Loss at Iteration @ 7871 is 2.2666921615600586\n",
      "Evaluation Loss at Iteration @ 7871 is 2.243647575378418\n",
      "Loss at Iteration @ 7872 is 2.344006061553955\n",
      "Evaluation Loss at Iteration @ 7872 is 2.268605947494507\n",
      "Loss at Iteration @ 7873 is 1.9318591356277466\n",
      "Evaluation Loss at Iteration @ 7873 is 2.2110812664031982\n",
      "Loss at Iteration @ 7874 is 2.331925392150879\n",
      "Evaluation Loss at Iteration @ 7874 is 2.3120977878570557\n",
      "Loss at Iteration @ 7875 is 2.4176673889160156\n",
      "Evaluation Loss at Iteration @ 7875 is 2.233161449432373\n",
      "Loss at Iteration @ 7876 is 2.3236188888549805\n",
      "Evaluation Loss at Iteration @ 7876 is 2.2459402084350586\n",
      "Loss at Iteration @ 7877 is 2.0441980361938477\n",
      "Evaluation Loss at Iteration @ 7877 is 2.269340991973877\n",
      "Loss at Iteration @ 7878 is 2.362691879272461\n",
      "Evaluation Loss at Iteration @ 7878 is 2.2354013919830322\n",
      "Loss at Iteration @ 7879 is 2.467475414276123\n",
      "Evaluation Loss at Iteration @ 7879 is 2.2330877780914307\n",
      "Loss at Iteration @ 7880 is 2.1322178840637207\n",
      "Evaluation Loss at Iteration @ 7880 is 2.2175605297088623\n",
      "Loss at Iteration @ 7881 is 2.020648717880249\n",
      "Evaluation Loss at Iteration @ 7881 is 2.274714469909668\n",
      "Loss at Iteration @ 7882 is 2.1398792266845703\n",
      "Evaluation Loss at Iteration @ 7882 is 2.249267101287842\n",
      "Loss at Iteration @ 7883 is 2.1697123050689697\n",
      "Evaluation Loss at Iteration @ 7883 is 2.240248918533325\n",
      "Loss at Iteration @ 7884 is 2.4065065383911133\n",
      "Evaluation Loss at Iteration @ 7884 is 2.29887056350708\n",
      "Loss at Iteration @ 7885 is 2.0201265811920166\n",
      "Evaluation Loss at Iteration @ 7885 is 2.2600226402282715\n",
      "Loss at Iteration @ 7886 is 2.269172430038452\n",
      "Evaluation Loss at Iteration @ 7886 is 2.2673418521881104\n",
      "Loss at Iteration @ 7887 is 2.66396164894104\n",
      "Evaluation Loss at Iteration @ 7887 is 2.325162410736084\n",
      "Loss at Iteration @ 7888 is 2.2316172122955322\n",
      "Evaluation Loss at Iteration @ 7888 is 2.218468189239502\n",
      "Loss at Iteration @ 7889 is 2.6855969429016113\n",
      "Evaluation Loss at Iteration @ 7889 is 2.268770217895508\n",
      "Loss at Iteration @ 7890 is 2.4461090564727783\n",
      "Evaluation Loss at Iteration @ 7890 is 2.2421059608459473\n",
      "Loss at Iteration @ 7891 is 2.400141477584839\n",
      "Evaluation Loss at Iteration @ 7891 is 2.2208964824676514\n",
      "Loss at Iteration @ 7892 is 2.316331386566162\n",
      "Evaluation Loss at Iteration @ 7892 is 2.2192230224609375\n",
      "Loss at Iteration @ 7893 is 2.2274274826049805\n",
      "Evaluation Loss at Iteration @ 7893 is 2.2441353797912598\n",
      "Loss at Iteration @ 7894 is 2.240910530090332\n",
      "Evaluation Loss at Iteration @ 7894 is 2.258485794067383\n",
      "Loss at Iteration @ 7895 is 2.3125698566436768\n",
      "Evaluation Loss at Iteration @ 7895 is 2.2598633766174316\n",
      "Loss at Iteration @ 7896 is 1.957436442375183\n",
      "Evaluation Loss at Iteration @ 7896 is 2.263700485229492\n",
      "Loss at Iteration @ 7897 is 2.485590934753418\n",
      "Evaluation Loss at Iteration @ 7897 is 2.270718574523926\n",
      "Loss at Iteration @ 7898 is 1.8595590591430664\n",
      "Evaluation Loss at Iteration @ 7898 is 2.2220022678375244\n",
      "Loss at Iteration @ 7899 is 2.0239968299865723\n",
      "Evaluation Loss at Iteration @ 7899 is 2.2415740489959717\n",
      "Loss at Iteration @ 7900 is 2.3166491985321045\n",
      "Evaluation Loss at Iteration @ 7900 is 2.2511208057403564\n",
      "Loss at Iteration @ 7901 is 2.3868355751037598\n",
      "Evaluation Loss at Iteration @ 7901 is 2.289834976196289\n",
      "Loss at Iteration @ 7902 is 2.11808705329895\n",
      "Evaluation Loss at Iteration @ 7902 is 2.279961347579956\n",
      "Loss at Iteration @ 7903 is 2.124089479446411\n",
      "Evaluation Loss at Iteration @ 7903 is 2.2543575763702393\n",
      "Loss at Iteration @ 7904 is 2.2507803440093994\n",
      "Evaluation Loss at Iteration @ 7904 is 2.281337022781372\n",
      "Loss at Iteration @ 7905 is 2.353315591812134\n",
      "Evaluation Loss at Iteration @ 7905 is 2.2567436695098877\n",
      "Loss at Iteration @ 7906 is 2.2587730884552\n",
      "Evaluation Loss at Iteration @ 7906 is 2.2738571166992188\n",
      "Loss at Iteration @ 7907 is 2.025981903076172\n",
      "Evaluation Loss at Iteration @ 7907 is 2.1987226009368896\n",
      "Loss at Iteration @ 7908 is 2.0818469524383545\n",
      "Evaluation Loss at Iteration @ 7908 is 2.286435127258301\n",
      "Loss at Iteration @ 7909 is 2.216094732284546\n",
      "Evaluation Loss at Iteration @ 7909 is 2.223001480102539\n",
      "Loss at Iteration @ 7910 is 2.284895896911621\n",
      "Evaluation Loss at Iteration @ 7910 is 2.2867157459259033\n",
      "Loss at Iteration @ 7911 is 2.158482074737549\n",
      "Evaluation Loss at Iteration @ 7911 is 2.237767219543457\n",
      "Loss at Iteration @ 7912 is 2.231627941131592\n",
      "Evaluation Loss at Iteration @ 7912 is 2.306746006011963\n",
      "Loss at Iteration @ 7913 is 2.256669282913208\n",
      "Evaluation Loss at Iteration @ 7913 is 2.2060189247131348\n",
      "Loss at Iteration @ 7914 is 2.16040301322937\n",
      "Evaluation Loss at Iteration @ 7914 is 2.2934012413024902\n",
      "Loss at Iteration @ 7915 is 2.227614164352417\n",
      "Evaluation Loss at Iteration @ 7915 is 2.265906572341919\n",
      "Loss at Iteration @ 7916 is 2.3419957160949707\n",
      "Evaluation Loss at Iteration @ 7916 is 2.268512487411499\n",
      "Loss at Iteration @ 7917 is 2.2712466716766357\n",
      "Evaluation Loss at Iteration @ 7917 is 2.19746470451355\n",
      "Loss at Iteration @ 7918 is 2.3134164810180664\n",
      "Evaluation Loss at Iteration @ 7918 is 2.2504687309265137\n",
      "Loss at Iteration @ 7919 is 2.1883702278137207\n",
      "Evaluation Loss at Iteration @ 7919 is 2.266278028488159\n",
      "Loss at Iteration @ 7920 is 2.266653060913086\n",
      "Evaluation Loss at Iteration @ 7920 is 2.2783186435699463\n",
      "Loss at Iteration @ 7921 is 2.2912940979003906\n",
      "Evaluation Loss at Iteration @ 7921 is 2.23476243019104\n",
      "Loss at Iteration @ 7922 is 1.9257150888442993\n",
      "Evaluation Loss at Iteration @ 7922 is 2.236633062362671\n",
      "Loss at Iteration @ 7923 is 2.2578213214874268\n",
      "Evaluation Loss at Iteration @ 7923 is 2.2198526859283447\n",
      "Loss at Iteration @ 7924 is 1.8988215923309326\n",
      "Evaluation Loss at Iteration @ 7924 is 2.2287826538085938\n",
      "Loss at Iteration @ 7925 is 2.157013416290283\n",
      "Evaluation Loss at Iteration @ 7925 is 2.274993896484375\n",
      "Loss at Iteration @ 7926 is 2.3164689540863037\n",
      "Evaluation Loss at Iteration @ 7926 is 2.2592947483062744\n",
      "Loss at Iteration @ 7927 is 2.312192440032959\n",
      "Evaluation Loss at Iteration @ 7927 is 2.26911997795105\n",
      "Loss at Iteration @ 7928 is 2.156341314315796\n",
      "Evaluation Loss at Iteration @ 7928 is 2.2735180854797363\n",
      "Loss at Iteration @ 7929 is 2.372410297393799\n",
      "Evaluation Loss at Iteration @ 7929 is 2.251277446746826\n",
      "Loss at Iteration @ 7930 is 2.3044869899749756\n",
      "Evaluation Loss at Iteration @ 7930 is 2.2031302452087402\n",
      "Loss at Iteration @ 7931 is 2.2318639755249023\n",
      "Evaluation Loss at Iteration @ 7931 is 2.279423475265503\n",
      "Loss at Iteration @ 7932 is 2.0555951595306396\n",
      "Evaluation Loss at Iteration @ 7932 is 2.259835958480835\n",
      "Loss at Iteration @ 7933 is 2.304936647415161\n",
      "Evaluation Loss at Iteration @ 7933 is 2.2599594593048096\n",
      "Loss at Iteration @ 7934 is 2.066908121109009\n",
      "Evaluation Loss at Iteration @ 7934 is 2.27837872505188\n",
      "Loss at Iteration @ 7935 is 2.183212995529175\n",
      "Evaluation Loss at Iteration @ 7935 is 2.2560338973999023\n",
      "Loss at Iteration @ 7936 is 2.2494583129882812\n",
      "Evaluation Loss at Iteration @ 7936 is 2.2619190216064453\n",
      "Loss at Iteration @ 7937 is 2.136361837387085\n",
      "Evaluation Loss at Iteration @ 7937 is 2.256375312805176\n",
      "Loss at Iteration @ 7938 is 2.5108578205108643\n",
      "Evaluation Loss at Iteration @ 7938 is 2.2689459323883057\n",
      "Loss at Iteration @ 7939 is 2.081156015396118\n",
      "Evaluation Loss at Iteration @ 7939 is 2.242680072784424\n",
      "Loss at Iteration @ 7940 is 2.175851583480835\n",
      "Evaluation Loss at Iteration @ 7940 is 2.2242772579193115\n",
      "Loss at Iteration @ 7941 is 2.1143102645874023\n",
      "Evaluation Loss at Iteration @ 7941 is 2.284780502319336\n",
      "Loss at Iteration @ 7942 is 2.4431352615356445\n",
      "Evaluation Loss at Iteration @ 7942 is 2.30728816986084\n",
      "Loss at Iteration @ 7943 is 2.148587703704834\n",
      "Evaluation Loss at Iteration @ 7943 is 2.2470908164978027\n",
      "Loss at Iteration @ 7944 is 2.2245473861694336\n",
      "Evaluation Loss at Iteration @ 7944 is 2.299922466278076\n",
      "Loss at Iteration @ 7945 is 2.1843700408935547\n",
      "Evaluation Loss at Iteration @ 7945 is 2.286489963531494\n",
      "Loss at Iteration @ 7946 is 2.191143274307251\n",
      "Evaluation Loss at Iteration @ 7946 is 2.24349308013916\n",
      "Loss at Iteration @ 7947 is 2.1487011909484863\n",
      "Evaluation Loss at Iteration @ 7947 is 2.2174651622772217\n",
      "Loss at Iteration @ 7948 is 2.257772445678711\n",
      "Evaluation Loss at Iteration @ 7948 is 2.257680654525757\n",
      "Loss at Iteration @ 7949 is 2.2488842010498047\n",
      "Evaluation Loss at Iteration @ 7949 is 2.273169994354248\n",
      "Loss at Iteration @ 7950 is 2.2968101501464844\n",
      "Evaluation Loss at Iteration @ 7950 is 2.288658380508423\n",
      "Loss at Iteration @ 7951 is 2.0047826766967773\n",
      "Evaluation Loss at Iteration @ 7951 is 2.2530922889709473\n",
      "Loss at Iteration @ 7952 is 2.301920175552368\n",
      "Evaluation Loss at Iteration @ 7952 is 2.201925277709961\n",
      "Loss at Iteration @ 7953 is 2.316025733947754\n",
      "Evaluation Loss at Iteration @ 7953 is 2.1937735080718994\n",
      "Loss at Iteration @ 7954 is 2.2644762992858887\n",
      "Evaluation Loss at Iteration @ 7954 is 2.2686767578125\n",
      "Loss at Iteration @ 7955 is 2.4085397720336914\n",
      "Evaluation Loss at Iteration @ 7955 is 2.2848336696624756\n",
      "Loss at Iteration @ 7956 is 2.3343312740325928\n",
      "Evaluation Loss at Iteration @ 7956 is 2.2670512199401855\n",
      "Loss at Iteration @ 7957 is 2.3480567932128906\n",
      "Evaluation Loss at Iteration @ 7957 is 2.261073589324951\n",
      "Loss at Iteration @ 7958 is 1.921492099761963\n",
      "Evaluation Loss at Iteration @ 7958 is 2.227174997329712\n",
      "Loss at Iteration @ 7959 is 1.8857783079147339\n",
      "Evaluation Loss at Iteration @ 7959 is 2.2452752590179443\n",
      "Loss at Iteration @ 7960 is 2.045836925506592\n",
      "Evaluation Loss at Iteration @ 7960 is 2.2645647525787354\n",
      "Loss at Iteration @ 7961 is 2.1945278644561768\n",
      "Evaluation Loss at Iteration @ 7961 is 2.257805824279785\n",
      "Loss at Iteration @ 7962 is 2.251264810562134\n",
      "Evaluation Loss at Iteration @ 7962 is 2.247926712036133\n",
      "Loss at Iteration @ 7963 is 2.4179975986480713\n",
      "Evaluation Loss at Iteration @ 7963 is 2.232302188873291\n",
      "Loss at Iteration @ 7964 is 2.518934726715088\n",
      "Evaluation Loss at Iteration @ 7964 is 2.249326467514038\n",
      "Loss at Iteration @ 7965 is 2.057739734649658\n",
      "Evaluation Loss at Iteration @ 7965 is 2.2354393005371094\n",
      "Loss at Iteration @ 7966 is 2.466327428817749\n",
      "Evaluation Loss at Iteration @ 7966 is 2.2698891162872314\n",
      "Loss at Iteration @ 7967 is 2.507293701171875\n",
      "Evaluation Loss at Iteration @ 7967 is 2.2219722270965576\n",
      "Loss at Iteration @ 7968 is 2.212881326675415\n",
      "Evaluation Loss at Iteration @ 7968 is 2.2395541667938232\n",
      "Loss at Iteration @ 7969 is 2.7572176456451416\n",
      "Evaluation Loss at Iteration @ 7969 is 2.257004737854004\n",
      "Loss at Iteration @ 7970 is 2.340860605239868\n",
      "Evaluation Loss at Iteration @ 7970 is 2.277944326400757\n",
      "Loss at Iteration @ 7971 is 2.431161403656006\n",
      "Evaluation Loss at Iteration @ 7971 is 2.259958028793335\n",
      "Loss at Iteration @ 7972 is 2.184901714324951\n",
      "Evaluation Loss at Iteration @ 7972 is 2.2611682415008545\n",
      "Loss at Iteration @ 7973 is 2.4208385944366455\n",
      "Evaluation Loss at Iteration @ 7973 is 2.2700161933898926\n",
      "Loss at Iteration @ 7974 is 2.253819704055786\n",
      "Evaluation Loss at Iteration @ 7974 is 2.2434442043304443\n",
      "Loss at Iteration @ 7975 is 2.210461378097534\n",
      "Evaluation Loss at Iteration @ 7975 is 2.233307123184204\n",
      "Loss at Iteration @ 7976 is 2.201381206512451\n",
      "Evaluation Loss at Iteration @ 7976 is 2.2125401496887207\n",
      "Loss at Iteration @ 7977 is 2.47115421295166\n",
      "Evaluation Loss at Iteration @ 7977 is 2.2707111835479736\n",
      "Loss at Iteration @ 7978 is 2.4888453483581543\n",
      "Evaluation Loss at Iteration @ 7978 is 2.239784002304077\n",
      "Loss at Iteration @ 7979 is 2.165921211242676\n",
      "Evaluation Loss at Iteration @ 7979 is 2.291673183441162\n",
      "Loss at Iteration @ 7980 is 2.1312170028686523\n",
      "Evaluation Loss at Iteration @ 7980 is 2.2671213150024414\n",
      "Loss at Iteration @ 7981 is 2.238077402114868\n",
      "Evaluation Loss at Iteration @ 7981 is 2.253138542175293\n",
      "Loss at Iteration @ 7982 is 2.601416826248169\n",
      "Evaluation Loss at Iteration @ 7982 is 2.2942068576812744\n",
      "Loss at Iteration @ 7983 is 2.33671498298645\n",
      "Evaluation Loss at Iteration @ 7983 is 2.2611100673675537\n",
      "Loss at Iteration @ 7984 is 2.2322704792022705\n",
      "Evaluation Loss at Iteration @ 7984 is 2.2250304222106934\n",
      "Loss at Iteration @ 7985 is 2.171138048171997\n",
      "Evaluation Loss at Iteration @ 7985 is 2.2408978939056396\n",
      "Loss at Iteration @ 7986 is 2.3163912296295166\n",
      "Evaluation Loss at Iteration @ 7986 is 2.259024143218994\n",
      "Loss at Iteration @ 7987 is 2.3605759143829346\n",
      "Evaluation Loss at Iteration @ 7987 is 2.2571494579315186\n",
      "Loss at Iteration @ 7988 is 2.0060014724731445\n",
      "Evaluation Loss at Iteration @ 7988 is 2.2194011211395264\n",
      "Loss at Iteration @ 7989 is 2.2579972743988037\n",
      "Evaluation Loss at Iteration @ 7989 is 2.2672948837280273\n",
      "Loss at Iteration @ 7990 is 2.2407402992248535\n",
      "Evaluation Loss at Iteration @ 7990 is 2.2356863021850586\n",
      "Loss at Iteration @ 7991 is 2.1566200256347656\n",
      "Evaluation Loss at Iteration @ 7991 is 2.2797746658325195\n",
      "Loss at Iteration @ 7992 is 2.255690574645996\n",
      "Evaluation Loss at Iteration @ 7992 is 2.289292097091675\n",
      "Loss at Iteration @ 7993 is 2.032827138900757\n",
      "Evaluation Loss at Iteration @ 7993 is 2.212932586669922\n",
      "Loss at Iteration @ 7994 is 1.9493250846862793\n",
      "Evaluation Loss at Iteration @ 7994 is 2.240509033203125\n",
      "Loss at Iteration @ 7995 is 2.1750383377075195\n",
      "Evaluation Loss at Iteration @ 7995 is 2.2279679775238037\n",
      "Loss at Iteration @ 7996 is 2.1656334400177\n",
      "Evaluation Loss at Iteration @ 7996 is 2.2597150802612305\n",
      "Loss at Iteration @ 7997 is 2.1675262451171875\n",
      "Evaluation Loss at Iteration @ 7997 is 2.2891337871551514\n",
      "Loss at Iteration @ 7998 is 2.20304274559021\n",
      "Evaluation Loss at Iteration @ 7998 is 2.260728359222412\n",
      "Loss at Iteration @ 7999 is 2.1462693214416504\n",
      "Evaluation Loss at Iteration @ 7999 is 2.254866123199463\n",
      "Loss at Iteration @ 8000 is 2.0718531608581543\n",
      "Evaluation Loss at Iteration @ 8000 is 2.2344744205474854\n",
      "Loss at Iteration @ 8001 is 2.2033743858337402\n",
      "Evaluation Loss at Iteration @ 8001 is 2.235557794570923\n",
      "Loss at Iteration @ 8002 is 2.1955084800720215\n",
      "Evaluation Loss at Iteration @ 8002 is 2.2252607345581055\n",
      "Loss at Iteration @ 8003 is 2.374176502227783\n",
      "Evaluation Loss at Iteration @ 8003 is 2.278658628463745\n",
      "Loss at Iteration @ 8004 is 2.204709768295288\n",
      "Evaluation Loss at Iteration @ 8004 is 2.271754503250122\n",
      "Loss at Iteration @ 8005 is 2.217209815979004\n",
      "Evaluation Loss at Iteration @ 8005 is 2.2738516330718994\n",
      "Loss at Iteration @ 8006 is 2.191551685333252\n",
      "Evaluation Loss at Iteration @ 8006 is 2.3058862686157227\n",
      "Loss at Iteration @ 8007 is 2.432678461074829\n",
      "Evaluation Loss at Iteration @ 8007 is 2.255703926086426\n",
      "Loss at Iteration @ 8008 is 2.116307020187378\n",
      "Evaluation Loss at Iteration @ 8008 is 2.2756099700927734\n",
      "Loss at Iteration @ 8009 is 2.146587610244751\n",
      "Evaluation Loss at Iteration @ 8009 is 2.2492713928222656\n",
      "Loss at Iteration @ 8010 is 1.9393067359924316\n",
      "Evaluation Loss at Iteration @ 8010 is 2.2041103839874268\n",
      "Loss at Iteration @ 8011 is 2.170118570327759\n",
      "Evaluation Loss at Iteration @ 8011 is 2.2224018573760986\n",
      "Loss at Iteration @ 8012 is 2.2877962589263916\n",
      "Evaluation Loss at Iteration @ 8012 is 2.288965940475464\n",
      "Loss at Iteration @ 8013 is 1.9766616821289062\n",
      "Evaluation Loss at Iteration @ 8013 is 2.228114604949951\n",
      "Loss at Iteration @ 8014 is 2.294454336166382\n",
      "Evaluation Loss at Iteration @ 8014 is 2.283602476119995\n",
      "Loss at Iteration @ 8015 is 2.2943716049194336\n",
      "Evaluation Loss at Iteration @ 8015 is 2.176896095275879\n",
      "Loss at Iteration @ 8016 is 2.0974011421203613\n",
      "Evaluation Loss at Iteration @ 8016 is 2.273482084274292\n",
      "Loss at Iteration @ 8017 is 2.1798038482666016\n",
      "Evaluation Loss at Iteration @ 8017 is 2.2430899143218994\n",
      "Loss at Iteration @ 8018 is 2.1490330696105957\n",
      "Evaluation Loss at Iteration @ 8018 is 2.272005081176758\n",
      "Loss at Iteration @ 8019 is 2.343883991241455\n",
      "Evaluation Loss at Iteration @ 8019 is 2.2452516555786133\n",
      "Loss at Iteration @ 8020 is 1.988932728767395\n",
      "Evaluation Loss at Iteration @ 8020 is 2.248539447784424\n",
      "Loss at Iteration @ 8021 is 2.409470796585083\n",
      "Evaluation Loss at Iteration @ 8021 is 2.315843105316162\n",
      "Loss at Iteration @ 8022 is 2.4549198150634766\n",
      "Evaluation Loss at Iteration @ 8022 is 2.2998385429382324\n",
      "Loss at Iteration @ 8023 is 2.2374448776245117\n",
      "Evaluation Loss at Iteration @ 8023 is 2.2501018047332764\n",
      "Loss at Iteration @ 8024 is 2.3395349979400635\n",
      "Evaluation Loss at Iteration @ 8024 is 2.2190334796905518\n",
      "Loss at Iteration @ 8025 is 2.139031410217285\n",
      "Evaluation Loss at Iteration @ 8025 is 2.233642339706421\n",
      "Loss at Iteration @ 8026 is 2.3341126441955566\n",
      "Evaluation Loss at Iteration @ 8026 is 2.2531120777130127\n",
      "Loss at Iteration @ 8027 is 2.0503764152526855\n",
      "Evaluation Loss at Iteration @ 8027 is 2.2695565223693848\n",
      "Loss at Iteration @ 8028 is 1.9954724311828613\n",
      "Evaluation Loss at Iteration @ 8028 is 2.208639144897461\n",
      "Loss at Iteration @ 8029 is 2.381988763809204\n",
      "Evaluation Loss at Iteration @ 8029 is 2.2416255474090576\n",
      "Loss at Iteration @ 8030 is 2.295231342315674\n",
      "Evaluation Loss at Iteration @ 8030 is 2.2592689990997314\n",
      "Loss at Iteration @ 8031 is 2.481438398361206\n",
      "Evaluation Loss at Iteration @ 8031 is 2.226733446121216\n",
      "Loss at Iteration @ 8032 is 1.9659518003463745\n",
      "Evaluation Loss at Iteration @ 8032 is 2.278310537338257\n",
      "Loss at Iteration @ 8033 is 2.2620561122894287\n",
      "Evaluation Loss at Iteration @ 8033 is 2.2646350860595703\n",
      "Loss at Iteration @ 8034 is 2.348254442214966\n",
      "Evaluation Loss at Iteration @ 8034 is 2.2565500736236572\n",
      "Loss at Iteration @ 8035 is 2.449690818786621\n",
      "Evaluation Loss at Iteration @ 8035 is 2.302633047103882\n",
      "Loss at Iteration @ 8036 is 2.227545738220215\n",
      "Evaluation Loss at Iteration @ 8036 is 2.307770013809204\n",
      "Loss at Iteration @ 8037 is 2.1062119007110596\n",
      "Evaluation Loss at Iteration @ 8037 is 2.2476232051849365\n",
      "Loss at Iteration @ 8038 is 2.280388593673706\n",
      "Evaluation Loss at Iteration @ 8038 is 2.283172369003296\n",
      "Loss at Iteration @ 8039 is 1.96890389919281\n",
      "Evaluation Loss at Iteration @ 8039 is 2.250108242034912\n",
      "Loss at Iteration @ 8040 is 2.389192581176758\n",
      "Evaluation Loss at Iteration @ 8040 is 2.218367099761963\n",
      "Loss at Iteration @ 8041 is 2.101921558380127\n",
      "Evaluation Loss at Iteration @ 8041 is 2.2296345233917236\n",
      "Loss at Iteration @ 8042 is 2.2243170738220215\n",
      "Evaluation Loss at Iteration @ 8042 is 2.242750883102417\n",
      "Loss at Iteration @ 8043 is 2.0285212993621826\n",
      "Evaluation Loss at Iteration @ 8043 is 2.2339301109313965\n",
      "Loss at Iteration @ 8044 is 2.1065142154693604\n",
      "Evaluation Loss at Iteration @ 8044 is 2.2801387310028076\n",
      "Loss at Iteration @ 8045 is 2.271765947341919\n",
      "Evaluation Loss at Iteration @ 8045 is 2.2441253662109375\n",
      "Loss at Iteration @ 8046 is 2.1499853134155273\n",
      "Evaluation Loss at Iteration @ 8046 is 2.258876323699951\n",
      "Loss at Iteration @ 8047 is 2.3202435970306396\n",
      "Evaluation Loss at Iteration @ 8047 is 2.2454006671905518\n",
      "Loss at Iteration @ 8048 is 2.433291435241699\n",
      "Evaluation Loss at Iteration @ 8048 is 2.244711399078369\n",
      "Loss at Iteration @ 8049 is 2.317890167236328\n",
      "Evaluation Loss at Iteration @ 8049 is 2.262394666671753\n",
      "Loss at Iteration @ 8050 is 2.276193618774414\n",
      "Evaluation Loss at Iteration @ 8050 is 2.232898712158203\n",
      "Loss at Iteration @ 8051 is 1.848427176475525\n",
      "Evaluation Loss at Iteration @ 8051 is 2.2900540828704834\n",
      "Loss at Iteration @ 8052 is 2.1963818073272705\n",
      "Evaluation Loss at Iteration @ 8052 is 2.2596187591552734\n",
      "Loss at Iteration @ 8053 is 2.2004342079162598\n",
      "Evaluation Loss at Iteration @ 8053 is 2.2710251808166504\n",
      "Loss at Iteration @ 8054 is 2.110281229019165\n",
      "Evaluation Loss at Iteration @ 8054 is 2.2238965034484863\n",
      "Loss at Iteration @ 8055 is 2.3936798572540283\n",
      "Evaluation Loss at Iteration @ 8055 is 2.2019143104553223\n",
      "Loss at Iteration @ 8056 is 2.087118148803711\n",
      "Evaluation Loss at Iteration @ 8056 is 2.216993808746338\n",
      "Loss at Iteration @ 8057 is 2.0100395679473877\n",
      "Evaluation Loss at Iteration @ 8057 is 2.237682342529297\n",
      "Loss at Iteration @ 8058 is 1.94613778591156\n",
      "Evaluation Loss at Iteration @ 8058 is 2.2518815994262695\n",
      "Loss at Iteration @ 8059 is 2.355186700820923\n",
      "Evaluation Loss at Iteration @ 8059 is 2.2648866176605225\n",
      "Loss at Iteration @ 8060 is 2.058140754699707\n",
      "Evaluation Loss at Iteration @ 8060 is 2.227526903152466\n",
      "Loss at Iteration @ 8061 is 2.0883007049560547\n",
      "Evaluation Loss at Iteration @ 8061 is 2.264141321182251\n",
      "Loss at Iteration @ 8062 is 2.1071977615356445\n",
      "Evaluation Loss at Iteration @ 8062 is 2.2832837104797363\n",
      "Loss at Iteration @ 8063 is 2.183229923248291\n",
      "Evaluation Loss at Iteration @ 8063 is 2.274411201477051\n",
      "Loss at Iteration @ 8064 is 2.053098201751709\n",
      "Evaluation Loss at Iteration @ 8064 is 2.244094133377075\n",
      "Loss at Iteration @ 8065 is 2.2413434982299805\n",
      "Evaluation Loss at Iteration @ 8065 is 2.2545382976531982\n",
      "Loss at Iteration @ 8066 is 2.0843143463134766\n",
      "Evaluation Loss at Iteration @ 8066 is 2.260160207748413\n",
      "Loss at Iteration @ 8067 is 2.0408973693847656\n",
      "Evaluation Loss at Iteration @ 8067 is 2.2672975063323975\n",
      "Loss at Iteration @ 8068 is 2.210169792175293\n",
      "Evaluation Loss at Iteration @ 8068 is 2.283263921737671\n",
      "Loss at Iteration @ 8069 is 2.311530590057373\n",
      "Evaluation Loss at Iteration @ 8069 is 2.250870943069458\n",
      "Loss at Iteration @ 8070 is 2.0901505947113037\n",
      "Evaluation Loss at Iteration @ 8070 is 2.2758092880249023\n",
      "Loss at Iteration @ 8071 is 2.3977913856506348\n",
      "Evaluation Loss at Iteration @ 8071 is 2.2629475593566895\n",
      "Loss at Iteration @ 8072 is 2.487311601638794\n",
      "Evaluation Loss at Iteration @ 8072 is 2.2903730869293213\n",
      "Loss at Iteration @ 8073 is 2.403033494949341\n",
      "Evaluation Loss at Iteration @ 8073 is 2.245197057723999\n",
      "Loss at Iteration @ 8074 is 2.197568416595459\n",
      "Evaluation Loss at Iteration @ 8074 is 2.2269420623779297\n",
      "Loss at Iteration @ 8075 is 2.12831711769104\n",
      "Evaluation Loss at Iteration @ 8075 is 2.218008518218994\n",
      "Loss at Iteration @ 8076 is 2.1458141803741455\n",
      "Evaluation Loss at Iteration @ 8076 is 2.27691912651062\n",
      "Loss at Iteration @ 8077 is 1.9079288244247437\n",
      "Evaluation Loss at Iteration @ 8077 is 2.2649154663085938\n",
      "Loss at Iteration @ 8078 is 1.9896996021270752\n",
      "Evaluation Loss at Iteration @ 8078 is 2.236461639404297\n",
      "Loss at Iteration @ 8079 is 2.2445666790008545\n",
      "Evaluation Loss at Iteration @ 8079 is 2.228811264038086\n",
      "Loss at Iteration @ 8080 is 2.3041255474090576\n",
      "Evaluation Loss at Iteration @ 8080 is 2.2602481842041016\n",
      "Loss at Iteration @ 8081 is 2.193171501159668\n",
      "Evaluation Loss at Iteration @ 8081 is 2.219038248062134\n",
      "Loss at Iteration @ 8082 is 2.153977870941162\n",
      "Evaluation Loss at Iteration @ 8082 is 2.284491777420044\n",
      "Loss at Iteration @ 8083 is 2.17990779876709\n",
      "Evaluation Loss at Iteration @ 8083 is 2.3026816844940186\n",
      "Loss at Iteration @ 8084 is 2.197629690170288\n",
      "Evaluation Loss at Iteration @ 8084 is 2.2147715091705322\n",
      "Loss at Iteration @ 8085 is 2.148042678833008\n",
      "Evaluation Loss at Iteration @ 8085 is 2.2565910816192627\n",
      "Loss at Iteration @ 8086 is 2.203145980834961\n",
      "Evaluation Loss at Iteration @ 8086 is 2.277310609817505\n",
      "Loss at Iteration @ 8087 is 2.2008719444274902\n",
      "Evaluation Loss at Iteration @ 8087 is 2.2512714862823486\n",
      "Loss at Iteration @ 8088 is 2.4935526847839355\n",
      "Evaluation Loss at Iteration @ 8088 is 2.262136459350586\n",
      "Loss at Iteration @ 8089 is 2.4482829570770264\n",
      "Evaluation Loss at Iteration @ 8089 is 2.2447381019592285\n",
      "Loss at Iteration @ 8090 is 2.434918165206909\n",
      "Evaluation Loss at Iteration @ 8090 is 2.2423276901245117\n",
      "Loss at Iteration @ 8091 is 2.2914047241210938\n",
      "Evaluation Loss at Iteration @ 8091 is 2.2684483528137207\n",
      "Loss at Iteration @ 8092 is 1.931172251701355\n",
      "Evaluation Loss at Iteration @ 8092 is 2.255690574645996\n",
      "Loss at Iteration @ 8093 is 2.087325096130371\n",
      "Evaluation Loss at Iteration @ 8093 is 2.2290406227111816\n",
      "Loss at Iteration @ 8094 is 2.2342655658721924\n",
      "Evaluation Loss at Iteration @ 8094 is 2.2968435287475586\n",
      "Loss at Iteration @ 8095 is 2.2348690032958984\n",
      "Evaluation Loss at Iteration @ 8095 is 2.259254217147827\n",
      "Loss at Iteration @ 8096 is 2.1803789138793945\n",
      "Evaluation Loss at Iteration @ 8096 is 2.2638025283813477\n",
      "Loss at Iteration @ 8097 is 2.3417303562164307\n",
      "Evaluation Loss at Iteration @ 8097 is 2.2092337608337402\n",
      "Loss at Iteration @ 8098 is 2.2607874870300293\n",
      "Evaluation Loss at Iteration @ 8098 is 2.214390754699707\n",
      "Loss at Iteration @ 8099 is 2.2898762226104736\n",
      "Evaluation Loss at Iteration @ 8099 is 2.2682390213012695\n",
      "Loss at Iteration @ 8100 is 1.9977285861968994\n",
      "Evaluation Loss at Iteration @ 8100 is 2.223677158355713\n",
      "Loss at Iteration @ 8101 is 2.271091938018799\n",
      "Evaluation Loss at Iteration @ 8101 is 2.2981443405151367\n",
      "Loss at Iteration @ 8102 is 2.146399974822998\n",
      "Evaluation Loss at Iteration @ 8102 is 2.2672183513641357\n",
      "Loss at Iteration @ 8103 is 2.15492582321167\n",
      "Evaluation Loss at Iteration @ 8103 is 2.2527732849121094\n",
      "Loss at Iteration @ 8104 is 2.2514991760253906\n",
      "Evaluation Loss at Iteration @ 8104 is 2.26747727394104\n",
      "Loss at Iteration @ 8105 is 2.4062507152557373\n",
      "Evaluation Loss at Iteration @ 8105 is 2.234433174133301\n",
      "Loss at Iteration @ 8106 is 2.241119623184204\n",
      "Evaluation Loss at Iteration @ 8106 is 2.2255771160125732\n",
      "Loss at Iteration @ 8107 is 2.0466079711914062\n",
      "Evaluation Loss at Iteration @ 8107 is 2.2416818141937256\n",
      "Loss at Iteration @ 8108 is 2.584925413131714\n",
      "Evaluation Loss at Iteration @ 8108 is 2.240154981613159\n",
      "Loss at Iteration @ 8109 is 2.344634532928467\n",
      "Evaluation Loss at Iteration @ 8109 is 2.241551637649536\n",
      "Loss at Iteration @ 8110 is 2.4183483123779297\n",
      "Evaluation Loss at Iteration @ 8110 is 2.2598369121551514\n",
      "Loss at Iteration @ 8111 is 2.0732550621032715\n",
      "Evaluation Loss at Iteration @ 8111 is 2.2958390712738037\n",
      "Loss at Iteration @ 8112 is 2.4112765789031982\n",
      "Evaluation Loss at Iteration @ 8112 is 2.2496018409729004\n",
      "Loss at Iteration @ 8113 is 2.2211196422576904\n",
      "Evaluation Loss at Iteration @ 8113 is 2.3022444248199463\n",
      "Loss at Iteration @ 8114 is 2.238447427749634\n",
      "Evaluation Loss at Iteration @ 8114 is 2.290961503982544\n",
      "Loss at Iteration @ 8115 is 2.2657833099365234\n",
      "Evaluation Loss at Iteration @ 8115 is 2.2335264682769775\n",
      "Loss at Iteration @ 8116 is 2.2328240871429443\n",
      "Evaluation Loss at Iteration @ 8116 is 2.2305963039398193\n",
      "Loss at Iteration @ 8117 is 2.2816576957702637\n",
      "Evaluation Loss at Iteration @ 8117 is 2.256882429122925\n",
      "Loss at Iteration @ 8118 is 2.383030414581299\n",
      "Evaluation Loss at Iteration @ 8118 is 2.2631735801696777\n",
      "Loss at Iteration @ 8119 is 2.048111915588379\n",
      "Evaluation Loss at Iteration @ 8119 is 2.2446935176849365\n",
      "Loss at Iteration @ 8120 is 2.3116674423217773\n",
      "Evaluation Loss at Iteration @ 8120 is 2.2645273208618164\n",
      "Loss at Iteration @ 8121 is 2.3050267696380615\n",
      "Evaluation Loss at Iteration @ 8121 is 2.216367244720459\n",
      "Loss at Iteration @ 8122 is 2.152204751968384\n",
      "Evaluation Loss at Iteration @ 8122 is 2.233773946762085\n",
      "Loss at Iteration @ 8123 is 2.0386579036712646\n",
      "Evaluation Loss at Iteration @ 8123 is 2.279754400253296\n",
      "Loss at Iteration @ 8124 is 2.32507586479187\n",
      "Evaluation Loss at Iteration @ 8124 is 2.3012661933898926\n",
      "Loss at Iteration @ 8125 is 2.3164732456207275\n",
      "Evaluation Loss at Iteration @ 8125 is 2.2828328609466553\n",
      "Loss at Iteration @ 8126 is 1.9957350492477417\n",
      "Evaluation Loss at Iteration @ 8126 is 2.2265591621398926\n",
      "Loss at Iteration @ 8127 is 2.4537546634674072\n",
      "Evaluation Loss at Iteration @ 8127 is 2.2415759563446045\n",
      "Loss at Iteration @ 8128 is 2.2227883338928223\n",
      "Evaluation Loss at Iteration @ 8128 is 2.2657039165496826\n",
      "Loss at Iteration @ 8129 is 2.120464324951172\n",
      "Evaluation Loss at Iteration @ 8129 is 2.2251386642456055\n",
      "Loss at Iteration @ 8130 is 2.028414011001587\n",
      "Evaluation Loss at Iteration @ 8130 is 2.2735114097595215\n",
      "Loss at Iteration @ 8131 is 2.4023895263671875\n",
      "Evaluation Loss at Iteration @ 8131 is 2.2097885608673096\n",
      "Loss at Iteration @ 8132 is 2.106444835662842\n",
      "Evaluation Loss at Iteration @ 8132 is 2.239107608795166\n",
      "Loss at Iteration @ 8133 is 2.0486483573913574\n",
      "Evaluation Loss at Iteration @ 8133 is 2.23378586769104\n",
      "Loss at Iteration @ 8134 is 2.2019760608673096\n",
      "Evaluation Loss at Iteration @ 8134 is 2.2541372776031494\n",
      "Loss at Iteration @ 8135 is 2.3954944610595703\n",
      "Evaluation Loss at Iteration @ 8135 is 2.229773998260498\n",
      "Loss at Iteration @ 8136 is 2.1548702716827393\n",
      "Evaluation Loss at Iteration @ 8136 is 2.2369251251220703\n",
      "Loss at Iteration @ 8137 is 1.9147249460220337\n",
      "Evaluation Loss at Iteration @ 8137 is 2.216136932373047\n",
      "Loss at Iteration @ 8138 is 2.20397686958313\n",
      "Evaluation Loss at Iteration @ 8138 is 2.263334035873413\n",
      "Loss at Iteration @ 8139 is 2.218221426010132\n",
      "Evaluation Loss at Iteration @ 8139 is 2.2181389331817627\n",
      "Loss at Iteration @ 8140 is 2.2091379165649414\n",
      "Evaluation Loss at Iteration @ 8140 is 2.2790277004241943\n",
      "Loss at Iteration @ 8141 is 2.2500760555267334\n",
      "Evaluation Loss at Iteration @ 8141 is 2.2029833793640137\n",
      "Loss at Iteration @ 8142 is 2.400902509689331\n",
      "Evaluation Loss at Iteration @ 8142 is 2.1890134811401367\n",
      "Loss at Iteration @ 8143 is 2.251067876815796\n",
      "Evaluation Loss at Iteration @ 8143 is 2.255812883377075\n",
      "Loss at Iteration @ 8144 is 2.1002421379089355\n",
      "Evaluation Loss at Iteration @ 8144 is 2.2379720211029053\n",
      "Loss at Iteration @ 8145 is 2.2852323055267334\n",
      "Evaluation Loss at Iteration @ 8145 is 2.278773307800293\n",
      "Loss at Iteration @ 8146 is 2.312307119369507\n",
      "Evaluation Loss at Iteration @ 8146 is 2.2631337642669678\n",
      "Loss at Iteration @ 8147 is 2.3374643325805664\n",
      "Evaluation Loss at Iteration @ 8147 is 2.22257661819458\n",
      "Loss at Iteration @ 8148 is 2.1784894466400146\n",
      "Evaluation Loss at Iteration @ 8148 is 2.2533886432647705\n",
      "Loss at Iteration @ 8149 is 2.5028135776519775\n",
      "Evaluation Loss at Iteration @ 8149 is 2.2720603942871094\n",
      "Loss at Iteration @ 8150 is 2.2235958576202393\n",
      "Evaluation Loss at Iteration @ 8150 is 2.238075017929077\n",
      "Loss at Iteration @ 8151 is 2.669395923614502\n",
      "Evaluation Loss at Iteration @ 8151 is 2.2416751384735107\n",
      "Loss at Iteration @ 8152 is 2.3163206577301025\n",
      "Evaluation Loss at Iteration @ 8152 is 2.2466118335723877\n",
      "Loss at Iteration @ 8153 is 2.406709909439087\n",
      "Evaluation Loss at Iteration @ 8153 is 2.25553560256958\n",
      "Loss at Iteration @ 8154 is 2.133488655090332\n",
      "Evaluation Loss at Iteration @ 8154 is 2.27203631401062\n",
      "Loss at Iteration @ 8155 is 2.024618625640869\n",
      "Evaluation Loss at Iteration @ 8155 is 2.2119083404541016\n",
      "Loss at Iteration @ 8156 is 2.252962350845337\n",
      "Evaluation Loss at Iteration @ 8156 is 2.261051893234253\n",
      "Loss at Iteration @ 8157 is 2.105433225631714\n",
      "Evaluation Loss at Iteration @ 8157 is 2.2573771476745605\n",
      "Loss at Iteration @ 8158 is 2.1774425506591797\n",
      "Evaluation Loss at Iteration @ 8158 is 2.211127281188965\n",
      "Loss at Iteration @ 8159 is 2.0492424964904785\n",
      "Evaluation Loss at Iteration @ 8159 is 2.2202370166778564\n",
      "Loss at Iteration @ 8160 is 2.352742910385132\n",
      "Evaluation Loss at Iteration @ 8160 is 2.2622036933898926\n",
      "Loss at Iteration @ 8161 is 1.912994623184204\n",
      "Evaluation Loss at Iteration @ 8161 is 2.240872621536255\n",
      "Loss at Iteration @ 8162 is 2.2151389122009277\n",
      "Evaluation Loss at Iteration @ 8162 is 2.23437762260437\n",
      "Loss at Iteration @ 8163 is 2.445719003677368\n",
      "Evaluation Loss at Iteration @ 8163 is 2.279371976852417\n",
      "Loss at Iteration @ 8164 is 2.319955348968506\n",
      "Evaluation Loss at Iteration @ 8164 is 2.2115390300750732\n",
      "Loss at Iteration @ 8165 is 2.1526737213134766\n",
      "Evaluation Loss at Iteration @ 8165 is 2.2317304611206055\n",
      "Loss at Iteration @ 8166 is 2.0513155460357666\n",
      "Evaluation Loss at Iteration @ 8166 is 2.2132530212402344\n",
      "Loss at Iteration @ 8167 is 2.220618724822998\n",
      "Evaluation Loss at Iteration @ 8167 is 2.2076258659362793\n",
      "Loss at Iteration @ 8168 is 2.3741419315338135\n",
      "Evaluation Loss at Iteration @ 8168 is 2.3107476234436035\n",
      "Loss at Iteration @ 8169 is 2.338479518890381\n",
      "Evaluation Loss at Iteration @ 8169 is 2.2703933715820312\n",
      "Loss at Iteration @ 8170 is 2.069592237472534\n",
      "Evaluation Loss at Iteration @ 8170 is 2.246826171875\n",
      "Loss at Iteration @ 8171 is 2.3033676147460938\n",
      "Evaluation Loss at Iteration @ 8171 is 2.24049973487854\n",
      "Loss at Iteration @ 8172 is 2.15265154838562\n",
      "Evaluation Loss at Iteration @ 8172 is 2.259822368621826\n",
      "Loss at Iteration @ 8173 is 2.011394739151001\n",
      "Evaluation Loss at Iteration @ 8173 is 2.227168560028076\n",
      "Loss at Iteration @ 8174 is 2.4592556953430176\n",
      "Evaluation Loss at Iteration @ 8174 is 2.2609431743621826\n",
      "Loss at Iteration @ 8175 is 2.274440050125122\n",
      "Evaluation Loss at Iteration @ 8175 is 2.2290380001068115\n",
      "Loss at Iteration @ 8176 is 2.3073782920837402\n",
      "Evaluation Loss at Iteration @ 8176 is 2.2700531482696533\n",
      "Loss at Iteration @ 8177 is 2.2111594676971436\n",
      "Evaluation Loss at Iteration @ 8177 is 2.2831778526306152\n",
      "Loss at Iteration @ 8178 is 2.2319986820220947\n",
      "Evaluation Loss at Iteration @ 8178 is 2.2453596591949463\n",
      "Loss at Iteration @ 8179 is 2.4493789672851562\n",
      "Evaluation Loss at Iteration @ 8179 is 2.2593307495117188\n",
      "Loss at Iteration @ 8180 is 2.288422107696533\n",
      "Evaluation Loss at Iteration @ 8180 is 2.2440407276153564\n",
      "Loss at Iteration @ 8181 is 2.240684747695923\n",
      "Evaluation Loss at Iteration @ 8181 is 2.2692103385925293\n",
      "Loss at Iteration @ 8182 is 2.4147768020629883\n",
      "Evaluation Loss at Iteration @ 8182 is 2.206089496612549\n",
      "Loss at Iteration @ 8183 is 2.3282041549682617\n",
      "Evaluation Loss at Iteration @ 8183 is 2.2606019973754883\n",
      "Loss at Iteration @ 8184 is 2.5871567726135254\n",
      "Evaluation Loss at Iteration @ 8184 is 2.2384390830993652\n",
      "Loss at Iteration @ 8185 is 2.465435743331909\n",
      "Evaluation Loss at Iteration @ 8185 is 2.2716081142425537\n",
      "Loss at Iteration @ 8186 is 2.155377149581909\n",
      "Evaluation Loss at Iteration @ 8186 is 2.248154640197754\n",
      "Loss at Iteration @ 8187 is 2.2071027755737305\n",
      "Evaluation Loss at Iteration @ 8187 is 2.2842230796813965\n",
      "Loss at Iteration @ 8188 is 2.198268175125122\n",
      "Evaluation Loss at Iteration @ 8188 is 2.2272040843963623\n",
      "Loss at Iteration @ 8189 is 2.2668914794921875\n",
      "Evaluation Loss at Iteration @ 8189 is 2.22478985786438\n",
      "Loss at Iteration @ 8190 is 2.028977155685425\n",
      "Evaluation Loss at Iteration @ 8190 is 2.246830701828003\n",
      "Loss at Iteration @ 8191 is 2.370425224304199\n",
      "Evaluation Loss at Iteration @ 8191 is 2.208264112472534\n",
      "Loss at Iteration @ 8192 is 2.1659181118011475\n",
      "Evaluation Loss at Iteration @ 8192 is 2.1946802139282227\n",
      "Loss at Iteration @ 8193 is 2.272395133972168\n",
      "Evaluation Loss at Iteration @ 8193 is 2.2527198791503906\n",
      "Loss at Iteration @ 8194 is 2.206796646118164\n",
      "Evaluation Loss at Iteration @ 8194 is 2.2333853244781494\n",
      "Loss at Iteration @ 8195 is 1.978377103805542\n",
      "Evaluation Loss at Iteration @ 8195 is 2.229440450668335\n",
      "Loss at Iteration @ 8196 is 2.402604341506958\n",
      "Evaluation Loss at Iteration @ 8196 is 2.2890353202819824\n",
      "Loss at Iteration @ 8197 is 2.3746373653411865\n",
      "Evaluation Loss at Iteration @ 8197 is 2.2669782638549805\n",
      "Loss at Iteration @ 8198 is 2.402705669403076\n",
      "Evaluation Loss at Iteration @ 8198 is 2.2547805309295654\n",
      "Loss at Iteration @ 8199 is 2.3325002193450928\n",
      "Evaluation Loss at Iteration @ 8199 is 2.2563772201538086\n",
      "Loss at Iteration @ 8200 is 2.2298099994659424\n",
      "Evaluation Loss at Iteration @ 8200 is 2.2065348625183105\n",
      "Loss at Iteration @ 8201 is 2.423257827758789\n",
      "Evaluation Loss at Iteration @ 8201 is 2.217946767807007\n",
      "Loss at Iteration @ 8202 is 2.013033151626587\n",
      "Evaluation Loss at Iteration @ 8202 is 2.280885934829712\n",
      "Loss at Iteration @ 8203 is 2.1619982719421387\n",
      "Evaluation Loss at Iteration @ 8203 is 2.1895480155944824\n",
      "Loss at Iteration @ 8204 is 2.18371844291687\n",
      "Evaluation Loss at Iteration @ 8204 is 2.2240803241729736\n",
      "Loss at Iteration @ 8205 is 1.9991387128829956\n",
      "Evaluation Loss at Iteration @ 8205 is 2.2414939403533936\n",
      "Loss at Iteration @ 8206 is 2.5356812477111816\n",
      "Evaluation Loss at Iteration @ 8206 is 2.2608892917633057\n",
      "Loss at Iteration @ 8207 is 2.339268922805786\n",
      "Evaluation Loss at Iteration @ 8207 is 2.2668344974517822\n",
      "Loss at Iteration @ 8208 is 2.093048334121704\n",
      "Evaluation Loss at Iteration @ 8208 is 2.22770094871521\n",
      "Loss at Iteration @ 8209 is 2.1547927856445312\n",
      "Evaluation Loss at Iteration @ 8209 is 2.2467381954193115\n",
      "Loss at Iteration @ 8210 is 2.1668143272399902\n",
      "Evaluation Loss at Iteration @ 8210 is 2.238513469696045\n",
      "Loss at Iteration @ 8211 is 2.196981430053711\n",
      "Evaluation Loss at Iteration @ 8211 is 2.2584385871887207\n",
      "Loss at Iteration @ 8212 is 2.3070285320281982\n",
      "Evaluation Loss at Iteration @ 8212 is 2.2595489025115967\n",
      "Loss at Iteration @ 8213 is 2.210782766342163\n",
      "Evaluation Loss at Iteration @ 8213 is 2.210312843322754\n",
      "Loss at Iteration @ 8214 is 2.3242337703704834\n",
      "Evaluation Loss at Iteration @ 8214 is 2.2566521167755127\n",
      "Loss at Iteration @ 8215 is 2.3169898986816406\n",
      "Evaluation Loss at Iteration @ 8215 is 2.2775888442993164\n",
      "Loss at Iteration @ 8216 is 2.558100461959839\n",
      "Evaluation Loss at Iteration @ 8216 is 2.207533836364746\n",
      "Loss at Iteration @ 8217 is 2.2159152030944824\n",
      "Evaluation Loss at Iteration @ 8217 is 2.2567195892333984\n",
      "Loss at Iteration @ 8218 is 2.168912410736084\n",
      "Evaluation Loss at Iteration @ 8218 is 2.2190945148468018\n",
      "Loss at Iteration @ 8219 is 2.3457863330841064\n",
      "Evaluation Loss at Iteration @ 8219 is 2.2008156776428223\n",
      "Loss at Iteration @ 8220 is 2.247516393661499\n",
      "Evaluation Loss at Iteration @ 8220 is 2.2278940677642822\n",
      "Loss at Iteration @ 8221 is 2.3537521362304688\n",
      "Evaluation Loss at Iteration @ 8221 is 2.2536935806274414\n",
      "Loss at Iteration @ 8222 is 2.451873302459717\n",
      "Evaluation Loss at Iteration @ 8222 is 2.246711015701294\n",
      "Loss at Iteration @ 8223 is 2.17663836479187\n",
      "Evaluation Loss at Iteration @ 8223 is 2.222860336303711\n",
      "Loss at Iteration @ 8224 is 2.0866646766662598\n",
      "Evaluation Loss at Iteration @ 8224 is 2.238422393798828\n",
      "Loss at Iteration @ 8225 is 2.485283851623535\n",
      "Evaluation Loss at Iteration @ 8225 is 2.2236835956573486\n",
      "Loss at Iteration @ 8226 is 2.3097221851348877\n",
      "Evaluation Loss at Iteration @ 8226 is 2.2263598442077637\n",
      "Loss at Iteration @ 8227 is 2.3293519020080566\n",
      "Evaluation Loss at Iteration @ 8227 is 2.246262311935425\n",
      "Loss at Iteration @ 8228 is 2.4068734645843506\n",
      "Evaluation Loss at Iteration @ 8228 is 2.2337284088134766\n",
      "Loss at Iteration @ 8229 is 2.2059624195098877\n",
      "Evaluation Loss at Iteration @ 8229 is 2.2220048904418945\n",
      "Loss at Iteration @ 8230 is 2.0661730766296387\n",
      "Evaluation Loss at Iteration @ 8230 is 2.215111494064331\n",
      "Loss at Iteration @ 8231 is 2.0184946060180664\n",
      "Evaluation Loss at Iteration @ 8231 is 2.240469455718994\n",
      "Loss at Iteration @ 8232 is 2.2013370990753174\n",
      "Evaluation Loss at Iteration @ 8232 is 2.2418901920318604\n",
      "Loss at Iteration @ 8233 is 2.469208240509033\n",
      "Evaluation Loss at Iteration @ 8233 is 2.2661843299865723\n",
      "Loss at Iteration @ 8234 is 2.123415946960449\n",
      "Evaluation Loss at Iteration @ 8234 is 2.255509614944458\n",
      "Loss at Iteration @ 8235 is 2.0607311725616455\n",
      "Evaluation Loss at Iteration @ 8235 is 2.2522342205047607\n",
      "Loss at Iteration @ 8236 is 2.341486692428589\n",
      "Evaluation Loss at Iteration @ 8236 is 2.2521891593933105\n",
      "Loss at Iteration @ 8237 is 2.3171980381011963\n",
      "Evaluation Loss at Iteration @ 8237 is 2.2889163494110107\n",
      "Loss at Iteration @ 8238 is 2.304800510406494\n",
      "Evaluation Loss at Iteration @ 8238 is 2.264561891555786\n",
      "Loss at Iteration @ 8239 is 2.3703320026397705\n",
      "Evaluation Loss at Iteration @ 8239 is 2.305373191833496\n",
      "Loss at Iteration @ 8240 is 2.1817667484283447\n",
      "Evaluation Loss at Iteration @ 8240 is 2.2755072116851807\n",
      "Loss at Iteration @ 8241 is 2.3659822940826416\n",
      "Evaluation Loss at Iteration @ 8241 is 2.2299885749816895\n",
      "Loss at Iteration @ 8242 is 2.176365852355957\n",
      "Evaluation Loss at Iteration @ 8242 is 2.2913753986358643\n",
      "Loss at Iteration @ 8243 is 2.5659279823303223\n",
      "Evaluation Loss at Iteration @ 8243 is 2.235750913619995\n",
      "Loss at Iteration @ 8244 is 2.4678361415863037\n",
      "Evaluation Loss at Iteration @ 8244 is 2.2682371139526367\n",
      "Loss at Iteration @ 8245 is 2.0131895542144775\n",
      "Evaluation Loss at Iteration @ 8245 is 2.246303081512451\n",
      "Loss at Iteration @ 8246 is 2.1929402351379395\n",
      "Evaluation Loss at Iteration @ 8246 is 2.273056745529175\n",
      "Loss at Iteration @ 8247 is 2.0223782062530518\n",
      "Evaluation Loss at Iteration @ 8247 is 2.2344536781311035\n",
      "Loss at Iteration @ 8248 is 2.2757973670959473\n",
      "Evaluation Loss at Iteration @ 8248 is 2.291656494140625\n",
      "Loss at Iteration @ 8249 is 2.327164649963379\n",
      "Evaluation Loss at Iteration @ 8249 is 2.2355830669403076\n",
      "Loss at Iteration @ 8250 is 2.3485467433929443\n",
      "Evaluation Loss at Iteration @ 8250 is 2.255181074142456\n",
      "Loss at Iteration @ 8251 is 2.095536231994629\n",
      "Evaluation Loss at Iteration @ 8251 is 2.2249557971954346\n",
      "Loss at Iteration @ 8252 is 2.154343366622925\n",
      "Evaluation Loss at Iteration @ 8252 is 2.2531628608703613\n",
      "Loss at Iteration @ 8253 is 2.182382583618164\n",
      "Evaluation Loss at Iteration @ 8253 is 2.2658002376556396\n",
      "Loss at Iteration @ 8254 is 2.4469687938690186\n",
      "Evaluation Loss at Iteration @ 8254 is 2.215841054916382\n",
      "Loss at Iteration @ 8255 is 2.33377742767334\n",
      "Evaluation Loss at Iteration @ 8255 is 2.243023157119751\n",
      "Loss at Iteration @ 8256 is 2.135525703430176\n",
      "Evaluation Loss at Iteration @ 8256 is 2.2823410034179688\n",
      "Loss at Iteration @ 8257 is 2.0493717193603516\n",
      "Evaluation Loss at Iteration @ 8257 is 2.2688040733337402\n",
      "Loss at Iteration @ 8258 is 1.8925909996032715\n",
      "Evaluation Loss at Iteration @ 8258 is 2.255983591079712\n",
      "Loss at Iteration @ 8259 is 2.397278308868408\n",
      "Evaluation Loss at Iteration @ 8259 is 2.197328567504883\n",
      "Loss at Iteration @ 8260 is 2.223381280899048\n",
      "Evaluation Loss at Iteration @ 8260 is 2.2314677238464355\n",
      "Loss at Iteration @ 8261 is 2.466485023498535\n",
      "Evaluation Loss at Iteration @ 8261 is 2.287482261657715\n",
      "Loss at Iteration @ 8262 is 2.403057813644409\n",
      "Evaluation Loss at Iteration @ 8262 is 2.258671998977661\n",
      "Loss at Iteration @ 8263 is 2.405160427093506\n",
      "Evaluation Loss at Iteration @ 8263 is 2.2807729244232178\n",
      "Loss at Iteration @ 8264 is 2.174588441848755\n",
      "Evaluation Loss at Iteration @ 8264 is 2.2118756771087646\n",
      "Loss at Iteration @ 8265 is 2.426942825317383\n",
      "Evaluation Loss at Iteration @ 8265 is 2.223233461380005\n",
      "Loss at Iteration @ 8266 is 1.9645271301269531\n",
      "Evaluation Loss at Iteration @ 8266 is 2.257058620452881\n",
      "Loss at Iteration @ 8267 is 2.032951593399048\n",
      "Evaluation Loss at Iteration @ 8267 is 2.260225296020508\n",
      "Loss at Iteration @ 8268 is 1.9360265731811523\n",
      "Evaluation Loss at Iteration @ 8268 is 2.254322052001953\n",
      "Loss at Iteration @ 8269 is 2.138333320617676\n",
      "Evaluation Loss at Iteration @ 8269 is 2.271662712097168\n",
      "Loss at Iteration @ 8270 is 2.2480859756469727\n",
      "Evaluation Loss at Iteration @ 8270 is 2.24723219871521\n",
      "Loss at Iteration @ 8271 is 1.9274897575378418\n",
      "Evaluation Loss at Iteration @ 8271 is 2.2499053478240967\n",
      "Loss at Iteration @ 8272 is 1.8995015621185303\n",
      "Evaluation Loss at Iteration @ 8272 is 2.292398691177368\n",
      "Loss at Iteration @ 8273 is 1.925726056098938\n",
      "Evaluation Loss at Iteration @ 8273 is 2.232102632522583\n",
      "Loss at Iteration @ 8274 is 2.423677921295166\n",
      "Evaluation Loss at Iteration @ 8274 is 2.2498064041137695\n",
      "Loss at Iteration @ 8275 is 2.29372501373291\n",
      "Evaluation Loss at Iteration @ 8275 is 2.224459648132324\n",
      "Loss at Iteration @ 8276 is 2.1787898540496826\n",
      "Evaluation Loss at Iteration @ 8276 is 2.24283504486084\n",
      "Loss at Iteration @ 8277 is 2.37453031539917\n",
      "Evaluation Loss at Iteration @ 8277 is 2.281723737716675\n",
      "Loss at Iteration @ 8278 is 2.45536470413208\n",
      "Evaluation Loss at Iteration @ 8278 is 2.2482779026031494\n",
      "Loss at Iteration @ 8279 is 2.352034091949463\n",
      "Evaluation Loss at Iteration @ 8279 is 2.284146308898926\n",
      "Loss at Iteration @ 8280 is 2.233004570007324\n",
      "Evaluation Loss at Iteration @ 8280 is 2.2692012786865234\n",
      "Loss at Iteration @ 8281 is 2.2770261764526367\n",
      "Evaluation Loss at Iteration @ 8281 is 2.249716281890869\n",
      "Loss at Iteration @ 8282 is 2.0923168659210205\n",
      "Evaluation Loss at Iteration @ 8282 is 2.251246452331543\n",
      "Loss at Iteration @ 8283 is 2.1453986167907715\n",
      "Evaluation Loss at Iteration @ 8283 is 2.2425994873046875\n",
      "Loss at Iteration @ 8284 is 2.291456699371338\n",
      "Evaluation Loss at Iteration @ 8284 is 2.2113277912139893\n",
      "Loss at Iteration @ 8285 is 2.343834161758423\n",
      "Evaluation Loss at Iteration @ 8285 is 2.271315097808838\n",
      "Loss at Iteration @ 8286 is 2.314352035522461\n",
      "Evaluation Loss at Iteration @ 8286 is 2.2739017009735107\n",
      "Loss at Iteration @ 8287 is 2.263416051864624\n",
      "Evaluation Loss at Iteration @ 8287 is 2.2315289974212646\n",
      "Loss at Iteration @ 8288 is 2.208282470703125\n",
      "Evaluation Loss at Iteration @ 8288 is 2.3069632053375244\n",
      "Loss at Iteration @ 8289 is 2.2553696632385254\n",
      "Evaluation Loss at Iteration @ 8289 is 2.2590200901031494\n",
      "Loss at Iteration @ 8290 is 2.4177236557006836\n",
      "Evaluation Loss at Iteration @ 8290 is 2.2425127029418945\n",
      "Loss at Iteration @ 8291 is 2.378241539001465\n",
      "Evaluation Loss at Iteration @ 8291 is 2.2461540699005127\n",
      "Loss at Iteration @ 8292 is 2.1141977310180664\n",
      "Evaluation Loss at Iteration @ 8292 is 2.243727684020996\n",
      "Loss at Iteration @ 8293 is 2.1755518913269043\n",
      "Evaluation Loss at Iteration @ 8293 is 2.279953718185425\n",
      "Loss at Iteration @ 8294 is 2.2615890502929688\n",
      "Evaluation Loss at Iteration @ 8294 is 2.283616304397583\n",
      "Loss at Iteration @ 8295 is 2.1570401191711426\n",
      "Evaluation Loss at Iteration @ 8295 is 2.2829837799072266\n",
      "Loss at Iteration @ 8296 is 2.1461026668548584\n",
      "Evaluation Loss at Iteration @ 8296 is 2.226515293121338\n",
      "Loss at Iteration @ 8297 is 2.4375221729278564\n",
      "Evaluation Loss at Iteration @ 8297 is 2.2652158737182617\n",
      "Loss at Iteration @ 8298 is 2.275759696960449\n",
      "Evaluation Loss at Iteration @ 8298 is 2.2346301078796387\n",
      "Loss at Iteration @ 8299 is 2.241691827774048\n",
      "Evaluation Loss at Iteration @ 8299 is 2.2465031147003174\n",
      "Loss at Iteration @ 8300 is 2.4186530113220215\n",
      "Evaluation Loss at Iteration @ 8300 is 2.2756693363189697\n",
      "Loss at Iteration @ 8301 is 2.1445324420928955\n",
      "Evaluation Loss at Iteration @ 8301 is 2.2360587120056152\n",
      "Loss at Iteration @ 8302 is 2.1980035305023193\n",
      "Evaluation Loss at Iteration @ 8302 is 2.2200100421905518\n",
      "Loss at Iteration @ 8303 is 2.0966835021972656\n",
      "Evaluation Loss at Iteration @ 8303 is 2.234123945236206\n",
      "Loss at Iteration @ 8304 is 2.339871406555176\n",
      "Evaluation Loss at Iteration @ 8304 is 2.2332043647766113\n",
      "Loss at Iteration @ 8305 is 2.2740893363952637\n",
      "Evaluation Loss at Iteration @ 8305 is 2.2541873455047607\n",
      "Loss at Iteration @ 8306 is 2.2001395225524902\n",
      "Evaluation Loss at Iteration @ 8306 is 2.2468485832214355\n",
      "Loss at Iteration @ 8307 is 2.5021557807922363\n",
      "Evaluation Loss at Iteration @ 8307 is 2.271580696105957\n",
      "Loss at Iteration @ 8308 is 2.0132339000701904\n",
      "Evaluation Loss at Iteration @ 8308 is 2.3002431392669678\n",
      "Loss at Iteration @ 8309 is 2.3042314052581787\n",
      "Evaluation Loss at Iteration @ 8309 is 2.2300455570220947\n",
      "Loss at Iteration @ 8310 is 2.1330862045288086\n",
      "Evaluation Loss at Iteration @ 8310 is 2.2246110439300537\n",
      "Loss at Iteration @ 8311 is 2.2223246097564697\n",
      "Evaluation Loss at Iteration @ 8311 is 2.2508468627929688\n",
      "Loss at Iteration @ 8312 is 2.0358641147613525\n",
      "Evaluation Loss at Iteration @ 8312 is 2.2202446460723877\n",
      "Loss at Iteration @ 8313 is 2.2347300052642822\n",
      "Evaluation Loss at Iteration @ 8313 is 2.209120988845825\n",
      "Loss at Iteration @ 8314 is 2.337066411972046\n",
      "Evaluation Loss at Iteration @ 8314 is 2.2441718578338623\n",
      "Loss at Iteration @ 8315 is 2.3916244506835938\n",
      "Evaluation Loss at Iteration @ 8315 is 2.2390496730804443\n",
      "Loss at Iteration @ 8316 is 2.1160948276519775\n",
      "Evaluation Loss at Iteration @ 8316 is 2.303487539291382\n",
      "Loss at Iteration @ 8317 is 2.3917760848999023\n",
      "Evaluation Loss at Iteration @ 8317 is 2.2062063217163086\n",
      "Loss at Iteration @ 8318 is 2.566622734069824\n",
      "Evaluation Loss at Iteration @ 8318 is 2.2556912899017334\n",
      "Loss at Iteration @ 8319 is 2.2062020301818848\n",
      "Evaluation Loss at Iteration @ 8319 is 2.268552303314209\n",
      "Loss at Iteration @ 8320 is 2.2721798419952393\n",
      "Evaluation Loss at Iteration @ 8320 is 2.221266031265259\n",
      "Loss at Iteration @ 8321 is 2.353987693786621\n",
      "Evaluation Loss at Iteration @ 8321 is 2.2862932682037354\n",
      "Loss at Iteration @ 8322 is 1.969704031944275\n",
      "Evaluation Loss at Iteration @ 8322 is 2.1983752250671387\n",
      "Loss at Iteration @ 8323 is 2.3643040657043457\n",
      "Evaluation Loss at Iteration @ 8323 is 2.3136074542999268\n",
      "Loss at Iteration @ 8324 is 2.390953302383423\n",
      "Evaluation Loss at Iteration @ 8324 is 2.25217866897583\n",
      "Loss at Iteration @ 8325 is 2.4017162322998047\n",
      "Evaluation Loss at Iteration @ 8325 is 2.2513017654418945\n",
      "Loss at Iteration @ 8326 is 2.3340184688568115\n",
      "Evaluation Loss at Iteration @ 8326 is 2.265596866607666\n",
      "Loss at Iteration @ 8327 is 2.17496657371521\n",
      "Evaluation Loss at Iteration @ 8327 is 2.248587131500244\n",
      "Loss at Iteration @ 8328 is 1.9609222412109375\n",
      "Evaluation Loss at Iteration @ 8328 is 2.259458303451538\n",
      "Loss at Iteration @ 8329 is 2.220737934112549\n",
      "Evaluation Loss at Iteration @ 8329 is 2.255563497543335\n",
      "Loss at Iteration @ 8330 is 2.3685245513916016\n",
      "Evaluation Loss at Iteration @ 8330 is 2.234930992126465\n",
      "Loss at Iteration @ 8331 is 2.17793869972229\n",
      "Evaluation Loss at Iteration @ 8331 is 2.2303428649902344\n",
      "Loss at Iteration @ 8332 is 2.2765064239501953\n",
      "Evaluation Loss at Iteration @ 8332 is 2.273310899734497\n",
      "Loss at Iteration @ 8333 is 2.2789506912231445\n",
      "Evaluation Loss at Iteration @ 8333 is 2.209030866622925\n",
      "Loss at Iteration @ 8334 is 2.4524710178375244\n",
      "Evaluation Loss at Iteration @ 8334 is 2.2660043239593506\n",
      "Loss at Iteration @ 8335 is 2.3573756217956543\n",
      "Evaluation Loss at Iteration @ 8335 is 2.283306837081909\n",
      "Loss at Iteration @ 8336 is 1.8641831874847412\n",
      "Evaluation Loss at Iteration @ 8336 is 2.2332468032836914\n",
      "Loss at Iteration @ 8337 is 2.2021689414978027\n",
      "Evaluation Loss at Iteration @ 8337 is 2.2709975242614746\n",
      "Loss at Iteration @ 8338 is 2.0498671531677246\n",
      "Evaluation Loss at Iteration @ 8338 is 2.2538504600524902\n",
      "Loss at Iteration @ 8339 is 2.0548086166381836\n",
      "Evaluation Loss at Iteration @ 8339 is 2.1889631748199463\n",
      "Loss at Iteration @ 8340 is 2.136305332183838\n",
      "Evaluation Loss at Iteration @ 8340 is 2.2574522495269775\n",
      "Loss at Iteration @ 8341 is 2.142021894454956\n",
      "Evaluation Loss at Iteration @ 8341 is 2.2816078662872314\n",
      "Loss at Iteration @ 8342 is 2.093338966369629\n",
      "Evaluation Loss at Iteration @ 8342 is 2.232733964920044\n",
      "Loss at Iteration @ 8343 is 2.219494581222534\n",
      "Evaluation Loss at Iteration @ 8343 is 2.260080099105835\n",
      "Loss at Iteration @ 8344 is 1.9977577924728394\n",
      "Evaluation Loss at Iteration @ 8344 is 2.254176378250122\n",
      "Loss at Iteration @ 8345 is 2.238048553466797\n",
      "Evaluation Loss at Iteration @ 8345 is 2.2633824348449707\n",
      "Loss at Iteration @ 8346 is 2.4551448822021484\n",
      "Evaluation Loss at Iteration @ 8346 is 2.2926957607269287\n",
      "Loss at Iteration @ 8347 is 2.203368902206421\n",
      "Evaluation Loss at Iteration @ 8347 is 2.256312370300293\n",
      "Loss at Iteration @ 8348 is 2.1183483600616455\n",
      "Evaluation Loss at Iteration @ 8348 is 2.2850468158721924\n",
      "Loss at Iteration @ 8349 is 2.5457468032836914\n",
      "Evaluation Loss at Iteration @ 8349 is 2.2737081050872803\n",
      "Loss at Iteration @ 8350 is 2.0763959884643555\n",
      "Evaluation Loss at Iteration @ 8350 is 2.2401821613311768\n",
      "Loss at Iteration @ 8351 is 2.1988883018493652\n",
      "Evaluation Loss at Iteration @ 8351 is 2.254002332687378\n",
      "Loss at Iteration @ 8352 is 2.336580276489258\n",
      "Evaluation Loss at Iteration @ 8352 is 2.2366390228271484\n",
      "Loss at Iteration @ 8353 is 2.3140389919281006\n",
      "Evaluation Loss at Iteration @ 8353 is 2.249178409576416\n",
      "Loss at Iteration @ 8354 is 2.451690435409546\n",
      "Evaluation Loss at Iteration @ 8354 is 2.2605767250061035\n",
      "Loss at Iteration @ 8355 is 2.1469995975494385\n",
      "Evaluation Loss at Iteration @ 8355 is 2.2641730308532715\n",
      "Loss at Iteration @ 8356 is 2.271440267562866\n",
      "Evaluation Loss at Iteration @ 8356 is 2.2543892860412598\n",
      "Loss at Iteration @ 8357 is 2.3324005603790283\n",
      "Evaluation Loss at Iteration @ 8357 is 2.277130126953125\n",
      "Loss at Iteration @ 8358 is 2.2237422466278076\n",
      "Evaluation Loss at Iteration @ 8358 is 2.2731857299804688\n",
      "Loss at Iteration @ 8359 is 2.3736510276794434\n",
      "Evaluation Loss at Iteration @ 8359 is 2.21687650680542\n",
      "Loss at Iteration @ 8360 is 2.3735904693603516\n",
      "Evaluation Loss at Iteration @ 8360 is 2.2446882724761963\n",
      "Loss at Iteration @ 8361 is 2.230412483215332\n",
      "Evaluation Loss at Iteration @ 8361 is 2.2382214069366455\n",
      "Loss at Iteration @ 8362 is 2.200028896331787\n",
      "Evaluation Loss at Iteration @ 8362 is 2.213726758956909\n",
      "Loss at Iteration @ 8363 is 2.327117919921875\n",
      "Evaluation Loss at Iteration @ 8363 is 2.2570860385894775\n",
      "Loss at Iteration @ 8364 is 2.1183652877807617\n",
      "Evaluation Loss at Iteration @ 8364 is 2.2410922050476074\n",
      "Loss at Iteration @ 8365 is 2.092994451522827\n",
      "Evaluation Loss at Iteration @ 8365 is 2.3075640201568604\n",
      "Loss at Iteration @ 8366 is 2.1470274925231934\n",
      "Evaluation Loss at Iteration @ 8366 is 2.2210686206817627\n",
      "Loss at Iteration @ 8367 is 2.2626733779907227\n",
      "Evaluation Loss at Iteration @ 8367 is 2.2495460510253906\n",
      "Loss at Iteration @ 8368 is 2.132464647293091\n",
      "Evaluation Loss at Iteration @ 8368 is 2.194528579711914\n",
      "Loss at Iteration @ 8369 is 2.028268337249756\n",
      "Evaluation Loss at Iteration @ 8369 is 2.2460172176361084\n",
      "Loss at Iteration @ 8370 is 2.2345645427703857\n",
      "Evaluation Loss at Iteration @ 8370 is 2.246809720993042\n",
      "Loss at Iteration @ 8371 is 2.642094135284424\n",
      "Evaluation Loss at Iteration @ 8371 is 2.233975887298584\n",
      "Loss at Iteration @ 8372 is 2.198230266571045\n",
      "Evaluation Loss at Iteration @ 8372 is 2.2325193881988525\n",
      "Loss at Iteration @ 8373 is 2.0824198722839355\n",
      "Evaluation Loss at Iteration @ 8373 is 2.2313008308410645\n",
      "Loss at Iteration @ 8374 is 2.17313551902771\n",
      "Evaluation Loss at Iteration @ 8374 is 2.2780070304870605\n",
      "Loss at Iteration @ 8375 is 2.2752275466918945\n",
      "Evaluation Loss at Iteration @ 8375 is 2.257319688796997\n",
      "Loss at Iteration @ 8376 is 2.3511624336242676\n",
      "Evaluation Loss at Iteration @ 8376 is 2.2605881690979004\n",
      "Loss at Iteration @ 8377 is 2.208242177963257\n",
      "Evaluation Loss at Iteration @ 8377 is 2.2262508869171143\n",
      "Loss at Iteration @ 8378 is 2.3474655151367188\n",
      "Evaluation Loss at Iteration @ 8378 is 2.2931466102600098\n",
      "Loss at Iteration @ 8379 is 2.2544639110565186\n",
      "Evaluation Loss at Iteration @ 8379 is 2.2129693031311035\n",
      "Loss at Iteration @ 8380 is 2.4175357818603516\n",
      "Evaluation Loss at Iteration @ 8380 is 2.247042179107666\n",
      "Loss at Iteration @ 8381 is 2.0803678035736084\n",
      "Evaluation Loss at Iteration @ 8381 is 2.264385223388672\n",
      "Loss at Iteration @ 8382 is 2.2206521034240723\n",
      "Evaluation Loss at Iteration @ 8382 is 2.2361183166503906\n",
      "Loss at Iteration @ 8383 is 2.6750848293304443\n",
      "Evaluation Loss at Iteration @ 8383 is 2.288296937942505\n",
      "Loss at Iteration @ 8384 is 2.5049502849578857\n",
      "Evaluation Loss at Iteration @ 8384 is 2.263598680496216\n",
      "Loss at Iteration @ 8385 is 2.2479653358459473\n",
      "Evaluation Loss at Iteration @ 8385 is 2.2303459644317627\n",
      "Loss at Iteration @ 8386 is 2.166658878326416\n",
      "Evaluation Loss at Iteration @ 8386 is 2.248774528503418\n",
      "Loss at Iteration @ 8387 is 2.366001844406128\n",
      "Evaluation Loss at Iteration @ 8387 is 2.247286319732666\n",
      "Loss at Iteration @ 8388 is 2.350083589553833\n",
      "Evaluation Loss at Iteration @ 8388 is 2.259528160095215\n",
      "Loss at Iteration @ 8389 is 2.0226356983184814\n",
      "Evaluation Loss at Iteration @ 8389 is 2.2546002864837646\n",
      "Loss at Iteration @ 8390 is 2.212663173675537\n",
      "Evaluation Loss at Iteration @ 8390 is 2.256061315536499\n",
      "Loss at Iteration @ 8391 is 2.1786115169525146\n",
      "Evaluation Loss at Iteration @ 8391 is 2.2453339099884033\n",
      "Loss at Iteration @ 8392 is 2.1087496280670166\n",
      "Evaluation Loss at Iteration @ 8392 is 2.307589530944824\n",
      "Loss at Iteration @ 8393 is 2.225975751876831\n",
      "Evaluation Loss at Iteration @ 8393 is 2.2234604358673096\n",
      "Loss at Iteration @ 8394 is 2.1553080081939697\n",
      "Evaluation Loss at Iteration @ 8394 is 2.2289469242095947\n",
      "Loss at Iteration @ 8395 is 2.0965964794158936\n",
      "Evaluation Loss at Iteration @ 8395 is 2.271878719329834\n",
      "Loss at Iteration @ 8396 is 2.472170829772949\n",
      "Evaluation Loss at Iteration @ 8396 is 2.244492530822754\n",
      "Loss at Iteration @ 8397 is 2.1405274868011475\n",
      "Evaluation Loss at Iteration @ 8397 is 2.266334056854248\n",
      "Loss at Iteration @ 8398 is 2.4344077110290527\n",
      "Evaluation Loss at Iteration @ 8398 is 2.263204574584961\n",
      "Loss at Iteration @ 8399 is 2.4025931358337402\n",
      "Evaluation Loss at Iteration @ 8399 is 2.33585262298584\n",
      "Loss at Iteration @ 8400 is 2.1837265491485596\n",
      "Evaluation Loss at Iteration @ 8400 is 2.2283387184143066\n",
      "Loss at Iteration @ 8401 is 2.041264533996582\n",
      "Evaluation Loss at Iteration @ 8401 is 2.333571195602417\n",
      "Loss at Iteration @ 8402 is 2.0506086349487305\n",
      "Evaluation Loss at Iteration @ 8402 is 2.235416889190674\n",
      "Loss at Iteration @ 8403 is 2.1403276920318604\n",
      "Evaluation Loss at Iteration @ 8403 is 2.294036865234375\n",
      "Loss at Iteration @ 8404 is 2.036405324935913\n",
      "Evaluation Loss at Iteration @ 8404 is 2.244079828262329\n",
      "Loss at Iteration @ 8405 is 2.3346896171569824\n",
      "Evaluation Loss at Iteration @ 8405 is 2.2483158111572266\n",
      "Loss at Iteration @ 8406 is 2.208994150161743\n",
      "Evaluation Loss at Iteration @ 8406 is 2.2458243370056152\n",
      "Loss at Iteration @ 8407 is 2.2794089317321777\n",
      "Evaluation Loss at Iteration @ 8407 is 2.236654281616211\n",
      "Loss at Iteration @ 8408 is 2.3167805671691895\n",
      "Evaluation Loss at Iteration @ 8408 is 2.2519843578338623\n",
      "Loss at Iteration @ 8409 is 2.3875293731689453\n",
      "Evaluation Loss at Iteration @ 8409 is 2.278566598892212\n",
      "Loss at Iteration @ 8410 is 2.124314308166504\n",
      "Evaluation Loss at Iteration @ 8410 is 2.282970666885376\n",
      "Loss at Iteration @ 8411 is 2.1815266609191895\n",
      "Evaluation Loss at Iteration @ 8411 is 2.2382235527038574\n",
      "Loss at Iteration @ 8412 is 2.1076083183288574\n",
      "Evaluation Loss at Iteration @ 8412 is 2.215352773666382\n",
      "Loss at Iteration @ 8413 is 2.1758744716644287\n",
      "Evaluation Loss at Iteration @ 8413 is 2.2213265895843506\n",
      "Loss at Iteration @ 8414 is 2.3798305988311768\n",
      "Evaluation Loss at Iteration @ 8414 is 2.1905713081359863\n",
      "Loss at Iteration @ 8415 is 2.1117165088653564\n",
      "Evaluation Loss at Iteration @ 8415 is 2.2177910804748535\n",
      "Loss at Iteration @ 8416 is 2.0165321826934814\n",
      "Evaluation Loss at Iteration @ 8416 is 2.2051093578338623\n",
      "Loss at Iteration @ 8417 is 1.985326886177063\n",
      "Evaluation Loss at Iteration @ 8417 is 2.2247471809387207\n",
      "Loss at Iteration @ 8418 is 2.1550824642181396\n",
      "Evaluation Loss at Iteration @ 8418 is 2.2724170684814453\n",
      "Loss at Iteration @ 8419 is 2.570962905883789\n",
      "Evaluation Loss at Iteration @ 8419 is 2.274625778198242\n",
      "Loss at Iteration @ 8420 is 2.4264137744903564\n",
      "Evaluation Loss at Iteration @ 8420 is 2.24208664894104\n",
      "Loss at Iteration @ 8421 is 2.109051465988159\n",
      "Evaluation Loss at Iteration @ 8421 is 2.2422256469726562\n",
      "Loss at Iteration @ 8422 is 2.5212812423706055\n",
      "Evaluation Loss at Iteration @ 8422 is 2.278064489364624\n",
      "Loss at Iteration @ 8423 is 2.254971504211426\n",
      "Evaluation Loss at Iteration @ 8423 is 2.2328364849090576\n",
      "Loss at Iteration @ 8424 is 2.0589816570281982\n",
      "Evaluation Loss at Iteration @ 8424 is 2.2547097206115723\n",
      "Loss at Iteration @ 8425 is 2.14206862449646\n",
      "Evaluation Loss at Iteration @ 8425 is 2.241082191467285\n",
      "Loss at Iteration @ 8426 is 2.5380959510803223\n",
      "Evaluation Loss at Iteration @ 8426 is 2.1940221786499023\n",
      "Loss at Iteration @ 8427 is 2.3010101318359375\n",
      "Evaluation Loss at Iteration @ 8427 is 2.2440128326416016\n",
      "Loss at Iteration @ 8428 is 2.231895685195923\n",
      "Evaluation Loss at Iteration @ 8428 is 2.2342705726623535\n",
      "Loss at Iteration @ 8429 is 2.076927900314331\n",
      "Evaluation Loss at Iteration @ 8429 is 2.21683669090271\n",
      "Loss at Iteration @ 8430 is 2.0850608348846436\n",
      "Evaluation Loss at Iteration @ 8430 is 2.2895805835723877\n",
      "Loss at Iteration @ 8431 is 2.310412645339966\n",
      "Evaluation Loss at Iteration @ 8431 is 2.2163922786712646\n",
      "Loss at Iteration @ 8432 is 2.1111059188842773\n",
      "Evaluation Loss at Iteration @ 8432 is 2.240480899810791\n",
      "Loss at Iteration @ 8433 is 1.9362472295761108\n",
      "Evaluation Loss at Iteration @ 8433 is 2.2826485633850098\n",
      "Loss at Iteration @ 8434 is 2.560819149017334\n",
      "Evaluation Loss at Iteration @ 8434 is 2.222975969314575\n",
      "Loss at Iteration @ 8435 is 2.5570812225341797\n",
      "Evaluation Loss at Iteration @ 8435 is 2.2394375801086426\n",
      "Loss at Iteration @ 8436 is 2.2675790786743164\n",
      "Evaluation Loss at Iteration @ 8436 is 2.2398149967193604\n",
      "Loss at Iteration @ 8437 is 2.50768780708313\n",
      "Evaluation Loss at Iteration @ 8437 is 2.227309226989746\n",
      "Loss at Iteration @ 8438 is 2.4895076751708984\n",
      "Evaluation Loss at Iteration @ 8438 is 2.2117550373077393\n",
      "Loss at Iteration @ 8439 is 2.4246089458465576\n",
      "Evaluation Loss at Iteration @ 8439 is 2.234527587890625\n",
      "Loss at Iteration @ 8440 is 2.1205856800079346\n",
      "Evaluation Loss at Iteration @ 8440 is 2.247359037399292\n",
      "Loss at Iteration @ 8441 is 2.1734886169433594\n",
      "Evaluation Loss at Iteration @ 8441 is 2.1977009773254395\n",
      "Loss at Iteration @ 8442 is 2.066129207611084\n",
      "Evaluation Loss at Iteration @ 8442 is 2.2715718746185303\n",
      "Loss at Iteration @ 8443 is 2.2394542694091797\n",
      "Evaluation Loss at Iteration @ 8443 is 2.2336502075195312\n",
      "Loss at Iteration @ 8444 is 2.3994596004486084\n",
      "Evaluation Loss at Iteration @ 8444 is 2.237121820449829\n",
      "Loss at Iteration @ 8445 is 2.33638334274292\n",
      "Evaluation Loss at Iteration @ 8445 is 2.25233793258667\n",
      "Loss at Iteration @ 8446 is 2.1833608150482178\n",
      "Evaluation Loss at Iteration @ 8446 is 2.2291109561920166\n",
      "Loss at Iteration @ 8447 is 2.3145670890808105\n",
      "Evaluation Loss at Iteration @ 8447 is 2.2394258975982666\n",
      "Loss at Iteration @ 8448 is 2.281723976135254\n",
      "Evaluation Loss at Iteration @ 8448 is 2.259777069091797\n",
      "Loss at Iteration @ 8449 is 2.2668585777282715\n",
      "Evaluation Loss at Iteration @ 8449 is 2.232781171798706\n",
      "Loss at Iteration @ 8450 is 1.9853872060775757\n",
      "Evaluation Loss at Iteration @ 8450 is 2.2580454349517822\n",
      "Loss at Iteration @ 8451 is 2.1034224033355713\n",
      "Evaluation Loss at Iteration @ 8451 is 2.255159378051758\n",
      "Loss at Iteration @ 8452 is 2.2167282104492188\n",
      "Evaluation Loss at Iteration @ 8452 is 2.2559351921081543\n",
      "Loss at Iteration @ 8453 is 2.1947460174560547\n",
      "Evaluation Loss at Iteration @ 8453 is 2.213406562805176\n",
      "Loss at Iteration @ 8454 is 2.2423832416534424\n",
      "Evaluation Loss at Iteration @ 8454 is 2.263889789581299\n",
      "Loss at Iteration @ 8455 is 2.2053511142730713\n",
      "Evaluation Loss at Iteration @ 8455 is 2.2828986644744873\n",
      "Loss at Iteration @ 8456 is 1.9123988151550293\n",
      "Evaluation Loss at Iteration @ 8456 is 2.2242350578308105\n",
      "Loss at Iteration @ 8457 is 2.2879955768585205\n",
      "Evaluation Loss at Iteration @ 8457 is 2.3118176460266113\n",
      "Loss at Iteration @ 8458 is 2.220508575439453\n",
      "Evaluation Loss at Iteration @ 8458 is 2.307220935821533\n",
      "Loss at Iteration @ 8459 is 2.2092173099517822\n",
      "Evaluation Loss at Iteration @ 8459 is 2.2363533973693848\n",
      "Loss at Iteration @ 8460 is 2.0730676651000977\n",
      "Evaluation Loss at Iteration @ 8460 is 2.2687160968780518\n",
      "Loss at Iteration @ 8461 is 2.149977684020996\n",
      "Evaluation Loss at Iteration @ 8461 is 2.2460739612579346\n",
      "Loss at Iteration @ 8462 is 2.103255271911621\n",
      "Evaluation Loss at Iteration @ 8462 is 2.3260998725891113\n",
      "Loss at Iteration @ 8463 is 2.154118776321411\n",
      "Evaluation Loss at Iteration @ 8463 is 2.301091432571411\n",
      "Loss at Iteration @ 8464 is 2.415642023086548\n",
      "Evaluation Loss at Iteration @ 8464 is 2.263016939163208\n",
      "Loss at Iteration @ 8465 is 2.224041700363159\n",
      "Evaluation Loss at Iteration @ 8465 is 2.2936935424804688\n",
      "Loss at Iteration @ 8466 is 2.433577060699463\n",
      "Evaluation Loss at Iteration @ 8466 is 2.2940175533294678\n",
      "Loss at Iteration @ 8467 is 2.010342597961426\n",
      "Evaluation Loss at Iteration @ 8467 is 2.253199815750122\n",
      "Loss at Iteration @ 8468 is 2.327279806137085\n",
      "Evaluation Loss at Iteration @ 8468 is 2.2079622745513916\n",
      "Loss at Iteration @ 8469 is 2.2731027603149414\n",
      "Evaluation Loss at Iteration @ 8469 is 2.2921736240386963\n",
      "Loss at Iteration @ 8470 is 2.371997594833374\n",
      "Evaluation Loss at Iteration @ 8470 is 2.224975824356079\n",
      "Loss at Iteration @ 8471 is 2.2530465126037598\n",
      "Evaluation Loss at Iteration @ 8471 is 2.2099392414093018\n",
      "Loss at Iteration @ 8472 is 2.1266849040985107\n",
      "Evaluation Loss at Iteration @ 8472 is 2.2846171855926514\n",
      "Loss at Iteration @ 8473 is 1.9465452432632446\n",
      "Evaluation Loss at Iteration @ 8473 is 2.275521993637085\n",
      "Loss at Iteration @ 8474 is 2.1482222080230713\n",
      "Evaluation Loss at Iteration @ 8474 is 2.2477757930755615\n",
      "Loss at Iteration @ 8475 is 2.205655097961426\n",
      "Evaluation Loss at Iteration @ 8475 is 2.2631466388702393\n",
      "Loss at Iteration @ 8476 is 2.0885207653045654\n",
      "Evaluation Loss at Iteration @ 8476 is 2.262468099594116\n",
      "Loss at Iteration @ 8477 is 2.366710662841797\n",
      "Evaluation Loss at Iteration @ 8477 is 2.272104501724243\n",
      "Loss at Iteration @ 8478 is 2.0867106914520264\n",
      "Evaluation Loss at Iteration @ 8478 is 2.249225616455078\n",
      "Loss at Iteration @ 8479 is 2.4210197925567627\n",
      "Evaluation Loss at Iteration @ 8479 is 2.2662429809570312\n",
      "Loss at Iteration @ 8480 is 1.983140230178833\n",
      "Evaluation Loss at Iteration @ 8480 is 2.281881332397461\n",
      "Loss at Iteration @ 8481 is 2.4594781398773193\n",
      "Evaluation Loss at Iteration @ 8481 is 2.2439088821411133\n",
      "Loss at Iteration @ 8482 is 2.445918560028076\n",
      "Evaluation Loss at Iteration @ 8482 is 2.262364149093628\n",
      "Loss at Iteration @ 8483 is 2.1811206340789795\n",
      "Evaluation Loss at Iteration @ 8483 is 2.2650959491729736\n",
      "Loss at Iteration @ 8484 is 1.9986470937728882\n",
      "Evaluation Loss at Iteration @ 8484 is 2.2534966468811035\n",
      "Loss at Iteration @ 8485 is 2.2469518184661865\n",
      "Evaluation Loss at Iteration @ 8485 is 2.2885749340057373\n",
      "Loss at Iteration @ 8486 is 2.652625322341919\n",
      "Evaluation Loss at Iteration @ 8486 is 2.282402753829956\n",
      "Loss at Iteration @ 8487 is 2.00957989692688\n",
      "Evaluation Loss at Iteration @ 8487 is 2.2424042224884033\n",
      "Loss at Iteration @ 8488 is 2.186525583267212\n",
      "Evaluation Loss at Iteration @ 8488 is 2.236020803451538\n",
      "Loss at Iteration @ 8489 is 2.345928192138672\n",
      "Evaluation Loss at Iteration @ 8489 is 2.2332427501678467\n",
      "Loss at Iteration @ 8490 is 2.0557961463928223\n",
      "Evaluation Loss at Iteration @ 8490 is 2.2580087184906006\n",
      "Loss at Iteration @ 8491 is 2.026787042617798\n",
      "Evaluation Loss at Iteration @ 8491 is 2.283099889755249\n",
      "Loss at Iteration @ 8492 is 2.3466415405273438\n",
      "Evaluation Loss at Iteration @ 8492 is 2.2210378646850586\n",
      "Loss at Iteration @ 8493 is 2.0597641468048096\n",
      "Evaluation Loss at Iteration @ 8493 is 2.2185983657836914\n",
      "Loss at Iteration @ 8494 is 1.933266043663025\n",
      "Evaluation Loss at Iteration @ 8494 is 2.2630112171173096\n",
      "Loss at Iteration @ 8495 is 2.466768264770508\n",
      "Evaluation Loss at Iteration @ 8495 is 2.197897434234619\n",
      "Loss at Iteration @ 8496 is 2.3440778255462646\n",
      "Evaluation Loss at Iteration @ 8496 is 2.3126683235168457\n",
      "Loss at Iteration @ 8497 is 2.165801525115967\n",
      "Evaluation Loss at Iteration @ 8497 is 2.221731424331665\n",
      "Loss at Iteration @ 8498 is 2.187131404876709\n",
      "Evaluation Loss at Iteration @ 8498 is 2.275503158569336\n",
      "Loss at Iteration @ 8499 is 2.1929497718811035\n",
      "Evaluation Loss at Iteration @ 8499 is 2.2634522914886475\n",
      "Loss at Iteration @ 8500 is 2.523347854614258\n",
      "Evaluation Loss at Iteration @ 8500 is 2.263350009918213\n",
      "Loss at Iteration @ 8501 is 2.2371628284454346\n",
      "Evaluation Loss at Iteration @ 8501 is 2.2852060794830322\n",
      "Loss at Iteration @ 8502 is 1.9802418947219849\n",
      "Evaluation Loss at Iteration @ 8502 is 2.2004024982452393\n",
      "Loss at Iteration @ 8503 is 2.2539474964141846\n",
      "Evaluation Loss at Iteration @ 8503 is 2.218346118927002\n",
      "Loss at Iteration @ 8504 is 2.384336471557617\n",
      "Evaluation Loss at Iteration @ 8504 is 2.2723801136016846\n",
      "Loss at Iteration @ 8505 is 2.298726797103882\n",
      "Evaluation Loss at Iteration @ 8505 is 2.267197370529175\n",
      "Loss at Iteration @ 8506 is 2.019442319869995\n",
      "Evaluation Loss at Iteration @ 8506 is 2.2495310306549072\n",
      "Loss at Iteration @ 8507 is 2.237473487854004\n",
      "Evaluation Loss at Iteration @ 8507 is 2.2835853099823\n",
      "Loss at Iteration @ 8508 is 2.211515188217163\n",
      "Evaluation Loss at Iteration @ 8508 is 2.2203826904296875\n",
      "Loss at Iteration @ 8509 is 2.358344554901123\n",
      "Evaluation Loss at Iteration @ 8509 is 2.1600358486175537\n",
      "Loss at Iteration @ 8510 is 2.166468381881714\n",
      "Evaluation Loss at Iteration @ 8510 is 2.221879720687866\n",
      "Loss at Iteration @ 8511 is 2.1496548652648926\n",
      "Evaluation Loss at Iteration @ 8511 is 2.26082444190979\n",
      "Loss at Iteration @ 8512 is 2.0698955059051514\n",
      "Evaluation Loss at Iteration @ 8512 is 2.2636959552764893\n",
      "Loss at Iteration @ 8513 is 2.220717191696167\n",
      "Evaluation Loss at Iteration @ 8513 is 2.226459264755249\n",
      "Loss at Iteration @ 8514 is 2.1255223751068115\n",
      "Evaluation Loss at Iteration @ 8514 is 2.256883382797241\n",
      "Loss at Iteration @ 8515 is 2.34502911567688\n",
      "Evaluation Loss at Iteration @ 8515 is 2.249166488647461\n",
      "Loss at Iteration @ 8516 is 1.9555009603500366\n",
      "Evaluation Loss at Iteration @ 8516 is 2.2535552978515625\n",
      "Loss at Iteration @ 8517 is 2.109220027923584\n",
      "Evaluation Loss at Iteration @ 8517 is 2.2379519939422607\n",
      "Loss at Iteration @ 8518 is 2.2935361862182617\n",
      "Evaluation Loss at Iteration @ 8518 is 2.271763563156128\n",
      "Loss at Iteration @ 8519 is 1.9878333806991577\n",
      "Evaluation Loss at Iteration @ 8519 is 2.288999319076538\n",
      "Loss at Iteration @ 8520 is 2.3057432174682617\n",
      "Evaluation Loss at Iteration @ 8520 is 2.2566144466400146\n",
      "Loss at Iteration @ 8521 is 2.301476001739502\n",
      "Evaluation Loss at Iteration @ 8521 is 2.2399063110351562\n",
      "Loss at Iteration @ 8522 is 2.399191379547119\n",
      "Evaluation Loss at Iteration @ 8522 is 2.25784969329834\n",
      "Loss at Iteration @ 8523 is 2.391768217086792\n",
      "Evaluation Loss at Iteration @ 8523 is 2.2513718605041504\n",
      "Loss at Iteration @ 8524 is 2.284536361694336\n",
      "Evaluation Loss at Iteration @ 8524 is 2.2286174297332764\n",
      "Loss at Iteration @ 8525 is 2.578352212905884\n",
      "Evaluation Loss at Iteration @ 8525 is 2.2413060665130615\n",
      "Loss at Iteration @ 8526 is 2.310666561126709\n",
      "Evaluation Loss at Iteration @ 8526 is 2.213711977005005\n",
      "Loss at Iteration @ 8527 is 2.4134769439697266\n",
      "Evaluation Loss at Iteration @ 8527 is 2.2348697185516357\n",
      "Loss at Iteration @ 8528 is 2.2502822875976562\n",
      "Evaluation Loss at Iteration @ 8528 is 2.234452962875366\n",
      "Loss at Iteration @ 8529 is 2.0243070125579834\n",
      "Evaluation Loss at Iteration @ 8529 is 2.2047414779663086\n",
      "Loss at Iteration @ 8530 is 2.225339889526367\n",
      "Evaluation Loss at Iteration @ 8530 is 2.273266315460205\n",
      "Loss at Iteration @ 8531 is 2.309739828109741\n",
      "Evaluation Loss at Iteration @ 8531 is 2.2397491931915283\n",
      "Loss at Iteration @ 8532 is 1.9091932773590088\n",
      "Evaluation Loss at Iteration @ 8532 is 2.2760307788848877\n",
      "Loss at Iteration @ 8533 is 2.4390151500701904\n",
      "Evaluation Loss at Iteration @ 8533 is 2.269270658493042\n",
      "Loss at Iteration @ 8534 is 2.388122797012329\n",
      "Evaluation Loss at Iteration @ 8534 is 2.2485458850860596\n",
      "Loss at Iteration @ 8535 is 2.117323398590088\n",
      "Evaluation Loss at Iteration @ 8535 is 2.2618114948272705\n",
      "Loss at Iteration @ 8536 is 2.1395986080169678\n",
      "Evaluation Loss at Iteration @ 8536 is 2.2057669162750244\n",
      "Loss at Iteration @ 8537 is 2.3718574047088623\n",
      "Evaluation Loss at Iteration @ 8537 is 2.2893009185791016\n",
      "Loss at Iteration @ 8538 is 2.043354034423828\n",
      "Evaluation Loss at Iteration @ 8538 is 2.296312093734741\n",
      "Loss at Iteration @ 8539 is 2.1319615840911865\n",
      "Evaluation Loss at Iteration @ 8539 is 2.2117462158203125\n",
      "Loss at Iteration @ 8540 is 2.4014174938201904\n",
      "Evaluation Loss at Iteration @ 8540 is 2.2524750232696533\n",
      "Loss at Iteration @ 8541 is 1.8793797492980957\n",
      "Evaluation Loss at Iteration @ 8541 is 2.305345296859741\n",
      "Loss at Iteration @ 8542 is 2.302189826965332\n",
      "Evaluation Loss at Iteration @ 8542 is 2.1938631534576416\n",
      "Loss at Iteration @ 8543 is 2.15377140045166\n",
      "Evaluation Loss at Iteration @ 8543 is 2.2267985343933105\n",
      "Loss at Iteration @ 8544 is 2.1928811073303223\n",
      "Evaluation Loss at Iteration @ 8544 is 2.197260856628418\n",
      "Loss at Iteration @ 8545 is 2.087913751602173\n",
      "Evaluation Loss at Iteration @ 8545 is 2.269224166870117\n",
      "Loss at Iteration @ 8546 is 2.3769192695617676\n",
      "Evaluation Loss at Iteration @ 8546 is 2.2223825454711914\n",
      "Loss at Iteration @ 8547 is 1.9772794246673584\n",
      "Evaluation Loss at Iteration @ 8547 is 2.2897696495056152\n",
      "Loss at Iteration @ 8548 is 2.1484029293060303\n",
      "Evaluation Loss at Iteration @ 8548 is 2.2347168922424316\n",
      "Loss at Iteration @ 8549 is 2.2166519165039062\n",
      "Evaluation Loss at Iteration @ 8549 is 2.2598648071289062\n",
      "Loss at Iteration @ 8550 is 2.2485032081604004\n",
      "Evaluation Loss at Iteration @ 8550 is 2.2552905082702637\n",
      "Loss at Iteration @ 8551 is 2.172419309616089\n",
      "Evaluation Loss at Iteration @ 8551 is 2.2534995079040527\n",
      "Loss at Iteration @ 8552 is 2.2454440593719482\n",
      "Evaluation Loss at Iteration @ 8552 is 2.2363176345825195\n",
      "Loss at Iteration @ 8553 is 2.557093381881714\n",
      "Evaluation Loss at Iteration @ 8553 is 2.2177236080169678\n",
      "Loss at Iteration @ 8554 is 2.072396755218506\n",
      "Evaluation Loss at Iteration @ 8554 is 2.278712272644043\n",
      "Loss at Iteration @ 8555 is 2.35744571685791\n",
      "Evaluation Loss at Iteration @ 8555 is 2.2509653568267822\n",
      "Loss at Iteration @ 8556 is 2.277099609375\n",
      "Evaluation Loss at Iteration @ 8556 is 2.248685836791992\n",
      "Loss at Iteration @ 8557 is 2.6376686096191406\n",
      "Evaluation Loss at Iteration @ 8557 is 2.268930196762085\n",
      "Loss at Iteration @ 8558 is 2.223867177963257\n",
      "Evaluation Loss at Iteration @ 8558 is 2.2992985248565674\n",
      "Loss at Iteration @ 8559 is 2.35577654838562\n",
      "Evaluation Loss at Iteration @ 8559 is 2.2414658069610596\n",
      "Loss at Iteration @ 8560 is 2.35800838470459\n",
      "Evaluation Loss at Iteration @ 8560 is 2.2529444694519043\n",
      "Loss at Iteration @ 8561 is 2.1665940284729004\n",
      "Evaluation Loss at Iteration @ 8561 is 2.2871785163879395\n",
      "Loss at Iteration @ 8562 is 2.3236169815063477\n",
      "Evaluation Loss at Iteration @ 8562 is 2.239666223526001\n",
      "Loss at Iteration @ 8563 is 2.057891607284546\n",
      "Evaluation Loss at Iteration @ 8563 is 2.230515241622925\n",
      "Loss at Iteration @ 8564 is 2.3287370204925537\n",
      "Evaluation Loss at Iteration @ 8564 is 2.272491216659546\n",
      "Loss at Iteration @ 8565 is 2.517153739929199\n",
      "Evaluation Loss at Iteration @ 8565 is 2.2767584323883057\n",
      "Loss at Iteration @ 8566 is 2.241863965988159\n",
      "Evaluation Loss at Iteration @ 8566 is 2.233289957046509\n",
      "Loss at Iteration @ 8567 is 2.0676825046539307\n",
      "Evaluation Loss at Iteration @ 8567 is 2.2328622341156006\n",
      "Loss at Iteration @ 8568 is 2.3988633155822754\n",
      "Evaluation Loss at Iteration @ 8568 is 2.267153263092041\n",
      "Loss at Iteration @ 8569 is 2.1128132343292236\n",
      "Evaluation Loss at Iteration @ 8569 is 2.2260050773620605\n",
      "Loss at Iteration @ 8570 is 2.165985107421875\n",
      "Evaluation Loss at Iteration @ 8570 is 2.284897804260254\n",
      "Loss at Iteration @ 8571 is 2.0685362815856934\n",
      "Evaluation Loss at Iteration @ 8571 is 2.264146089553833\n",
      "Loss at Iteration @ 8572 is 2.188416004180908\n",
      "Evaluation Loss at Iteration @ 8572 is 2.274066925048828\n",
      "Loss at Iteration @ 8573 is 2.42570161819458\n",
      "Evaluation Loss at Iteration @ 8573 is 2.296813488006592\n",
      "Loss at Iteration @ 8574 is 2.278937339782715\n",
      "Evaluation Loss at Iteration @ 8574 is 2.2863645553588867\n",
      "Loss at Iteration @ 8575 is 2.2458434104919434\n",
      "Evaluation Loss at Iteration @ 8575 is 2.2875194549560547\n",
      "Loss at Iteration @ 8576 is 2.4867990016937256\n",
      "Evaluation Loss at Iteration @ 8576 is 2.247854232788086\n",
      "Loss at Iteration @ 8577 is 2.2262203693389893\n",
      "Evaluation Loss at Iteration @ 8577 is 2.235992908477783\n",
      "Loss at Iteration @ 8578 is 2.394134044647217\n",
      "Evaluation Loss at Iteration @ 8578 is 2.2356362342834473\n",
      "Loss at Iteration @ 8579 is 2.0103330612182617\n",
      "Evaluation Loss at Iteration @ 8579 is 2.2484090328216553\n",
      "Loss at Iteration @ 8580 is 2.4551639556884766\n",
      "Evaluation Loss at Iteration @ 8580 is 2.21765398979187\n",
      "Loss at Iteration @ 8581 is 2.2790451049804688\n",
      "Evaluation Loss at Iteration @ 8581 is 2.298243761062622\n",
      "Loss at Iteration @ 8582 is 2.1112701892852783\n",
      "Evaluation Loss at Iteration @ 8582 is 2.256140947341919\n",
      "Loss at Iteration @ 8583 is 2.284684419631958\n",
      "Evaluation Loss at Iteration @ 8583 is 2.2750353813171387\n",
      "Loss at Iteration @ 8584 is 2.126880168914795\n",
      "Evaluation Loss at Iteration @ 8584 is 2.2591822147369385\n",
      "Loss at Iteration @ 8585 is 2.5106089115142822\n",
      "Evaluation Loss at Iteration @ 8585 is 2.2602779865264893\n",
      "Loss at Iteration @ 8586 is 2.464167356491089\n",
      "Evaluation Loss at Iteration @ 8586 is 2.2346041202545166\n",
      "Loss at Iteration @ 8587 is 2.3135454654693604\n",
      "Evaluation Loss at Iteration @ 8587 is 2.271101236343384\n",
      "Loss at Iteration @ 8588 is 2.336643695831299\n",
      "Evaluation Loss at Iteration @ 8588 is 2.2394325733184814\n",
      "Loss at Iteration @ 8589 is 2.296628475189209\n",
      "Evaluation Loss at Iteration @ 8589 is 2.2405202388763428\n",
      "Loss at Iteration @ 8590 is 2.178154468536377\n",
      "Evaluation Loss at Iteration @ 8590 is 2.218797445297241\n",
      "Loss at Iteration @ 8591 is 2.2113096714019775\n",
      "Evaluation Loss at Iteration @ 8591 is 2.281693696975708\n",
      "Loss at Iteration @ 8592 is 2.5890707969665527\n",
      "Evaluation Loss at Iteration @ 8592 is 2.22914457321167\n",
      "Loss at Iteration @ 8593 is 2.194282054901123\n",
      "Evaluation Loss at Iteration @ 8593 is 2.2753219604492188\n",
      "Loss at Iteration @ 8594 is 2.4202229976654053\n",
      "Evaluation Loss at Iteration @ 8594 is 2.3070180416107178\n",
      "Loss at Iteration @ 8595 is 2.227222204208374\n",
      "Evaluation Loss at Iteration @ 8595 is 2.297595977783203\n",
      "Loss at Iteration @ 8596 is 2.1734681129455566\n",
      "Evaluation Loss at Iteration @ 8596 is 2.2580373287200928\n",
      "Loss at Iteration @ 8597 is 2.119724988937378\n",
      "Evaluation Loss at Iteration @ 8597 is 2.230203628540039\n",
      "Loss at Iteration @ 8598 is 2.0213911533355713\n",
      "Evaluation Loss at Iteration @ 8598 is 2.297334909439087\n",
      "Loss at Iteration @ 8599 is 2.3487472534179688\n",
      "Evaluation Loss at Iteration @ 8599 is 2.2181191444396973\n",
      "Loss at Iteration @ 8600 is 2.4995007514953613\n",
      "Evaluation Loss at Iteration @ 8600 is 2.2317233085632324\n",
      "Loss at Iteration @ 8601 is 2.393688201904297\n",
      "Evaluation Loss at Iteration @ 8601 is 2.287567138671875\n",
      "Loss at Iteration @ 8602 is 2.147721529006958\n",
      "Evaluation Loss at Iteration @ 8602 is 2.2903640270233154\n",
      "Loss at Iteration @ 8603 is 2.1955032348632812\n",
      "Evaluation Loss at Iteration @ 8603 is 2.2432429790496826\n",
      "Loss at Iteration @ 8604 is 2.4124913215637207\n",
      "Evaluation Loss at Iteration @ 8604 is 2.231985569000244\n",
      "Loss at Iteration @ 8605 is 2.476854085922241\n",
      "Evaluation Loss at Iteration @ 8605 is 2.234234094619751\n",
      "Loss at Iteration @ 8606 is 2.1130621433258057\n",
      "Evaluation Loss at Iteration @ 8606 is 2.226174831390381\n",
      "Loss at Iteration @ 8607 is 1.970064640045166\n",
      "Evaluation Loss at Iteration @ 8607 is 2.2839574813842773\n",
      "Loss at Iteration @ 8608 is 1.9520283937454224\n",
      "Evaluation Loss at Iteration @ 8608 is 2.2489075660705566\n",
      "Loss at Iteration @ 8609 is 2.215888261795044\n",
      "Evaluation Loss at Iteration @ 8609 is 2.261988878250122\n",
      "Loss at Iteration @ 8610 is 2.313819169998169\n",
      "Evaluation Loss at Iteration @ 8610 is 2.210338592529297\n",
      "Loss at Iteration @ 8611 is 2.456494092941284\n",
      "Evaluation Loss at Iteration @ 8611 is 2.262737274169922\n",
      "Loss at Iteration @ 8612 is 2.312544822692871\n",
      "Evaluation Loss at Iteration @ 8612 is 2.285193681716919\n",
      "Loss at Iteration @ 8613 is 2.0728330612182617\n",
      "Evaluation Loss at Iteration @ 8613 is 2.1860926151275635\n",
      "Loss at Iteration @ 8614 is 2.196214199066162\n",
      "Evaluation Loss at Iteration @ 8614 is 2.28631591796875\n",
      "Loss at Iteration @ 8615 is 2.252568244934082\n",
      "Evaluation Loss at Iteration @ 8615 is 2.2399778366088867\n",
      "Loss at Iteration @ 8616 is 2.332547664642334\n",
      "Evaluation Loss at Iteration @ 8616 is 2.287074565887451\n",
      "Loss at Iteration @ 8617 is 2.3939871788024902\n",
      "Evaluation Loss at Iteration @ 8617 is 2.2805275917053223\n",
      "Loss at Iteration @ 8618 is 2.426300525665283\n",
      "Evaluation Loss at Iteration @ 8618 is 2.2685024738311768\n",
      "Loss at Iteration @ 8619 is 2.17539644241333\n",
      "Evaluation Loss at Iteration @ 8619 is 2.2456517219543457\n",
      "Loss at Iteration @ 8620 is 2.44038462638855\n",
      "Evaluation Loss at Iteration @ 8620 is 2.2584636211395264\n",
      "Loss at Iteration @ 8621 is 2.51724910736084\n",
      "Evaluation Loss at Iteration @ 8621 is 2.194812536239624\n",
      "Loss at Iteration @ 8622 is 1.8586806058883667\n",
      "Evaluation Loss at Iteration @ 8622 is 2.2590432167053223\n",
      "Loss at Iteration @ 8623 is 2.255481719970703\n",
      "Evaluation Loss at Iteration @ 8623 is 2.20285964012146\n",
      "Loss at Iteration @ 8624 is 2.2344295978546143\n",
      "Evaluation Loss at Iteration @ 8624 is 2.2599692344665527\n",
      "Loss at Iteration @ 8625 is 2.054257869720459\n",
      "Evaluation Loss at Iteration @ 8625 is 2.261467933654785\n",
      "Loss at Iteration @ 8626 is 2.2165400981903076\n",
      "Evaluation Loss at Iteration @ 8626 is 2.2767128944396973\n",
      "Loss at Iteration @ 8627 is 1.8872909545898438\n",
      "Evaluation Loss at Iteration @ 8627 is 2.2638161182403564\n",
      "Loss at Iteration @ 8628 is 2.125331401824951\n",
      "Evaluation Loss at Iteration @ 8628 is 2.227672815322876\n",
      "Loss at Iteration @ 8629 is 2.1881604194641113\n",
      "Evaluation Loss at Iteration @ 8629 is 2.285202741622925\n",
      "Loss at Iteration @ 8630 is 2.1843764781951904\n",
      "Evaluation Loss at Iteration @ 8630 is 2.2674577236175537\n",
      "Loss at Iteration @ 8631 is 2.505436420440674\n",
      "Evaluation Loss at Iteration @ 8631 is 2.2020044326782227\n",
      "Loss at Iteration @ 8632 is 2.057687759399414\n",
      "Evaluation Loss at Iteration @ 8632 is 2.2338099479675293\n",
      "Loss at Iteration @ 8633 is 2.503373861312866\n",
      "Evaluation Loss at Iteration @ 8633 is 2.253983974456787\n",
      "Loss at Iteration @ 8634 is 2.251832962036133\n",
      "Evaluation Loss at Iteration @ 8634 is 2.215012550354004\n",
      "Loss at Iteration @ 8635 is 1.9706603288650513\n",
      "Evaluation Loss at Iteration @ 8635 is 2.24680757522583\n",
      "Loss at Iteration @ 8636 is 2.513841390609741\n",
      "Evaluation Loss at Iteration @ 8636 is 2.236018657684326\n",
      "Loss at Iteration @ 8637 is 2.137484550476074\n",
      "Evaluation Loss at Iteration @ 8637 is 2.2575433254241943\n",
      "Loss at Iteration @ 8638 is 2.40010404586792\n",
      "Evaluation Loss at Iteration @ 8638 is 2.2311904430389404\n",
      "Loss at Iteration @ 8639 is 2.240995407104492\n",
      "Evaluation Loss at Iteration @ 8639 is 2.1886239051818848\n",
      "Loss at Iteration @ 8640 is 2.4207921028137207\n",
      "Evaluation Loss at Iteration @ 8640 is 2.221892833709717\n",
      "Loss at Iteration @ 8641 is 2.312448024749756\n",
      "Evaluation Loss at Iteration @ 8641 is 2.2779574394226074\n",
      "Loss at Iteration @ 8642 is 2.434122323989868\n",
      "Evaluation Loss at Iteration @ 8642 is 2.240213394165039\n",
      "Loss at Iteration @ 8643 is 2.1354763507843018\n",
      "Evaluation Loss at Iteration @ 8643 is 2.251309871673584\n",
      "Loss at Iteration @ 8644 is 2.0892019271850586\n",
      "Evaluation Loss at Iteration @ 8644 is 2.245577335357666\n",
      "Loss at Iteration @ 8645 is 2.147176504135132\n",
      "Evaluation Loss at Iteration @ 8645 is 2.2470409870147705\n",
      "Loss at Iteration @ 8646 is 2.2506697177886963\n",
      "Evaluation Loss at Iteration @ 8646 is 2.2749805450439453\n",
      "Loss at Iteration @ 8647 is 2.224039316177368\n",
      "Evaluation Loss at Iteration @ 8647 is 2.265608549118042\n",
      "Loss at Iteration @ 8648 is 2.072080135345459\n",
      "Evaluation Loss at Iteration @ 8648 is 2.2972097396850586\n",
      "Loss at Iteration @ 8649 is 2.3301682472229004\n",
      "Evaluation Loss at Iteration @ 8649 is 2.255362033843994\n",
      "Loss at Iteration @ 8650 is 2.2506442070007324\n",
      "Evaluation Loss at Iteration @ 8650 is 2.2373344898223877\n",
      "Loss at Iteration @ 8651 is 2.346784830093384\n",
      "Evaluation Loss at Iteration @ 8651 is 2.2189748287200928\n",
      "Loss at Iteration @ 8652 is 2.018545627593994\n",
      "Evaluation Loss at Iteration @ 8652 is 2.2827157974243164\n",
      "Loss at Iteration @ 8653 is 2.037952184677124\n",
      "Evaluation Loss at Iteration @ 8653 is 2.2188994884490967\n",
      "Loss at Iteration @ 8654 is 2.423841953277588\n",
      "Evaluation Loss at Iteration @ 8654 is 2.23349666595459\n",
      "Loss at Iteration @ 8655 is 2.5428860187530518\n",
      "Evaluation Loss at Iteration @ 8655 is 2.241157054901123\n",
      "Loss at Iteration @ 8656 is 2.1907589435577393\n",
      "Evaluation Loss at Iteration @ 8656 is 2.2315309047698975\n",
      "Loss at Iteration @ 8657 is 2.3385391235351562\n",
      "Evaluation Loss at Iteration @ 8657 is 2.2195348739624023\n",
      "Loss at Iteration @ 8658 is 2.3175346851348877\n",
      "Evaluation Loss at Iteration @ 8658 is 2.2626841068267822\n",
      "Loss at Iteration @ 8659 is 2.2275466918945312\n",
      "Evaluation Loss at Iteration @ 8659 is 2.2442102432250977\n",
      "Loss at Iteration @ 8660 is 2.261014223098755\n",
      "Evaluation Loss at Iteration @ 8660 is 2.252204656600952\n",
      "Loss at Iteration @ 8661 is 2.112215757369995\n",
      "Evaluation Loss at Iteration @ 8661 is 2.2403135299682617\n",
      "Loss at Iteration @ 8662 is 2.0024304389953613\n",
      "Evaluation Loss at Iteration @ 8662 is 2.3007164001464844\n",
      "Loss at Iteration @ 8663 is 2.306582450866699\n",
      "Evaluation Loss at Iteration @ 8663 is 2.242766857147217\n",
      "Loss at Iteration @ 8664 is 2.279508590698242\n",
      "Evaluation Loss at Iteration @ 8664 is 2.28817081451416\n",
      "Loss at Iteration @ 8665 is 2.266517162322998\n",
      "Evaluation Loss at Iteration @ 8665 is 2.265587568283081\n",
      "Loss at Iteration @ 8666 is 2.2862987518310547\n",
      "Evaluation Loss at Iteration @ 8666 is 2.2437198162078857\n",
      "Loss at Iteration @ 8667 is 2.2443058490753174\n",
      "Evaluation Loss at Iteration @ 8667 is 2.241455316543579\n",
      "Loss at Iteration @ 8668 is 2.166773557662964\n",
      "Evaluation Loss at Iteration @ 8668 is 2.3239777088165283\n",
      "Loss at Iteration @ 8669 is 2.4414191246032715\n",
      "Evaluation Loss at Iteration @ 8669 is 2.222783327102661\n",
      "Loss at Iteration @ 8670 is 2.071075677871704\n",
      "Evaluation Loss at Iteration @ 8670 is 2.256229877471924\n",
      "Loss at Iteration @ 8671 is 2.3463289737701416\n",
      "Evaluation Loss at Iteration @ 8671 is 2.2328131198883057\n",
      "Loss at Iteration @ 8672 is 2.3204877376556396\n",
      "Evaluation Loss at Iteration @ 8672 is 2.194690704345703\n",
      "Loss at Iteration @ 8673 is 2.061046838760376\n",
      "Evaluation Loss at Iteration @ 8673 is 2.2574098110198975\n",
      "Loss at Iteration @ 8674 is 2.016474485397339\n",
      "Evaluation Loss at Iteration @ 8674 is 2.2833805084228516\n",
      "Loss at Iteration @ 8675 is 2.102186441421509\n",
      "Evaluation Loss at Iteration @ 8675 is 2.303570032119751\n",
      "Loss at Iteration @ 8676 is 2.0540993213653564\n",
      "Evaluation Loss at Iteration @ 8676 is 2.303165912628174\n",
      "Loss at Iteration @ 8677 is 1.9536938667297363\n",
      "Evaluation Loss at Iteration @ 8677 is 2.2390899658203125\n",
      "Loss at Iteration @ 8678 is 2.3170228004455566\n",
      "Evaluation Loss at Iteration @ 8678 is 2.2236413955688477\n",
      "Loss at Iteration @ 8679 is 2.3780155181884766\n",
      "Evaluation Loss at Iteration @ 8679 is 2.2232115268707275\n",
      "Loss at Iteration @ 8680 is 2.1607449054718018\n",
      "Evaluation Loss at Iteration @ 8680 is 2.233708620071411\n",
      "Loss at Iteration @ 8681 is 2.06632137298584\n",
      "Evaluation Loss at Iteration @ 8681 is 2.2678844928741455\n",
      "Loss at Iteration @ 8682 is 2.1155970096588135\n",
      "Evaluation Loss at Iteration @ 8682 is 2.2808098793029785\n",
      "Loss at Iteration @ 8683 is 2.319607973098755\n",
      "Evaluation Loss at Iteration @ 8683 is 2.223335027694702\n",
      "Loss at Iteration @ 8684 is 2.2935221195220947\n",
      "Evaluation Loss at Iteration @ 8684 is 2.221853733062744\n",
      "Loss at Iteration @ 8685 is 2.310060977935791\n",
      "Evaluation Loss at Iteration @ 8685 is 2.2047996520996094\n",
      "Loss at Iteration @ 8686 is 2.281273126602173\n",
      "Evaluation Loss at Iteration @ 8686 is 2.2620763778686523\n",
      "Loss at Iteration @ 8687 is 2.4915051460266113\n",
      "Evaluation Loss at Iteration @ 8687 is 2.229318618774414\n",
      "Loss at Iteration @ 8688 is 2.433246374130249\n",
      "Evaluation Loss at Iteration @ 8688 is 2.2769153118133545\n",
      "Loss at Iteration @ 8689 is 2.696115493774414\n",
      "Evaluation Loss at Iteration @ 8689 is 2.2389614582061768\n",
      "Loss at Iteration @ 8690 is 2.304678440093994\n",
      "Evaluation Loss at Iteration @ 8690 is 2.2369322776794434\n",
      "Loss at Iteration @ 8691 is 2.3159375190734863\n",
      "Evaluation Loss at Iteration @ 8691 is 2.233307123184204\n",
      "Loss at Iteration @ 8692 is 2.27730131149292\n",
      "Evaluation Loss at Iteration @ 8692 is 2.226017713546753\n",
      "Loss at Iteration @ 8693 is 2.107006072998047\n",
      "Evaluation Loss at Iteration @ 8693 is 2.2044668197631836\n",
      "Loss at Iteration @ 8694 is 2.3102645874023438\n",
      "Evaluation Loss at Iteration @ 8694 is 2.244173049926758\n",
      "Loss at Iteration @ 8695 is 2.3418681621551514\n",
      "Evaluation Loss at Iteration @ 8695 is 2.26033353805542\n",
      "Loss at Iteration @ 8696 is 2.10788893699646\n",
      "Evaluation Loss at Iteration @ 8696 is 2.2557291984558105\n",
      "Loss at Iteration @ 8697 is 2.1430397033691406\n",
      "Evaluation Loss at Iteration @ 8697 is 2.2447569370269775\n",
      "Loss at Iteration @ 8698 is 2.4586830139160156\n",
      "Evaluation Loss at Iteration @ 8698 is 2.287371873855591\n",
      "Loss at Iteration @ 8699 is 2.222764730453491\n",
      "Evaluation Loss at Iteration @ 8699 is 2.245194673538208\n",
      "Loss at Iteration @ 8700 is 2.348039388656616\n",
      "Evaluation Loss at Iteration @ 8700 is 2.220198154449463\n",
      "Loss at Iteration @ 8701 is 2.3818094730377197\n",
      "Evaluation Loss at Iteration @ 8701 is 2.3074495792388916\n",
      "Loss at Iteration @ 8702 is 2.0126187801361084\n",
      "Evaluation Loss at Iteration @ 8702 is 2.2615206241607666\n",
      "Loss at Iteration @ 8703 is 2.1548056602478027\n",
      "Evaluation Loss at Iteration @ 8703 is 2.2611236572265625\n",
      "Loss at Iteration @ 8704 is 2.071071147918701\n",
      "Evaluation Loss at Iteration @ 8704 is 2.2647767066955566\n",
      "Loss at Iteration @ 8705 is 2.2596888542175293\n",
      "Evaluation Loss at Iteration @ 8705 is 2.2416744232177734\n",
      "Loss at Iteration @ 8706 is 2.298865795135498\n",
      "Evaluation Loss at Iteration @ 8706 is 2.2433393001556396\n",
      "Loss at Iteration @ 8707 is 2.16450572013855\n",
      "Evaluation Loss at Iteration @ 8707 is 2.2743031978607178\n",
      "Loss at Iteration @ 8708 is 2.1572322845458984\n",
      "Evaluation Loss at Iteration @ 8708 is 2.261901617050171\n",
      "Loss at Iteration @ 8709 is 2.300969362258911\n",
      "Evaluation Loss at Iteration @ 8709 is 2.240130662918091\n",
      "Loss at Iteration @ 8710 is 2.4857687950134277\n",
      "Evaluation Loss at Iteration @ 8710 is 2.2620151042938232\n",
      "Loss at Iteration @ 8711 is 2.0821964740753174\n",
      "Evaluation Loss at Iteration @ 8711 is 2.253415822982788\n",
      "Loss at Iteration @ 8712 is 2.102191209793091\n",
      "Evaluation Loss at Iteration @ 8712 is 2.258967399597168\n",
      "Loss at Iteration @ 8713 is 2.543252468109131\n",
      "Evaluation Loss at Iteration @ 8713 is 2.184826135635376\n",
      "Loss at Iteration @ 8714 is 2.1432979106903076\n",
      "Evaluation Loss at Iteration @ 8714 is 2.275127410888672\n",
      "Loss at Iteration @ 8715 is 2.349144697189331\n",
      "Evaluation Loss at Iteration @ 8715 is 2.276188373565674\n",
      "Loss at Iteration @ 8716 is 2.182063579559326\n",
      "Evaluation Loss at Iteration @ 8716 is 2.2719380855560303\n",
      "Loss at Iteration @ 8717 is 2.0282113552093506\n",
      "Evaluation Loss at Iteration @ 8717 is 2.25656795501709\n",
      "Loss at Iteration @ 8718 is 2.1493282318115234\n",
      "Evaluation Loss at Iteration @ 8718 is 2.2339189052581787\n",
      "Loss at Iteration @ 8719 is 2.3918395042419434\n",
      "Evaluation Loss at Iteration @ 8719 is 2.2709767818450928\n",
      "Loss at Iteration @ 8720 is 2.1224610805511475\n",
      "Evaluation Loss at Iteration @ 8720 is 2.2725682258605957\n",
      "Loss at Iteration @ 8721 is 2.4774110317230225\n",
      "Evaluation Loss at Iteration @ 8721 is 2.2041072845458984\n",
      "Loss at Iteration @ 8722 is 2.174705743789673\n",
      "Evaluation Loss at Iteration @ 8722 is 2.2836015224456787\n",
      "Loss at Iteration @ 8723 is 2.340235948562622\n",
      "Evaluation Loss at Iteration @ 8723 is 2.2146294116973877\n",
      "Loss at Iteration @ 8724 is 2.526289939880371\n",
      "Evaluation Loss at Iteration @ 8724 is 2.2577500343322754\n",
      "Loss at Iteration @ 8725 is 2.15472149848938\n",
      "Evaluation Loss at Iteration @ 8725 is 2.2466046810150146\n",
      "Loss at Iteration @ 8726 is 2.305908441543579\n",
      "Evaluation Loss at Iteration @ 8726 is 2.2663700580596924\n",
      "Loss at Iteration @ 8727 is 2.2724013328552246\n",
      "Evaluation Loss at Iteration @ 8727 is 2.2373287677764893\n",
      "Loss at Iteration @ 8728 is 2.1811561584472656\n",
      "Evaluation Loss at Iteration @ 8728 is 2.2746450901031494\n",
      "Loss at Iteration @ 8729 is 2.2921438217163086\n",
      "Evaluation Loss at Iteration @ 8729 is 2.2409183979034424\n",
      "Loss at Iteration @ 8730 is 2.315208911895752\n",
      "Evaluation Loss at Iteration @ 8730 is 2.2832107543945312\n",
      "Loss at Iteration @ 8731 is 2.4167685508728027\n",
      "Evaluation Loss at Iteration @ 8731 is 2.245633840560913\n",
      "Loss at Iteration @ 8732 is 2.366497039794922\n",
      "Evaluation Loss at Iteration @ 8732 is 2.246365547180176\n",
      "Loss at Iteration @ 8733 is 2.2693657875061035\n",
      "Evaluation Loss at Iteration @ 8733 is 2.231611967086792\n",
      "Loss at Iteration @ 8734 is 2.0590734481811523\n",
      "Evaluation Loss at Iteration @ 8734 is 2.2727925777435303\n",
      "Loss at Iteration @ 8735 is 2.227689504623413\n",
      "Evaluation Loss at Iteration @ 8735 is 2.2625651359558105\n",
      "Loss at Iteration @ 8736 is 2.4204556941986084\n",
      "Evaluation Loss at Iteration @ 8736 is 2.227402687072754\n",
      "Loss at Iteration @ 8737 is 2.2430779933929443\n",
      "Evaluation Loss at Iteration @ 8737 is 2.2871055603027344\n",
      "Loss at Iteration @ 8738 is 2.352935791015625\n",
      "Evaluation Loss at Iteration @ 8738 is 2.24773907661438\n",
      "Loss at Iteration @ 8739 is 1.9751293659210205\n",
      "Evaluation Loss at Iteration @ 8739 is 2.2537992000579834\n",
      "Loss at Iteration @ 8740 is 2.3078455924987793\n",
      "Evaluation Loss at Iteration @ 8740 is 2.2686822414398193\n",
      "Loss at Iteration @ 8741 is 2.157761812210083\n",
      "Evaluation Loss at Iteration @ 8741 is 2.2557804584503174\n",
      "Loss at Iteration @ 8742 is 2.160966157913208\n",
      "Evaluation Loss at Iteration @ 8742 is 2.245836019515991\n",
      "Loss at Iteration @ 8743 is 2.2881617546081543\n",
      "Evaluation Loss at Iteration @ 8743 is 2.241487741470337\n",
      "Loss at Iteration @ 8744 is 2.2772114276885986\n",
      "Evaluation Loss at Iteration @ 8744 is 2.2213988304138184\n",
      "Loss at Iteration @ 8745 is 2.472998857498169\n",
      "Evaluation Loss at Iteration @ 8745 is 2.228700637817383\n",
      "Loss at Iteration @ 8746 is 2.2896199226379395\n",
      "Evaluation Loss at Iteration @ 8746 is 2.2632336616516113\n",
      "Loss at Iteration @ 8747 is 2.0844430923461914\n",
      "Evaluation Loss at Iteration @ 8747 is 2.2132787704467773\n",
      "Loss at Iteration @ 8748 is 2.3542394638061523\n",
      "Evaluation Loss at Iteration @ 8748 is 2.293207883834839\n",
      "Loss at Iteration @ 8749 is 2.3153891563415527\n",
      "Evaluation Loss at Iteration @ 8749 is 2.2583351135253906\n",
      "Loss at Iteration @ 8750 is 2.084226608276367\n",
      "Evaluation Loss at Iteration @ 8750 is 2.2743184566497803\n",
      "Loss at Iteration @ 8751 is 2.2612152099609375\n",
      "Evaluation Loss at Iteration @ 8751 is 2.269455671310425\n",
      "Loss at Iteration @ 8752 is 2.223465919494629\n",
      "Evaluation Loss at Iteration @ 8752 is 2.2822160720825195\n",
      "Loss at Iteration @ 8753 is 2.373718738555908\n",
      "Evaluation Loss at Iteration @ 8753 is 2.2656912803649902\n",
      "Loss at Iteration @ 8754 is 2.290825128555298\n",
      "Evaluation Loss at Iteration @ 8754 is 2.2470827102661133\n",
      "Loss at Iteration @ 8755 is 2.1476621627807617\n",
      "Evaluation Loss at Iteration @ 8755 is 2.2401211261749268\n",
      "Loss at Iteration @ 8756 is 2.398531436920166\n",
      "Evaluation Loss at Iteration @ 8756 is 2.2689850330352783\n",
      "Loss at Iteration @ 8757 is 2.35404896736145\n",
      "Evaluation Loss at Iteration @ 8757 is 2.242173194885254\n",
      "Loss at Iteration @ 8758 is 2.0804593563079834\n",
      "Evaluation Loss at Iteration @ 8758 is 2.2118868827819824\n",
      "Loss at Iteration @ 8759 is 2.231039047241211\n",
      "Evaluation Loss at Iteration @ 8759 is 2.221036195755005\n",
      "Loss at Iteration @ 8760 is 2.381772994995117\n",
      "Evaluation Loss at Iteration @ 8760 is 2.2484443187713623\n",
      "Loss at Iteration @ 8761 is 2.6094539165496826\n",
      "Evaluation Loss at Iteration @ 8761 is 2.272508144378662\n",
      "Loss at Iteration @ 8762 is 2.4786365032196045\n",
      "Evaluation Loss at Iteration @ 8762 is 2.2638421058654785\n",
      "Loss at Iteration @ 8763 is 2.2854373455047607\n",
      "Evaluation Loss at Iteration @ 8763 is 2.1838459968566895\n",
      "Loss at Iteration @ 8764 is 2.5328774452209473\n",
      "Evaluation Loss at Iteration @ 8764 is 2.2396092414855957\n",
      "Loss at Iteration @ 8765 is 2.0303030014038086\n",
      "Evaluation Loss at Iteration @ 8765 is 2.2753777503967285\n",
      "Loss at Iteration @ 8766 is 2.446058988571167\n",
      "Evaluation Loss at Iteration @ 8766 is 2.275848627090454\n",
      "Loss at Iteration @ 8767 is 2.1713407039642334\n",
      "Evaluation Loss at Iteration @ 8767 is 2.203263998031616\n",
      "Loss at Iteration @ 8768 is 2.1379528045654297\n",
      "Evaluation Loss at Iteration @ 8768 is 2.2816193103790283\n",
      "Loss at Iteration @ 8769 is 1.9402170181274414\n",
      "Evaluation Loss at Iteration @ 8769 is 2.2847402095794678\n",
      "Loss at Iteration @ 8770 is 2.270643472671509\n",
      "Evaluation Loss at Iteration @ 8770 is 2.2551393508911133\n",
      "Loss at Iteration @ 8771 is 2.1936254501342773\n",
      "Evaluation Loss at Iteration @ 8771 is 2.251504421234131\n",
      "Loss at Iteration @ 8772 is 2.02374529838562\n",
      "Evaluation Loss at Iteration @ 8772 is 2.2182974815368652\n",
      "Loss at Iteration @ 8773 is 2.195119619369507\n",
      "Evaluation Loss at Iteration @ 8773 is 2.2326436042785645\n",
      "Loss at Iteration @ 8774 is 2.5127882957458496\n",
      "Evaluation Loss at Iteration @ 8774 is 2.2516167163848877\n",
      "Loss at Iteration @ 8775 is 2.035112142562866\n",
      "Evaluation Loss at Iteration @ 8775 is 2.2459495067596436\n",
      "Loss at Iteration @ 8776 is 2.1904191970825195\n",
      "Evaluation Loss at Iteration @ 8776 is 2.324117660522461\n",
      "Loss at Iteration @ 8777 is 2.4653847217559814\n",
      "Evaluation Loss at Iteration @ 8777 is 2.2435686588287354\n",
      "Loss at Iteration @ 8778 is 2.439362049102783\n",
      "Evaluation Loss at Iteration @ 8778 is 2.249901294708252\n",
      "Loss at Iteration @ 8779 is 2.28560209274292\n",
      "Evaluation Loss at Iteration @ 8779 is 2.2408976554870605\n",
      "Loss at Iteration @ 8780 is 2.176827907562256\n",
      "Evaluation Loss at Iteration @ 8780 is 2.2202699184417725\n",
      "Loss at Iteration @ 8781 is 1.9582617282867432\n",
      "Evaluation Loss at Iteration @ 8781 is 2.251185417175293\n",
      "Loss at Iteration @ 8782 is 2.5198566913604736\n",
      "Evaluation Loss at Iteration @ 8782 is 2.2129509449005127\n",
      "Loss at Iteration @ 8783 is 2.228404998779297\n",
      "Evaluation Loss at Iteration @ 8783 is 2.261944532394409\n",
      "Loss at Iteration @ 8784 is 2.532231092453003\n",
      "Evaluation Loss at Iteration @ 8784 is 2.2576863765716553\n",
      "Loss at Iteration @ 8785 is 2.290646553039551\n",
      "Evaluation Loss at Iteration @ 8785 is 2.264540910720825\n",
      "Loss at Iteration @ 8786 is 2.214437484741211\n",
      "Evaluation Loss at Iteration @ 8786 is 2.247145652770996\n",
      "Loss at Iteration @ 8787 is 2.5694189071655273\n",
      "Evaluation Loss at Iteration @ 8787 is 2.268611192703247\n",
      "Loss at Iteration @ 8788 is 1.8311477899551392\n",
      "Evaluation Loss at Iteration @ 8788 is 2.2671988010406494\n",
      "Loss at Iteration @ 8789 is 2.3779091835021973\n",
      "Evaluation Loss at Iteration @ 8789 is 2.2906010150909424\n",
      "Loss at Iteration @ 8790 is 2.1397504806518555\n",
      "Evaluation Loss at Iteration @ 8790 is 2.2244462966918945\n",
      "Loss at Iteration @ 8791 is 2.133479356765747\n",
      "Evaluation Loss at Iteration @ 8791 is 2.262441396713257\n",
      "Loss at Iteration @ 8792 is 2.515754222869873\n",
      "Evaluation Loss at Iteration @ 8792 is 2.220731735229492\n",
      "Loss at Iteration @ 8793 is 2.2600479125976562\n",
      "Evaluation Loss at Iteration @ 8793 is 2.215158700942993\n",
      "Loss at Iteration @ 8794 is 2.2325937747955322\n",
      "Evaluation Loss at Iteration @ 8794 is 2.339057683944702\n",
      "Loss at Iteration @ 8795 is 2.031952142715454\n",
      "Evaluation Loss at Iteration @ 8795 is 2.2271337509155273\n",
      "Loss at Iteration @ 8796 is 2.1805171966552734\n",
      "Evaluation Loss at Iteration @ 8796 is 2.2229089736938477\n",
      "Loss at Iteration @ 8797 is 2.315406560897827\n",
      "Evaluation Loss at Iteration @ 8797 is 2.271385908126831\n",
      "Loss at Iteration @ 8798 is 2.182386636734009\n",
      "Evaluation Loss at Iteration @ 8798 is 2.219919443130493\n",
      "Loss at Iteration @ 8799 is 2.366598606109619\n",
      "Evaluation Loss at Iteration @ 8799 is 2.2805795669555664\n",
      "Loss at Iteration @ 8800 is 2.3946127891540527\n",
      "Evaluation Loss at Iteration @ 8800 is 2.2640490531921387\n",
      "Loss at Iteration @ 8801 is 2.0623035430908203\n",
      "Evaluation Loss at Iteration @ 8801 is 2.2385382652282715\n",
      "Loss at Iteration @ 8802 is 2.178945302963257\n",
      "Evaluation Loss at Iteration @ 8802 is 2.2236287593841553\n",
      "Loss at Iteration @ 8803 is 2.3011438846588135\n",
      "Evaluation Loss at Iteration @ 8803 is 2.2436840534210205\n",
      "Loss at Iteration @ 8804 is 2.389331340789795\n",
      "Evaluation Loss at Iteration @ 8804 is 2.2647440433502197\n",
      "Loss at Iteration @ 8805 is 2.3671422004699707\n",
      "Evaluation Loss at Iteration @ 8805 is 2.288931131362915\n",
      "Loss at Iteration @ 8806 is 2.271353244781494\n",
      "Evaluation Loss at Iteration @ 8806 is 2.284724712371826\n",
      "Loss at Iteration @ 8807 is 1.9577794075012207\n",
      "Evaluation Loss at Iteration @ 8807 is 2.3027796745300293\n",
      "Loss at Iteration @ 8808 is 2.1382195949554443\n",
      "Evaluation Loss at Iteration @ 8808 is 2.2793080806732178\n",
      "Loss at Iteration @ 8809 is 2.1434390544891357\n",
      "Evaluation Loss at Iteration @ 8809 is 2.2414445877075195\n",
      "Loss at Iteration @ 8810 is 2.1502597332000732\n",
      "Evaluation Loss at Iteration @ 8810 is 2.267801284790039\n",
      "Loss at Iteration @ 8811 is 2.281240463256836\n",
      "Evaluation Loss at Iteration @ 8811 is 2.224046468734741\n",
      "Loss at Iteration @ 8812 is 2.148181438446045\n",
      "Evaluation Loss at Iteration @ 8812 is 2.2942416667938232\n",
      "Loss at Iteration @ 8813 is 2.3159937858581543\n",
      "Evaluation Loss at Iteration @ 8813 is 2.2431106567382812\n",
      "Loss at Iteration @ 8814 is 2.0890119075775146\n",
      "Evaluation Loss at Iteration @ 8814 is 2.258828639984131\n",
      "Loss at Iteration @ 8815 is 2.187511920928955\n",
      "Evaluation Loss at Iteration @ 8815 is 2.2775964736938477\n",
      "Loss at Iteration @ 8816 is 2.2500011920928955\n",
      "Evaluation Loss at Iteration @ 8816 is 2.209164619445801\n",
      "Loss at Iteration @ 8817 is 2.237431526184082\n",
      "Evaluation Loss at Iteration @ 8817 is 2.2635223865509033\n",
      "Loss at Iteration @ 8818 is 2.421745777130127\n",
      "Evaluation Loss at Iteration @ 8818 is 2.2159159183502197\n",
      "Loss at Iteration @ 8819 is 2.384347438812256\n",
      "Evaluation Loss at Iteration @ 8819 is 2.2539987564086914\n",
      "Loss at Iteration @ 8820 is 2.5295495986938477\n",
      "Evaluation Loss at Iteration @ 8820 is 2.2370834350585938\n",
      "Loss at Iteration @ 8821 is 2.5817763805389404\n",
      "Evaluation Loss at Iteration @ 8821 is 2.268389940261841\n",
      "Loss at Iteration @ 8822 is 2.09006929397583\n",
      "Evaluation Loss at Iteration @ 8822 is 2.2645843029022217\n",
      "Loss at Iteration @ 8823 is 2.196714401245117\n",
      "Evaluation Loss at Iteration @ 8823 is 2.237701892852783\n",
      "Loss at Iteration @ 8824 is 2.3337059020996094\n",
      "Evaluation Loss at Iteration @ 8824 is 2.2480413913726807\n",
      "Loss at Iteration @ 8825 is 1.991316318511963\n",
      "Evaluation Loss at Iteration @ 8825 is 2.2356455326080322\n",
      "Loss at Iteration @ 8826 is 2.159193992614746\n",
      "Evaluation Loss at Iteration @ 8826 is 2.2141969203948975\n",
      "Loss at Iteration @ 8827 is 2.3684020042419434\n",
      "Evaluation Loss at Iteration @ 8827 is 2.2830283641815186\n",
      "Loss at Iteration @ 8828 is 2.036176919937134\n",
      "Evaluation Loss at Iteration @ 8828 is 2.2678983211517334\n",
      "Loss at Iteration @ 8829 is 2.546217203140259\n",
      "Evaluation Loss at Iteration @ 8829 is 2.284050703048706\n",
      "Loss at Iteration @ 8830 is 2.387251615524292\n",
      "Evaluation Loss at Iteration @ 8830 is 2.235022783279419\n",
      "Loss at Iteration @ 8831 is 2.249190092086792\n",
      "Evaluation Loss at Iteration @ 8831 is 2.2611567974090576\n",
      "Loss at Iteration @ 8832 is 2.1099913120269775\n",
      "Evaluation Loss at Iteration @ 8832 is 2.2347419261932373\n",
      "Loss at Iteration @ 8833 is 2.2258546352386475\n",
      "Evaluation Loss at Iteration @ 8833 is 2.220043659210205\n",
      "Loss at Iteration @ 8834 is 2.142799139022827\n",
      "Evaluation Loss at Iteration @ 8834 is 2.238950252532959\n",
      "Loss at Iteration @ 8835 is 2.356506824493408\n",
      "Evaluation Loss at Iteration @ 8835 is 2.2157931327819824\n",
      "Loss at Iteration @ 8836 is 1.9860424995422363\n",
      "Evaluation Loss at Iteration @ 8836 is 2.2461531162261963\n",
      "Loss at Iteration @ 8837 is 2.1470179557800293\n",
      "Evaluation Loss at Iteration @ 8837 is 2.2591605186462402\n",
      "Loss at Iteration @ 8838 is 2.225464344024658\n",
      "Evaluation Loss at Iteration @ 8838 is 2.291513442993164\n",
      "Loss at Iteration @ 8839 is 2.0764846801757812\n",
      "Evaluation Loss at Iteration @ 8839 is 2.196420669555664\n",
      "Loss at Iteration @ 8840 is 2.1023361682891846\n",
      "Evaluation Loss at Iteration @ 8840 is 2.250535249710083\n",
      "Loss at Iteration @ 8841 is 2.0791501998901367\n",
      "Evaluation Loss at Iteration @ 8841 is 2.269124984741211\n",
      "Loss at Iteration @ 8842 is 2.24226450920105\n",
      "Evaluation Loss at Iteration @ 8842 is 2.2697670459747314\n",
      "Loss at Iteration @ 8843 is 2.135700225830078\n",
      "Evaluation Loss at Iteration @ 8843 is 2.2350451946258545\n",
      "Loss at Iteration @ 8844 is 2.3692686557769775\n",
      "Evaluation Loss at Iteration @ 8844 is 2.2571861743927\n",
      "Loss at Iteration @ 8845 is 2.0374512672424316\n",
      "Evaluation Loss at Iteration @ 8845 is 2.288517475128174\n",
      "Loss at Iteration @ 8846 is 2.2954628467559814\n",
      "Evaluation Loss at Iteration @ 8846 is 2.2523353099823\n",
      "Loss at Iteration @ 8847 is 2.084967851638794\n",
      "Evaluation Loss at Iteration @ 8847 is 2.2507667541503906\n",
      "Loss at Iteration @ 8848 is 2.3597209453582764\n",
      "Evaluation Loss at Iteration @ 8848 is 2.2836995124816895\n",
      "Loss at Iteration @ 8849 is 2.299510955810547\n",
      "Evaluation Loss at Iteration @ 8849 is 2.168909788131714\n",
      "Loss at Iteration @ 8850 is 2.1162850856781006\n",
      "Evaluation Loss at Iteration @ 8850 is 2.305370807647705\n",
      "Loss at Iteration @ 8851 is 2.328195810317993\n",
      "Evaluation Loss at Iteration @ 8851 is 2.2199392318725586\n",
      "Loss at Iteration @ 8852 is 2.1821017265319824\n",
      "Evaluation Loss at Iteration @ 8852 is 2.244570016860962\n",
      "Loss at Iteration @ 8853 is 2.2706851959228516\n",
      "Evaluation Loss at Iteration @ 8853 is 2.2191402912139893\n",
      "Loss at Iteration @ 8854 is 2.224519729614258\n",
      "Evaluation Loss at Iteration @ 8854 is 2.2416927814483643\n",
      "Loss at Iteration @ 8855 is 2.288360357284546\n",
      "Evaluation Loss at Iteration @ 8855 is 2.2461979389190674\n",
      "Loss at Iteration @ 8856 is 2.3076343536376953\n",
      "Evaluation Loss at Iteration @ 8856 is 2.2406816482543945\n",
      "Loss at Iteration @ 8857 is 2.343325614929199\n",
      "Evaluation Loss at Iteration @ 8857 is 2.248473882675171\n",
      "Loss at Iteration @ 8858 is 2.298441171646118\n",
      "Evaluation Loss at Iteration @ 8858 is 2.264334201812744\n",
      "Loss at Iteration @ 8859 is 1.8427040576934814\n",
      "Evaluation Loss at Iteration @ 8859 is 2.2439873218536377\n",
      "Loss at Iteration @ 8860 is 2.4080443382263184\n",
      "Evaluation Loss at Iteration @ 8860 is 2.248732089996338\n",
      "Loss at Iteration @ 8861 is 2.1279218196868896\n",
      "Evaluation Loss at Iteration @ 8861 is 2.2812328338623047\n",
      "Loss at Iteration @ 8862 is 2.4224135875701904\n",
      "Evaluation Loss at Iteration @ 8862 is 2.2205698490142822\n",
      "Loss at Iteration @ 8863 is 2.377141237258911\n",
      "Evaluation Loss at Iteration @ 8863 is 2.2458078861236572\n",
      "Loss at Iteration @ 8864 is 2.608675956726074\n",
      "Evaluation Loss at Iteration @ 8864 is 2.2186059951782227\n",
      "Loss at Iteration @ 8865 is 2.256865978240967\n",
      "Evaluation Loss at Iteration @ 8865 is 2.2090063095092773\n",
      "Loss at Iteration @ 8866 is 2.100705862045288\n",
      "Evaluation Loss at Iteration @ 8866 is 2.2447988986968994\n",
      "Loss at Iteration @ 8867 is 2.0788581371307373\n",
      "Evaluation Loss at Iteration @ 8867 is 2.249217987060547\n",
      "Loss at Iteration @ 8868 is 2.302056074142456\n",
      "Evaluation Loss at Iteration @ 8868 is 2.2789180278778076\n",
      "Loss at Iteration @ 8869 is 2.4374845027923584\n",
      "Evaluation Loss at Iteration @ 8869 is 2.2324106693267822\n",
      "Loss at Iteration @ 8870 is 2.4860923290252686\n",
      "Evaluation Loss at Iteration @ 8870 is 2.272479772567749\n",
      "Loss at Iteration @ 8871 is 2.3856709003448486\n",
      "Evaluation Loss at Iteration @ 8871 is 2.2796077728271484\n",
      "Loss at Iteration @ 8872 is 2.088139533996582\n",
      "Evaluation Loss at Iteration @ 8872 is 2.25408673286438\n",
      "Loss at Iteration @ 8873 is 2.3567185401916504\n",
      "Evaluation Loss at Iteration @ 8873 is 2.2607998847961426\n",
      "Loss at Iteration @ 8874 is 2.260162353515625\n",
      "Evaluation Loss at Iteration @ 8874 is 2.228076219558716\n",
      "Loss at Iteration @ 8875 is 2.066446542739868\n",
      "Evaluation Loss at Iteration @ 8875 is 2.250491142272949\n",
      "Loss at Iteration @ 8876 is 2.358954429626465\n",
      "Evaluation Loss at Iteration @ 8876 is 2.237154722213745\n",
      "Loss at Iteration @ 8877 is 2.1226093769073486\n",
      "Evaluation Loss at Iteration @ 8877 is 2.2364859580993652\n",
      "Loss at Iteration @ 8878 is 2.414407730102539\n",
      "Evaluation Loss at Iteration @ 8878 is 2.2681751251220703\n",
      "Loss at Iteration @ 8879 is 2.1737465858459473\n",
      "Evaluation Loss at Iteration @ 8879 is 2.2870781421661377\n",
      "Loss at Iteration @ 8880 is 2.1766624450683594\n",
      "Evaluation Loss at Iteration @ 8880 is 2.2572836875915527\n",
      "Loss at Iteration @ 8881 is 2.1597354412078857\n",
      "Evaluation Loss at Iteration @ 8881 is 2.2581937313079834\n",
      "Loss at Iteration @ 8882 is 2.204028367996216\n",
      "Evaluation Loss at Iteration @ 8882 is 2.2540652751922607\n",
      "Loss at Iteration @ 8883 is 2.182994842529297\n",
      "Evaluation Loss at Iteration @ 8883 is 2.2903246879577637\n",
      "Loss at Iteration @ 8884 is 1.916108250617981\n",
      "Evaluation Loss at Iteration @ 8884 is 2.185962438583374\n",
      "Loss at Iteration @ 8885 is 2.2616429328918457\n",
      "Evaluation Loss at Iteration @ 8885 is 2.2843987941741943\n",
      "Loss at Iteration @ 8886 is 2.1453535556793213\n",
      "Evaluation Loss at Iteration @ 8886 is 2.24765944480896\n",
      "Loss at Iteration @ 8887 is 2.196820020675659\n",
      "Evaluation Loss at Iteration @ 8887 is 2.3047022819519043\n",
      "Loss at Iteration @ 8888 is 2.072519063949585\n",
      "Evaluation Loss at Iteration @ 8888 is 2.2950263023376465\n",
      "Loss at Iteration @ 8889 is 2.3743512630462646\n",
      "Evaluation Loss at Iteration @ 8889 is 2.262871742248535\n",
      "Loss at Iteration @ 8890 is 2.3024168014526367\n",
      "Evaluation Loss at Iteration @ 8890 is 2.2375409603118896\n",
      "Loss at Iteration @ 8891 is 2.502885103225708\n",
      "Evaluation Loss at Iteration @ 8891 is 2.260070562362671\n",
      "Loss at Iteration @ 8892 is 2.521529197692871\n",
      "Evaluation Loss at Iteration @ 8892 is 2.2478015422821045\n",
      "Loss at Iteration @ 8893 is 2.385676860809326\n",
      "Evaluation Loss at Iteration @ 8893 is 2.231884717941284\n",
      "Loss at Iteration @ 8894 is 2.237948179244995\n",
      "Evaluation Loss at Iteration @ 8894 is 2.2163784503936768\n",
      "Loss at Iteration @ 8895 is 2.6492795944213867\n",
      "Evaluation Loss at Iteration @ 8895 is 2.239894151687622\n",
      "Loss at Iteration @ 8896 is 2.282569646835327\n",
      "Evaluation Loss at Iteration @ 8896 is 2.2769525051116943\n",
      "Loss at Iteration @ 8897 is 2.0893731117248535\n",
      "Evaluation Loss at Iteration @ 8897 is 2.254284620285034\n",
      "Loss at Iteration @ 8898 is 2.3539066314697266\n",
      "Evaluation Loss at Iteration @ 8898 is 2.299098491668701\n",
      "Loss at Iteration @ 8899 is 2.1927483081817627\n",
      "Evaluation Loss at Iteration @ 8899 is 2.2450592517852783\n",
      "Loss at Iteration @ 8900 is 2.0287930965423584\n",
      "Evaluation Loss at Iteration @ 8900 is 2.245220422744751\n",
      "Loss at Iteration @ 8901 is 2.4118242263793945\n",
      "Evaluation Loss at Iteration @ 8901 is 2.2501165866851807\n",
      "Loss at Iteration @ 8902 is 2.007066011428833\n",
      "Evaluation Loss at Iteration @ 8902 is 2.239016532897949\n",
      "Loss at Iteration @ 8903 is 2.4017984867095947\n",
      "Evaluation Loss at Iteration @ 8903 is 2.222917318344116\n",
      "Loss at Iteration @ 8904 is 2.1718060970306396\n",
      "Evaluation Loss at Iteration @ 8904 is 2.191805839538574\n",
      "Loss at Iteration @ 8905 is 2.149390697479248\n",
      "Evaluation Loss at Iteration @ 8905 is 2.2819271087646484\n",
      "Loss at Iteration @ 8906 is 2.359473705291748\n",
      "Evaluation Loss at Iteration @ 8906 is 2.2740249633789062\n",
      "Loss at Iteration @ 8907 is 2.3638851642608643\n",
      "Evaluation Loss at Iteration @ 8907 is 2.2442433834075928\n",
      "Loss at Iteration @ 8908 is 2.147641658782959\n",
      "Evaluation Loss at Iteration @ 8908 is 2.2371511459350586\n",
      "Loss at Iteration @ 8909 is 2.175236701965332\n",
      "Evaluation Loss at Iteration @ 8909 is 2.212306261062622\n",
      "Loss at Iteration @ 8910 is 2.1669182777404785\n",
      "Evaluation Loss at Iteration @ 8910 is 2.220762014389038\n",
      "Loss at Iteration @ 8911 is 2.257633686065674\n",
      "Evaluation Loss at Iteration @ 8911 is 2.250244379043579\n",
      "Loss at Iteration @ 8912 is 2.2602100372314453\n",
      "Evaluation Loss at Iteration @ 8912 is 2.259229898452759\n",
      "Loss at Iteration @ 8913 is 2.2656469345092773\n",
      "Evaluation Loss at Iteration @ 8913 is 2.228762626647949\n",
      "Loss at Iteration @ 8914 is 2.052844762802124\n",
      "Evaluation Loss at Iteration @ 8914 is 2.241058826446533\n",
      "Loss at Iteration @ 8915 is 2.231476306915283\n",
      "Evaluation Loss at Iteration @ 8915 is 2.2480762004852295\n",
      "Loss at Iteration @ 8916 is 2.2892353534698486\n",
      "Evaluation Loss at Iteration @ 8916 is 2.2337493896484375\n",
      "Loss at Iteration @ 8917 is 2.352726697921753\n",
      "Evaluation Loss at Iteration @ 8917 is 2.2691171169281006\n",
      "Loss at Iteration @ 8918 is 2.2450919151306152\n",
      "Evaluation Loss at Iteration @ 8918 is 2.2728633880615234\n",
      "Loss at Iteration @ 8919 is 2.320239305496216\n",
      "Evaluation Loss at Iteration @ 8919 is 2.2907660007476807\n",
      "Loss at Iteration @ 8920 is 2.316624402999878\n",
      "Evaluation Loss at Iteration @ 8920 is 2.2339398860931396\n",
      "Loss at Iteration @ 8921 is 2.379049301147461\n",
      "Evaluation Loss at Iteration @ 8921 is 2.255847454071045\n",
      "Loss at Iteration @ 8922 is 2.4003989696502686\n",
      "Evaluation Loss at Iteration @ 8922 is 2.26336407661438\n",
      "Loss at Iteration @ 8923 is 2.032055377960205\n",
      "Evaluation Loss at Iteration @ 8923 is 2.2341184616088867\n",
      "Loss at Iteration @ 8924 is 2.0553481578826904\n",
      "Evaluation Loss at Iteration @ 8924 is 2.251476287841797\n",
      "Loss at Iteration @ 8925 is 2.193002700805664\n",
      "Evaluation Loss at Iteration @ 8925 is 2.2260334491729736\n",
      "Loss at Iteration @ 8926 is 2.0677225589752197\n",
      "Evaluation Loss at Iteration @ 8926 is 2.2689263820648193\n",
      "Loss at Iteration @ 8927 is 2.1031854152679443\n",
      "Evaluation Loss at Iteration @ 8927 is 2.2357466220855713\n",
      "Loss at Iteration @ 8928 is 2.1239709854125977\n",
      "Evaluation Loss at Iteration @ 8928 is 2.258795738220215\n",
      "Loss at Iteration @ 8929 is 2.3140676021575928\n",
      "Evaluation Loss at Iteration @ 8929 is 2.224067449569702\n",
      "Loss at Iteration @ 8930 is 2.3174612522125244\n",
      "Evaluation Loss at Iteration @ 8930 is 2.286573648452759\n",
      "Loss at Iteration @ 8931 is 2.2184178829193115\n",
      "Evaluation Loss at Iteration @ 8931 is 2.2866153717041016\n",
      "Loss at Iteration @ 8932 is 2.201157569885254\n",
      "Evaluation Loss at Iteration @ 8932 is 2.293994665145874\n",
      "Loss at Iteration @ 8933 is 1.8509447574615479\n",
      "Evaluation Loss at Iteration @ 8933 is 2.2596914768218994\n",
      "Loss at Iteration @ 8934 is 2.3392043113708496\n",
      "Evaluation Loss at Iteration @ 8934 is 2.2400357723236084\n",
      "Loss at Iteration @ 8935 is 2.3232686519622803\n",
      "Evaluation Loss at Iteration @ 8935 is 2.2723329067230225\n",
      "Loss at Iteration @ 8936 is 2.5147135257720947\n",
      "Evaluation Loss at Iteration @ 8936 is 2.257906198501587\n",
      "Loss at Iteration @ 8937 is 2.0393736362457275\n",
      "Evaluation Loss at Iteration @ 8937 is 2.2197701930999756\n",
      "Loss at Iteration @ 8938 is 2.0188510417938232\n",
      "Evaluation Loss at Iteration @ 8938 is 2.240239381790161\n",
      "Loss at Iteration @ 8939 is 2.3742871284484863\n",
      "Evaluation Loss at Iteration @ 8939 is 2.2308108806610107\n",
      "Loss at Iteration @ 8940 is 2.626995801925659\n",
      "Evaluation Loss at Iteration @ 8940 is 2.2130637168884277\n",
      "Loss at Iteration @ 8941 is 2.12410831451416\n",
      "Evaluation Loss at Iteration @ 8941 is 2.2640304565429688\n",
      "Loss at Iteration @ 8942 is 2.3873839378356934\n",
      "Evaluation Loss at Iteration @ 8942 is 2.261765241622925\n",
      "Loss at Iteration @ 8943 is 2.2433862686157227\n",
      "Evaluation Loss at Iteration @ 8943 is 2.258479118347168\n",
      "Loss at Iteration @ 8944 is 2.0522589683532715\n",
      "Evaluation Loss at Iteration @ 8944 is 2.2800278663635254\n",
      "Loss at Iteration @ 8945 is 2.2880806922912598\n",
      "Evaluation Loss at Iteration @ 8945 is 2.25964617729187\n",
      "Loss at Iteration @ 8946 is 2.2967569828033447\n",
      "Evaluation Loss at Iteration @ 8946 is 2.236618995666504\n",
      "Loss at Iteration @ 8947 is 2.3670654296875\n",
      "Evaluation Loss at Iteration @ 8947 is 2.277137279510498\n",
      "Loss at Iteration @ 8948 is 2.4933342933654785\n",
      "Evaluation Loss at Iteration @ 8948 is 2.24107027053833\n",
      "Loss at Iteration @ 8949 is 2.3313028812408447\n",
      "Evaluation Loss at Iteration @ 8949 is 2.214195728302002\n",
      "Loss at Iteration @ 8950 is 2.147484064102173\n",
      "Evaluation Loss at Iteration @ 8950 is 2.254228115081787\n",
      "Loss at Iteration @ 8951 is 2.2065634727478027\n",
      "Evaluation Loss at Iteration @ 8951 is 2.2782657146453857\n",
      "Loss at Iteration @ 8952 is 2.2933077812194824\n",
      "Evaluation Loss at Iteration @ 8952 is 2.231316089630127\n",
      "Loss at Iteration @ 8953 is 2.6603949069976807\n",
      "Evaluation Loss at Iteration @ 8953 is 2.244025230407715\n",
      "Loss at Iteration @ 8954 is 1.9909330606460571\n",
      "Evaluation Loss at Iteration @ 8954 is 2.25374174118042\n",
      "Loss at Iteration @ 8955 is 2.410850763320923\n",
      "Evaluation Loss at Iteration @ 8955 is 2.2124409675598145\n",
      "Loss at Iteration @ 8956 is 2.042079210281372\n",
      "Evaluation Loss at Iteration @ 8956 is 2.2654197216033936\n",
      "Loss at Iteration @ 8957 is 2.3246357440948486\n",
      "Evaluation Loss at Iteration @ 8957 is 2.243788957595825\n",
      "Loss at Iteration @ 8958 is 2.481543779373169\n",
      "Evaluation Loss at Iteration @ 8958 is 2.262911319732666\n",
      "Loss at Iteration @ 8959 is 2.1378321647644043\n",
      "Evaluation Loss at Iteration @ 8959 is 2.2101168632507324\n",
      "Loss at Iteration @ 8960 is 2.3906478881835938\n",
      "Evaluation Loss at Iteration @ 8960 is 2.2569468021392822\n",
      "Loss at Iteration @ 8961 is 2.3628671169281006\n",
      "Evaluation Loss at Iteration @ 8961 is 2.2826106548309326\n",
      "Loss at Iteration @ 8962 is 2.0879759788513184\n",
      "Evaluation Loss at Iteration @ 8962 is 2.272705554962158\n",
      "Loss at Iteration @ 8963 is 2.0905280113220215\n",
      "Evaluation Loss at Iteration @ 8963 is 2.2920029163360596\n",
      "Loss at Iteration @ 8964 is 2.3146204948425293\n",
      "Evaluation Loss at Iteration @ 8964 is 2.23636531829834\n",
      "Loss at Iteration @ 8965 is 2.342674493789673\n",
      "Evaluation Loss at Iteration @ 8965 is 2.2541935443878174\n",
      "Loss at Iteration @ 8966 is 2.315336227416992\n",
      "Evaluation Loss at Iteration @ 8966 is 2.197760820388794\n",
      "Loss at Iteration @ 8967 is 2.4046337604522705\n",
      "Evaluation Loss at Iteration @ 8967 is 2.2663400173187256\n",
      "Loss at Iteration @ 8968 is 2.4663729667663574\n",
      "Evaluation Loss at Iteration @ 8968 is 2.230313539505005\n",
      "Loss at Iteration @ 8969 is 2.3498051166534424\n",
      "Evaluation Loss at Iteration @ 8969 is 2.2748007774353027\n",
      "Loss at Iteration @ 8970 is 2.4474382400512695\n",
      "Evaluation Loss at Iteration @ 8970 is 2.2240049839019775\n",
      "Loss at Iteration @ 8971 is 2.4032175540924072\n",
      "Evaluation Loss at Iteration @ 8971 is 2.2358078956604004\n",
      "Loss at Iteration @ 8972 is 2.128809928894043\n",
      "Evaluation Loss at Iteration @ 8972 is 2.2211170196533203\n",
      "Loss at Iteration @ 8973 is 2.2502763271331787\n",
      "Evaluation Loss at Iteration @ 8973 is 2.259761095046997\n",
      "Loss at Iteration @ 8974 is 2.2675671577453613\n",
      "Evaluation Loss at Iteration @ 8974 is 2.212381601333618\n",
      "Loss at Iteration @ 8975 is 2.125551700592041\n",
      "Evaluation Loss at Iteration @ 8975 is 2.2291245460510254\n",
      "Loss at Iteration @ 8976 is 2.2490673065185547\n",
      "Evaluation Loss at Iteration @ 8976 is 2.2721407413482666\n",
      "Loss at Iteration @ 8977 is 2.030629873275757\n",
      "Evaluation Loss at Iteration @ 8977 is 2.2538130283355713\n",
      "Loss at Iteration @ 8978 is 2.2206780910491943\n",
      "Evaluation Loss at Iteration @ 8978 is 2.2113170623779297\n",
      "Loss at Iteration @ 8979 is 2.2065086364746094\n",
      "Evaluation Loss at Iteration @ 8979 is 2.230930805206299\n",
      "Loss at Iteration @ 8980 is 2.4442367553710938\n",
      "Evaluation Loss at Iteration @ 8980 is 2.213581085205078\n",
      "Loss at Iteration @ 8981 is 2.4330215454101562\n",
      "Evaluation Loss at Iteration @ 8981 is 2.243961811065674\n",
      "Loss at Iteration @ 8982 is 2.31331467628479\n",
      "Evaluation Loss at Iteration @ 8982 is 2.2216813564300537\n",
      "Loss at Iteration @ 8983 is 2.486987590789795\n",
      "Evaluation Loss at Iteration @ 8983 is 2.249946355819702\n",
      "Loss at Iteration @ 8984 is 2.142897367477417\n",
      "Evaluation Loss at Iteration @ 8984 is 2.220447540283203\n",
      "Loss at Iteration @ 8985 is 2.1675524711608887\n",
      "Evaluation Loss at Iteration @ 8985 is 2.2689244747161865\n",
      "Loss at Iteration @ 8986 is 2.2970101833343506\n",
      "Evaluation Loss at Iteration @ 8986 is 2.2395434379577637\n",
      "Loss at Iteration @ 8987 is 2.1498913764953613\n",
      "Evaluation Loss at Iteration @ 8987 is 2.221344232559204\n",
      "Loss at Iteration @ 8988 is 2.1049158573150635\n",
      "Evaluation Loss at Iteration @ 8988 is 2.272988796234131\n",
      "Loss at Iteration @ 8989 is 2.251322031021118\n",
      "Evaluation Loss at Iteration @ 8989 is 2.1767613887786865\n",
      "Loss at Iteration @ 8990 is 2.269937038421631\n",
      "Evaluation Loss at Iteration @ 8990 is 2.242551565170288\n",
      "Loss at Iteration @ 8991 is 2.1338248252868652\n",
      "Evaluation Loss at Iteration @ 8991 is 2.2006616592407227\n",
      "Loss at Iteration @ 8992 is 2.242075204849243\n",
      "Evaluation Loss at Iteration @ 8992 is 2.258814811706543\n",
      "Loss at Iteration @ 8993 is 2.3289453983306885\n",
      "Evaluation Loss at Iteration @ 8993 is 2.2324540615081787\n",
      "Loss at Iteration @ 8994 is 2.0599074363708496\n",
      "Evaluation Loss at Iteration @ 8994 is 2.267941474914551\n",
      "Loss at Iteration @ 8995 is 2.3657114505767822\n",
      "Evaluation Loss at Iteration @ 8995 is 2.246934413909912\n",
      "Loss at Iteration @ 8996 is 2.112236976623535\n",
      "Evaluation Loss at Iteration @ 8996 is 2.2572827339172363\n",
      "Loss at Iteration @ 8997 is 2.0758395195007324\n",
      "Evaluation Loss at Iteration @ 8997 is 2.233133554458618\n",
      "Loss at Iteration @ 8998 is 2.0659031867980957\n",
      "Evaluation Loss at Iteration @ 8998 is 2.2223012447357178\n",
      "Loss at Iteration @ 8999 is 2.3077189922332764\n",
      "Evaluation Loss at Iteration @ 8999 is 2.2595720291137695\n",
      "Loss at Iteration @ 9000 is 2.2718329429626465\n",
      "Evaluation Loss at Iteration @ 9000 is 2.243941068649292\n",
      "Loss at Iteration @ 9001 is 2.4629831314086914\n",
      "Evaluation Loss at Iteration @ 9001 is 2.2308526039123535\n",
      "Loss at Iteration @ 9002 is 2.2682931423187256\n",
      "Evaluation Loss at Iteration @ 9002 is 2.25901460647583\n",
      "Loss at Iteration @ 9003 is 2.0482981204986572\n",
      "Evaluation Loss at Iteration @ 9003 is 2.262963056564331\n",
      "Loss at Iteration @ 9004 is 2.4884414672851562\n",
      "Evaluation Loss at Iteration @ 9004 is 2.2284538745880127\n",
      "Loss at Iteration @ 9005 is 1.9737745523452759\n",
      "Evaluation Loss at Iteration @ 9005 is 2.219407081604004\n",
      "Loss at Iteration @ 9006 is 2.055152177810669\n",
      "Evaluation Loss at Iteration @ 9006 is 2.2503886222839355\n",
      "Loss at Iteration @ 9007 is 2.0875463485717773\n",
      "Evaluation Loss at Iteration @ 9007 is 2.298250675201416\n",
      "Loss at Iteration @ 9008 is 2.232544422149658\n",
      "Evaluation Loss at Iteration @ 9008 is 2.301027536392212\n",
      "Loss at Iteration @ 9009 is 2.1907267570495605\n",
      "Evaluation Loss at Iteration @ 9009 is 2.234745502471924\n",
      "Loss at Iteration @ 9010 is 2.231010913848877\n",
      "Evaluation Loss at Iteration @ 9010 is 2.267611026763916\n",
      "Loss at Iteration @ 9011 is 2.16168475151062\n",
      "Evaluation Loss at Iteration @ 9011 is 2.268921136856079\n",
      "Loss at Iteration @ 9012 is 2.356858253479004\n",
      "Evaluation Loss at Iteration @ 9012 is 2.2698283195495605\n",
      "Loss at Iteration @ 9013 is 2.3519175052642822\n",
      "Evaluation Loss at Iteration @ 9013 is 2.2641336917877197\n",
      "Loss at Iteration @ 9014 is 2.372504949569702\n",
      "Evaluation Loss at Iteration @ 9014 is 2.2915728092193604\n",
      "Loss at Iteration @ 9015 is 2.1187081336975098\n",
      "Evaluation Loss at Iteration @ 9015 is 2.202346086502075\n",
      "Loss at Iteration @ 9016 is 2.05172061920166\n",
      "Evaluation Loss at Iteration @ 9016 is 2.239572763442993\n",
      "Loss at Iteration @ 9017 is 2.277425765991211\n",
      "Evaluation Loss at Iteration @ 9017 is 2.2785091400146484\n",
      "Loss at Iteration @ 9018 is 2.0244827270507812\n",
      "Evaluation Loss at Iteration @ 9018 is 2.292954683303833\n",
      "Loss at Iteration @ 9019 is 2.2406961917877197\n",
      "Evaluation Loss at Iteration @ 9019 is 2.2748305797576904\n",
      "Loss at Iteration @ 9020 is 2.437084674835205\n",
      "Evaluation Loss at Iteration @ 9020 is 2.265902042388916\n",
      "Loss at Iteration @ 9021 is 2.2154369354248047\n",
      "Evaluation Loss at Iteration @ 9021 is 2.254711151123047\n",
      "Loss at Iteration @ 9022 is 2.4917736053466797\n",
      "Evaluation Loss at Iteration @ 9022 is 2.2741336822509766\n",
      "Loss at Iteration @ 9023 is 2.29738712310791\n",
      "Evaluation Loss at Iteration @ 9023 is 2.2206807136535645\n",
      "Loss at Iteration @ 9024 is 2.4103188514709473\n",
      "Evaluation Loss at Iteration @ 9024 is 2.2454206943511963\n",
      "Loss at Iteration @ 9025 is 2.2295846939086914\n",
      "Evaluation Loss at Iteration @ 9025 is 2.294884443283081\n",
      "Loss at Iteration @ 9026 is 2.365196704864502\n",
      "Evaluation Loss at Iteration @ 9026 is 2.25228214263916\n",
      "Loss at Iteration @ 9027 is 2.2847564220428467\n",
      "Evaluation Loss at Iteration @ 9027 is 2.2284915447235107\n",
      "Loss at Iteration @ 9028 is 1.9295166730880737\n",
      "Evaluation Loss at Iteration @ 9028 is 2.260556697845459\n",
      "Loss at Iteration @ 9029 is 2.246253490447998\n",
      "Evaluation Loss at Iteration @ 9029 is 2.227073907852173\n",
      "Loss at Iteration @ 9030 is 2.0131688117980957\n",
      "Evaluation Loss at Iteration @ 9030 is 2.269327163696289\n",
      "Loss at Iteration @ 9031 is 1.9396350383758545\n",
      "Evaluation Loss at Iteration @ 9031 is 2.2531392574310303\n",
      "Loss at Iteration @ 9032 is 2.382697582244873\n",
      "Evaluation Loss at Iteration @ 9032 is 2.190495729446411\n",
      "Loss at Iteration @ 9033 is 2.163707971572876\n",
      "Evaluation Loss at Iteration @ 9033 is 2.287546157836914\n",
      "Loss at Iteration @ 9034 is 2.190246820449829\n",
      "Evaluation Loss at Iteration @ 9034 is 2.2081642150878906\n",
      "Loss at Iteration @ 9035 is 2.060424327850342\n",
      "Evaluation Loss at Iteration @ 9035 is 2.27321457862854\n",
      "Loss at Iteration @ 9036 is 2.0702803134918213\n",
      "Evaluation Loss at Iteration @ 9036 is 2.2580840587615967\n",
      "Loss at Iteration @ 9037 is 2.151689052581787\n",
      "Evaluation Loss at Iteration @ 9037 is 2.2477734088897705\n",
      "Loss at Iteration @ 9038 is 2.0723700523376465\n",
      "Evaluation Loss at Iteration @ 9038 is 2.2764813899993896\n",
      "Loss at Iteration @ 9039 is 2.0682666301727295\n",
      "Evaluation Loss at Iteration @ 9039 is 2.235955238342285\n",
      "Loss at Iteration @ 9040 is 2.7231240272521973\n",
      "Evaluation Loss at Iteration @ 9040 is 2.2630014419555664\n",
      "Loss at Iteration @ 9041 is 2.302642345428467\n",
      "Evaluation Loss at Iteration @ 9041 is 2.2436797618865967\n",
      "Loss at Iteration @ 9042 is 2.2260830402374268\n",
      "Evaluation Loss at Iteration @ 9042 is 2.2057743072509766\n",
      "Loss at Iteration @ 9043 is 2.4458279609680176\n",
      "Evaluation Loss at Iteration @ 9043 is 2.2582197189331055\n",
      "Loss at Iteration @ 9044 is 2.43076229095459\n",
      "Evaluation Loss at Iteration @ 9044 is 2.2458343505859375\n",
      "Loss at Iteration @ 9045 is 2.490356206893921\n",
      "Evaluation Loss at Iteration @ 9045 is 2.251060724258423\n",
      "Loss at Iteration @ 9046 is 2.3424041271209717\n",
      "Evaluation Loss at Iteration @ 9046 is 2.2779347896575928\n",
      "Loss at Iteration @ 9047 is 2.3206124305725098\n",
      "Evaluation Loss at Iteration @ 9047 is 2.218590497970581\n",
      "Loss at Iteration @ 9048 is 2.1964986324310303\n",
      "Evaluation Loss at Iteration @ 9048 is 2.240452527999878\n",
      "Loss at Iteration @ 9049 is 2.1757638454437256\n",
      "Evaluation Loss at Iteration @ 9049 is 2.235476493835449\n",
      "Loss at Iteration @ 9050 is 2.3715898990631104\n",
      "Evaluation Loss at Iteration @ 9050 is 2.276522159576416\n",
      "Loss at Iteration @ 9051 is 2.1426587104797363\n",
      "Evaluation Loss at Iteration @ 9051 is 2.1970694065093994\n",
      "Loss at Iteration @ 9052 is 2.217050790786743\n",
      "Evaluation Loss at Iteration @ 9052 is 2.259270429611206\n",
      "Loss at Iteration @ 9053 is 2.373845100402832\n",
      "Evaluation Loss at Iteration @ 9053 is 2.294965982437134\n",
      "Loss at Iteration @ 9054 is 2.1424739360809326\n",
      "Evaluation Loss at Iteration @ 9054 is 2.2619073390960693\n",
      "Loss at Iteration @ 9055 is 2.3923256397247314\n",
      "Evaluation Loss at Iteration @ 9055 is 2.2519750595092773\n",
      "Loss at Iteration @ 9056 is 2.6101343631744385\n",
      "Evaluation Loss at Iteration @ 9056 is 2.2616496086120605\n",
      "Loss at Iteration @ 9057 is 1.9909347295761108\n",
      "Evaluation Loss at Iteration @ 9057 is 2.254366874694824\n",
      "Loss at Iteration @ 9058 is 2.172975778579712\n",
      "Evaluation Loss at Iteration @ 9058 is 2.23374080657959\n",
      "Loss at Iteration @ 9059 is 2.538177251815796\n",
      "Evaluation Loss at Iteration @ 9059 is 2.241189956665039\n",
      "Loss at Iteration @ 9060 is 2.443641424179077\n",
      "Evaluation Loss at Iteration @ 9060 is 2.254648447036743\n",
      "Loss at Iteration @ 9061 is 2.333139419555664\n",
      "Evaluation Loss at Iteration @ 9061 is 2.264169931411743\n",
      "Loss at Iteration @ 9062 is 2.131437063217163\n",
      "Evaluation Loss at Iteration @ 9062 is 2.252929210662842\n",
      "Loss at Iteration @ 9063 is 1.9575867652893066\n",
      "Evaluation Loss at Iteration @ 9063 is 2.2561862468719482\n",
      "Loss at Iteration @ 9064 is 2.2685515880584717\n",
      "Evaluation Loss at Iteration @ 9064 is 2.282477617263794\n",
      "Loss at Iteration @ 9065 is 2.151202917098999\n",
      "Evaluation Loss at Iteration @ 9065 is 2.251312255859375\n",
      "Loss at Iteration @ 9066 is 2.2253379821777344\n",
      "Evaluation Loss at Iteration @ 9066 is 2.224881410598755\n",
      "Loss at Iteration @ 9067 is 2.0952701568603516\n",
      "Evaluation Loss at Iteration @ 9067 is 2.3395252227783203\n",
      "Loss at Iteration @ 9068 is 2.333233118057251\n",
      "Evaluation Loss at Iteration @ 9068 is 2.2349209785461426\n",
      "Loss at Iteration @ 9069 is 2.445157051086426\n",
      "Evaluation Loss at Iteration @ 9069 is 2.284959077835083\n",
      "Loss at Iteration @ 9070 is 2.235607862472534\n",
      "Evaluation Loss at Iteration @ 9070 is 2.304859161376953\n",
      "Loss at Iteration @ 9071 is 2.2911362648010254\n",
      "Evaluation Loss at Iteration @ 9071 is 2.284536361694336\n",
      "Loss at Iteration @ 9072 is 2.2478978633880615\n",
      "Evaluation Loss at Iteration @ 9072 is 2.1901283264160156\n",
      "Loss at Iteration @ 9073 is 2.591606616973877\n",
      "Evaluation Loss at Iteration @ 9073 is 2.226860523223877\n",
      "Loss at Iteration @ 9074 is 2.2429089546203613\n",
      "Evaluation Loss at Iteration @ 9074 is 2.2537436485290527\n",
      "Loss at Iteration @ 9075 is 2.1925241947174072\n",
      "Evaluation Loss at Iteration @ 9075 is 2.222323417663574\n",
      "Loss at Iteration @ 9076 is 2.13921856880188\n",
      "Evaluation Loss at Iteration @ 9076 is 2.2520315647125244\n",
      "Loss at Iteration @ 9077 is 2.317725658416748\n",
      "Evaluation Loss at Iteration @ 9077 is 2.2499217987060547\n",
      "Loss at Iteration @ 9078 is 2.2993783950805664\n",
      "Evaluation Loss at Iteration @ 9078 is 2.25539493560791\n",
      "Loss at Iteration @ 9079 is 2.368156909942627\n",
      "Evaluation Loss at Iteration @ 9079 is 2.255884885787964\n",
      "Loss at Iteration @ 9080 is 2.438533306121826\n",
      "Evaluation Loss at Iteration @ 9080 is 2.2656097412109375\n",
      "Loss at Iteration @ 9081 is 2.2812082767486572\n",
      "Evaluation Loss at Iteration @ 9081 is 2.2142984867095947\n",
      "Loss at Iteration @ 9082 is 2.2990596294403076\n",
      "Evaluation Loss at Iteration @ 9082 is 2.2663509845733643\n",
      "Loss at Iteration @ 9083 is 2.2639358043670654\n",
      "Evaluation Loss at Iteration @ 9083 is 2.2742795944213867\n",
      "Loss at Iteration @ 9084 is 2.546440839767456\n",
      "Evaluation Loss at Iteration @ 9084 is 2.1540606021881104\n",
      "Loss at Iteration @ 9085 is 2.2841854095458984\n",
      "Evaluation Loss at Iteration @ 9085 is 2.2729504108428955\n",
      "Loss at Iteration @ 9086 is 2.058192729949951\n",
      "Evaluation Loss at Iteration @ 9086 is 2.23176646232605\n",
      "Loss at Iteration @ 9087 is 2.3826510906219482\n",
      "Evaluation Loss at Iteration @ 9087 is 2.249056100845337\n",
      "Loss at Iteration @ 9088 is 1.9841760396957397\n",
      "Evaluation Loss at Iteration @ 9088 is 2.2556331157684326\n",
      "Loss at Iteration @ 9089 is 2.160444498062134\n",
      "Evaluation Loss at Iteration @ 9089 is 2.2561020851135254\n",
      "Loss at Iteration @ 9090 is 2.1472327709198\n",
      "Evaluation Loss at Iteration @ 9090 is 2.2658255100250244\n",
      "Loss at Iteration @ 9091 is 2.377967119216919\n",
      "Evaluation Loss at Iteration @ 9091 is 2.2833876609802246\n",
      "Loss at Iteration @ 9092 is 2.2248165607452393\n",
      "Evaluation Loss at Iteration @ 9092 is 2.243211030960083\n",
      "Loss at Iteration @ 9093 is 2.5181429386138916\n",
      "Evaluation Loss at Iteration @ 9093 is 2.3093650341033936\n",
      "Loss at Iteration @ 9094 is 2.280381917953491\n",
      "Evaluation Loss at Iteration @ 9094 is 2.247797727584839\n",
      "Loss at Iteration @ 9095 is 2.04630708694458\n",
      "Evaluation Loss at Iteration @ 9095 is 2.2139055728912354\n",
      "Loss at Iteration @ 9096 is 2.326842784881592\n",
      "Evaluation Loss at Iteration @ 9096 is 2.1939520835876465\n",
      "Loss at Iteration @ 9097 is 2.2363548278808594\n",
      "Evaluation Loss at Iteration @ 9097 is 2.279104709625244\n",
      "Loss at Iteration @ 9098 is 2.178565740585327\n",
      "Evaluation Loss at Iteration @ 9098 is 2.2083587646484375\n",
      "Loss at Iteration @ 9099 is 2.173377752304077\n",
      "Evaluation Loss at Iteration @ 9099 is 2.269080638885498\n",
      "Loss at Iteration @ 9100 is 2.272259473800659\n",
      "Evaluation Loss at Iteration @ 9100 is 2.279679775238037\n",
      "Loss at Iteration @ 9101 is 2.177034378051758\n",
      "Evaluation Loss at Iteration @ 9101 is 2.2186455726623535\n",
      "Loss at Iteration @ 9102 is 2.3179895877838135\n",
      "Evaluation Loss at Iteration @ 9102 is 2.2663354873657227\n",
      "Loss at Iteration @ 9103 is 2.138134002685547\n",
      "Evaluation Loss at Iteration @ 9103 is 2.2670512199401855\n",
      "Loss at Iteration @ 9104 is 2.1543641090393066\n",
      "Evaluation Loss at Iteration @ 9104 is 2.234752655029297\n",
      "Loss at Iteration @ 9105 is 1.8967053890228271\n",
      "Evaluation Loss at Iteration @ 9105 is 2.297053813934326\n",
      "Loss at Iteration @ 9106 is 2.2303831577301025\n",
      "Evaluation Loss at Iteration @ 9106 is 2.212435483932495\n",
      "Loss at Iteration @ 9107 is 2.133868932723999\n",
      "Evaluation Loss at Iteration @ 9107 is 2.2669951915740967\n",
      "Loss at Iteration @ 9108 is 2.3221096992492676\n",
      "Evaluation Loss at Iteration @ 9108 is 2.2642340660095215\n",
      "Loss at Iteration @ 9109 is 2.452547788619995\n",
      "Evaluation Loss at Iteration @ 9109 is 2.2108564376831055\n",
      "Loss at Iteration @ 9110 is 2.370391368865967\n",
      "Evaluation Loss at Iteration @ 9110 is 2.2594616413116455\n",
      "Loss at Iteration @ 9111 is 2.128549575805664\n",
      "Evaluation Loss at Iteration @ 9111 is 2.2504587173461914\n",
      "Loss at Iteration @ 9112 is 2.1464180946350098\n",
      "Evaluation Loss at Iteration @ 9112 is 2.2224299907684326\n",
      "Loss at Iteration @ 9113 is 2.049858570098877\n",
      "Evaluation Loss at Iteration @ 9113 is 2.3037562370300293\n",
      "Loss at Iteration @ 9114 is 2.2520592212677\n",
      "Evaluation Loss at Iteration @ 9114 is 2.256408929824829\n",
      "Loss at Iteration @ 9115 is 2.0646817684173584\n",
      "Evaluation Loss at Iteration @ 9115 is 2.263313055038452\n",
      "Loss at Iteration @ 9116 is 2.29278826713562\n",
      "Evaluation Loss at Iteration @ 9116 is 2.225428342819214\n",
      "Loss at Iteration @ 9117 is 2.248527765274048\n",
      "Evaluation Loss at Iteration @ 9117 is 2.22367525100708\n",
      "Loss at Iteration @ 9118 is 2.207401990890503\n",
      "Evaluation Loss at Iteration @ 9118 is 2.298201560974121\n",
      "Loss at Iteration @ 9119 is 2.1750829219818115\n",
      "Evaluation Loss at Iteration @ 9119 is 2.249375104904175\n",
      "Loss at Iteration @ 9120 is 2.2626049518585205\n",
      "Evaluation Loss at Iteration @ 9120 is 2.181988000869751\n",
      "Loss at Iteration @ 9121 is 2.1901493072509766\n",
      "Evaluation Loss at Iteration @ 9121 is 2.209652900695801\n",
      "Loss at Iteration @ 9122 is 2.5770623683929443\n",
      "Evaluation Loss at Iteration @ 9122 is 2.1681458950042725\n",
      "Loss at Iteration @ 9123 is 2.3357417583465576\n",
      "Evaluation Loss at Iteration @ 9123 is 2.220933675765991\n",
      "Loss at Iteration @ 9124 is 2.3900554180145264\n",
      "Evaluation Loss at Iteration @ 9124 is 2.275752544403076\n",
      "Loss at Iteration @ 9125 is 2.2756412029266357\n",
      "Evaluation Loss at Iteration @ 9125 is 2.224929094314575\n",
      "Loss at Iteration @ 9126 is 2.31774640083313\n",
      "Evaluation Loss at Iteration @ 9126 is 2.2234435081481934\n",
      "Loss at Iteration @ 9127 is 2.3227427005767822\n",
      "Evaluation Loss at Iteration @ 9127 is 2.2619786262512207\n",
      "Loss at Iteration @ 9128 is 2.540066957473755\n",
      "Evaluation Loss at Iteration @ 9128 is 2.2775917053222656\n",
      "Loss at Iteration @ 9129 is 2.0839285850524902\n",
      "Evaluation Loss at Iteration @ 9129 is 2.248404026031494\n",
      "Loss at Iteration @ 9130 is 2.194303512573242\n",
      "Evaluation Loss at Iteration @ 9130 is 2.2808597087860107\n",
      "Loss at Iteration @ 9131 is 2.1520514488220215\n",
      "Evaluation Loss at Iteration @ 9131 is 2.2597384452819824\n",
      "Loss at Iteration @ 9132 is 2.2220256328582764\n",
      "Evaluation Loss at Iteration @ 9132 is 2.2613818645477295\n",
      "Loss at Iteration @ 9133 is 2.147594928741455\n",
      "Evaluation Loss at Iteration @ 9133 is 2.2291526794433594\n",
      "Loss at Iteration @ 9134 is 2.3951714038848877\n",
      "Evaluation Loss at Iteration @ 9134 is 2.273425340652466\n",
      "Loss at Iteration @ 9135 is 2.2353389263153076\n",
      "Evaluation Loss at Iteration @ 9135 is 2.2491536140441895\n",
      "Loss at Iteration @ 9136 is 2.24798583984375\n",
      "Evaluation Loss at Iteration @ 9136 is 2.277312994003296\n",
      "Loss at Iteration @ 9137 is 2.431527614593506\n",
      "Evaluation Loss at Iteration @ 9137 is 2.2534799575805664\n",
      "Loss at Iteration @ 9138 is 2.1745543479919434\n",
      "Evaluation Loss at Iteration @ 9138 is 2.267563581466675\n",
      "Loss at Iteration @ 9139 is 2.249249219894409\n",
      "Evaluation Loss at Iteration @ 9139 is 2.2457311153411865\n",
      "Loss at Iteration @ 9140 is 2.1160504817962646\n",
      "Evaluation Loss at Iteration @ 9140 is 2.2874937057495117\n",
      "Loss at Iteration @ 9141 is 2.4554097652435303\n",
      "Evaluation Loss at Iteration @ 9141 is 2.2363221645355225\n",
      "Loss at Iteration @ 9142 is 2.3493106365203857\n",
      "Evaluation Loss at Iteration @ 9142 is 2.3035011291503906\n",
      "Loss at Iteration @ 9143 is 2.374438762664795\n",
      "Evaluation Loss at Iteration @ 9143 is 2.2400271892547607\n",
      "Loss at Iteration @ 9144 is 2.498445987701416\n",
      "Evaluation Loss at Iteration @ 9144 is 2.24710750579834\n",
      "Loss at Iteration @ 9145 is 2.2556583881378174\n",
      "Evaluation Loss at Iteration @ 9145 is 2.230055570602417\n",
      "Loss at Iteration @ 9146 is 2.24393892288208\n",
      "Evaluation Loss at Iteration @ 9146 is 2.2563202381134033\n",
      "Loss at Iteration @ 9147 is 2.2492361068725586\n",
      "Evaluation Loss at Iteration @ 9147 is 2.261943817138672\n",
      "Loss at Iteration @ 9148 is 2.1011643409729004\n",
      "Evaluation Loss at Iteration @ 9148 is 2.2384846210479736\n",
      "Loss at Iteration @ 9149 is 2.318256378173828\n",
      "Evaluation Loss at Iteration @ 9149 is 2.2492125034332275\n",
      "Loss at Iteration @ 9150 is 2.226862907409668\n",
      "Evaluation Loss at Iteration @ 9150 is 2.240334987640381\n",
      "Loss at Iteration @ 9151 is 1.9435124397277832\n",
      "Evaluation Loss at Iteration @ 9151 is 2.249993324279785\n",
      "Loss at Iteration @ 9152 is 2.2481722831726074\n",
      "Evaluation Loss at Iteration @ 9152 is 2.267040491104126\n",
      "Loss at Iteration @ 9153 is 2.3483633995056152\n",
      "Evaluation Loss at Iteration @ 9153 is 2.209200620651245\n",
      "Loss at Iteration @ 9154 is 2.467484474182129\n",
      "Evaluation Loss at Iteration @ 9154 is 2.2318966388702393\n",
      "Loss at Iteration @ 9155 is 1.9398692846298218\n",
      "Evaluation Loss at Iteration @ 9155 is 2.2079081535339355\n",
      "Loss at Iteration @ 9156 is 2.316840648651123\n",
      "Evaluation Loss at Iteration @ 9156 is 2.2688632011413574\n",
      "Loss at Iteration @ 9157 is 2.408815860748291\n",
      "Evaluation Loss at Iteration @ 9157 is 2.285818338394165\n",
      "Loss at Iteration @ 9158 is 2.3123881816864014\n",
      "Evaluation Loss at Iteration @ 9158 is 2.2709977626800537\n",
      "Loss at Iteration @ 9159 is 2.2160494327545166\n",
      "Evaluation Loss at Iteration @ 9159 is 2.2198245525360107\n",
      "Loss at Iteration @ 9160 is 2.451974391937256\n",
      "Evaluation Loss at Iteration @ 9160 is 2.2773046493530273\n",
      "Loss at Iteration @ 9161 is 2.3716399669647217\n",
      "Evaluation Loss at Iteration @ 9161 is 2.2742161750793457\n",
      "Loss at Iteration @ 9162 is 2.1946370601654053\n",
      "Evaluation Loss at Iteration @ 9162 is 2.256854295730591\n",
      "Loss at Iteration @ 9163 is 1.9983168840408325\n",
      "Evaluation Loss at Iteration @ 9163 is 2.2431914806365967\n",
      "Loss at Iteration @ 9164 is 2.1355855464935303\n",
      "Evaluation Loss at Iteration @ 9164 is 2.2365522384643555\n",
      "Loss at Iteration @ 9165 is 2.3798210620880127\n",
      "Evaluation Loss at Iteration @ 9165 is 2.247774362564087\n",
      "Loss at Iteration @ 9166 is 2.1130475997924805\n",
      "Evaluation Loss at Iteration @ 9166 is 2.2306132316589355\n",
      "Loss at Iteration @ 9167 is 2.156738042831421\n",
      "Evaluation Loss at Iteration @ 9167 is 2.258066177368164\n",
      "Loss at Iteration @ 9168 is 2.289539098739624\n",
      "Evaluation Loss at Iteration @ 9168 is 2.206895112991333\n",
      "Loss at Iteration @ 9169 is 2.045016288757324\n",
      "Evaluation Loss at Iteration @ 9169 is 2.211683750152588\n",
      "Loss at Iteration @ 9170 is 2.0387332439422607\n",
      "Evaluation Loss at Iteration @ 9170 is 2.2518606185913086\n",
      "Loss at Iteration @ 9171 is 2.3167014122009277\n",
      "Evaluation Loss at Iteration @ 9171 is 2.2292511463165283\n",
      "Loss at Iteration @ 9172 is 2.2623918056488037\n",
      "Evaluation Loss at Iteration @ 9172 is 2.2583699226379395\n",
      "Loss at Iteration @ 9173 is 2.083592653274536\n",
      "Evaluation Loss at Iteration @ 9173 is 2.2411818504333496\n",
      "Loss at Iteration @ 9174 is 2.380707025527954\n",
      "Evaluation Loss at Iteration @ 9174 is 2.2844088077545166\n",
      "Loss at Iteration @ 9175 is 2.1128358840942383\n",
      "Evaluation Loss at Iteration @ 9175 is 2.292745590209961\n",
      "Loss at Iteration @ 9176 is 2.10610032081604\n",
      "Evaluation Loss at Iteration @ 9176 is 2.2567272186279297\n",
      "Loss at Iteration @ 9177 is 2.352113723754883\n",
      "Evaluation Loss at Iteration @ 9177 is 2.269603729248047\n",
      "Loss at Iteration @ 9178 is 2.239670991897583\n",
      "Evaluation Loss at Iteration @ 9178 is 2.2595818042755127\n",
      "Loss at Iteration @ 9179 is 2.3535356521606445\n",
      "Evaluation Loss at Iteration @ 9179 is 2.2621939182281494\n",
      "Loss at Iteration @ 9180 is 2.4151880741119385\n",
      "Evaluation Loss at Iteration @ 9180 is 2.2112879753112793\n",
      "Loss at Iteration @ 9181 is 2.114140748977661\n",
      "Evaluation Loss at Iteration @ 9181 is 2.288822889328003\n",
      "Loss at Iteration @ 9182 is 2.1848156452178955\n",
      "Evaluation Loss at Iteration @ 9182 is 2.245605230331421\n",
      "Loss at Iteration @ 9183 is 2.293179988861084\n",
      "Evaluation Loss at Iteration @ 9183 is 2.214324951171875\n",
      "Loss at Iteration @ 9184 is 2.127305746078491\n",
      "Evaluation Loss at Iteration @ 9184 is 2.2665441036224365\n",
      "Loss at Iteration @ 9185 is 2.0639073848724365\n",
      "Evaluation Loss at Iteration @ 9185 is 2.2268636226654053\n",
      "Loss at Iteration @ 9186 is 2.315699338912964\n",
      "Evaluation Loss at Iteration @ 9186 is 2.2289187908172607\n",
      "Loss at Iteration @ 9187 is 2.2802889347076416\n",
      "Evaluation Loss at Iteration @ 9187 is 2.292205333709717\n",
      "Loss at Iteration @ 9188 is 2.098059892654419\n",
      "Evaluation Loss at Iteration @ 9188 is 2.272655487060547\n",
      "Loss at Iteration @ 9189 is 2.2338755130767822\n",
      "Evaluation Loss at Iteration @ 9189 is 2.2584750652313232\n",
      "Loss at Iteration @ 9190 is 2.3027503490448\n",
      "Evaluation Loss at Iteration @ 9190 is 2.248293161392212\n",
      "Loss at Iteration @ 9191 is 2.1149492263793945\n",
      "Evaluation Loss at Iteration @ 9191 is 2.2241921424865723\n",
      "Loss at Iteration @ 9192 is 2.473022699356079\n",
      "Evaluation Loss at Iteration @ 9192 is 2.263395071029663\n",
      "Loss at Iteration @ 9193 is 2.354302406311035\n",
      "Evaluation Loss at Iteration @ 9193 is 2.2520434856414795\n",
      "Loss at Iteration @ 9194 is 2.1745917797088623\n",
      "Evaluation Loss at Iteration @ 9194 is 2.24147629737854\n",
      "Loss at Iteration @ 9195 is 2.129038095474243\n",
      "Evaluation Loss at Iteration @ 9195 is 2.312001943588257\n",
      "Loss at Iteration @ 9196 is 2.0553269386291504\n",
      "Evaluation Loss at Iteration @ 9196 is 2.2813849449157715\n",
      "Loss at Iteration @ 9197 is 2.309945821762085\n",
      "Evaluation Loss at Iteration @ 9197 is 2.240727186203003\n",
      "Loss at Iteration @ 9198 is 2.4256093502044678\n",
      "Evaluation Loss at Iteration @ 9198 is 2.249446392059326\n",
      "Loss at Iteration @ 9199 is 2.182614326477051\n",
      "Evaluation Loss at Iteration @ 9199 is 2.2516748905181885\n",
      "Loss at Iteration @ 9200 is 2.2881622314453125\n",
      "Evaluation Loss at Iteration @ 9200 is 2.2720794677734375\n",
      "Loss at Iteration @ 9201 is 2.235149621963501\n",
      "Evaluation Loss at Iteration @ 9201 is 2.246234893798828\n",
      "Loss at Iteration @ 9202 is 2.3658366203308105\n",
      "Evaluation Loss at Iteration @ 9202 is 2.164247512817383\n",
      "Loss at Iteration @ 9203 is 2.382575511932373\n",
      "Evaluation Loss at Iteration @ 9203 is 2.257746696472168\n",
      "Loss at Iteration @ 9204 is 2.2050063610076904\n",
      "Evaluation Loss at Iteration @ 9204 is 2.228516101837158\n",
      "Loss at Iteration @ 9205 is 2.197314500808716\n",
      "Evaluation Loss at Iteration @ 9205 is 2.2546212673187256\n",
      "Loss at Iteration @ 9206 is 2.199306011199951\n",
      "Evaluation Loss at Iteration @ 9206 is 2.2657361030578613\n",
      "Loss at Iteration @ 9207 is 2.4734385013580322\n",
      "Evaluation Loss at Iteration @ 9207 is 2.211273193359375\n",
      "Loss at Iteration @ 9208 is 2.4340367317199707\n",
      "Evaluation Loss at Iteration @ 9208 is 2.293487787246704\n",
      "Loss at Iteration @ 9209 is 2.2765865325927734\n",
      "Evaluation Loss at Iteration @ 9209 is 2.2501542568206787\n",
      "Loss at Iteration @ 9210 is 2.321467876434326\n",
      "Evaluation Loss at Iteration @ 9210 is 2.2921853065490723\n",
      "Loss at Iteration @ 9211 is 2.2380077838897705\n",
      "Evaluation Loss at Iteration @ 9211 is 2.2996039390563965\n",
      "Loss at Iteration @ 9212 is 2.1767075061798096\n",
      "Evaluation Loss at Iteration @ 9212 is 2.2467010021209717\n",
      "Loss at Iteration @ 9213 is 2.0487380027770996\n",
      "Evaluation Loss at Iteration @ 9213 is 2.2246358394622803\n",
      "Loss at Iteration @ 9214 is 2.1525659561157227\n",
      "Evaluation Loss at Iteration @ 9214 is 2.252908229827881\n",
      "Loss at Iteration @ 9215 is 2.384274482727051\n",
      "Evaluation Loss at Iteration @ 9215 is 2.2439916133880615\n",
      "Loss at Iteration @ 9216 is 2.0633997917175293\n",
      "Evaluation Loss at Iteration @ 9216 is 2.2766270637512207\n",
      "Loss at Iteration @ 9217 is 2.0448977947235107\n",
      "Evaluation Loss at Iteration @ 9217 is 2.2234244346618652\n",
      "Loss at Iteration @ 9218 is 2.387258529663086\n",
      "Evaluation Loss at Iteration @ 9218 is 2.2348294258117676\n",
      "Loss at Iteration @ 9219 is 2.517265796661377\n",
      "Evaluation Loss at Iteration @ 9219 is 2.2870020866394043\n",
      "Loss at Iteration @ 9220 is 2.2163302898406982\n",
      "Evaluation Loss at Iteration @ 9220 is 2.2552309036254883\n",
      "Loss at Iteration @ 9221 is 2.4587156772613525\n",
      "Evaluation Loss at Iteration @ 9221 is 2.257831335067749\n",
      "Loss at Iteration @ 9222 is 2.139716148376465\n",
      "Evaluation Loss at Iteration @ 9222 is 2.2459986209869385\n",
      "Loss at Iteration @ 9223 is 2.0635576248168945\n",
      "Evaluation Loss at Iteration @ 9223 is 2.2535974979400635\n",
      "Loss at Iteration @ 9224 is 2.2646191120147705\n",
      "Evaluation Loss at Iteration @ 9224 is 2.2664732933044434\n",
      "Loss at Iteration @ 9225 is 2.174941301345825\n",
      "Evaluation Loss at Iteration @ 9225 is 2.202866554260254\n",
      "Loss at Iteration @ 9226 is 2.1663365364074707\n",
      "Evaluation Loss at Iteration @ 9226 is 2.2629129886627197\n",
      "Loss at Iteration @ 9227 is 2.09242582321167\n",
      "Evaluation Loss at Iteration @ 9227 is 2.3174996376037598\n",
      "Loss at Iteration @ 9228 is 2.234448194503784\n",
      "Evaluation Loss at Iteration @ 9228 is 2.264360189437866\n",
      "Loss at Iteration @ 9229 is 2.05015230178833\n",
      "Evaluation Loss at Iteration @ 9229 is 2.204376459121704\n",
      "Loss at Iteration @ 9230 is 2.173035144805908\n",
      "Evaluation Loss at Iteration @ 9230 is 2.2189388275146484\n",
      "Loss at Iteration @ 9231 is 2.4270780086517334\n",
      "Evaluation Loss at Iteration @ 9231 is 2.246519088745117\n",
      "Loss at Iteration @ 9232 is 2.5177934169769287\n",
      "Evaluation Loss at Iteration @ 9232 is 2.2395377159118652\n",
      "Loss at Iteration @ 9233 is 2.4155759811401367\n",
      "Evaluation Loss at Iteration @ 9233 is 2.224792718887329\n",
      "Loss at Iteration @ 9234 is 2.092918872833252\n",
      "Evaluation Loss at Iteration @ 9234 is 2.25463604927063\n",
      "Loss at Iteration @ 9235 is 1.8778148889541626\n",
      "Evaluation Loss at Iteration @ 9235 is 2.2186639308929443\n",
      "Loss at Iteration @ 9236 is 2.4770395755767822\n",
      "Evaluation Loss at Iteration @ 9236 is 2.2507214546203613\n",
      "Loss at Iteration @ 9237 is 2.215526580810547\n",
      "Evaluation Loss at Iteration @ 9237 is 2.215848207473755\n",
      "Loss at Iteration @ 9238 is 2.2657647132873535\n",
      "Evaluation Loss at Iteration @ 9238 is 2.281978130340576\n",
      "Loss at Iteration @ 9239 is 1.9978735446929932\n",
      "Evaluation Loss at Iteration @ 9239 is 2.21905779838562\n",
      "Loss at Iteration @ 9240 is 2.766404628753662\n",
      "Evaluation Loss at Iteration @ 9240 is 2.2380642890930176\n",
      "Loss at Iteration @ 9241 is 2.0908284187316895\n",
      "Evaluation Loss at Iteration @ 9241 is 2.225346088409424\n",
      "Loss at Iteration @ 9242 is 2.07124662399292\n",
      "Evaluation Loss at Iteration @ 9242 is 2.2628681659698486\n",
      "Loss at Iteration @ 9243 is 2.3810057640075684\n",
      "Evaluation Loss at Iteration @ 9243 is 2.2473134994506836\n",
      "Loss at Iteration @ 9244 is 2.085538625717163\n",
      "Evaluation Loss at Iteration @ 9244 is 2.218400478363037\n",
      "Loss at Iteration @ 9245 is 2.4468016624450684\n",
      "Evaluation Loss at Iteration @ 9245 is 2.240650177001953\n",
      "Loss at Iteration @ 9246 is 2.290933847427368\n",
      "Evaluation Loss at Iteration @ 9246 is 2.2572295665740967\n",
      "Loss at Iteration @ 9247 is 2.171673536300659\n",
      "Evaluation Loss at Iteration @ 9247 is 2.307807207107544\n",
      "Loss at Iteration @ 9248 is 2.2593820095062256\n",
      "Evaluation Loss at Iteration @ 9248 is 2.2560782432556152\n",
      "Loss at Iteration @ 9249 is 2.1861321926116943\n",
      "Evaluation Loss at Iteration @ 9249 is 2.2169370651245117\n",
      "Loss at Iteration @ 9250 is 1.952833890914917\n",
      "Evaluation Loss at Iteration @ 9250 is 2.275385856628418\n",
      "Loss at Iteration @ 9251 is 2.3109333515167236\n",
      "Evaluation Loss at Iteration @ 9251 is 2.2582976818084717\n",
      "Loss at Iteration @ 9252 is 2.0197818279266357\n",
      "Evaluation Loss at Iteration @ 9252 is 2.232698440551758\n",
      "Loss at Iteration @ 9253 is 2.252791166305542\n",
      "Evaluation Loss at Iteration @ 9253 is 2.228332281112671\n",
      "Loss at Iteration @ 9254 is 2.1037211418151855\n",
      "Evaluation Loss at Iteration @ 9254 is 2.260230302810669\n",
      "Loss at Iteration @ 9255 is 2.269994020462036\n",
      "Evaluation Loss at Iteration @ 9255 is 2.223463773727417\n",
      "Loss at Iteration @ 9256 is 2.250764846801758\n",
      "Evaluation Loss at Iteration @ 9256 is 2.1981711387634277\n",
      "Loss at Iteration @ 9257 is 2.153029680252075\n",
      "Evaluation Loss at Iteration @ 9257 is 2.224490165710449\n",
      "Loss at Iteration @ 9258 is 2.346245288848877\n",
      "Evaluation Loss at Iteration @ 9258 is 2.2500717639923096\n",
      "Loss at Iteration @ 9259 is 2.085646390914917\n",
      "Evaluation Loss at Iteration @ 9259 is 2.247809410095215\n",
      "Loss at Iteration @ 9260 is 2.556241750717163\n",
      "Evaluation Loss at Iteration @ 9260 is 2.234340190887451\n",
      "Loss at Iteration @ 9261 is 2.2800257205963135\n",
      "Evaluation Loss at Iteration @ 9261 is 2.28790283203125\n",
      "Loss at Iteration @ 9262 is 2.332440137863159\n",
      "Evaluation Loss at Iteration @ 9262 is 2.2830090522766113\n",
      "Loss at Iteration @ 9263 is 2.244196653366089\n",
      "Evaluation Loss at Iteration @ 9263 is 2.245957374572754\n",
      "Loss at Iteration @ 9264 is 2.4429359436035156\n",
      "Evaluation Loss at Iteration @ 9264 is 2.2697741985321045\n",
      "Loss at Iteration @ 9265 is 2.2142679691314697\n",
      "Evaluation Loss at Iteration @ 9265 is 2.2356982231140137\n",
      "Loss at Iteration @ 9266 is 2.145475387573242\n",
      "Evaluation Loss at Iteration @ 9266 is 2.2616145610809326\n",
      "Loss at Iteration @ 9267 is 1.9944158792495728\n",
      "Evaluation Loss at Iteration @ 9267 is 2.25527024269104\n",
      "Loss at Iteration @ 9268 is 2.3155808448791504\n",
      "Evaluation Loss at Iteration @ 9268 is 2.3034582138061523\n",
      "Loss at Iteration @ 9269 is 2.3842427730560303\n",
      "Evaluation Loss at Iteration @ 9269 is 2.2872748374938965\n",
      "Loss at Iteration @ 9270 is 2.4806606769561768\n",
      "Evaluation Loss at Iteration @ 9270 is 2.251145839691162\n",
      "Loss at Iteration @ 9271 is 1.9775346517562866\n",
      "Evaluation Loss at Iteration @ 9271 is 2.2566308975219727\n",
      "Loss at Iteration @ 9272 is 2.1468539237976074\n",
      "Evaluation Loss at Iteration @ 9272 is 2.246129274368286\n",
      "Loss at Iteration @ 9273 is 2.5528640747070312\n",
      "Evaluation Loss at Iteration @ 9273 is 2.2508583068847656\n",
      "Loss at Iteration @ 9274 is 2.2693493366241455\n",
      "Evaluation Loss at Iteration @ 9274 is 2.194178819656372\n",
      "Loss at Iteration @ 9275 is 2.1185760498046875\n",
      "Evaluation Loss at Iteration @ 9275 is 2.2508463859558105\n",
      "Loss at Iteration @ 9276 is 2.3573222160339355\n",
      "Evaluation Loss at Iteration @ 9276 is 2.240818500518799\n",
      "Loss at Iteration @ 9277 is 2.091076135635376\n",
      "Evaluation Loss at Iteration @ 9277 is 2.306875705718994\n",
      "Loss at Iteration @ 9278 is 2.2668426036834717\n",
      "Evaluation Loss at Iteration @ 9278 is 2.2093756198883057\n",
      "Loss at Iteration @ 9279 is 2.1680259704589844\n",
      "Evaluation Loss at Iteration @ 9279 is 2.2163376808166504\n",
      "Loss at Iteration @ 9280 is 2.606294631958008\n",
      "Evaluation Loss at Iteration @ 9280 is 2.29763126373291\n",
      "Loss at Iteration @ 9281 is 2.2829482555389404\n",
      "Evaluation Loss at Iteration @ 9281 is 2.240461587905884\n",
      "Loss at Iteration @ 9282 is 2.226250648498535\n",
      "Evaluation Loss at Iteration @ 9282 is 2.2350618839263916\n",
      "Loss at Iteration @ 9283 is 2.420654058456421\n",
      "Evaluation Loss at Iteration @ 9283 is 2.248567581176758\n",
      "Loss at Iteration @ 9284 is 2.0903897285461426\n",
      "Evaluation Loss at Iteration @ 9284 is 2.2577943801879883\n",
      "Loss at Iteration @ 9285 is 2.074340343475342\n",
      "Evaluation Loss at Iteration @ 9285 is 2.268810510635376\n",
      "Loss at Iteration @ 9286 is 2.0579540729522705\n",
      "Evaluation Loss at Iteration @ 9286 is 2.2380688190460205\n",
      "Loss at Iteration @ 9287 is 2.0126428604125977\n",
      "Evaluation Loss at Iteration @ 9287 is 2.299304962158203\n",
      "Loss at Iteration @ 9288 is 2.0395567417144775\n",
      "Evaluation Loss at Iteration @ 9288 is 2.2465450763702393\n",
      "Loss at Iteration @ 9289 is 2.637052297592163\n",
      "Evaluation Loss at Iteration @ 9289 is 2.260749101638794\n",
      "Loss at Iteration @ 9290 is 2.403510093688965\n",
      "Evaluation Loss at Iteration @ 9290 is 2.257322072982788\n",
      "Loss at Iteration @ 9291 is 2.085157632827759\n",
      "Evaluation Loss at Iteration @ 9291 is 2.2653229236602783\n",
      "Loss at Iteration @ 9292 is 2.025932550430298\n",
      "Evaluation Loss at Iteration @ 9292 is 2.2475318908691406\n",
      "Loss at Iteration @ 9293 is 2.276930809020996\n",
      "Evaluation Loss at Iteration @ 9293 is 2.236772060394287\n",
      "Loss at Iteration @ 9294 is 2.2925941944122314\n",
      "Evaluation Loss at Iteration @ 9294 is 2.291984796524048\n",
      "Loss at Iteration @ 9295 is 2.072754144668579\n",
      "Evaluation Loss at Iteration @ 9295 is 2.224186420440674\n",
      "Loss at Iteration @ 9296 is 2.11033034324646\n",
      "Evaluation Loss at Iteration @ 9296 is 2.260589599609375\n",
      "Loss at Iteration @ 9297 is 2.415229558944702\n",
      "Evaluation Loss at Iteration @ 9297 is 2.2482502460479736\n",
      "Loss at Iteration @ 9298 is 2.418933153152466\n",
      "Evaluation Loss at Iteration @ 9298 is 2.201629161834717\n",
      "Loss at Iteration @ 9299 is 2.158473014831543\n",
      "Evaluation Loss at Iteration @ 9299 is 2.2538201808929443\n",
      "Loss at Iteration @ 9300 is 1.9061723947525024\n",
      "Evaluation Loss at Iteration @ 9300 is 2.244593620300293\n",
      "Loss at Iteration @ 9301 is 1.9863680601119995\n",
      "Evaluation Loss at Iteration @ 9301 is 2.2426323890686035\n",
      "Loss at Iteration @ 9302 is 2.15041446685791\n",
      "Evaluation Loss at Iteration @ 9302 is 2.2251105308532715\n",
      "Loss at Iteration @ 9303 is 2.281167507171631\n",
      "Evaluation Loss at Iteration @ 9303 is 2.2102599143981934\n",
      "Loss at Iteration @ 9304 is 2.2389492988586426\n",
      "Evaluation Loss at Iteration @ 9304 is 2.2578446865081787\n",
      "Loss at Iteration @ 9305 is 2.306394100189209\n",
      "Evaluation Loss at Iteration @ 9305 is 2.2583184242248535\n",
      "Loss at Iteration @ 9306 is 2.5128979682922363\n",
      "Evaluation Loss at Iteration @ 9306 is 2.279933452606201\n",
      "Loss at Iteration @ 9307 is 2.1831445693969727\n",
      "Evaluation Loss at Iteration @ 9307 is 2.26619815826416\n",
      "Loss at Iteration @ 9308 is 2.5736639499664307\n",
      "Evaluation Loss at Iteration @ 9308 is 2.253674030303955\n",
      "Loss at Iteration @ 9309 is 2.1384384632110596\n",
      "Evaluation Loss at Iteration @ 9309 is 2.2715768814086914\n",
      "Loss at Iteration @ 9310 is 2.2046616077423096\n",
      "Evaluation Loss at Iteration @ 9310 is 2.2517426013946533\n",
      "Loss at Iteration @ 9311 is 2.1484055519104004\n",
      "Evaluation Loss at Iteration @ 9311 is 2.245187997817993\n",
      "Loss at Iteration @ 9312 is 2.308769702911377\n",
      "Evaluation Loss at Iteration @ 9312 is 2.274265766143799\n",
      "Loss at Iteration @ 9313 is 2.2366271018981934\n",
      "Evaluation Loss at Iteration @ 9313 is 2.2372257709503174\n",
      "Loss at Iteration @ 9314 is 2.501547336578369\n",
      "Evaluation Loss at Iteration @ 9314 is 2.3216373920440674\n",
      "Loss at Iteration @ 9315 is 2.4072792530059814\n",
      "Evaluation Loss at Iteration @ 9315 is 2.2440292835235596\n",
      "Loss at Iteration @ 9316 is 2.483275890350342\n",
      "Evaluation Loss at Iteration @ 9316 is 2.262862205505371\n",
      "Loss at Iteration @ 9317 is 2.3925132751464844\n",
      "Evaluation Loss at Iteration @ 9317 is 2.2659687995910645\n",
      "Loss at Iteration @ 9318 is 2.185595989227295\n",
      "Evaluation Loss at Iteration @ 9318 is 2.2805473804473877\n",
      "Loss at Iteration @ 9319 is 2.2292022705078125\n",
      "Evaluation Loss at Iteration @ 9319 is 2.2799935340881348\n",
      "Loss at Iteration @ 9320 is 2.192457675933838\n",
      "Evaluation Loss at Iteration @ 9320 is 2.222388982772827\n",
      "Loss at Iteration @ 9321 is 2.111131429672241\n",
      "Evaluation Loss at Iteration @ 9321 is 2.230431079864502\n",
      "Loss at Iteration @ 9322 is 2.2313578128814697\n",
      "Evaluation Loss at Iteration @ 9322 is 2.1983602046966553\n",
      "Loss at Iteration @ 9323 is 2.160064458847046\n",
      "Evaluation Loss at Iteration @ 9323 is 2.283994197845459\n",
      "Loss at Iteration @ 9324 is 2.2153189182281494\n",
      "Evaluation Loss at Iteration @ 9324 is 2.2381324768066406\n",
      "Loss at Iteration @ 9325 is 2.001075029373169\n",
      "Evaluation Loss at Iteration @ 9325 is 2.22265362739563\n",
      "Loss at Iteration @ 9326 is 1.9686869382858276\n",
      "Evaluation Loss at Iteration @ 9326 is 2.254664897918701\n",
      "Loss at Iteration @ 9327 is 2.0422005653381348\n",
      "Evaluation Loss at Iteration @ 9327 is 2.2394912242889404\n",
      "Loss at Iteration @ 9328 is 2.2559797763824463\n",
      "Evaluation Loss at Iteration @ 9328 is 2.264023542404175\n",
      "Loss at Iteration @ 9329 is 2.2385647296905518\n",
      "Evaluation Loss at Iteration @ 9329 is 2.2247157096862793\n",
      "Loss at Iteration @ 9330 is 2.0578742027282715\n",
      "Evaluation Loss at Iteration @ 9330 is 2.2187933921813965\n",
      "Loss at Iteration @ 9331 is 2.4551517963409424\n",
      "Evaluation Loss at Iteration @ 9331 is 2.2652430534362793\n",
      "Loss at Iteration @ 9332 is 2.1560068130493164\n",
      "Evaluation Loss at Iteration @ 9332 is 2.2900161743164062\n",
      "Loss at Iteration @ 9333 is 2.205686330795288\n",
      "Evaluation Loss at Iteration @ 9333 is 2.2452142238616943\n",
      "Loss at Iteration @ 9334 is 2.1697232723236084\n",
      "Evaluation Loss at Iteration @ 9334 is 2.211207389831543\n",
      "Loss at Iteration @ 9335 is 2.0440783500671387\n",
      "Evaluation Loss at Iteration @ 9335 is 2.2622766494750977\n",
      "Loss at Iteration @ 9336 is 2.407200813293457\n",
      "Evaluation Loss at Iteration @ 9336 is 2.24316143989563\n",
      "Loss at Iteration @ 9337 is 2.3337273597717285\n",
      "Evaluation Loss at Iteration @ 9337 is 2.2317099571228027\n",
      "Loss at Iteration @ 9338 is 2.3638105392456055\n",
      "Evaluation Loss at Iteration @ 9338 is 2.2660839557647705\n",
      "Loss at Iteration @ 9339 is 2.2359230518341064\n",
      "Evaluation Loss at Iteration @ 9339 is 2.255284309387207\n",
      "Loss at Iteration @ 9340 is 1.8747485876083374\n",
      "Evaluation Loss at Iteration @ 9340 is 2.2229511737823486\n",
      "Loss at Iteration @ 9341 is 2.0793299674987793\n",
      "Evaluation Loss at Iteration @ 9341 is 2.2711849212646484\n",
      "Loss at Iteration @ 9342 is 2.1148078441619873\n",
      "Evaluation Loss at Iteration @ 9342 is 2.266514539718628\n",
      "Loss at Iteration @ 9343 is 2.0486412048339844\n",
      "Evaluation Loss at Iteration @ 9343 is 2.270939826965332\n",
      "Loss at Iteration @ 9344 is 2.0660369396209717\n",
      "Evaluation Loss at Iteration @ 9344 is 2.261486768722534\n",
      "Loss at Iteration @ 9345 is 2.3346121311187744\n",
      "Evaluation Loss at Iteration @ 9345 is 2.2055563926696777\n",
      "Loss at Iteration @ 9346 is 2.4785914421081543\n",
      "Evaluation Loss at Iteration @ 9346 is 2.254206657409668\n",
      "Loss at Iteration @ 9347 is 2.1111292839050293\n",
      "Evaluation Loss at Iteration @ 9347 is 2.246354341506958\n",
      "Loss at Iteration @ 9348 is 2.3127996921539307\n",
      "Evaluation Loss at Iteration @ 9348 is 2.212879180908203\n",
      "Loss at Iteration @ 9349 is 2.2732625007629395\n",
      "Evaluation Loss at Iteration @ 9349 is 2.2420971393585205\n",
      "Loss at Iteration @ 9350 is 2.3727383613586426\n",
      "Evaluation Loss at Iteration @ 9350 is 2.222266674041748\n",
      "Loss at Iteration @ 9351 is 2.220871925354004\n",
      "Evaluation Loss at Iteration @ 9351 is 2.2502613067626953\n",
      "Loss at Iteration @ 9352 is 2.2409582138061523\n",
      "Evaluation Loss at Iteration @ 9352 is 2.244847059249878\n",
      "Loss at Iteration @ 9353 is 2.131382942199707\n",
      "Evaluation Loss at Iteration @ 9353 is 2.2096657752990723\n",
      "Loss at Iteration @ 9354 is 2.1370556354522705\n",
      "Evaluation Loss at Iteration @ 9354 is 2.1773440837860107\n",
      "Loss at Iteration @ 9355 is 1.8384884595870972\n",
      "Evaluation Loss at Iteration @ 9355 is 2.2776801586151123\n",
      "Loss at Iteration @ 9356 is 2.3302297592163086\n",
      "Evaluation Loss at Iteration @ 9356 is 2.2270395755767822\n",
      "Loss at Iteration @ 9357 is 2.4017741680145264\n",
      "Evaluation Loss at Iteration @ 9357 is 2.2349798679351807\n",
      "Loss at Iteration @ 9358 is 2.3359291553497314\n",
      "Evaluation Loss at Iteration @ 9358 is 2.2056925296783447\n",
      "Loss at Iteration @ 9359 is 2.275940179824829\n",
      "Evaluation Loss at Iteration @ 9359 is 2.263225793838501\n",
      "Loss at Iteration @ 9360 is 2.1012330055236816\n",
      "Evaluation Loss at Iteration @ 9360 is 2.230719804763794\n",
      "Loss at Iteration @ 9361 is 2.433150053024292\n",
      "Evaluation Loss at Iteration @ 9361 is 2.2738122940063477\n",
      "Loss at Iteration @ 9362 is 1.9763506650924683\n",
      "Evaluation Loss at Iteration @ 9362 is 2.2736175060272217\n",
      "Loss at Iteration @ 9363 is 2.2449846267700195\n",
      "Evaluation Loss at Iteration @ 9363 is 2.285809278488159\n",
      "Loss at Iteration @ 9364 is 2.081547498703003\n",
      "Evaluation Loss at Iteration @ 9364 is 2.261704444885254\n",
      "Loss at Iteration @ 9365 is 1.9318445920944214\n",
      "Evaluation Loss at Iteration @ 9365 is 2.233616828918457\n",
      "Loss at Iteration @ 9366 is 2.0136890411376953\n",
      "Evaluation Loss at Iteration @ 9366 is 2.264508008956909\n",
      "Loss at Iteration @ 9367 is 1.934109091758728\n",
      "Evaluation Loss at Iteration @ 9367 is 2.2129452228546143\n",
      "Loss at Iteration @ 9368 is 2.1423497200012207\n",
      "Evaluation Loss at Iteration @ 9368 is 2.281846761703491\n",
      "Loss at Iteration @ 9369 is 2.1720972061157227\n",
      "Evaluation Loss at Iteration @ 9369 is 2.2253005504608154\n",
      "Loss at Iteration @ 9370 is 2.5737528800964355\n",
      "Evaluation Loss at Iteration @ 9370 is 2.267171621322632\n",
      "Loss at Iteration @ 9371 is 2.2211203575134277\n",
      "Evaluation Loss at Iteration @ 9371 is 2.2510879039764404\n",
      "Loss at Iteration @ 9372 is 2.421874523162842\n",
      "Evaluation Loss at Iteration @ 9372 is 2.2701356410980225\n",
      "Loss at Iteration @ 9373 is 2.1193320751190186\n",
      "Evaluation Loss at Iteration @ 9373 is 2.2017083168029785\n",
      "Loss at Iteration @ 9374 is 2.342242479324341\n",
      "Evaluation Loss at Iteration @ 9374 is 2.2900755405426025\n",
      "Loss at Iteration @ 9375 is 2.3486783504486084\n",
      "Evaluation Loss at Iteration @ 9375 is 2.2372612953186035\n",
      "Loss at Iteration @ 9376 is 2.3126115798950195\n",
      "Evaluation Loss at Iteration @ 9376 is 2.2595551013946533\n",
      "Loss at Iteration @ 9377 is 2.3659744262695312\n",
      "Evaluation Loss at Iteration @ 9377 is 2.2531607151031494\n",
      "Loss at Iteration @ 9378 is 2.0601892471313477\n",
      "Evaluation Loss at Iteration @ 9378 is 2.229667901992798\n",
      "Loss at Iteration @ 9379 is 2.3100109100341797\n",
      "Evaluation Loss at Iteration @ 9379 is 2.303863763809204\n",
      "Loss at Iteration @ 9380 is 2.338503360748291\n",
      "Evaluation Loss at Iteration @ 9380 is 2.235396146774292\n",
      "Loss at Iteration @ 9381 is 2.241595983505249\n",
      "Evaluation Loss at Iteration @ 9381 is 2.258643388748169\n",
      "Loss at Iteration @ 9382 is 2.090925455093384\n",
      "Evaluation Loss at Iteration @ 9382 is 2.2723629474639893\n",
      "Loss at Iteration @ 9383 is 2.2296695709228516\n",
      "Evaluation Loss at Iteration @ 9383 is 2.2562882900238037\n",
      "Loss at Iteration @ 9384 is 2.3601763248443604\n",
      "Evaluation Loss at Iteration @ 9384 is 2.240652322769165\n",
      "Loss at Iteration @ 9385 is 1.9647926092147827\n",
      "Evaluation Loss at Iteration @ 9385 is 2.1988284587860107\n",
      "Loss at Iteration @ 9386 is 2.1769466400146484\n",
      "Evaluation Loss at Iteration @ 9386 is 2.201092004776001\n",
      "Loss at Iteration @ 9387 is 2.4673502445220947\n",
      "Evaluation Loss at Iteration @ 9387 is 2.259556293487549\n",
      "Loss at Iteration @ 9388 is 2.410587787628174\n",
      "Evaluation Loss at Iteration @ 9388 is 2.2230286598205566\n",
      "Loss at Iteration @ 9389 is 2.164024591445923\n",
      "Evaluation Loss at Iteration @ 9389 is 2.21628999710083\n",
      "Loss at Iteration @ 9390 is 2.4415183067321777\n",
      "Evaluation Loss at Iteration @ 9390 is 2.156710386276245\n",
      "Loss at Iteration @ 9391 is 2.504513740539551\n",
      "Evaluation Loss at Iteration @ 9391 is 2.283252239227295\n",
      "Loss at Iteration @ 9392 is 2.0164525508880615\n",
      "Evaluation Loss at Iteration @ 9392 is 2.222167491912842\n",
      "Loss at Iteration @ 9393 is 2.1251676082611084\n",
      "Evaluation Loss at Iteration @ 9393 is 2.251380681991577\n",
      "Loss at Iteration @ 9394 is 2.3615031242370605\n",
      "Evaluation Loss at Iteration @ 9394 is 2.2496657371520996\n",
      "Loss at Iteration @ 9395 is 1.9768470525741577\n",
      "Evaluation Loss at Iteration @ 9395 is 2.2289724349975586\n",
      "Loss at Iteration @ 9396 is 1.9776817560195923\n",
      "Evaluation Loss at Iteration @ 9396 is 2.2201454639434814\n",
      "Loss at Iteration @ 9397 is 2.143564462661743\n",
      "Evaluation Loss at Iteration @ 9397 is 2.25644850730896\n",
      "Loss at Iteration @ 9398 is 2.327432632446289\n",
      "Evaluation Loss at Iteration @ 9398 is 2.2628068923950195\n",
      "Loss at Iteration @ 9399 is 2.1310322284698486\n",
      "Evaluation Loss at Iteration @ 9399 is 2.2740085124969482\n",
      "Loss at Iteration @ 9400 is 2.123610258102417\n",
      "Evaluation Loss at Iteration @ 9400 is 2.294602870941162\n",
      "Loss at Iteration @ 9401 is 2.5133485794067383\n",
      "Evaluation Loss at Iteration @ 9401 is 2.2948718070983887\n",
      "Loss at Iteration @ 9402 is 2.1587517261505127\n",
      "Evaluation Loss at Iteration @ 9402 is 2.2789225578308105\n",
      "Loss at Iteration @ 9403 is 2.3265349864959717\n",
      "Evaluation Loss at Iteration @ 9403 is 2.220126152038574\n",
      "Loss at Iteration @ 9404 is 2.252387046813965\n",
      "Evaluation Loss at Iteration @ 9404 is 2.2835352420806885\n",
      "Loss at Iteration @ 9405 is 2.144636869430542\n",
      "Evaluation Loss at Iteration @ 9405 is 2.283567428588867\n",
      "Loss at Iteration @ 9406 is 2.300034284591675\n",
      "Evaluation Loss at Iteration @ 9406 is 2.2359282970428467\n",
      "Loss at Iteration @ 9407 is 2.1458241939544678\n",
      "Evaluation Loss at Iteration @ 9407 is 2.212310314178467\n",
      "Loss at Iteration @ 9408 is 2.2560911178588867\n",
      "Evaluation Loss at Iteration @ 9408 is 2.2099499702453613\n",
      "Loss at Iteration @ 9409 is 2.060824394226074\n",
      "Evaluation Loss at Iteration @ 9409 is 2.2679190635681152\n",
      "Loss at Iteration @ 9410 is 2.227884292602539\n",
      "Evaluation Loss at Iteration @ 9410 is 2.225139856338501\n",
      "Loss at Iteration @ 9411 is 2.2306902408599854\n",
      "Evaluation Loss at Iteration @ 9411 is 2.191416025161743\n",
      "Loss at Iteration @ 9412 is 2.112583637237549\n",
      "Evaluation Loss at Iteration @ 9412 is 2.27466082572937\n",
      "Loss at Iteration @ 9413 is 1.9589450359344482\n",
      "Evaluation Loss at Iteration @ 9413 is 2.2259721755981445\n",
      "Loss at Iteration @ 9414 is 2.173994779586792\n",
      "Evaluation Loss at Iteration @ 9414 is 2.2145111560821533\n",
      "Loss at Iteration @ 9415 is 2.1971843242645264\n",
      "Evaluation Loss at Iteration @ 9415 is 2.2416484355926514\n",
      "Loss at Iteration @ 9416 is 2.4341342449188232\n",
      "Evaluation Loss at Iteration @ 9416 is 2.1932737827301025\n",
      "Loss at Iteration @ 9417 is 2.1405320167541504\n",
      "Evaluation Loss at Iteration @ 9417 is 2.255059003829956\n",
      "Loss at Iteration @ 9418 is 2.0684847831726074\n",
      "Evaluation Loss at Iteration @ 9418 is 2.2851710319519043\n",
      "Loss at Iteration @ 9419 is 2.542745590209961\n",
      "Evaluation Loss at Iteration @ 9419 is 2.264237880706787\n",
      "Loss at Iteration @ 9420 is 2.2054944038391113\n",
      "Evaluation Loss at Iteration @ 9420 is 2.236288070678711\n",
      "Loss at Iteration @ 9421 is 2.110029697418213\n",
      "Evaluation Loss at Iteration @ 9421 is 2.254279613494873\n",
      "Loss at Iteration @ 9422 is 2.544008731842041\n",
      "Evaluation Loss at Iteration @ 9422 is 2.259021043777466\n",
      "Loss at Iteration @ 9423 is 2.291947364807129\n",
      "Evaluation Loss at Iteration @ 9423 is 2.277853488922119\n",
      "Loss at Iteration @ 9424 is 2.2033870220184326\n",
      "Evaluation Loss at Iteration @ 9424 is 2.2535440921783447\n",
      "Loss at Iteration @ 9425 is 2.3061296939849854\n",
      "Evaluation Loss at Iteration @ 9425 is 2.2143378257751465\n",
      "Loss at Iteration @ 9426 is 2.15739107131958\n",
      "Evaluation Loss at Iteration @ 9426 is 2.257827043533325\n",
      "Loss at Iteration @ 9427 is 2.1492106914520264\n",
      "Evaluation Loss at Iteration @ 9427 is 2.264101028442383\n",
      "Loss at Iteration @ 9428 is 2.3646364212036133\n",
      "Evaluation Loss at Iteration @ 9428 is 2.235372543334961\n",
      "Loss at Iteration @ 9429 is 2.0523324012756348\n",
      "Evaluation Loss at Iteration @ 9429 is 2.2616384029388428\n",
      "Loss at Iteration @ 9430 is 2.273463726043701\n",
      "Evaluation Loss at Iteration @ 9430 is 2.250420331954956\n",
      "Loss at Iteration @ 9431 is 2.154191493988037\n",
      "Evaluation Loss at Iteration @ 9431 is 2.2771222591400146\n",
      "Loss at Iteration @ 9432 is 2.353275775909424\n",
      "Evaluation Loss at Iteration @ 9432 is 2.140692949295044\n",
      "Loss at Iteration @ 9433 is 2.342306613922119\n",
      "Evaluation Loss at Iteration @ 9433 is 2.2934868335723877\n",
      "Loss at Iteration @ 9434 is 2.385047674179077\n",
      "Evaluation Loss at Iteration @ 9434 is 2.2127115726470947\n",
      "Loss at Iteration @ 9435 is 2.387369394302368\n",
      "Evaluation Loss at Iteration @ 9435 is 2.232053279876709\n",
      "Loss at Iteration @ 9436 is 2.1924657821655273\n",
      "Evaluation Loss at Iteration @ 9436 is 2.2295594215393066\n",
      "Loss at Iteration @ 9437 is 2.374659299850464\n",
      "Evaluation Loss at Iteration @ 9437 is 2.2250516414642334\n",
      "Loss at Iteration @ 9438 is 2.2768423557281494\n",
      "Evaluation Loss at Iteration @ 9438 is 2.2346062660217285\n",
      "Loss at Iteration @ 9439 is 2.1827290058135986\n",
      "Evaluation Loss at Iteration @ 9439 is 2.2442922592163086\n",
      "Loss at Iteration @ 9440 is 2.168382167816162\n",
      "Evaluation Loss at Iteration @ 9440 is 2.3148019313812256\n",
      "Loss at Iteration @ 9441 is 2.066596508026123\n",
      "Evaluation Loss at Iteration @ 9441 is 2.247262477874756\n",
      "Loss at Iteration @ 9442 is 2.2560853958129883\n",
      "Evaluation Loss at Iteration @ 9442 is 2.2458066940307617\n",
      "Loss at Iteration @ 9443 is 2.0651636123657227\n",
      "Evaluation Loss at Iteration @ 9443 is 2.207041025161743\n",
      "Loss at Iteration @ 9444 is 2.44846510887146\n",
      "Evaluation Loss at Iteration @ 9444 is 2.258943557739258\n",
      "Loss at Iteration @ 9445 is 2.179145574569702\n",
      "Evaluation Loss at Iteration @ 9445 is 2.1997768878936768\n",
      "Loss at Iteration @ 9446 is 2.3092105388641357\n",
      "Evaluation Loss at Iteration @ 9446 is 2.335360527038574\n",
      "Loss at Iteration @ 9447 is 2.0973732471466064\n",
      "Evaluation Loss at Iteration @ 9447 is 2.2510387897491455\n",
      "Loss at Iteration @ 9448 is 2.4951770305633545\n",
      "Evaluation Loss at Iteration @ 9448 is 2.2594475746154785\n",
      "Loss at Iteration @ 9449 is 1.9941825866699219\n",
      "Evaluation Loss at Iteration @ 9449 is 2.2436776161193848\n",
      "Loss at Iteration @ 9450 is 2.228686809539795\n",
      "Evaluation Loss at Iteration @ 9450 is 2.238598346710205\n",
      "Loss at Iteration @ 9451 is 2.0948879718780518\n",
      "Evaluation Loss at Iteration @ 9451 is 2.2384841442108154\n",
      "Loss at Iteration @ 9452 is 1.9270129203796387\n",
      "Evaluation Loss at Iteration @ 9452 is 2.286841630935669\n",
      "Loss at Iteration @ 9453 is 1.9747226238250732\n",
      "Evaluation Loss at Iteration @ 9453 is 2.280740976333618\n",
      "Loss at Iteration @ 9454 is 2.344555377960205\n",
      "Evaluation Loss at Iteration @ 9454 is 2.2582263946533203\n",
      "Loss at Iteration @ 9455 is 2.1706278324127197\n",
      "Evaluation Loss at Iteration @ 9455 is 2.2429347038269043\n",
      "Loss at Iteration @ 9456 is 2.4314332008361816\n",
      "Evaluation Loss at Iteration @ 9456 is 2.215329647064209\n",
      "Loss at Iteration @ 9457 is 2.1083924770355225\n",
      "Evaluation Loss at Iteration @ 9457 is 2.264281988143921\n",
      "Loss at Iteration @ 9458 is 2.3706889152526855\n",
      "Evaluation Loss at Iteration @ 9458 is 2.243762254714966\n",
      "Loss at Iteration @ 9459 is 2.24814772605896\n",
      "Evaluation Loss at Iteration @ 9459 is 2.2352540493011475\n",
      "Loss at Iteration @ 9460 is 2.287135601043701\n",
      "Evaluation Loss at Iteration @ 9460 is 2.252490758895874\n",
      "Loss at Iteration @ 9461 is 2.3909101486206055\n",
      "Evaluation Loss at Iteration @ 9461 is 2.2807211875915527\n",
      "Loss at Iteration @ 9462 is 2.141902208328247\n",
      "Evaluation Loss at Iteration @ 9462 is 2.2493770122528076\n",
      "Loss at Iteration @ 9463 is 2.147944927215576\n",
      "Evaluation Loss at Iteration @ 9463 is 2.2695086002349854\n",
      "Loss at Iteration @ 9464 is 2.266146421432495\n",
      "Evaluation Loss at Iteration @ 9464 is 2.251037359237671\n",
      "Loss at Iteration @ 9465 is 2.0149824619293213\n",
      "Evaluation Loss at Iteration @ 9465 is 2.250946521759033\n",
      "Loss at Iteration @ 9466 is 2.3610942363739014\n",
      "Evaluation Loss at Iteration @ 9466 is 2.2601969242095947\n",
      "Loss at Iteration @ 9467 is 2.2055861949920654\n",
      "Evaluation Loss at Iteration @ 9467 is 2.2302262783050537\n",
      "Loss at Iteration @ 9468 is 1.994923710823059\n",
      "Evaluation Loss at Iteration @ 9468 is 2.240849733352661\n",
      "Loss at Iteration @ 9469 is 2.054140090942383\n",
      "Evaluation Loss at Iteration @ 9469 is 2.224201202392578\n",
      "Loss at Iteration @ 9470 is 2.3781135082244873\n",
      "Evaluation Loss at Iteration @ 9470 is 2.231874942779541\n",
      "Loss at Iteration @ 9471 is 2.160078287124634\n",
      "Evaluation Loss at Iteration @ 9471 is 2.2480852603912354\n",
      "Loss at Iteration @ 9472 is 2.4039642810821533\n",
      "Evaluation Loss at Iteration @ 9472 is 2.2388713359832764\n",
      "Loss at Iteration @ 9473 is 2.4132046699523926\n",
      "Evaluation Loss at Iteration @ 9473 is 2.270329236984253\n",
      "Loss at Iteration @ 9474 is 2.311953067779541\n",
      "Evaluation Loss at Iteration @ 9474 is 2.269754409790039\n",
      "Loss at Iteration @ 9475 is 1.936827540397644\n",
      "Evaluation Loss at Iteration @ 9475 is 2.245293140411377\n",
      "Loss at Iteration @ 9476 is 1.9708350896835327\n",
      "Evaluation Loss at Iteration @ 9476 is 2.3040339946746826\n",
      "Loss at Iteration @ 9477 is 2.2779040336608887\n",
      "Evaluation Loss at Iteration @ 9477 is 2.202868700027466\n",
      "Loss at Iteration @ 9478 is 2.1986865997314453\n",
      "Evaluation Loss at Iteration @ 9478 is 2.2651374340057373\n",
      "Loss at Iteration @ 9479 is 2.0932350158691406\n",
      "Evaluation Loss at Iteration @ 9479 is 2.3001253604888916\n",
      "Loss at Iteration @ 9480 is 2.2006804943084717\n",
      "Evaluation Loss at Iteration @ 9480 is 2.2836031913757324\n",
      "Loss at Iteration @ 9481 is 2.379032850265503\n",
      "Evaluation Loss at Iteration @ 9481 is 2.2458014488220215\n",
      "Loss at Iteration @ 9482 is 2.1865570545196533\n",
      "Evaluation Loss at Iteration @ 9482 is 2.268543004989624\n",
      "Loss at Iteration @ 9483 is 2.345599412918091\n",
      "Evaluation Loss at Iteration @ 9483 is 2.2350401878356934\n",
      "Loss at Iteration @ 9484 is 2.1926162242889404\n",
      "Evaluation Loss at Iteration @ 9484 is 2.258561849594116\n",
      "Loss at Iteration @ 9485 is 2.06178879737854\n",
      "Evaluation Loss at Iteration @ 9485 is 2.2565457820892334\n",
      "Loss at Iteration @ 9486 is 2.135263442993164\n",
      "Evaluation Loss at Iteration @ 9486 is 2.242846727371216\n",
      "Loss at Iteration @ 9487 is 2.1445586681365967\n",
      "Evaluation Loss at Iteration @ 9487 is 2.2434043884277344\n",
      "Loss at Iteration @ 9488 is 2.21966290473938\n",
      "Evaluation Loss at Iteration @ 9488 is 2.219391107559204\n",
      "Loss at Iteration @ 9489 is 1.9679850339889526\n",
      "Evaluation Loss at Iteration @ 9489 is 2.200967311859131\n",
      "Loss at Iteration @ 9490 is 2.404801368713379\n",
      "Evaluation Loss at Iteration @ 9490 is 2.203854560852051\n",
      "Loss at Iteration @ 9491 is 1.8352124691009521\n",
      "Evaluation Loss at Iteration @ 9491 is 2.2096657752990723\n",
      "Loss at Iteration @ 9492 is 2.169877529144287\n",
      "Evaluation Loss at Iteration @ 9492 is 2.2730350494384766\n",
      "Loss at Iteration @ 9493 is 2.5411605834960938\n",
      "Evaluation Loss at Iteration @ 9493 is 2.2661988735198975\n",
      "Loss at Iteration @ 9494 is 1.8879125118255615\n",
      "Evaluation Loss at Iteration @ 9494 is 2.2895829677581787\n",
      "Loss at Iteration @ 9495 is 2.0956435203552246\n",
      "Evaluation Loss at Iteration @ 9495 is 2.2557249069213867\n",
      "Loss at Iteration @ 9496 is 2.2926599979400635\n",
      "Evaluation Loss at Iteration @ 9496 is 2.3019914627075195\n",
      "Loss at Iteration @ 9497 is 2.2655510902404785\n",
      "Evaluation Loss at Iteration @ 9497 is 2.2474005222320557\n",
      "Loss at Iteration @ 9498 is 2.085233449935913\n",
      "Evaluation Loss at Iteration @ 9498 is 2.2452478408813477\n",
      "Loss at Iteration @ 9499 is 2.2868664264678955\n",
      "Evaluation Loss at Iteration @ 9499 is 2.2384347915649414\n",
      "Loss at Iteration @ 9500 is 2.069577693939209\n",
      "Evaluation Loss at Iteration @ 9500 is 2.252995729446411\n",
      "Loss at Iteration @ 9501 is 2.2778615951538086\n",
      "Evaluation Loss at Iteration @ 9501 is 2.2555460929870605\n",
      "Loss at Iteration @ 9502 is 2.2298178672790527\n",
      "Evaluation Loss at Iteration @ 9502 is 2.275905132293701\n",
      "Loss at Iteration @ 9503 is 2.335355281829834\n",
      "Evaluation Loss at Iteration @ 9503 is 2.240300416946411\n",
      "Loss at Iteration @ 9504 is 2.3863158226013184\n",
      "Evaluation Loss at Iteration @ 9504 is 2.275122880935669\n",
      "Loss at Iteration @ 9505 is 2.3470187187194824\n",
      "Evaluation Loss at Iteration @ 9505 is 2.2557315826416016\n",
      "Loss at Iteration @ 9506 is 2.3511877059936523\n",
      "Evaluation Loss at Iteration @ 9506 is 2.20719838142395\n",
      "Loss at Iteration @ 9507 is 2.358825206756592\n",
      "Evaluation Loss at Iteration @ 9507 is 2.2251698970794678\n",
      "Loss at Iteration @ 9508 is 2.203258752822876\n",
      "Evaluation Loss at Iteration @ 9508 is 2.209290027618408\n",
      "Loss at Iteration @ 9509 is 2.429321050643921\n",
      "Evaluation Loss at Iteration @ 9509 is 2.2028250694274902\n",
      "Loss at Iteration @ 9510 is 2.283884286880493\n",
      "Evaluation Loss at Iteration @ 9510 is 2.3085086345672607\n",
      "Loss at Iteration @ 9511 is 1.9438194036483765\n",
      "Evaluation Loss at Iteration @ 9511 is 2.2684991359710693\n",
      "Loss at Iteration @ 9512 is 2.2979753017425537\n",
      "Evaluation Loss at Iteration @ 9512 is 2.2604000568389893\n",
      "Loss at Iteration @ 9513 is 2.0250914096832275\n",
      "Evaluation Loss at Iteration @ 9513 is 2.2843401432037354\n",
      "Loss at Iteration @ 9514 is 2.306051015853882\n",
      "Evaluation Loss at Iteration @ 9514 is 2.2719130516052246\n",
      "Loss at Iteration @ 9515 is 2.257128953933716\n",
      "Evaluation Loss at Iteration @ 9515 is 2.237722635269165\n",
      "Loss at Iteration @ 9516 is 2.103764295578003\n",
      "Evaluation Loss at Iteration @ 9516 is 2.2562758922576904\n",
      "Loss at Iteration @ 9517 is 2.0043609142303467\n",
      "Evaluation Loss at Iteration @ 9517 is 2.195784091949463\n",
      "Loss at Iteration @ 9518 is 2.5788819789886475\n",
      "Evaluation Loss at Iteration @ 9518 is 2.2503530979156494\n",
      "Loss at Iteration @ 9519 is 2.4776322841644287\n",
      "Evaluation Loss at Iteration @ 9519 is 2.243856191635132\n",
      "Loss at Iteration @ 9520 is 2.44653582572937\n",
      "Evaluation Loss at Iteration @ 9520 is 2.2236568927764893\n",
      "Loss at Iteration @ 9521 is 2.178345203399658\n",
      "Evaluation Loss at Iteration @ 9521 is 2.2630417346954346\n",
      "Loss at Iteration @ 9522 is 2.3777832984924316\n",
      "Evaluation Loss at Iteration @ 9522 is 2.2306087017059326\n",
      "Loss at Iteration @ 9523 is 2.0683987140655518\n",
      "Evaluation Loss at Iteration @ 9523 is 2.2267544269561768\n",
      "Loss at Iteration @ 9524 is 2.185619831085205\n",
      "Evaluation Loss at Iteration @ 9524 is 2.2711422443389893\n",
      "Loss at Iteration @ 9525 is 2.2901129722595215\n",
      "Evaluation Loss at Iteration @ 9525 is 2.2273874282836914\n",
      "Loss at Iteration @ 9526 is 1.992520809173584\n",
      "Evaluation Loss at Iteration @ 9526 is 2.2626006603240967\n",
      "Loss at Iteration @ 9527 is 2.291802167892456\n",
      "Evaluation Loss at Iteration @ 9527 is 2.2567639350891113\n",
      "Loss at Iteration @ 9528 is 2.116964101791382\n",
      "Evaluation Loss at Iteration @ 9528 is 2.2543954849243164\n",
      "Loss at Iteration @ 9529 is 2.3239452838897705\n",
      "Evaluation Loss at Iteration @ 9529 is 2.212366819381714\n",
      "Loss at Iteration @ 9530 is 2.0146942138671875\n",
      "Evaluation Loss at Iteration @ 9530 is 2.2624099254608154\n",
      "Loss at Iteration @ 9531 is 2.1880311965942383\n",
      "Evaluation Loss at Iteration @ 9531 is 2.2271888256073\n",
      "Loss at Iteration @ 9532 is 2.0145671367645264\n",
      "Evaluation Loss at Iteration @ 9532 is 2.2552926540374756\n",
      "Loss at Iteration @ 9533 is 2.175907850265503\n",
      "Evaluation Loss at Iteration @ 9533 is 2.2467381954193115\n",
      "Loss at Iteration @ 9534 is 2.6480472087860107\n",
      "Evaluation Loss at Iteration @ 9534 is 2.2262604236602783\n",
      "Loss at Iteration @ 9535 is 2.1622097492218018\n",
      "Evaluation Loss at Iteration @ 9535 is 2.272351026535034\n",
      "Loss at Iteration @ 9536 is 2.4466965198516846\n",
      "Evaluation Loss at Iteration @ 9536 is 2.2381675243377686\n",
      "Loss at Iteration @ 9537 is 2.3123700618743896\n",
      "Evaluation Loss at Iteration @ 9537 is 2.229551076889038\n",
      "Loss at Iteration @ 9538 is 2.19315505027771\n",
      "Evaluation Loss at Iteration @ 9538 is 2.2177512645721436\n",
      "Loss at Iteration @ 9539 is 2.3147287368774414\n",
      "Evaluation Loss at Iteration @ 9539 is 2.2799153327941895\n",
      "Loss at Iteration @ 9540 is 2.2773804664611816\n",
      "Evaluation Loss at Iteration @ 9540 is 2.2604339122772217\n",
      "Loss at Iteration @ 9541 is 2.2143681049346924\n",
      "Evaluation Loss at Iteration @ 9541 is 2.2920305728912354\n",
      "Loss at Iteration @ 9542 is 2.3904173374176025\n",
      "Evaluation Loss at Iteration @ 9542 is 2.2168893814086914\n",
      "Loss at Iteration @ 9543 is 2.128002166748047\n",
      "Evaluation Loss at Iteration @ 9543 is 2.2883341312408447\n",
      "Loss at Iteration @ 9544 is 2.5099761486053467\n",
      "Evaluation Loss at Iteration @ 9544 is 2.205057144165039\n",
      "Loss at Iteration @ 9545 is 2.2156715393066406\n",
      "Evaluation Loss at Iteration @ 9545 is 2.229320764541626\n",
      "Loss at Iteration @ 9546 is 2.363412380218506\n",
      "Evaluation Loss at Iteration @ 9546 is 2.2389421463012695\n",
      "Loss at Iteration @ 9547 is 2.171628713607788\n",
      "Evaluation Loss at Iteration @ 9547 is 2.234712600708008\n",
      "Loss at Iteration @ 9548 is 2.3882522583007812\n",
      "Evaluation Loss at Iteration @ 9548 is 2.2012176513671875\n",
      "Loss at Iteration @ 9549 is 2.4261844158172607\n",
      "Evaluation Loss at Iteration @ 9549 is 2.2614784240722656\n",
      "Loss at Iteration @ 9550 is 2.4582173824310303\n",
      "Evaluation Loss at Iteration @ 9550 is 2.2126686573028564\n",
      "Loss at Iteration @ 9551 is 2.2545716762542725\n",
      "Evaluation Loss at Iteration @ 9551 is 2.3203935623168945\n",
      "Loss at Iteration @ 9552 is 2.1013784408569336\n",
      "Evaluation Loss at Iteration @ 9552 is 2.24287748336792\n",
      "Loss at Iteration @ 9553 is 2.1264965534210205\n",
      "Evaluation Loss at Iteration @ 9553 is 2.2649989128112793\n",
      "Loss at Iteration @ 9554 is 2.14188814163208\n",
      "Evaluation Loss at Iteration @ 9554 is 2.262852907180786\n",
      "Loss at Iteration @ 9555 is 2.103654623031616\n",
      "Evaluation Loss at Iteration @ 9555 is 2.2326624393463135\n",
      "Loss at Iteration @ 9556 is 2.535829544067383\n",
      "Evaluation Loss at Iteration @ 9556 is 2.2811524868011475\n",
      "Loss at Iteration @ 9557 is 2.059610605239868\n",
      "Evaluation Loss at Iteration @ 9557 is 2.2308995723724365\n",
      "Loss at Iteration @ 9558 is 2.4829885959625244\n",
      "Evaluation Loss at Iteration @ 9558 is 2.2771716117858887\n",
      "Loss at Iteration @ 9559 is 2.4516942501068115\n",
      "Evaluation Loss at Iteration @ 9559 is 2.252166509628296\n",
      "Loss at Iteration @ 9560 is 2.4541072845458984\n",
      "Evaluation Loss at Iteration @ 9560 is 2.315079689025879\n",
      "Loss at Iteration @ 9561 is 2.018615961074829\n",
      "Evaluation Loss at Iteration @ 9561 is 2.245330572128296\n",
      "Loss at Iteration @ 9562 is 1.985209584236145\n",
      "Evaluation Loss at Iteration @ 9562 is 2.2635223865509033\n",
      "Loss at Iteration @ 9563 is 2.294088363647461\n",
      "Evaluation Loss at Iteration @ 9563 is 2.2258927822113037\n",
      "Loss at Iteration @ 9564 is 2.2270028591156006\n",
      "Evaluation Loss at Iteration @ 9564 is 2.213292121887207\n",
      "Loss at Iteration @ 9565 is 2.2766149044036865\n",
      "Evaluation Loss at Iteration @ 9565 is 2.269702196121216\n",
      "Loss at Iteration @ 9566 is 1.9386576414108276\n",
      "Evaluation Loss at Iteration @ 9566 is 2.294605255126953\n",
      "Loss at Iteration @ 9567 is 2.0365002155303955\n",
      "Evaluation Loss at Iteration @ 9567 is 2.259395122528076\n",
      "Loss at Iteration @ 9568 is 2.478670597076416\n",
      "Evaluation Loss at Iteration @ 9568 is 2.2335855960845947\n",
      "Loss at Iteration @ 9569 is 2.2235352993011475\n",
      "Evaluation Loss at Iteration @ 9569 is 2.245666265487671\n",
      "Loss at Iteration @ 9570 is 2.2212374210357666\n",
      "Evaluation Loss at Iteration @ 9570 is 2.2450029850006104\n",
      "Loss at Iteration @ 9571 is 2.2827565670013428\n",
      "Evaluation Loss at Iteration @ 9571 is 2.2124745845794678\n",
      "Loss at Iteration @ 9572 is 2.543537139892578\n",
      "Evaluation Loss at Iteration @ 9572 is 2.2548725605010986\n",
      "Loss at Iteration @ 9573 is 2.207427978515625\n",
      "Evaluation Loss at Iteration @ 9573 is 2.2231292724609375\n",
      "Loss at Iteration @ 9574 is 2.201955556869507\n",
      "Evaluation Loss at Iteration @ 9574 is 2.286087989807129\n",
      "Loss at Iteration @ 9575 is 2.413886308670044\n",
      "Evaluation Loss at Iteration @ 9575 is 2.2858879566192627\n",
      "Loss at Iteration @ 9576 is 2.00783634185791\n",
      "Evaluation Loss at Iteration @ 9576 is 2.2320477962493896\n",
      "Loss at Iteration @ 9577 is 2.3782958984375\n",
      "Evaluation Loss at Iteration @ 9577 is 2.24200177192688\n",
      "Loss at Iteration @ 9578 is 2.0655930042266846\n",
      "Evaluation Loss at Iteration @ 9578 is 2.213560104370117\n",
      "Loss at Iteration @ 9579 is 1.7773317098617554\n",
      "Evaluation Loss at Iteration @ 9579 is 2.304657459259033\n",
      "Loss at Iteration @ 9580 is 2.2336957454681396\n",
      "Evaluation Loss at Iteration @ 9580 is 2.2386558055877686\n",
      "Loss at Iteration @ 9581 is 2.200789213180542\n",
      "Evaluation Loss at Iteration @ 9581 is 2.2368855476379395\n",
      "Loss at Iteration @ 9582 is 2.191281318664551\n",
      "Evaluation Loss at Iteration @ 9582 is 2.280003070831299\n",
      "Loss at Iteration @ 9583 is 2.664599657058716\n",
      "Evaluation Loss at Iteration @ 9583 is 2.2378628253936768\n",
      "Loss at Iteration @ 9584 is 2.5854904651641846\n",
      "Evaluation Loss at Iteration @ 9584 is 2.2765300273895264\n",
      "Loss at Iteration @ 9585 is 2.232999324798584\n",
      "Evaluation Loss at Iteration @ 9585 is 2.2205119132995605\n",
      "Loss at Iteration @ 9586 is 2.180915594100952\n",
      "Evaluation Loss at Iteration @ 9586 is 2.2541959285736084\n",
      "Loss at Iteration @ 9587 is 2.3017938137054443\n",
      "Evaluation Loss at Iteration @ 9587 is 2.278029441833496\n",
      "Loss at Iteration @ 9588 is 2.1488237380981445\n",
      "Evaluation Loss at Iteration @ 9588 is 2.247316598892212\n",
      "Loss at Iteration @ 9589 is 2.3652873039245605\n",
      "Evaluation Loss at Iteration @ 9589 is 2.2087509632110596\n",
      "Loss at Iteration @ 9590 is 2.293853521347046\n",
      "Evaluation Loss at Iteration @ 9590 is 2.2951102256774902\n",
      "Loss at Iteration @ 9591 is 2.375073194503784\n",
      "Evaluation Loss at Iteration @ 9591 is 2.235856294631958\n",
      "Loss at Iteration @ 9592 is 2.2655558586120605\n",
      "Evaluation Loss at Iteration @ 9592 is 2.22530460357666\n",
      "Loss at Iteration @ 9593 is 1.8972663879394531\n",
      "Evaluation Loss at Iteration @ 9593 is 2.218385696411133\n",
      "Loss at Iteration @ 9594 is 2.240506649017334\n",
      "Evaluation Loss at Iteration @ 9594 is 2.2244362831115723\n",
      "Loss at Iteration @ 9595 is 2.246812105178833\n",
      "Evaluation Loss at Iteration @ 9595 is 2.2369868755340576\n",
      "Loss at Iteration @ 9596 is 2.046776294708252\n",
      "Evaluation Loss at Iteration @ 9596 is 2.239942789077759\n",
      "Loss at Iteration @ 9597 is 2.1758995056152344\n",
      "Evaluation Loss at Iteration @ 9597 is 2.2647693157196045\n",
      "Loss at Iteration @ 9598 is 2.204648971557617\n",
      "Evaluation Loss at Iteration @ 9598 is 2.321223497390747\n",
      "Loss at Iteration @ 9599 is 2.18792986869812\n",
      "Evaluation Loss at Iteration @ 9599 is 2.253572463989258\n",
      "Loss at Iteration @ 9600 is 2.2787654399871826\n",
      "Evaluation Loss at Iteration @ 9600 is 2.24798583984375\n",
      "Loss at Iteration @ 9601 is 2.599033832550049\n",
      "Evaluation Loss at Iteration @ 9601 is 2.3138656616210938\n",
      "Loss at Iteration @ 9602 is 2.228849172592163\n",
      "Evaluation Loss at Iteration @ 9602 is 2.2309987545013428\n",
      "Loss at Iteration @ 9603 is 2.153653383255005\n",
      "Evaluation Loss at Iteration @ 9603 is 2.250969648361206\n",
      "Loss at Iteration @ 9604 is 2.2360339164733887\n",
      "Evaluation Loss at Iteration @ 9604 is 2.1978533267974854\n",
      "Loss at Iteration @ 9605 is 2.493924856185913\n",
      "Evaluation Loss at Iteration @ 9605 is 2.291801691055298\n",
      "Loss at Iteration @ 9606 is 2.1585683822631836\n",
      "Evaluation Loss at Iteration @ 9606 is 2.373208999633789\n",
      "Loss at Iteration @ 9607 is 2.3081908226013184\n",
      "Evaluation Loss at Iteration @ 9607 is 2.2332141399383545\n",
      "Loss at Iteration @ 9608 is 2.4535629749298096\n",
      "Evaluation Loss at Iteration @ 9608 is 2.2106258869171143\n",
      "Loss at Iteration @ 9609 is 2.3396027088165283\n",
      "Evaluation Loss at Iteration @ 9609 is 2.222635507583618\n",
      "Loss at Iteration @ 9610 is 2.2708938121795654\n",
      "Evaluation Loss at Iteration @ 9610 is 2.26629900932312\n",
      "Loss at Iteration @ 9611 is 2.280653476715088\n",
      "Evaluation Loss at Iteration @ 9611 is 2.209395408630371\n",
      "Loss at Iteration @ 9612 is 2.258629322052002\n",
      "Evaluation Loss at Iteration @ 9612 is 2.2445876598358154\n",
      "Loss at Iteration @ 9613 is 2.166295051574707\n",
      "Evaluation Loss at Iteration @ 9613 is 2.2366726398468018\n",
      "Loss at Iteration @ 9614 is 2.2751121520996094\n",
      "Evaluation Loss at Iteration @ 9614 is 2.2468953132629395\n",
      "Loss at Iteration @ 9615 is 2.3945484161376953\n",
      "Evaluation Loss at Iteration @ 9615 is 2.267137289047241\n",
      "Loss at Iteration @ 9616 is 2.266413688659668\n",
      "Evaluation Loss at Iteration @ 9616 is 2.2655293941497803\n",
      "Loss at Iteration @ 9617 is 2.272789478302002\n",
      "Evaluation Loss at Iteration @ 9617 is 2.28656005859375\n",
      "Loss at Iteration @ 9618 is 2.3140745162963867\n",
      "Evaluation Loss at Iteration @ 9618 is 2.281959056854248\n",
      "Loss at Iteration @ 9619 is 2.627847909927368\n",
      "Evaluation Loss at Iteration @ 9619 is 2.2600200176239014\n",
      "Loss at Iteration @ 9620 is 2.398057699203491\n",
      "Evaluation Loss at Iteration @ 9620 is 2.2395741939544678\n",
      "Loss at Iteration @ 9621 is 2.149836778640747\n",
      "Evaluation Loss at Iteration @ 9621 is 2.1905252933502197\n",
      "Loss at Iteration @ 9622 is 2.06154727935791\n",
      "Evaluation Loss at Iteration @ 9622 is 2.2323849201202393\n",
      "Loss at Iteration @ 9623 is 2.19457745552063\n",
      "Evaluation Loss at Iteration @ 9623 is 2.2836666107177734\n",
      "Loss at Iteration @ 9624 is 2.0889103412628174\n",
      "Evaluation Loss at Iteration @ 9624 is 2.234138250350952\n",
      "Loss at Iteration @ 9625 is 2.443007230758667\n",
      "Evaluation Loss at Iteration @ 9625 is 2.2766270637512207\n",
      "Loss at Iteration @ 9626 is 2.2156691551208496\n",
      "Evaluation Loss at Iteration @ 9626 is 2.224228620529175\n",
      "Loss at Iteration @ 9627 is 2.1409456729888916\n",
      "Evaluation Loss at Iteration @ 9627 is 2.2406086921691895\n",
      "Loss at Iteration @ 9628 is 2.3082821369171143\n",
      "Evaluation Loss at Iteration @ 9628 is 2.2424206733703613\n",
      "Loss at Iteration @ 9629 is 2.287943124771118\n",
      "Evaluation Loss at Iteration @ 9629 is 2.332318067550659\n",
      "Loss at Iteration @ 9630 is 1.925540804862976\n",
      "Evaluation Loss at Iteration @ 9630 is 2.264733076095581\n",
      "Loss at Iteration @ 9631 is 2.3750789165496826\n",
      "Evaluation Loss at Iteration @ 9631 is 2.2470335960388184\n",
      "Loss at Iteration @ 9632 is 1.9699474573135376\n",
      "Evaluation Loss at Iteration @ 9632 is 2.2572689056396484\n",
      "Loss at Iteration @ 9633 is 2.2270190715789795\n",
      "Evaluation Loss at Iteration @ 9633 is 2.1981024742126465\n",
      "Loss at Iteration @ 9634 is 2.1685733795166016\n",
      "Evaluation Loss at Iteration @ 9634 is 2.2464566230773926\n",
      "Loss at Iteration @ 9635 is 2.156761646270752\n",
      "Evaluation Loss at Iteration @ 9635 is 2.2503647804260254\n",
      "Loss at Iteration @ 9636 is 2.163801670074463\n",
      "Evaluation Loss at Iteration @ 9636 is 2.252260208129883\n",
      "Loss at Iteration @ 9637 is 2.3723909854888916\n",
      "Evaluation Loss at Iteration @ 9637 is 2.2369046211242676\n",
      "Loss at Iteration @ 9638 is 2.0778775215148926\n",
      "Evaluation Loss at Iteration @ 9638 is 2.241342306137085\n",
      "Loss at Iteration @ 9639 is 2.3950278759002686\n",
      "Evaluation Loss at Iteration @ 9639 is 2.283672332763672\n",
      "Loss at Iteration @ 9640 is 2.0647943019866943\n",
      "Evaluation Loss at Iteration @ 9640 is 2.217463731765747\n",
      "Loss at Iteration @ 9641 is 2.146536350250244\n",
      "Evaluation Loss at Iteration @ 9641 is 2.2471394538879395\n",
      "Loss at Iteration @ 9642 is 2.2036352157592773\n",
      "Evaluation Loss at Iteration @ 9642 is 2.2809102535247803\n",
      "Loss at Iteration @ 9643 is 2.004176378250122\n",
      "Evaluation Loss at Iteration @ 9643 is 2.262120485305786\n",
      "Loss at Iteration @ 9644 is 2.4505162239074707\n",
      "Evaluation Loss at Iteration @ 9644 is 2.224477767944336\n",
      "Loss at Iteration @ 9645 is 2.206040859222412\n",
      "Evaluation Loss at Iteration @ 9645 is 2.229388952255249\n",
      "Loss at Iteration @ 9646 is 2.235433578491211\n",
      "Evaluation Loss at Iteration @ 9646 is 2.2752535343170166\n",
      "Loss at Iteration @ 9647 is 2.3137171268463135\n",
      "Evaluation Loss at Iteration @ 9647 is 2.253678560256958\n",
      "Loss at Iteration @ 9648 is 2.3421337604522705\n",
      "Evaluation Loss at Iteration @ 9648 is 2.228231906890869\n",
      "Loss at Iteration @ 9649 is 2.0831117630004883\n",
      "Evaluation Loss at Iteration @ 9649 is 2.2514615058898926\n",
      "Loss at Iteration @ 9650 is 2.290494918823242\n",
      "Evaluation Loss at Iteration @ 9650 is 2.253676652908325\n",
      "Loss at Iteration @ 9651 is 2.178579807281494\n",
      "Evaluation Loss at Iteration @ 9651 is 2.242945909500122\n",
      "Loss at Iteration @ 9652 is 2.19858980178833\n",
      "Evaluation Loss at Iteration @ 9652 is 2.2333977222442627\n",
      "Loss at Iteration @ 9653 is 2.237941026687622\n",
      "Evaluation Loss at Iteration @ 9653 is 2.2676758766174316\n",
      "Loss at Iteration @ 9654 is 2.1731059551239014\n",
      "Evaluation Loss at Iteration @ 9654 is 2.2270426750183105\n",
      "Loss at Iteration @ 9655 is 2.2514488697052\n",
      "Evaluation Loss at Iteration @ 9655 is 2.2637500762939453\n",
      "Loss at Iteration @ 9656 is 2.174360513687134\n",
      "Evaluation Loss at Iteration @ 9656 is 2.2458059787750244\n",
      "Loss at Iteration @ 9657 is 2.261092185974121\n",
      "Evaluation Loss at Iteration @ 9657 is 2.246309518814087\n",
      "Loss at Iteration @ 9658 is 1.9333750009536743\n",
      "Evaluation Loss at Iteration @ 9658 is 2.2039413452148438\n",
      "Loss at Iteration @ 9659 is 2.287604808807373\n",
      "Evaluation Loss at Iteration @ 9659 is 2.230057954788208\n",
      "Loss at Iteration @ 9660 is 1.9491655826568604\n",
      "Evaluation Loss at Iteration @ 9660 is 2.2728734016418457\n",
      "Loss at Iteration @ 9661 is 2.3572998046875\n",
      "Evaluation Loss at Iteration @ 9661 is 2.2599363327026367\n",
      "Loss at Iteration @ 9662 is 2.0465662479400635\n",
      "Evaluation Loss at Iteration @ 9662 is 2.240450382232666\n",
      "Loss at Iteration @ 9663 is 2.1268701553344727\n",
      "Evaluation Loss at Iteration @ 9663 is 2.2352564334869385\n",
      "Loss at Iteration @ 9664 is 2.3503236770629883\n",
      "Evaluation Loss at Iteration @ 9664 is 2.2240376472473145\n",
      "Loss at Iteration @ 9665 is 2.1438701152801514\n",
      "Evaluation Loss at Iteration @ 9665 is 2.1793432235717773\n",
      "Loss at Iteration @ 9666 is 2.291335105895996\n",
      "Evaluation Loss at Iteration @ 9666 is 2.180579900741577\n",
      "Loss at Iteration @ 9667 is 2.016279697418213\n",
      "Evaluation Loss at Iteration @ 9667 is 2.257840633392334\n",
      "Loss at Iteration @ 9668 is 2.205045700073242\n",
      "Evaluation Loss at Iteration @ 9668 is 2.2463855743408203\n",
      "Loss at Iteration @ 9669 is 1.9655466079711914\n",
      "Evaluation Loss at Iteration @ 9669 is 2.2417409420013428\n",
      "Loss at Iteration @ 9670 is 2.186624050140381\n",
      "Evaluation Loss at Iteration @ 9670 is 2.2967851161956787\n",
      "Loss at Iteration @ 9671 is 2.216834545135498\n",
      "Evaluation Loss at Iteration @ 9671 is 2.2222580909729004\n",
      "Loss at Iteration @ 9672 is 2.3674776554107666\n",
      "Evaluation Loss at Iteration @ 9672 is 2.2219157218933105\n",
      "Loss at Iteration @ 9673 is 2.32515811920166\n",
      "Evaluation Loss at Iteration @ 9673 is 2.295428991317749\n",
      "Loss at Iteration @ 9674 is 2.317244529724121\n",
      "Evaluation Loss at Iteration @ 9674 is 2.2808151245117188\n",
      "Loss at Iteration @ 9675 is 2.048687219619751\n",
      "Evaluation Loss at Iteration @ 9675 is 2.2209665775299072\n",
      "Loss at Iteration @ 9676 is 1.8135241270065308\n",
      "Evaluation Loss at Iteration @ 9676 is 2.307616949081421\n",
      "Loss at Iteration @ 9677 is 2.2703404426574707\n",
      "Evaluation Loss at Iteration @ 9677 is 2.274209976196289\n",
      "Loss at Iteration @ 9678 is 2.302441358566284\n",
      "Evaluation Loss at Iteration @ 9678 is 2.2989871501922607\n",
      "Loss at Iteration @ 9679 is 2.328965425491333\n",
      "Evaluation Loss at Iteration @ 9679 is 2.235508441925049\n",
      "Loss at Iteration @ 9680 is 2.054450750350952\n",
      "Evaluation Loss at Iteration @ 9680 is 2.20906662940979\n",
      "Loss at Iteration @ 9681 is 2.3237369060516357\n",
      "Evaluation Loss at Iteration @ 9681 is 2.2356433868408203\n",
      "Loss at Iteration @ 9682 is 2.1777827739715576\n",
      "Evaluation Loss at Iteration @ 9682 is 2.2701497077941895\n",
      "Loss at Iteration @ 9683 is 2.153024673461914\n",
      "Evaluation Loss at Iteration @ 9683 is 2.2971789836883545\n",
      "Loss at Iteration @ 9684 is 2.1569619178771973\n",
      "Evaluation Loss at Iteration @ 9684 is 2.274294137954712\n",
      "Loss at Iteration @ 9685 is 2.3125689029693604\n",
      "Evaluation Loss at Iteration @ 9685 is 2.238468885421753\n",
      "Loss at Iteration @ 9686 is 2.063596248626709\n",
      "Evaluation Loss at Iteration @ 9686 is 2.273921012878418\n",
      "Loss at Iteration @ 9687 is 2.079833507537842\n",
      "Evaluation Loss at Iteration @ 9687 is 2.252711772918701\n",
      "Loss at Iteration @ 9688 is 2.4388227462768555\n",
      "Evaluation Loss at Iteration @ 9688 is 2.2642624378204346\n",
      "Loss at Iteration @ 9689 is 1.8724709749221802\n",
      "Evaluation Loss at Iteration @ 9689 is 2.2627761363983154\n",
      "Loss at Iteration @ 9690 is 2.135897397994995\n",
      "Evaluation Loss at Iteration @ 9690 is 2.2239620685577393\n",
      "Loss at Iteration @ 9691 is 1.8396354913711548\n",
      "Evaluation Loss at Iteration @ 9691 is 2.244908571243286\n",
      "Loss at Iteration @ 9692 is 2.5608460903167725\n",
      "Evaluation Loss at Iteration @ 9692 is 2.209477663040161\n",
      "Loss at Iteration @ 9693 is 2.5881357192993164\n",
      "Evaluation Loss at Iteration @ 9693 is 2.1573328971862793\n",
      "Loss at Iteration @ 9694 is 2.4702093601226807\n",
      "Evaluation Loss at Iteration @ 9694 is 2.268540382385254\n",
      "Loss at Iteration @ 9695 is 2.151076316833496\n",
      "Evaluation Loss at Iteration @ 9695 is 2.2720425128936768\n",
      "Loss at Iteration @ 9696 is 2.295165538787842\n",
      "Evaluation Loss at Iteration @ 9696 is 2.208629846572876\n",
      "Loss at Iteration @ 9697 is 2.144742965698242\n",
      "Evaluation Loss at Iteration @ 9697 is 2.3044486045837402\n",
      "Loss at Iteration @ 9698 is 2.647693634033203\n",
      "Evaluation Loss at Iteration @ 9698 is 2.2445614337921143\n",
      "Loss at Iteration @ 9699 is 1.9035230875015259\n",
      "Evaluation Loss at Iteration @ 9699 is 2.2614481449127197\n",
      "Loss at Iteration @ 9700 is 2.4120798110961914\n",
      "Evaluation Loss at Iteration @ 9700 is 2.2628846168518066\n",
      "Loss at Iteration @ 9701 is 2.227463722229004\n",
      "Evaluation Loss at Iteration @ 9701 is 2.1894447803497314\n",
      "Loss at Iteration @ 9702 is 2.073077917098999\n",
      "Evaluation Loss at Iteration @ 9702 is 2.2841506004333496\n",
      "Loss at Iteration @ 9703 is 2.1582605838775635\n",
      "Evaluation Loss at Iteration @ 9703 is 2.2214200496673584\n",
      "Loss at Iteration @ 9704 is 2.385329484939575\n",
      "Evaluation Loss at Iteration @ 9704 is 2.276231050491333\n",
      "Loss at Iteration @ 9705 is 2.2231407165527344\n",
      "Evaluation Loss at Iteration @ 9705 is 2.244342803955078\n",
      "Loss at Iteration @ 9706 is 2.2889907360076904\n",
      "Evaluation Loss at Iteration @ 9706 is 2.261622905731201\n",
      "Loss at Iteration @ 9707 is 2.34683895111084\n",
      "Evaluation Loss at Iteration @ 9707 is 2.244708299636841\n",
      "Loss at Iteration @ 9708 is 2.3138134479522705\n",
      "Evaluation Loss at Iteration @ 9708 is 2.2871551513671875\n",
      "Loss at Iteration @ 9709 is 2.3904061317443848\n",
      "Evaluation Loss at Iteration @ 9709 is 2.2393639087677\n",
      "Loss at Iteration @ 9710 is 2.2744383811950684\n",
      "Evaluation Loss at Iteration @ 9710 is 2.3109822273254395\n",
      "Loss at Iteration @ 9711 is 2.2959113121032715\n",
      "Evaluation Loss at Iteration @ 9711 is 2.2590370178222656\n",
      "Loss at Iteration @ 9712 is 2.1365177631378174\n",
      "Evaluation Loss at Iteration @ 9712 is 2.2732789516448975\n",
      "Loss at Iteration @ 9713 is 2.3531129360198975\n",
      "Evaluation Loss at Iteration @ 9713 is 2.2952659130096436\n",
      "Loss at Iteration @ 9714 is 2.258277177810669\n",
      "Evaluation Loss at Iteration @ 9714 is 2.2300801277160645\n",
      "Loss at Iteration @ 9715 is 2.3400673866271973\n",
      "Evaluation Loss at Iteration @ 9715 is 2.2313294410705566\n",
      "Loss at Iteration @ 9716 is 2.6524832248687744\n",
      "Evaluation Loss at Iteration @ 9716 is 2.275749444961548\n",
      "Loss at Iteration @ 9717 is 2.3361446857452393\n",
      "Evaluation Loss at Iteration @ 9717 is 2.2773399353027344\n",
      "Loss at Iteration @ 9718 is 2.108959913253784\n",
      "Evaluation Loss at Iteration @ 9718 is 2.2534255981445312\n",
      "Loss at Iteration @ 9719 is 2.321096420288086\n",
      "Evaluation Loss at Iteration @ 9719 is 2.2360572814941406\n",
      "Loss at Iteration @ 9720 is 2.150191307067871\n",
      "Evaluation Loss at Iteration @ 9720 is 2.2812232971191406\n",
      "Loss at Iteration @ 9721 is 2.4198155403137207\n",
      "Evaluation Loss at Iteration @ 9721 is 2.2216551303863525\n",
      "Loss at Iteration @ 9722 is 1.9294122457504272\n",
      "Evaluation Loss at Iteration @ 9722 is 2.2546801567077637\n",
      "Loss at Iteration @ 9723 is 2.326637029647827\n",
      "Evaluation Loss at Iteration @ 9723 is 2.258829355239868\n",
      "Loss at Iteration @ 9724 is 2.025127410888672\n",
      "Evaluation Loss at Iteration @ 9724 is 2.321692943572998\n",
      "Loss at Iteration @ 9725 is 2.1273155212402344\n",
      "Evaluation Loss at Iteration @ 9725 is 2.284078598022461\n",
      "Loss at Iteration @ 9726 is 2.341602325439453\n",
      "Evaluation Loss at Iteration @ 9726 is 2.2463631629943848\n",
      "Loss at Iteration @ 9727 is 2.1793134212493896\n",
      "Evaluation Loss at Iteration @ 9727 is 2.2713568210601807\n",
      "Loss at Iteration @ 9728 is 2.428258180618286\n",
      "Evaluation Loss at Iteration @ 9728 is 2.244133710861206\n",
      "Loss at Iteration @ 9729 is 2.1912105083465576\n",
      "Evaluation Loss at Iteration @ 9729 is 2.2745521068573\n",
      "Loss at Iteration @ 9730 is 1.9857245683670044\n",
      "Evaluation Loss at Iteration @ 9730 is 2.184525966644287\n",
      "Loss at Iteration @ 9731 is 1.9240072965621948\n",
      "Evaluation Loss at Iteration @ 9731 is 2.2455978393554688\n",
      "Loss at Iteration @ 9732 is 2.2717509269714355\n",
      "Evaluation Loss at Iteration @ 9732 is 2.2286648750305176\n",
      "Loss at Iteration @ 9733 is 2.1579325199127197\n",
      "Evaluation Loss at Iteration @ 9733 is 2.2765729427337646\n",
      "Loss at Iteration @ 9734 is 2.3281288146972656\n",
      "Evaluation Loss at Iteration @ 9734 is 2.2330195903778076\n",
      "Loss at Iteration @ 9735 is 2.1102755069732666\n",
      "Evaluation Loss at Iteration @ 9735 is 2.2251288890838623\n",
      "Loss at Iteration @ 9736 is 2.2142162322998047\n",
      "Evaluation Loss at Iteration @ 9736 is 2.290168523788452\n",
      "Loss at Iteration @ 9737 is 2.0977044105529785\n",
      "Evaluation Loss at Iteration @ 9737 is 2.292454719543457\n",
      "Loss at Iteration @ 9738 is 2.315603733062744\n",
      "Evaluation Loss at Iteration @ 9738 is 2.23482084274292\n",
      "Loss at Iteration @ 9739 is 2.223267078399658\n",
      "Evaluation Loss at Iteration @ 9739 is 2.2392401695251465\n",
      "Loss at Iteration @ 9740 is 2.272277355194092\n",
      "Evaluation Loss at Iteration @ 9740 is 2.2213680744171143\n",
      "Loss at Iteration @ 9741 is 2.1250853538513184\n",
      "Evaluation Loss at Iteration @ 9741 is 2.269019842147827\n",
      "Loss at Iteration @ 9742 is 2.317074775695801\n",
      "Evaluation Loss at Iteration @ 9742 is 2.2545084953308105\n",
      "Loss at Iteration @ 9743 is 2.403104782104492\n",
      "Evaluation Loss at Iteration @ 9743 is 2.264045476913452\n",
      "Loss at Iteration @ 9744 is 2.1839241981506348\n",
      "Evaluation Loss at Iteration @ 9744 is 2.2097442150115967\n",
      "Loss at Iteration @ 9745 is 2.0472891330718994\n",
      "Evaluation Loss at Iteration @ 9745 is 2.2315847873687744\n",
      "Loss at Iteration @ 9746 is 2.443990707397461\n",
      "Evaluation Loss at Iteration @ 9746 is 2.2774758338928223\n",
      "Loss at Iteration @ 9747 is 2.2070562839508057\n",
      "Evaluation Loss at Iteration @ 9747 is 2.2705771923065186\n",
      "Loss at Iteration @ 9748 is 2.468576669692993\n",
      "Evaluation Loss at Iteration @ 9748 is 2.238468647003174\n",
      "Loss at Iteration @ 9749 is 1.9461456537246704\n",
      "Evaluation Loss at Iteration @ 9749 is 2.2475311756134033\n",
      "Loss at Iteration @ 9750 is 2.201679229736328\n",
      "Evaluation Loss at Iteration @ 9750 is 2.2805328369140625\n",
      "Loss at Iteration @ 9751 is 2.0705583095550537\n",
      "Evaluation Loss at Iteration @ 9751 is 2.1988508701324463\n",
      "Loss at Iteration @ 9752 is 2.2725796699523926\n",
      "Evaluation Loss at Iteration @ 9752 is 2.2883968353271484\n",
      "Loss at Iteration @ 9753 is 2.1334006786346436\n",
      "Evaluation Loss at Iteration @ 9753 is 2.2781851291656494\n",
      "Loss at Iteration @ 9754 is 2.304882049560547\n",
      "Evaluation Loss at Iteration @ 9754 is 2.297863245010376\n",
      "Loss at Iteration @ 9755 is 2.0839755535125732\n",
      "Evaluation Loss at Iteration @ 9755 is 2.2992653846740723\n",
      "Loss at Iteration @ 9756 is 2.2603023052215576\n",
      "Evaluation Loss at Iteration @ 9756 is 2.2670886516571045\n",
      "Loss at Iteration @ 9757 is 2.2395002841949463\n",
      "Evaluation Loss at Iteration @ 9757 is 2.2837579250335693\n",
      "Loss at Iteration @ 9758 is 2.125026226043701\n",
      "Evaluation Loss at Iteration @ 9758 is 2.267484188079834\n",
      "Loss at Iteration @ 9759 is 1.950370192527771\n",
      "Evaluation Loss at Iteration @ 9759 is 2.291900634765625\n",
      "Loss at Iteration @ 9760 is 2.259131908416748\n",
      "Evaluation Loss at Iteration @ 9760 is 2.2379722595214844\n",
      "Loss at Iteration @ 9761 is 2.3431830406188965\n",
      "Evaluation Loss at Iteration @ 9761 is 2.237652063369751\n",
      "Loss at Iteration @ 9762 is 2.2318687438964844\n",
      "Evaluation Loss at Iteration @ 9762 is 2.231570243835449\n",
      "Loss at Iteration @ 9763 is 2.042778253555298\n",
      "Evaluation Loss at Iteration @ 9763 is 2.2404377460479736\n",
      "Loss at Iteration @ 9764 is 2.2489476203918457\n",
      "Evaluation Loss at Iteration @ 9764 is 2.2650675773620605\n",
      "Loss at Iteration @ 9765 is 2.2511370182037354\n",
      "Evaluation Loss at Iteration @ 9765 is 2.225266218185425\n",
      "Loss at Iteration @ 9766 is 2.26723575592041\n",
      "Evaluation Loss at Iteration @ 9766 is 2.245861530303955\n",
      "Loss at Iteration @ 9767 is 2.087233543395996\n",
      "Evaluation Loss at Iteration @ 9767 is 2.2454214096069336\n",
      "Loss at Iteration @ 9768 is 2.0760395526885986\n",
      "Evaluation Loss at Iteration @ 9768 is 2.2415647506713867\n",
      "Loss at Iteration @ 9769 is 2.210465669631958\n",
      "Evaluation Loss at Iteration @ 9769 is 2.2846057415008545\n",
      "Loss at Iteration @ 9770 is 2.1237950325012207\n",
      "Evaluation Loss at Iteration @ 9770 is 2.2337961196899414\n",
      "Loss at Iteration @ 9771 is 2.683713674545288\n",
      "Evaluation Loss at Iteration @ 9771 is 2.251718044281006\n",
      "Loss at Iteration @ 9772 is 2.210949182510376\n",
      "Evaluation Loss at Iteration @ 9772 is 2.2319672107696533\n",
      "Loss at Iteration @ 9773 is 2.252093553543091\n",
      "Evaluation Loss at Iteration @ 9773 is 2.218724489212036\n",
      "Loss at Iteration @ 9774 is 2.182901620864868\n",
      "Evaluation Loss at Iteration @ 9774 is 2.2476272583007812\n",
      "Loss at Iteration @ 9775 is 2.2241859436035156\n",
      "Evaluation Loss at Iteration @ 9775 is 2.2504351139068604\n",
      "Loss at Iteration @ 9776 is 2.2149763107299805\n",
      "Evaluation Loss at Iteration @ 9776 is 2.272472620010376\n",
      "Loss at Iteration @ 9777 is 2.237461566925049\n",
      "Evaluation Loss at Iteration @ 9777 is 2.2343897819519043\n",
      "Loss at Iteration @ 9778 is 2.0711538791656494\n",
      "Evaluation Loss at Iteration @ 9778 is 2.2340054512023926\n",
      "Loss at Iteration @ 9779 is 1.9707669019699097\n",
      "Evaluation Loss at Iteration @ 9779 is 2.26859450340271\n",
      "Loss at Iteration @ 9780 is 2.2731218338012695\n",
      "Evaluation Loss at Iteration @ 9780 is 2.2495346069335938\n",
      "Loss at Iteration @ 9781 is 2.3457441329956055\n",
      "Evaluation Loss at Iteration @ 9781 is 2.244964361190796\n",
      "Loss at Iteration @ 9782 is 2.1842715740203857\n",
      "Evaluation Loss at Iteration @ 9782 is 2.1944398880004883\n",
      "Loss at Iteration @ 9783 is 2.2690486907958984\n",
      "Evaluation Loss at Iteration @ 9783 is 2.24051570892334\n",
      "Loss at Iteration @ 9784 is 2.3248283863067627\n",
      "Evaluation Loss at Iteration @ 9784 is 2.2421133518218994\n",
      "Loss at Iteration @ 9785 is 2.24002742767334\n",
      "Evaluation Loss at Iteration @ 9785 is 2.2417283058166504\n",
      "Loss at Iteration @ 9786 is 2.672024965286255\n",
      "Evaluation Loss at Iteration @ 9786 is 2.2822506427764893\n",
      "Loss at Iteration @ 9787 is 2.260291814804077\n",
      "Evaluation Loss at Iteration @ 9787 is 2.2642016410827637\n",
      "Loss at Iteration @ 9788 is 2.311830759048462\n",
      "Evaluation Loss at Iteration @ 9788 is 2.2907826900482178\n",
      "Loss at Iteration @ 9789 is 2.247262954711914\n",
      "Evaluation Loss at Iteration @ 9789 is 2.2896625995635986\n",
      "Loss at Iteration @ 9790 is 2.502974271774292\n",
      "Evaluation Loss at Iteration @ 9790 is 2.253621816635132\n",
      "Loss at Iteration @ 9791 is 2.241771936416626\n",
      "Evaluation Loss at Iteration @ 9791 is 2.232330799102783\n",
      "Loss at Iteration @ 9792 is 2.383897542953491\n",
      "Evaluation Loss at Iteration @ 9792 is 2.275731325149536\n",
      "Loss at Iteration @ 9793 is 2.095118999481201\n",
      "Evaluation Loss at Iteration @ 9793 is 2.281069040298462\n",
      "Loss at Iteration @ 9794 is 2.34108567237854\n",
      "Evaluation Loss at Iteration @ 9794 is 2.184494733810425\n",
      "Loss at Iteration @ 9795 is 2.366710901260376\n",
      "Evaluation Loss at Iteration @ 9795 is 2.2750229835510254\n",
      "Loss at Iteration @ 9796 is 2.1131324768066406\n",
      "Evaluation Loss at Iteration @ 9796 is 2.2873353958129883\n",
      "Loss at Iteration @ 9797 is 2.3730251789093018\n",
      "Evaluation Loss at Iteration @ 9797 is 2.231205940246582\n",
      "Loss at Iteration @ 9798 is 2.190805196762085\n",
      "Evaluation Loss at Iteration @ 9798 is 2.3084378242492676\n",
      "Loss at Iteration @ 9799 is 2.2442760467529297\n",
      "Evaluation Loss at Iteration @ 9799 is 2.260307788848877\n",
      "Loss at Iteration @ 9800 is 2.263504981994629\n",
      "Evaluation Loss at Iteration @ 9800 is 2.2722578048706055\n",
      "Loss at Iteration @ 9801 is 2.1552138328552246\n",
      "Evaluation Loss at Iteration @ 9801 is 2.253572940826416\n",
      "Loss at Iteration @ 9802 is 2.261167287826538\n",
      "Evaluation Loss at Iteration @ 9802 is 2.185086488723755\n",
      "Loss at Iteration @ 9803 is 2.2101778984069824\n",
      "Evaluation Loss at Iteration @ 9803 is 2.1861908435821533\n",
      "Loss at Iteration @ 9804 is 1.9080857038497925\n",
      "Evaluation Loss at Iteration @ 9804 is 2.2517971992492676\n",
      "Loss at Iteration @ 9805 is 2.33593487739563\n",
      "Evaluation Loss at Iteration @ 9805 is 2.2715437412261963\n",
      "Loss at Iteration @ 9806 is 2.259182929992676\n",
      "Evaluation Loss at Iteration @ 9806 is 2.237807512283325\n",
      "Loss at Iteration @ 9807 is 2.1866753101348877\n",
      "Evaluation Loss at Iteration @ 9807 is 2.272472620010376\n",
      "Loss at Iteration @ 9808 is 2.3436503410339355\n",
      "Evaluation Loss at Iteration @ 9808 is 2.268909454345703\n",
      "Loss at Iteration @ 9809 is 2.4279417991638184\n",
      "Evaluation Loss at Iteration @ 9809 is 2.267777681350708\n",
      "Loss at Iteration @ 9810 is 2.519559621810913\n",
      "Evaluation Loss at Iteration @ 9810 is 2.232846736907959\n",
      "Loss at Iteration @ 9811 is 2.2089834213256836\n",
      "Evaluation Loss at Iteration @ 9811 is 2.2689294815063477\n",
      "Loss at Iteration @ 9812 is 2.1537363529205322\n",
      "Evaluation Loss at Iteration @ 9812 is 2.3032474517822266\n",
      "Loss at Iteration @ 9813 is 2.247039556503296\n",
      "Evaluation Loss at Iteration @ 9813 is 2.206986665725708\n",
      "Loss at Iteration @ 9814 is 2.0678815841674805\n",
      "Evaluation Loss at Iteration @ 9814 is 2.2433414459228516\n",
      "Loss at Iteration @ 9815 is 2.5533533096313477\n",
      "Evaluation Loss at Iteration @ 9815 is 2.2355597019195557\n",
      "Loss at Iteration @ 9816 is 2.012932538986206\n",
      "Evaluation Loss at Iteration @ 9816 is 2.23691987991333\n",
      "Loss at Iteration @ 9817 is 2.2083146572113037\n",
      "Evaluation Loss at Iteration @ 9817 is 2.235511302947998\n",
      "Loss at Iteration @ 9818 is 2.0257585048675537\n",
      "Evaluation Loss at Iteration @ 9818 is 2.3000974655151367\n",
      "Loss at Iteration @ 9819 is 2.280573606491089\n",
      "Evaluation Loss at Iteration @ 9819 is 2.2304656505584717\n",
      "Loss at Iteration @ 9820 is 2.2690484523773193\n",
      "Evaluation Loss at Iteration @ 9820 is 2.2043182849884033\n",
      "Loss at Iteration @ 9821 is 2.385246515274048\n",
      "Evaluation Loss at Iteration @ 9821 is 2.2437453269958496\n",
      "Loss at Iteration @ 9822 is 2.3685030937194824\n",
      "Evaluation Loss at Iteration @ 9822 is 2.289293050765991\n",
      "Loss at Iteration @ 9823 is 2.3813600540161133\n",
      "Evaluation Loss at Iteration @ 9823 is 2.256929397583008\n",
      "Loss at Iteration @ 9824 is 2.290512800216675\n",
      "Evaluation Loss at Iteration @ 9824 is 2.283334493637085\n",
      "Loss at Iteration @ 9825 is 2.0143063068389893\n",
      "Evaluation Loss at Iteration @ 9825 is 2.2377145290374756\n",
      "Loss at Iteration @ 9826 is 2.3093783855438232\n",
      "Evaluation Loss at Iteration @ 9826 is 2.2366299629211426\n",
      "Loss at Iteration @ 9827 is 2.5127384662628174\n",
      "Evaluation Loss at Iteration @ 9827 is 2.192965269088745\n",
      "Loss at Iteration @ 9828 is 2.377648115158081\n",
      "Evaluation Loss at Iteration @ 9828 is 2.28574800491333\n",
      "Loss at Iteration @ 9829 is 2.295473575592041\n",
      "Evaluation Loss at Iteration @ 9829 is 2.231228828430176\n",
      "Loss at Iteration @ 9830 is 2.2655389308929443\n",
      "Evaluation Loss at Iteration @ 9830 is 2.2375597953796387\n",
      "Loss at Iteration @ 9831 is 2.158384084701538\n",
      "Evaluation Loss at Iteration @ 9831 is 2.258805513381958\n",
      "Loss at Iteration @ 9832 is 2.1817948818206787\n",
      "Evaluation Loss at Iteration @ 9832 is 2.2395880222320557\n",
      "Loss at Iteration @ 9833 is 2.140247106552124\n",
      "Evaluation Loss at Iteration @ 9833 is 2.2549920082092285\n",
      "Loss at Iteration @ 9834 is 2.3209047317504883\n",
      "Evaluation Loss at Iteration @ 9834 is 2.2683136463165283\n",
      "Loss at Iteration @ 9835 is 2.3182029724121094\n",
      "Evaluation Loss at Iteration @ 9835 is 2.2443766593933105\n",
      "Loss at Iteration @ 9836 is 2.2230687141418457\n",
      "Evaluation Loss at Iteration @ 9836 is 2.2683887481689453\n",
      "Loss at Iteration @ 9837 is 2.1056277751922607\n",
      "Evaluation Loss at Iteration @ 9837 is 2.263112783432007\n",
      "Loss at Iteration @ 9838 is 2.4814095497131348\n",
      "Evaluation Loss at Iteration @ 9838 is 2.22566294670105\n",
      "Loss at Iteration @ 9839 is 1.9569886922836304\n",
      "Evaluation Loss at Iteration @ 9839 is 2.251969814300537\n",
      "Loss at Iteration @ 9840 is 2.1843907833099365\n",
      "Evaluation Loss at Iteration @ 9840 is 2.304532766342163\n",
      "Loss at Iteration @ 9841 is 2.316570520401001\n",
      "Evaluation Loss at Iteration @ 9841 is 2.220311403274536\n",
      "Loss at Iteration @ 9842 is 2.4515271186828613\n",
      "Evaluation Loss at Iteration @ 9842 is 2.2195916175842285\n",
      "Loss at Iteration @ 9843 is 2.207092046737671\n",
      "Evaluation Loss at Iteration @ 9843 is 2.253599166870117\n",
      "Loss at Iteration @ 9844 is 2.4494597911834717\n",
      "Evaluation Loss at Iteration @ 9844 is 2.245478868484497\n",
      "Loss at Iteration @ 9845 is 2.2684593200683594\n",
      "Evaluation Loss at Iteration @ 9845 is 2.258986473083496\n",
      "Loss at Iteration @ 9846 is 2.367563486099243\n",
      "Evaluation Loss at Iteration @ 9846 is 2.267400026321411\n",
      "Loss at Iteration @ 9847 is 2.1794581413269043\n",
      "Evaluation Loss at Iteration @ 9847 is 2.2308993339538574\n",
      "Loss at Iteration @ 9848 is 2.19116473197937\n",
      "Evaluation Loss at Iteration @ 9848 is 2.2427384853363037\n",
      "Loss at Iteration @ 9849 is 2.377469062805176\n",
      "Evaluation Loss at Iteration @ 9849 is 2.2614943981170654\n",
      "Loss at Iteration @ 9850 is 2.5459694862365723\n",
      "Evaluation Loss at Iteration @ 9850 is 2.283283233642578\n",
      "Loss at Iteration @ 9851 is 2.3176612854003906\n",
      "Evaluation Loss at Iteration @ 9851 is 2.3168461322784424\n",
      "Loss at Iteration @ 9852 is 2.1820716857910156\n",
      "Evaluation Loss at Iteration @ 9852 is 2.259267807006836\n",
      "Loss at Iteration @ 9853 is 2.2127525806427\n",
      "Evaluation Loss at Iteration @ 9853 is 2.2201919555664062\n",
      "Loss at Iteration @ 9854 is 2.5948386192321777\n",
      "Evaluation Loss at Iteration @ 9854 is 2.2631518840789795\n",
      "Loss at Iteration @ 9855 is 2.169724941253662\n",
      "Evaluation Loss at Iteration @ 9855 is 2.2237908840179443\n",
      "Loss at Iteration @ 9856 is 2.115642786026001\n",
      "Evaluation Loss at Iteration @ 9856 is 2.2681260108947754\n",
      "Loss at Iteration @ 9857 is 2.1935043334960938\n",
      "Evaluation Loss at Iteration @ 9857 is 2.239710569381714\n",
      "Loss at Iteration @ 9858 is 2.2177417278289795\n",
      "Evaluation Loss at Iteration @ 9858 is 2.2468056678771973\n",
      "Loss at Iteration @ 9859 is 1.9634820222854614\n",
      "Evaluation Loss at Iteration @ 9859 is 2.2790639400482178\n",
      "Loss at Iteration @ 9860 is 2.1471660137176514\n",
      "Evaluation Loss at Iteration @ 9860 is 2.2795469760894775\n",
      "Loss at Iteration @ 9861 is 2.4197638034820557\n",
      "Evaluation Loss at Iteration @ 9861 is 2.2410693168640137\n",
      "Loss at Iteration @ 9862 is 2.2374069690704346\n",
      "Evaluation Loss at Iteration @ 9862 is 2.2381880283355713\n",
      "Loss at Iteration @ 9863 is 2.2071821689605713\n",
      "Evaluation Loss at Iteration @ 9863 is 2.2488019466400146\n",
      "Loss at Iteration @ 9864 is 2.2301993370056152\n",
      "Evaluation Loss at Iteration @ 9864 is 2.2626330852508545\n",
      "Loss at Iteration @ 9865 is 2.3871958255767822\n",
      "Evaluation Loss at Iteration @ 9865 is 2.2611567974090576\n",
      "Loss at Iteration @ 9866 is 2.2382256984710693\n",
      "Evaluation Loss at Iteration @ 9866 is 2.2532308101654053\n",
      "Loss at Iteration @ 9867 is 2.195840835571289\n",
      "Evaluation Loss at Iteration @ 9867 is 2.2725741863250732\n",
      "Loss at Iteration @ 9868 is 2.0453455448150635\n",
      "Evaluation Loss at Iteration @ 9868 is 2.2079715728759766\n",
      "Loss at Iteration @ 9869 is 2.2652552127838135\n",
      "Evaluation Loss at Iteration @ 9869 is 2.299389362335205\n",
      "Loss at Iteration @ 9870 is 2.0541892051696777\n",
      "Evaluation Loss at Iteration @ 9870 is 2.2439124584198\n",
      "Loss at Iteration @ 9871 is 2.517042875289917\n",
      "Evaluation Loss at Iteration @ 9871 is 2.2678439617156982\n",
      "Loss at Iteration @ 9872 is 2.3475730419158936\n",
      "Evaluation Loss at Iteration @ 9872 is 2.235819101333618\n",
      "Loss at Iteration @ 9873 is 2.610326051712036\n",
      "Evaluation Loss at Iteration @ 9873 is 2.287703275680542\n",
      "Loss at Iteration @ 9874 is 2.2730941772460938\n",
      "Evaluation Loss at Iteration @ 9874 is 2.280550003051758\n",
      "Loss at Iteration @ 9875 is 2.118039131164551\n",
      "Evaluation Loss at Iteration @ 9875 is 2.2547860145568848\n",
      "Loss at Iteration @ 9876 is 2.1996960639953613\n",
      "Evaluation Loss at Iteration @ 9876 is 2.3132221698760986\n",
      "Loss at Iteration @ 9877 is 2.115668296813965\n",
      "Evaluation Loss at Iteration @ 9877 is 2.2647435665130615\n",
      "Loss at Iteration @ 9878 is 2.4078094959259033\n",
      "Evaluation Loss at Iteration @ 9878 is 2.218313455581665\n",
      "Loss at Iteration @ 9879 is 2.192385673522949\n",
      "Evaluation Loss at Iteration @ 9879 is 2.2354044914245605\n",
      "Loss at Iteration @ 9880 is 2.209261417388916\n",
      "Evaluation Loss at Iteration @ 9880 is 2.2393667697906494\n",
      "Loss at Iteration @ 9881 is 2.171614170074463\n",
      "Evaluation Loss at Iteration @ 9881 is 2.2167842388153076\n",
      "Loss at Iteration @ 9882 is 2.052953004837036\n",
      "Evaluation Loss at Iteration @ 9882 is 2.2405896186828613\n",
      "Loss at Iteration @ 9883 is 2.2726056575775146\n",
      "Evaluation Loss at Iteration @ 9883 is 2.279233455657959\n",
      "Loss at Iteration @ 9884 is 2.3412249088287354\n",
      "Evaluation Loss at Iteration @ 9884 is 2.2693047523498535\n",
      "Loss at Iteration @ 9885 is 2.2304835319519043\n",
      "Evaluation Loss at Iteration @ 9885 is 2.2230570316314697\n",
      "Loss at Iteration @ 9886 is 2.161891460418701\n",
      "Evaluation Loss at Iteration @ 9886 is 2.244305372238159\n",
      "Loss at Iteration @ 9887 is 2.243170976638794\n",
      "Evaluation Loss at Iteration @ 9887 is 2.2808101177215576\n",
      "Loss at Iteration @ 9888 is 2.6774792671203613\n",
      "Evaluation Loss at Iteration @ 9888 is 2.2640650272369385\n",
      "Loss at Iteration @ 9889 is 2.369422435760498\n",
      "Evaluation Loss at Iteration @ 9889 is 2.2852659225463867\n",
      "Loss at Iteration @ 9890 is 2.35634708404541\n",
      "Evaluation Loss at Iteration @ 9890 is 2.2233870029449463\n",
      "Loss at Iteration @ 9891 is 2.2761268615722656\n",
      "Evaluation Loss at Iteration @ 9891 is 2.2900278568267822\n",
      "Loss at Iteration @ 9892 is 2.4536430835723877\n",
      "Evaluation Loss at Iteration @ 9892 is 2.290959358215332\n",
      "Loss at Iteration @ 9893 is 2.389744281768799\n",
      "Evaluation Loss at Iteration @ 9893 is 2.2125024795532227\n",
      "Loss at Iteration @ 9894 is 2.350327253341675\n",
      "Evaluation Loss at Iteration @ 9894 is 2.231584072113037\n",
      "Loss at Iteration @ 9895 is 2.115565061569214\n",
      "Evaluation Loss at Iteration @ 9895 is 2.245277166366577\n",
      "Loss at Iteration @ 9896 is 2.2816829681396484\n",
      "Evaluation Loss at Iteration @ 9896 is 2.250920534133911\n",
      "Loss at Iteration @ 9897 is 2.4334843158721924\n",
      "Evaluation Loss at Iteration @ 9897 is 2.2531898021698\n",
      "Loss at Iteration @ 9898 is 2.1834471225738525\n",
      "Evaluation Loss at Iteration @ 9898 is 2.291322708129883\n",
      "Loss at Iteration @ 9899 is 2.320521593093872\n",
      "Evaluation Loss at Iteration @ 9899 is 2.2554306983947754\n",
      "Loss at Iteration @ 9900 is 2.250281572341919\n",
      "Evaluation Loss at Iteration @ 9900 is 2.2455615997314453\n",
      "Loss at Iteration @ 9901 is 2.519705295562744\n",
      "Evaluation Loss at Iteration @ 9901 is 2.2733819484710693\n",
      "Loss at Iteration @ 9902 is 2.2877724170684814\n",
      "Evaluation Loss at Iteration @ 9902 is 2.248413324356079\n",
      "Loss at Iteration @ 9903 is 2.224673271179199\n",
      "Evaluation Loss at Iteration @ 9903 is 2.262162923812866\n",
      "Loss at Iteration @ 9904 is 2.3658766746520996\n",
      "Evaluation Loss at Iteration @ 9904 is 2.2261130809783936\n",
      "Loss at Iteration @ 9905 is 2.449362277984619\n",
      "Evaluation Loss at Iteration @ 9905 is 2.2452518939971924\n",
      "Loss at Iteration @ 9906 is 2.2342586517333984\n",
      "Evaluation Loss at Iteration @ 9906 is 2.214993953704834\n",
      "Loss at Iteration @ 9907 is 2.27657413482666\n",
      "Evaluation Loss at Iteration @ 9907 is 2.243868350982666\n",
      "Loss at Iteration @ 9908 is 2.3923003673553467\n",
      "Evaluation Loss at Iteration @ 9908 is 2.3016726970672607\n",
      "Loss at Iteration @ 9909 is 2.40256404876709\n",
      "Evaluation Loss at Iteration @ 9909 is 2.280294895172119\n",
      "Loss at Iteration @ 9910 is 2.401662588119507\n",
      "Evaluation Loss at Iteration @ 9910 is 2.2300405502319336\n",
      "Loss at Iteration @ 9911 is 2.2869181632995605\n",
      "Evaluation Loss at Iteration @ 9911 is 2.2624943256378174\n",
      "Loss at Iteration @ 9912 is 2.273453712463379\n",
      "Evaluation Loss at Iteration @ 9912 is 2.2076003551483154\n",
      "Loss at Iteration @ 9913 is 2.0573277473449707\n",
      "Evaluation Loss at Iteration @ 9913 is 2.2745840549468994\n",
      "Loss at Iteration @ 9914 is 2.403379201889038\n",
      "Evaluation Loss at Iteration @ 9914 is 2.2423293590545654\n",
      "Loss at Iteration @ 9915 is 2.1745047569274902\n",
      "Evaluation Loss at Iteration @ 9915 is 2.246217727661133\n",
      "Loss at Iteration @ 9916 is 2.2843167781829834\n",
      "Evaluation Loss at Iteration @ 9916 is 2.2405734062194824\n",
      "Loss at Iteration @ 9917 is 2.201040506362915\n",
      "Evaluation Loss at Iteration @ 9917 is 2.276118040084839\n",
      "Loss at Iteration @ 9918 is 2.2540035247802734\n",
      "Evaluation Loss at Iteration @ 9918 is 2.2650816440582275\n",
      "Loss at Iteration @ 9919 is 2.1153573989868164\n",
      "Evaluation Loss at Iteration @ 9919 is 2.288022041320801\n",
      "Loss at Iteration @ 9920 is 2.22064208984375\n",
      "Evaluation Loss at Iteration @ 9920 is 2.19169282913208\n",
      "Loss at Iteration @ 9921 is 2.2120232582092285\n",
      "Evaluation Loss at Iteration @ 9921 is 2.2793047428131104\n",
      "Loss at Iteration @ 9922 is 2.4896936416625977\n",
      "Evaluation Loss at Iteration @ 9922 is 2.2127888202667236\n",
      "Loss at Iteration @ 9923 is 2.298649311065674\n",
      "Evaluation Loss at Iteration @ 9923 is 2.20617413520813\n",
      "Loss at Iteration @ 9924 is 2.3969225883483887\n",
      "Evaluation Loss at Iteration @ 9924 is 2.257067918777466\n",
      "Loss at Iteration @ 9925 is 2.073781728744507\n",
      "Evaluation Loss at Iteration @ 9925 is 2.252485752105713\n",
      "Loss at Iteration @ 9926 is 2.14686918258667\n",
      "Evaluation Loss at Iteration @ 9926 is 2.252333402633667\n",
      "Loss at Iteration @ 9927 is 2.3973233699798584\n",
      "Evaluation Loss at Iteration @ 9927 is 2.2853078842163086\n",
      "Loss at Iteration @ 9928 is 2.1257455348968506\n",
      "Evaluation Loss at Iteration @ 9928 is 2.2536771297454834\n",
      "Loss at Iteration @ 9929 is 2.459942102432251\n",
      "Evaluation Loss at Iteration @ 9929 is 2.2525100708007812\n",
      "Loss at Iteration @ 9930 is 2.2654671669006348\n",
      "Evaluation Loss at Iteration @ 9930 is 2.263946533203125\n",
      "Loss at Iteration @ 9931 is 1.9285608530044556\n",
      "Evaluation Loss at Iteration @ 9931 is 2.2343909740448\n",
      "Loss at Iteration @ 9932 is 2.4540421962738037\n",
      "Evaluation Loss at Iteration @ 9932 is 2.2103331089019775\n",
      "Loss at Iteration @ 9933 is 2.130509853363037\n",
      "Evaluation Loss at Iteration @ 9933 is 2.2526068687438965\n",
      "Loss at Iteration @ 9934 is 2.1160786151885986\n",
      "Evaluation Loss at Iteration @ 9934 is 2.262247323989868\n",
      "Loss at Iteration @ 9935 is 2.117837905883789\n",
      "Evaluation Loss at Iteration @ 9935 is 2.2265524864196777\n",
      "Loss at Iteration @ 9936 is 2.1734135150909424\n",
      "Evaluation Loss at Iteration @ 9936 is 2.2074286937713623\n",
      "Loss at Iteration @ 9937 is 2.3285508155822754\n",
      "Evaluation Loss at Iteration @ 9937 is 2.283080577850342\n",
      "Loss at Iteration @ 9938 is 2.3312137126922607\n",
      "Evaluation Loss at Iteration @ 9938 is 2.2529797554016113\n",
      "Loss at Iteration @ 9939 is 2.2537879943847656\n",
      "Evaluation Loss at Iteration @ 9939 is 2.2633895874023438\n",
      "Loss at Iteration @ 9940 is 2.1809232234954834\n",
      "Evaluation Loss at Iteration @ 9940 is 2.201205015182495\n",
      "Loss at Iteration @ 9941 is 2.157789468765259\n",
      "Evaluation Loss at Iteration @ 9941 is 2.2030649185180664\n",
      "Loss at Iteration @ 9942 is 2.0969576835632324\n",
      "Evaluation Loss at Iteration @ 9942 is 2.249340534210205\n",
      "Loss at Iteration @ 9943 is 2.0945982933044434\n",
      "Evaluation Loss at Iteration @ 9943 is 2.2361867427825928\n",
      "Loss at Iteration @ 9944 is 2.2781057357788086\n",
      "Evaluation Loss at Iteration @ 9944 is 2.222090721130371\n",
      "Loss at Iteration @ 9945 is 2.388765335083008\n",
      "Evaluation Loss at Iteration @ 9945 is 2.203754186630249\n",
      "Loss at Iteration @ 9946 is 2.367136001586914\n",
      "Evaluation Loss at Iteration @ 9946 is 2.2169251441955566\n",
      "Loss at Iteration @ 9947 is 2.1578946113586426\n",
      "Evaluation Loss at Iteration @ 9947 is 2.2618179321289062\n",
      "Loss at Iteration @ 9948 is 2.276506185531616\n",
      "Evaluation Loss at Iteration @ 9948 is 2.2338526248931885\n",
      "Loss at Iteration @ 9949 is 2.309117317199707\n",
      "Evaluation Loss at Iteration @ 9949 is 2.2351999282836914\n",
      "Loss at Iteration @ 9950 is 2.240516185760498\n",
      "Evaluation Loss at Iteration @ 9950 is 2.311596632003784\n",
      "Loss at Iteration @ 9951 is 2.218743085861206\n",
      "Evaluation Loss at Iteration @ 9951 is 2.2953996658325195\n",
      "Loss at Iteration @ 9952 is 2.2488512992858887\n",
      "Evaluation Loss at Iteration @ 9952 is 2.205483913421631\n",
      "Loss at Iteration @ 9953 is 2.0765762329101562\n",
      "Evaluation Loss at Iteration @ 9953 is 2.294769763946533\n",
      "Loss at Iteration @ 9954 is 2.314260721206665\n",
      "Evaluation Loss at Iteration @ 9954 is 2.236436128616333\n",
      "Loss at Iteration @ 9955 is 2.433823347091675\n",
      "Evaluation Loss at Iteration @ 9955 is 2.2670512199401855\n",
      "Loss at Iteration @ 9956 is 2.2495288848876953\n",
      "Evaluation Loss at Iteration @ 9956 is 2.262740135192871\n",
      "Loss at Iteration @ 9957 is 2.0487844944000244\n",
      "Evaluation Loss at Iteration @ 9957 is 2.230961322784424\n",
      "Loss at Iteration @ 9958 is 1.9829899072647095\n",
      "Evaluation Loss at Iteration @ 9958 is 2.234105348587036\n",
      "Loss at Iteration @ 9959 is 2.075059413909912\n",
      "Evaluation Loss at Iteration @ 9959 is 2.288593292236328\n",
      "Loss at Iteration @ 9960 is 2.3360671997070312\n",
      "Evaluation Loss at Iteration @ 9960 is 2.269544839859009\n",
      "Loss at Iteration @ 9961 is 2.0652647018432617\n",
      "Evaluation Loss at Iteration @ 9961 is 2.2669129371643066\n",
      "Loss at Iteration @ 9962 is 2.058650255203247\n",
      "Evaluation Loss at Iteration @ 9962 is 2.2101569175720215\n",
      "Loss at Iteration @ 9963 is 2.135451078414917\n",
      "Evaluation Loss at Iteration @ 9963 is 2.2591397762298584\n",
      "Loss at Iteration @ 9964 is 2.148371458053589\n",
      "Evaluation Loss at Iteration @ 9964 is 2.244119644165039\n",
      "Loss at Iteration @ 9965 is 2.1382365226745605\n",
      "Evaluation Loss at Iteration @ 9965 is 2.220987319946289\n",
      "Loss at Iteration @ 9966 is 2.0961785316467285\n",
      "Evaluation Loss at Iteration @ 9966 is 2.2476747035980225\n",
      "Loss at Iteration @ 9967 is 2.321742296218872\n",
      "Evaluation Loss at Iteration @ 9967 is 2.280996084213257\n",
      "Loss at Iteration @ 9968 is 2.302875280380249\n",
      "Evaluation Loss at Iteration @ 9968 is 2.2309417724609375\n",
      "Loss at Iteration @ 9969 is 2.335670232772827\n",
      "Evaluation Loss at Iteration @ 9969 is 2.2757909297943115\n",
      "Loss at Iteration @ 9970 is 2.4437479972839355\n",
      "Evaluation Loss at Iteration @ 9970 is 2.2391130924224854\n",
      "Loss at Iteration @ 9971 is 2.27514910697937\n",
      "Evaluation Loss at Iteration @ 9971 is 2.262300968170166\n",
      "Loss at Iteration @ 9972 is 2.532733678817749\n",
      "Evaluation Loss at Iteration @ 9972 is 2.2163631916046143\n",
      "Loss at Iteration @ 9973 is 2.4117419719696045\n",
      "Evaluation Loss at Iteration @ 9973 is 2.24294376373291\n",
      "Loss at Iteration @ 9974 is 2.5534462928771973\n",
      "Evaluation Loss at Iteration @ 9974 is 2.2138671875\n",
      "Loss at Iteration @ 9975 is 2.3643853664398193\n",
      "Evaluation Loss at Iteration @ 9975 is 2.2325844764709473\n",
      "Loss at Iteration @ 9976 is 2.414560556411743\n",
      "Evaluation Loss at Iteration @ 9976 is 2.262376070022583\n",
      "Loss at Iteration @ 9977 is 2.2354676723480225\n",
      "Evaluation Loss at Iteration @ 9977 is 2.2648887634277344\n",
      "Loss at Iteration @ 9978 is 2.4657845497131348\n",
      "Evaluation Loss at Iteration @ 9978 is 2.194572687149048\n",
      "Loss at Iteration @ 9979 is 2.2130520343780518\n",
      "Evaluation Loss at Iteration @ 9979 is 2.2193715572357178\n",
      "Loss at Iteration @ 9980 is 2.5494487285614014\n",
      "Evaluation Loss at Iteration @ 9980 is 2.2127602100372314\n",
      "Loss at Iteration @ 9981 is 1.9316449165344238\n",
      "Evaluation Loss at Iteration @ 9981 is 2.2380447387695312\n",
      "Loss at Iteration @ 9982 is 2.0305116176605225\n",
      "Evaluation Loss at Iteration @ 9982 is 2.2083895206451416\n",
      "Loss at Iteration @ 9983 is 2.2276694774627686\n",
      "Evaluation Loss at Iteration @ 9983 is 2.2492737770080566\n",
      "Loss at Iteration @ 9984 is 2.4920337200164795\n",
      "Evaluation Loss at Iteration @ 9984 is 2.2388203144073486\n",
      "Loss at Iteration @ 9985 is 2.2907321453094482\n",
      "Evaluation Loss at Iteration @ 9985 is 2.2354307174682617\n",
      "Loss at Iteration @ 9986 is 2.420377492904663\n",
      "Evaluation Loss at Iteration @ 9986 is 2.267141819000244\n",
      "Loss at Iteration @ 9987 is 2.1370904445648193\n",
      "Evaluation Loss at Iteration @ 9987 is 2.2726988792419434\n",
      "Loss at Iteration @ 9988 is 2.353926658630371\n",
      "Evaluation Loss at Iteration @ 9988 is 2.2384512424468994\n",
      "Loss at Iteration @ 9989 is 2.0706422328948975\n",
      "Evaluation Loss at Iteration @ 9989 is 2.274942636489868\n",
      "Loss at Iteration @ 9990 is 2.313424825668335\n",
      "Evaluation Loss at Iteration @ 9990 is 2.25946044921875\n",
      "Loss at Iteration @ 9991 is 2.433014154434204\n",
      "Evaluation Loss at Iteration @ 9991 is 2.226034164428711\n",
      "Loss at Iteration @ 9992 is 2.1777312755584717\n",
      "Evaluation Loss at Iteration @ 9992 is 2.235809326171875\n",
      "Loss at Iteration @ 9993 is 2.402658224105835\n",
      "Evaluation Loss at Iteration @ 9993 is 2.2171859741210938\n",
      "Loss at Iteration @ 9994 is 2.261324644088745\n",
      "Evaluation Loss at Iteration @ 9994 is 2.247260332107544\n",
      "Loss at Iteration @ 9995 is 2.2129156589508057\n",
      "Evaluation Loss at Iteration @ 9995 is 2.2363104820251465\n",
      "Loss at Iteration @ 9996 is 2.280968189239502\n",
      "Evaluation Loss at Iteration @ 9996 is 2.254729986190796\n",
      "Loss at Iteration @ 9997 is 2.1149864196777344\n",
      "Evaluation Loss at Iteration @ 9997 is 2.2297542095184326\n",
      "Loss at Iteration @ 9998 is 2.094597578048706\n",
      "Evaluation Loss at Iteration @ 9998 is 2.2104651927948\n",
      "Loss at Iteration @ 9999 is 2.117619752883911\n",
      "Evaluation Loss at Iteration @ 9999 is 2.2709848880767822\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "\n",
    "for i in range(10000):\n",
    "\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "\n",
    "    # Forward pass\n",
    "    logits = (torch.tanh(C[Xtr[ix]].view(-1, context_shape) @ W1 + b1)) @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "    \n",
    "    print(f'Loss at Iteration @ {i} is {loss.item()}')\n",
    "\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    lr = learning_rate if i < 5000 else 0.005\n",
    "\n",
    "    if i > 5000:\n",
    "        ix = torch.randint(0, Xdev.shape[0], (2200,))\n",
    "        loss_eval = F.cross_entropy(((torch.tanh(C[Xdev[ix]].view(-1, context_shape) @ W1 + b1)) @ W2 + b2), Ydev[ix])\n",
    "        print(f'Evaluation Loss at Iteration @ {i} is {loss_eval.item()}')\n",
    "        if loss_eval <=2.1:\n",
    "            break\n",
    "\n",
    "    #update\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22655, 27])\n",
      "Loss for Dev set is 2.251899003982544\n",
      "torch.Size([22866, 27])\n",
      "Loss for Test set is 2.250943422317505\n"
     ]
    }
   ],
   "source": [
    "emb = C[Xdev]\n",
    "logits =(torch.tanh(emb.view(-1, context_shape) @ W1 + b1)) @ W2 + b2\n",
    "print(logits.shape)\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "\n",
    "print(f'Loss for Dev set is {loss.item()}')\n",
    "\n",
    "emb = C[Xte]\n",
    "logits = (torch.tanh(emb.view(-1, context_shape) @ W1 + b1)) @ W2 + b2\n",
    "print(logits.shape)\n",
    "loss = F.cross_entropy(logits, Yte)\n",
    "\n",
    "print(f'Loss for Test set is {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zamy.\n",
      "eederessaesorewtavie.\n",
      "katlyna.\n",
      "rondy.\n",
      "jemforianmaineslayarilian.\n",
      "heee.\n",
      "viton.\n",
      "maertothan.\n",
      "ell.\n",
      "anaaursi.\n",
      "elyn.\n",
      "pori.\n",
      "arnushn.\n",
      "kadamahyi.\n",
      "aetu.\n",
      "gzllian.\n",
      "byci.\n",
      "thya.\n",
      "jezre.\n",
      "saira.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "      logits = h @ W2 + b2\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 27])\n",
      "THe loss with equal probability distribution is loss=tensor(3.2958)\n"
     ]
    }
   ],
   "source": [
    "# Total Garbage\n",
    "p = torch.ones((Ytr.shape[0],27))\n",
    "print(p.shape)\n",
    "loss = F.cross_entropy(p, Ytr)\n",
    "\n",
    "print(f'THe loss with equal probability distribution is {loss=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No, I can't find anyway to optimize the neural network to get 1.0 of loss as value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
